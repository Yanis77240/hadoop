[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for org.apache.hadoop:hadoop-dist:jar:3.1.1-TDP-0.1.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.apache.maven.plugins:maven-gpg-plugin is missing. @ line 133, column 15
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Apache Hadoop Main                                                 [pom]
[INFO] Apache Hadoop Build Tools                                          [jar]
[INFO] Apache Hadoop Project POM                                          [pom]
[INFO] Apache Hadoop Annotations                                          [jar]
[INFO] Apache Hadoop Project Dist POM                                     [pom]
[INFO] Apache Hadoop Assemblies                                           [jar]
[INFO] Apache Hadoop Maven Plugins                               [maven-plugin]
[INFO] Apache Hadoop MiniKDC                                              [jar]
[INFO] Apache Hadoop Auth                                                 [jar]
[INFO] Apache Hadoop Auth Examples                                        [war]
[INFO] Apache Hadoop Common                                               [jar]
[INFO] Apache Hadoop NFS                                                  [jar]
[INFO] Apache Hadoop KMS                                                  [jar]
[INFO] Apache Hadoop Common Project                                       [pom]
[INFO] Apache Hadoop HDFS Client                                          [jar]
[INFO] Apache Hadoop HDFS                                                 [jar]
[INFO] Apache Hadoop HDFS Native Client                                   [jar]
[INFO] Apache Hadoop HttpFS                                               [jar]
[INFO] Apache Hadoop HDFS-NFS                                             [jar]
[INFO] Apache Hadoop HDFS-RBF                                             [jar]
[INFO] Apache Hadoop HDFS Project                                         [pom]
[INFO] Apache Hadoop YARN                                                 [pom]
[INFO] Apache Hadoop YARN API                                             [jar]
[INFO] Apache Hadoop YARN Common                                          [jar]
[INFO] Apache Hadoop YARN Registry                                        [jar]
[INFO] Apache Hadoop YARN Server                                          [pom]
[INFO] Apache Hadoop YARN Server Common                                   [jar]
[INFO] Apache Hadoop YARN NodeManager                                     [jar]
[INFO] Apache Hadoop YARN Web Proxy                                       [jar]
[INFO] Apache Hadoop YARN ApplicationHistoryService                       [jar]
[INFO] Apache Hadoop YARN Timeline Service                                [jar]
[INFO] Apache Hadoop YARN ResourceManager                                 [jar]
[INFO] Apache Hadoop YARN Server Tests                                    [jar]
[INFO] Apache Hadoop YARN Client                                          [jar]
[INFO] Apache Hadoop YARN SharedCacheManager                              [jar]
[INFO] Apache Hadoop YARN Timeline Plugin Storage                         [jar]
[INFO] Apache Hadoop YARN TimelineService HBase Backend                   [pom]
[INFO] Apache Hadoop YARN TimelineService HBase Common                    [jar]
[INFO] Apache Hadoop YARN TimelineService HBase Client                    [jar]
[INFO] Apache Hadoop YARN TimelineService HBase Servers                   [pom]
[INFO] Apache Hadoop YARN TimelineService HBase Server 1.2                [jar]
[INFO] Apache Hadoop YARN TimelineService HBase tests                     [jar]
[INFO] Apache Hadoop YARN Router                                          [jar]
[INFO] Apache Hadoop YARN Applications                                    [pom]
[INFO] Apache Hadoop YARN DistributedShell                                [jar]
[INFO] Apache Hadoop YARN Unmanaged Am Launcher                           [jar]
[INFO] Apache Hadoop MapReduce Client                                     [pom]
[INFO] Apache Hadoop MapReduce Core                                       [jar]
[INFO] Apache Hadoop MapReduce Common                                     [jar]
[INFO] Apache Hadoop MapReduce Shuffle                                    [jar]
[INFO] Apache Hadoop MapReduce App                                        [jar]
[INFO] Apache Hadoop MapReduce HistoryServer                              [jar]
[INFO] Apache Hadoop MapReduce JobClient                                  [jar]
[INFO] Apache Hadoop Mini-Cluster                                         [jar]
[INFO] Apache Hadoop YARN Services                                        [pom]
[INFO] Apache Hadoop YARN Services Core                                   [jar]
[INFO] Apache Hadoop YARN Services API                                    [jar]
[INFO] Apache Hadoop YARN Site                                            [pom]
[INFO] Apache Hadoop YARN UI                                              [pom]
[INFO] Apache Hadoop YARN Project                                         [pom]
[INFO] Apache Hadoop MapReduce HistoryServer Plugins                      [jar]
[INFO] Apache Hadoop MapReduce NativeTask                                 [jar]
[INFO] Apache Hadoop MapReduce Uploader                                   [jar]
[INFO] Apache Hadoop MapReduce Examples                                   [jar]
[INFO] Apache Hadoop MapReduce                                            [pom]
[INFO] Apache Hadoop MapReduce Streaming                                  [jar]
[INFO] Apache Hadoop Distributed Copy                                     [jar]
[INFO] Apache Hadoop Archives                                             [jar]
[INFO] Apache Hadoop Archive Logs                                         [jar]
[INFO] Apache Hadoop Rumen                                                [jar]
[INFO] Apache Hadoop Gridmix                                              [jar]
[INFO] Apache Hadoop Data Join                                            [jar]
[INFO] Apache Hadoop Extras                                               [jar]
[INFO] Apache Hadoop Pipes                                                [pom]
[INFO] Apache Hadoop OpenStack support                                    [jar]
[INFO] Apache Hadoop Amazon Web Services support                          [jar]
[INFO] Apache Hadoop Kafka Library support                                [jar]
[INFO] Apache Hadoop Azure support                                        [jar]
[INFO] Apache Hadoop Aliyun OSS support                                   [jar]
[INFO] Apache Hadoop Client Aggregator                                    [jar]
[INFO] Apache Hadoop Scheduler Load Simulator                             [jar]
[INFO] Apache Hadoop Resource Estimator Service                           [jar]
[INFO] Apache Hadoop Azure Data Lake support                              [jar]
[INFO] Apache Hadoop Image Generation Tool                                [jar]
[INFO] Apache Hadoop Tools Dist                                           [jar]
[INFO] Apache Hadoop Tools                                                [pom]
[INFO] Apache Hadoop Client API                                           [jar]
[INFO] Apache Hadoop Client Runtime                                       [jar]
[INFO] Apache Hadoop Client Packaging Invariants                          [pom]
[INFO] Apache Hadoop Client Test Minicluster                              [jar]
[INFO] Apache Hadoop Client Packaging Invariants for Test                 [pom]
[INFO] Apache Hadoop Client Packaging Integration Tests                   [jar]
[INFO] Apache Hadoop Distribution                                         [jar]
[INFO] Apache Hadoop Client Modules                                       [pom]
[INFO] Apache Hadoop Cloud Storage                                        [jar]
[INFO] Apache Hadoop Cloud Storage Project                                [pom]
[INFO] 
[INFO] -------------------< org.apache.hadoop:hadoop-main >--------------------
[INFO] Building Apache Hadoop Main 3.1.1-TDP-0.1.0-SNAPSHOT              [1/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-enforcer-plugin:3.0.0-M1:enforce (clean) @ hadoop-main ---
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-main ---
[INFO] 
[INFO] --- maven-enforcer-plugin:3.0.0-M1:enforce (default) @ hadoop-main ---
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-build-tools >----------------
[INFO] Building Apache Hadoop Build Tools 3.1.1-TDP-0.1.0-SNAPSHOT       [2/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-build-tools ---
[INFO] Deleting /tdp/hadoop/hadoop-build-tools/target
[INFO] 
[INFO] --- maven-resources-plugin:3.0.1:copy-resources (copy-resources) @ hadoop-build-tools ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (dummy) @ hadoop-build-tools ---
[INFO] No ant target defined - SKIPPED
[INFO] 
[INFO] --- maven-resources-plugin:3.0.1:resources (default-resources) @ hadoop-build-tools ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources to META-INF
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:bundle (default) @ hadoop-build-tools ---
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-build-tools ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:3.0.1:testResources (default-testResources) @ hadoop-build-tools ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-build-tools/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-build-tools ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ hadoop-build-tools ---
[INFO] No tests to run.
[INFO] 
[INFO] ------------------< org.apache.hadoop:hadoop-project >------------------
[INFO] Building Apache Hadoop Project POM 3.1.1-TDP-0.1.0-SNAPSHOT       [3/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-project ---
[INFO] Deleting /tdp/hadoop/hadoop-project/target
[INFO] Deleting /tdp/hadoop/hadoop-project (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-project ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-project/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-project ---
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-annotations >----------------
[INFO] Building Apache Hadoop Annotations 3.1.1-TDP-0.1.0-SNAPSHOT       [4/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-annotations ---
[INFO] Deleting /tdp/hadoop/hadoop-common-project/hadoop-annotations/target
[INFO] Deleting /tdp/hadoop/hadoop-common-project/hadoop-annotations (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-annotations ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-common-project/hadoop-annotations/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-annotations ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-annotations ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-common-project/hadoop-annotations/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-annotations ---
[INFO] Compiling 9 source files to /tdp/hadoop/hadoop-common-project/hadoop-annotations/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-annotations ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-common-project/hadoop-annotations/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-annotations ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-annotations ---
[INFO] 
[INFO] ---------------< org.apache.hadoop:hadoop-project-dist >----------------
[INFO] Building Apache Hadoop Project Dist POM 3.1.1-TDP-0.1.0-SNAPSHOT  [5/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-project-dist ---
[INFO] Deleting /tdp/hadoop/hadoop-project-dist/target
[INFO] Deleting /tdp/hadoop/hadoop-project-dist (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-project-dist ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-project-dist/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-project-dist/target/test/data
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-project-dist ---
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-assemblies >-----------------
[INFO] Building Apache Hadoop Assemblies 3.1.1-TDP-0.1.0-SNAPSHOT        [6/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-enforcer-plugin:3.0.0-M1:enforce (clean) @ hadoop-assemblies ---
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-assemblies ---
[INFO] Deleting /tdp/hadoop/hadoop-assemblies/target
[INFO] Deleting /tdp/hadoop/hadoop-assemblies (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-assemblies ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-assemblies/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-enforcer-plugin:3.0.0-M1:enforce (default) @ hadoop-assemblies ---
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-assemblies ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-assemblies ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 11 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-assemblies ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-assemblies ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-assemblies/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-assemblies ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-assemblies ---
[INFO] 
[INFO] ---------------< org.apache.hadoop:hadoop-maven-plugins >---------------
[INFO] Building Apache Hadoop Maven Plugins 3.1.1-TDP-0.1.0-SNAPSHOT     [7/96]
[INFO] ----------------------------[ maven-plugin ]----------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-maven-plugins ---
[INFO] Deleting /tdp/hadoop/hadoop-maven-plugins/target
[INFO] Deleting /tdp/hadoop/hadoop-maven-plugins (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-maven-plugins ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-maven-plugins/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-maven-plugins ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-maven-plugins ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-maven-plugins/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-maven-plugins ---
[INFO] Compiling 13 source files to /tdp/hadoop/hadoop-maven-plugins/target/classes
[WARNING] /tdp/hadoop/hadoop-maven-plugins/src/main/java/org/apache/hadoop/maven/plugin/resourcegz/ResourceGzMojo.java:[116,19] [deprecation] copy(Reader,OutputStream) in IOUtils has been deprecated
[INFO] 
[INFO] --- maven-plugin-plugin:3.4:descriptor (default-descriptor) @ hadoop-maven-plugins ---
[INFO] Using 'UTF-8' encoding to read mojo metadata.
[INFO] Mojo extractor with id: java-javadoc found 0 mojo descriptors.
[INFO] Mojo extractor with id: java-annotations found 7 mojo descriptors.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-maven-plugins ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-maven-plugins/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-maven-plugins ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-maven-plugins ---
[INFO] 
[INFO] ------------------< org.apache.hadoop:hadoop-minikdc >------------------
[INFO] Building Apache Hadoop MiniKDC 3.1.1-TDP-0.1.0-SNAPSHOT           [8/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-minikdc ---
[INFO] Deleting /tdp/hadoop/hadoop-common-project/hadoop-minikdc/target
[INFO] Deleting /tdp/hadoop/hadoop-common-project/hadoop-minikdc (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-minikdc ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-common-project/hadoop-minikdc/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-minikdc ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-minikdc ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-minikdc ---
[INFO] Compiling 2 source files to /tdp/hadoop/hadoop-common-project/hadoop-minikdc/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-minikdc ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-common-project/hadoop-minikdc/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-minikdc ---
[INFO] Compiling 2 source files to /tdp/hadoop/hadoop-common-project/hadoop-minikdc/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-minikdc ---
Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.21.0/surefire-junit4-2.21.0.pom
Progress (1): 1.4/3.1 kBProgress (1): 2.7/3.1 kBProgress (1): 3.1 kB                        Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.21.0/surefire-junit4-2.21.0.pom (3.1 kB at 11 kB/s)
Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.21.0/surefire-providers-2.21.0.pom
Progress (1): 1.4/2.5 kBProgress (1): 2.5 kB                        Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.21.0/surefire-providers-2.21.0.pom (2.5 kB at 79 kB/s)
Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.21.0/surefire-junit4-2.21.0.jar
Progress (1): 4.1/85 kBProgress (1): 8.2/85 kBProgress (1): 12/85 kB Progress (1): 16/85 kBProgress (1): 20/85 kBProgress (1): 25/85 kBProgress (1): 29/85 kBProgress (1): 33/85 kBProgress (1): 37/85 kBProgress (1): 41/85 kBProgress (1): 45/85 kBProgress (1): 49/85 kBProgress (1): 53/85 kBProgress (1): 57/85 kBProgress (1): 61/85 kBProgress (1): 66/85 kBProgress (1): 70/85 kBProgress (1): 74/85 kBProgress (1): 78/85 kBProgress (1): 82/85 kBProgress (1): 85 kB                      Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.21.0/surefire-junit4-2.21.0.jar (85 kB at 1.6 MB/s)
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.minikdc.TestChangeOrgNameAndDomain
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.413 s - in org.apache.hadoop.minikdc.TestChangeOrgNameAndDomain
[INFO] Running org.apache.hadoop.minikdc.TestMiniKdc
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.545 s - in org.apache.hadoop.minikdc.TestMiniKdc
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -------------------< org.apache.hadoop:hadoop-auth >--------------------
[INFO] Building Apache Hadoop Auth 3.1.1-TDP-0.1.0-SNAPSHOT              [9/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-auth ---
[INFO] Deleting /tdp/hadoop/hadoop-common-project/hadoop-auth/target
[INFO] Deleting /tdp/hadoop/hadoop-common-project/hadoop-auth (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-auth ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-common-project/hadoop-auth/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-auth ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-auth ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-common-project/hadoop-auth/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-auth ---
[INFO] Compiling 31 source files to /tdp/hadoop/hadoop-common-project/hadoop-auth/target/classes
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-auth/src/main/java/org/apache/hadoop/security/authentication/client/KerberosAuthenticator.java:[233,17] [unchecked] unchecked cast
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-auth ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-common-project/hadoop-auth/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-auth ---
[INFO] Compiling 27 source files to /tdp/hadoop/hadoop-common-project/hadoop-auth/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-auth ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.security.authentication.util.TestFileSignerSecretProvider
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.055 s - in org.apache.hadoop.security.authentication.util.TestFileSignerSecretProvider
[INFO] Running org.apache.hadoop.security.authentication.util.TestStringSignerSecretProvider
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.047 s - in org.apache.hadoop.security.authentication.util.TestStringSignerSecretProvider
[INFO] Running org.apache.hadoop.security.authentication.util.TestKerberosName
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.162 s - in org.apache.hadoop.security.authentication.util.TestKerberosName
[INFO] Running org.apache.hadoop.security.authentication.util.TestKerberosUtil
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.168 s - in org.apache.hadoop.security.authentication.util.TestKerberosUtil
[INFO] Running org.apache.hadoop.security.authentication.util.TestAuthToken
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.189 s - in org.apache.hadoop.security.authentication.util.TestAuthToken
[INFO] Running org.apache.hadoop.security.authentication.util.TestSigner
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.103 s - in org.apache.hadoop.security.authentication.util.TestSigner
[INFO] Running org.apache.hadoop.security.authentication.util.TestRandomSignerSecretProvider
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.336 s - in org.apache.hadoop.security.authentication.util.TestRandomSignerSecretProvider
[INFO] Running org.apache.hadoop.security.authentication.util.TestRolloverSignerSecretProvider
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 51.1 s - in org.apache.hadoop.security.authentication.util.TestRolloverSignerSecretProvider
[INFO] Running org.apache.hadoop.security.authentication.util.TestCertificateUtil
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.053 s - in org.apache.hadoop.security.authentication.util.TestCertificateUtil
[INFO] Running org.apache.hadoop.security.authentication.util.TestJaasConfiguration
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.036 s - in org.apache.hadoop.security.authentication.util.TestJaasConfiguration
[INFO] Running org.apache.hadoop.security.authentication.util.TestZKSignerSecretProvider
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.048 s - in org.apache.hadoop.security.authentication.util.TestZKSignerSecretProvider
[INFO] Running org.apache.hadoop.security.authentication.client.TestAuthenticatedURL
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.205 s - in org.apache.hadoop.security.authentication.client.TestAuthenticatedURL
[INFO] Running org.apache.hadoop.security.authentication.client.TestPseudoAuthenticator
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.38 s - in org.apache.hadoop.security.authentication.client.TestPseudoAuthenticator
[INFO] Running org.apache.hadoop.security.authentication.client.TestKerberosAuthenticator
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.082 s - in org.apache.hadoop.security.authentication.client.TestKerberosAuthenticator
[INFO] Running org.apache.hadoop.security.authentication.server.TestAltKerberosAuthenticationHandler
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.541 s - in org.apache.hadoop.security.authentication.server.TestAltKerberosAuthenticationHandler
[INFO] Running org.apache.hadoop.security.authentication.server.TestAuthenticationToken
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.042 s - in org.apache.hadoop.security.authentication.server.TestAuthenticationToken
[INFO] Running org.apache.hadoop.security.authentication.server.TestKerberosAuthenticationHandler
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.401 s - in org.apache.hadoop.security.authentication.server.TestKerberosAuthenticationHandler
[INFO] Running org.apache.hadoop.security.authentication.server.TestPseudoAuthenticationHandler
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.155 s - in org.apache.hadoop.security.authentication.server.TestPseudoAuthenticationHandler
[INFO] Running org.apache.hadoop.security.authentication.server.TestMultiSchemeAuthenticationHandler
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.191 s - in org.apache.hadoop.security.authentication.server.TestMultiSchemeAuthenticationHandler
[INFO] Running org.apache.hadoop.security.authentication.server.TestJWTRedirectAuthenticationHandler
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.064 s - in org.apache.hadoop.security.authentication.server.TestJWTRedirectAuthenticationHandler
[INFO] Running org.apache.hadoop.security.authentication.server.TestAuthenticationFilter
[INFO] Tests run: 26, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.38 s - in org.apache.hadoop.security.authentication.server.TestAuthenticationFilter
[INFO] Running org.apache.hadoop.security.authentication.server.TestLdapAuthenticationHandler
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.217 s - in org.apache.hadoop.security.authentication.server.TestLdapAuthenticationHandler
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 125, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ---------------< org.apache.hadoop:hadoop-auth-examples >---------------
[INFO] Building Apache Hadoop Auth Examples 3.1.1-TDP-0.1.0-SNAPSHOT    [10/96]
[INFO] --------------------------------[ war ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-auth-examples ---
[INFO] Deleting /tdp/hadoop/hadoop-common-project/hadoop-auth-examples/target
[INFO] Deleting /tdp/hadoop/hadoop-common-project/hadoop-auth-examples (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-auth-examples ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-common-project/hadoop-auth-examples/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-auth-examples ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-auth-examples ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-auth-examples ---
[INFO] Compiling 3 source files to /tdp/hadoop/hadoop-common-project/hadoop-auth-examples/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-auth-examples ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-common-project/hadoop-auth-examples/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-auth-examples ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-auth-examples ---
[INFO] 
[INFO] ------------------< org.apache.hadoop:hadoop-common >-------------------
[INFO] Building Apache Hadoop Common 3.1.1-TDP-0.1.0-SNAPSHOT           [11/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-common ---
[INFO] Deleting /tdp/hadoop/hadoop-common-project/hadoop-common/target
[INFO] Deleting /tdp/hadoop/hadoop-common-project/hadoop-common/src/site/markdown (includes = [UnixShellAPI.md], excludes = [])
[INFO] Deleting /tdp/hadoop/hadoop-common-project/hadoop-common/src/site/resources (includes = [configuration.xsl, core-default.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-common-project/hadoop-common/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-common-project/hadoop-common/target/test/data
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-enforcer-plugin:3.0.0-M1:enforce (enforce-os) @ hadoop-common ---
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:protoc (compile-protoc) @ hadoop-common ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-common-project/hadoop-common/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-common ---
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:version-info (version-info) @ hadoop-common ---
[INFO] SCM: GIT
[INFO] Computed MD5: 2cb970d52098bdb356706e1be71dbcf
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:resource-gz (resource-gz) @ hadoop-common ---
[INFO] Compressing /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/webapps/static/hadoop.css to /tdp/hadoop/hadoop-common-project/hadoop-common/target/webapps/static/hadoop.css.gz
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 10 resources
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-common ---
[INFO] Compiling 977 source files to /tdp/hadoop/hadoop-common-project/hadoop-common/target/classes
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java:[47,15] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/service/launcher/IrqHandler.java:[26,15] Signal is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/service/launcher/IrqHandler.java:[27,15] SignalHandler is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/curator/ChildReaper.java:[22,49] [deprecation] Reaper in org.apache.curator.framework.recipes.locks has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/FastByteComparisons.java:[27,15] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/ZKDelegationTokenSecretManager.java:[50,31] [deprecation] EnsurePath in org.apache.curator.utils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SecurityUtil.java:[56,18] ResolverConfiguration is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SecurityUtil.java:[57,19] IPAddressUtil is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/SignalLogger.java:[21,15] Signal is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/SignalLogger.java:[22,15] SignalHandler is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java:[3297,32] [unchecked] unchecked call to retainAll(Collection<?>) as a member of the raw type Set
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java:[3320,57] [unchecked] unchecked cast
[WARNING]   required: Class<? extends FileSystem>
  found:    Class<CAP#1>
  where CAP#1 is a fresh type-variable:
    CAP#1 extends Object from capture of ?
/tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java:[251,17] [deprecation] rename(Path,Path,Rename...) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java:[253,6] [deprecation] rename(Path,Path,Rename...) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java:[419,14] [deprecation] getDefaultBlockSize() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java:[420,13] [deprecation] getDefaultBlockSize() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java:[424,15] [deprecation] getDefaultReplication() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java:[425,13] [deprecation] getDefaultReplication() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java:[429,26] [deprecation] getServerDefaults() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java:[430,13] [deprecation] getServerDefaults() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java:[539,31] [deprecation] primitiveCreate(Path,FsPermission,EnumSet<CreateFlag>,int,short,long,Progressable,ChecksumOpt) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java:[544,13] [deprecation] primitiveCreate(Path,FsPermission,EnumSet<CreateFlag>,int,short,long,Progressable,ChecksumOpt) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java:[212,36] [deprecation] WritableRpcEngine in org.apache.hadoop.ipc has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java:[1226,19] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java:[2618,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java:[2620,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java:[332,38] DirectBuffer is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java:[333,16] Cleaner is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java:[334,24] DirectBuffer is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java:[718,16] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java:[720,6] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java:[720,23] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/DiskChecker.java:[299,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/Options.java:[149,43] [unchecked] Possible heap pollution from parameterized vararg type T
[WARNING] T...)
/tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/viewfs/NflyFSystem.java:[253,17] [deprecation] getStatistics(String,Class<? extends FileSystem>) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/SequenceFile.java:[1980,8] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/SequenceFile.java:[1980,29] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/CryptoStreamUtils.java:[39,36] DirectBuffer is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/CryptoStreamUtils.java:[40,20] Cleaner is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/CryptoStreamUtils.java:[41,22] DirectBuffer is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/viewfs/ViewFileSystem.java:[694,14] [deprecation] getDefaultBlockSize() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/viewfs/ViewFileSystem.java:[699,15] [deprecation] getDefaultReplication() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/viewfs/ViewFileSystem.java:[704,26] [deprecation] getServerDefaults() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/service/launcher/IrqHandler.java:[42,41] SignalHandler is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/service/launcher/IrqHandler.java:[71,10] Signal is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/service/launcher/IrqHandler.java:[92,19] Signal is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/service/launcher/IrqHandler.java:[93,6] Signal is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/service/launcher/IrqHandler.java:[113,4] Signal is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/service/launcher/IrqHandler.java:[126,21] Signal is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/MD5Hash.java:[144,18] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/MD5Hash.java:[148,31] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/ObjectWritable.java:[107,25] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/ObjectWritable.java:[119,6] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/ObjectWritable.java:[160,4] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/ObjectWritable.java:[174,6] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/ObjectWritable.java:[199,6] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/ObjectWritable.java:[201,6] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/ObjectWritable.java:[225,23] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/ObjectWritable.java:[274,17] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/ObjectWritable.java:[276,69] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/ObjectWritable.java:[281,19] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/LdapGroupsMapping.java:[545,27] LdapCtxFactory is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/StringUtils.java:[696,50] [deprecation] create(Log) in LogAdapter has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/ZKDelegationTokenSecretManager.java:[309,6] [deprecation] EnsurePath in org.apache.curator.utils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/ZKDelegationTokenSecretManager.java:[310,16] [deprecation] newNamespaceAwareEnsurePath(String) in CuratorFramework has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/ProviderUtils.java:[228,24] [deprecation] toString(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/kms/KMSClientProvider.java:[859,12] [unchecked] unchecked conversion
[WARNING]   required: List<Map>
  found:    List
/tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/SetFile.java:[80,6] [deprecation] Reader(FileSystem,String,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/curator/ChildReaper.java:[59,16] [deprecation] Reaper in org.apache.curator.framework.recipes.locks has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/curator/ChildReaper.java:[63,16] [deprecation] Reaper in org.apache.curator.framework.recipes.locks has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/curator/ChildReaper.java:[100,59] [deprecation] Reaper in org.apache.curator.framework.recipes.locks has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/curator/ChildReaper.java:[111,59] [deprecation] Reaper in org.apache.curator.framework.recipes.locks has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/curator/ChildReaper.java:[123,59] [deprecation] Reaper in org.apache.curator.framework.recipes.locks has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/curator/ChildReaper.java:[136,59] [deprecation] Reaper in org.apache.curator.framework.recipes.locks has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/curator/ChildReaper.java:[142,22] [deprecation] Reaper in org.apache.curator.framework.recipes.locks has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/WritableName.java:[42,25] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/FastByteComparisons.java:[135,19] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/FastByteComparisons.java:[141,21] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/FastByteComparisons.java:[146,28] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java:[243,21] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SecurityUtil.java:[589,8] ResolverConfiguration is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SecurityUtil.java:[607,10] IPAddressUtil is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SecurityUtil.java:[609,20] IPAddressUtil is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SecurityUtil.java:[611,17] IPAddressUtil is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SecurityUtil.java:[613,20] IPAddressUtil is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/ArrayWritable.java:[61,9] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/ArrayWritable.java:[63,22] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicyDefault.java:[312,10] [deprecation] rename(Path,Path,Rename...) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/permission/PermissionStatus.java:[105,14] [deprecation] write(DataOutput) in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/SignalLogger.java:[44,42] SignalHandler is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/SignalLogger.java:[46,18] SignalHandler is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/SignalLogger.java:[50,38] Signal is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/SignalLogger.java:[50,20] Signal is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/SignalLogger.java:[59,23] Signal is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/SignalLogger.java:[72,23] [deprecation] create(Log) in LogAdapter has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/KDiag.java:[927,32] [deprecation] readLines(InputStream) in IOUtils has been deprecated
[INFO] 
[INFO] --- native-maven-plugin:1.0-alpha-8:javah (default) @ hadoop-common ---
[INFO] /bin/sh -c cd /tdp/hadoop/hadoop-common-project/hadoop-common && /usr/lib/jvm/java-8-openjdk-amd64/bin/javah -d /tdp/hadoop/hadoop-common-project/hadoop-common/target/native/javah -classpath /tdp/hadoop/hadoop-common-project/hadoop-common/target/classes:/tdp/hadoop/hadoop-common-project/hadoop-annotations/target/classes:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/builder/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/builder/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/builder/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/builder/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/builder/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/builder/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/builder/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/builder/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/builder/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/builder/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-server/9.3.19.v20170502/jetty-server-9.3.19.v20170502.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-http/9.3.19.v20170502/jetty-http-9.3.19.v20170502.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-io/9.3.19.v20170502/jetty-io-9.3.19.v20170502.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-util/9.3.19.v20170502/jetty-util-9.3.19.v20170502.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.19.v20170502/jetty-servlet-9.3.19.v20170502.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-security/9.3.19.v20170502/jetty-security-9.3.19.v20170502.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.19.v20170502/jetty-webapp-9.3.19.v20170502.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.19.v20170502/jetty-xml-9.3.19.v20170502.jar:/home/builder/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/builder/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/builder/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/builder/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/builder/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/builder/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/builder/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/builder/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/builder/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/builder/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/builder/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/builder/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/builder/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/builder/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/builder/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/builder/.m2/repository/commons-beanutils/commons-beanutils/1.9.3/commons-beanutils-1.9.3.jar:/home/builder/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/builder/.m2/repository/org/apache/commons/commons-lang3/3.4/commons-lang3-3.4.jar:/home/builder/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/builder/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/builder/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/builder/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/builder/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/builder/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/builder/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/builder/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/tdp/hadoop/hadoop-common-project/hadoop-auth/target/classes:/home/builder/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/builder/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/builder/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/builder/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/builder/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/builder/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/builder/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/builder/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/builder/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/builder/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/builder/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/builder/.m2/repository/org/apache/zookeeper/zookeeper/3.4.9/zookeeper-3.4.9.jar:/home/builder/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/builder/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/builder/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/builder/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.7.8/jackson-databind-2.7.8.jar:/home/builder/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.7.8/jackson-annotations-2.7.8.jar:/home/builder/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.7.8/jackson-core-2.7.8.jar:/home/builder/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/builder/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar org.apache.hadoop.io.compress.zlib.ZlibCompressor org.apache.hadoop.io.compress.zlib.ZlibDecompressor org.apache.hadoop.io.compress.bzip2.Bzip2Compressor org.apache.hadoop.io.compress.bzip2.Bzip2Decompressor org.apache.hadoop.security.JniBasedUnixGroupsMapping org.apache.hadoop.io.nativeio.NativeIO org.apache.hadoop.io.nativeio.SharedFileDescriptorFactory org.apache.hadoop.security.JniBasedUnixGroupsNetgroupMapping org.apache.hadoop.io.compress.snappy.SnappyCompressor org.apache.hadoop.io.compress.snappy.SnappyDecompressor org.apache.hadoop.io.compress.zstd.ZStandardCompressor org.apache.hadoop.io.compress.zstd.ZStandardDecompressor org.apache.hadoop.io.compress.lz4.Lz4Compressor org.apache.hadoop.io.compress.lz4.Lz4Decompressor org.apache.hadoop.io.erasurecode.ErasureCodeNative org.apache.hadoop.io.erasurecode.rawcoder.NativeRSRawEncoder org.apache.hadoop.io.erasurecode.rawcoder.NativeRSRawDecoder org.apache.hadoop.io.erasurecode.rawcoder.NativeXORRawEncoder org.apache.hadoop.io.erasurecode.rawcoder.NativeXORRawDecoder org.apache.hadoop.crypto.OpensslCipher org.apache.hadoop.crypto.random.OpensslSecureRandom org.apache.hadoop.util.NativeCrc32 org.apache.hadoop.net.unix.DomainSocket org.apache.hadoop.net.unix.DomainSocketWatcher
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:cmake-compile (cmake-compile) @ hadoop-common ---
[INFO] Running cmake /tdp/hadoop/hadoop-common-project/hadoop-common/src -DGENERATED_JAVAH=/tdp/hadoop/hadoop-common-project/hadoop-common/target/native/javah -DJVM_ARCH_DATA_MODEL=64 -DREQUIRE_BZIP2=false -DREQUIRE_ISAL=false -DREQUIRE_OPENSSL=true -DREQUIRE_SNAPPY=true -DREQUIRE_ZSTD=true -G Unix Makefiles
[INFO] with extra environment variables {}
[INFO] Running make -j 8 VERBOSE=1
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/native/src/test/org/apache/hadoop/io/erasurecode/erasure_code_test.c: In function 'main':
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/native/src/test/org/apache/hadoop/io/erasurecode/erasure_code_test.c:116:7: warning: implicit declaration of function 'dumpDecoder'; did you mean 'initDecoder'? [-Wimplicit-function-declaration]
[WARNING]        dumpDecoder(pDecoder);
[WARNING]        ^~~~~~~~~~~
[WARNING]        initDecoder
[WARNING] CMakeFiles/hadoop.dir/main/native/src/exception.c.o: In function `terror':
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/native/src/exception.c:121: warning: `sys_errlist' is deprecated; use `strerror' or `strerror_r' instead
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/native/src/exception.c:118: warning: `sys_nerr' is deprecated; use `strerror' or `strerror_r' instead
[INFO] cmake compilation finished successfully in 4228 millisecond(s).
[INFO] 
[INFO] --- avro-maven-plugin:1.7.7:schema (generate-avro-test-sources) @ hadoop-common ---
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:test-protoc (compile-test-protoc) @ hadoop-common ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-common-project/hadoop-common/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:parallel-tests-createdir (parallel-tests-createdir) @ hadoop-common ---
[INFO] Creating /tdp/hadoop/hadoop-common-project/hadoop-common/target/test-dir/1
[INFO] Creating /tdp/hadoop/hadoop-common-project/hadoop-common/target/test-dir/2
[INFO] Creating /tdp/hadoop/hadoop-common-project/hadoop-common/target/test-dir/3
[INFO] Creating /tdp/hadoop/hadoop-common-project/hadoop-common/target/test-dir/4
[INFO] Creating /tdp/hadoop/hadoop-common-project/hadoop-common/target/tmp/1
[INFO] Creating /tdp/hadoop/hadoop-common-project/hadoop-common/target/tmp/2
[INFO] Creating /tdp/hadoop/hadoop-common-project/hadoop-common/target/tmp/3
[INFO] Creating /tdp/hadoop/hadoop-common-project/hadoop-common/target/tmp/4
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 33 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-log-dir) @ hadoop-common ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /tdp/hadoop/hadoop-common-project/hadoop-common/target/test/data
    [mkdir] Created dir: /tdp/hadoop/hadoop-common-project/hadoop-common/target/test/data
    [mkdir] Created dir: /tdp/hadoop/hadoop-common-project/hadoop-common/target/log
     [copy] Copying 8 files to /tdp/hadoop/hadoop-common-project/hadoop-common/target/test-classes
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-common ---
[INFO] Compiling 620 source files to /tdp/hadoop/hadoop-common-project/hadoop-common/target/test-classes
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/curator/TestChildReaper.java:[20,49] [deprecation] Reaper in org.apache.curator.framework.recipes.locks has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/ssl/KeyStoreTestUtil.java:[53,28] [deprecation] X509V1CertificateGenerator in org.bouncycastle.x509 has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestTextCommand.java:[127,11] [deprecation] copy(InputStream,Writer) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java:[116,26] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java:[117,32] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java:[121,26] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java:[122,32] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java:[131,26] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java:[132,32] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java:[144,26] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java:[145,32] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java:[148,26] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java:[149,32] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java:[169,26] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java:[170,32] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java:[178,26] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java:[179,32] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java:[286,26] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/contract/AbstractFSContractTestBase.java:[372,10] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextUtilBase.java:[53,22] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextPermissionBase.java:[66,22] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCodec.java:[573,45] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType,CompressionCodec) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCodec.java:[588,33] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java:[419,18] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestKDiag.java:[237,32] [deprecation] readLines(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java:[190,18] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java:[195,18] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java:[200,42] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java:[201,18] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java:[205,18] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java:[209,18] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/log/TestLogLevel.java:[81,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/log/TestLogLevel.java:[286,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestTrash.java:[918,16] [deprecation] initialize(Configuration,FileSystem,Path) in TrashPolicy has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/StatUtils.java:[107,23] [unchecked] unchecked call to ArrayList(Collection<? extends E>) as a member of the raw type ArrayList
[WARNING]   where E is a type-variable:
    E extends Object declared in class ArrayList
/tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/StatUtils.java:[107,23] [unchecked] unchecked conversion
[WARNING]   required: List<String>
  found:    ArrayList
/tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestListFiles.java:[38,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/LambdaTestUtils.java:[497,17] [unchecked] unchecked cast
[WARNING]   required: E
  found:    Throwable
  where E,T are type-variables:
    E extends Throwable declared in method <T,E>intercept(Class<E>,String,String,Callable<T>)
    T extends Object declared in method <T,E>intercept(Class<E>,String,String,Callable<T>)
/tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestApplicationClassLoader.java:[138,33] [deprecation] toString(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFilterFileSystem.java:[274,6] [deprecation] rename(Path,Path,Rename...) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFilterFileSystem.java:[275,18] [deprecation] rename(Path,Path,Rename...) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeqFileComparison.java:[268,24] [deprecation] createWriter(Configuration,FSDataOutputStream,Class,Class,CompressionType,CompressionCodec) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeqFileComparison.java:[273,24] [deprecation] createWriter(Configuration,FSDataOutputStream,Class,Class,CompressionType,CompressionCodec) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeqFileComparison.java:[300,15] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBloomMapFile.java:[176,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBloomMapFile.java:[205,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBloomMapFile.java:[240,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/curator/TestChildReaper.java:[87,48] [deprecation] Reaper in org.apache.curator.framework.recipes.locks has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/curator/TestChildReaper.java:[117,48] [deprecation] Reaper in org.apache.curator.framework.recipes.locks has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/curator/TestChildReaper.java:[149,49] [deprecation] Reaper in org.apache.curator.framework.recipes.locks has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/curator/TestChildReaper.java:[190,48] [deprecation] Reaper in org.apache.curator.framework.recipes.locks has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/net/unix/TestDomainSocket.java:[762,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java:[115,24] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java:[122,24] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java:[134,24] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java:[282,19] [deprecation] delete(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java:[283,45] [deprecation] delete(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java:[284,54] [deprecation] delete(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java:[290,38] [deprecation] getAllStatistics() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java:[308,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestIPC.java:[1404,23] [deprecation] getTimeout(Configuration) in Client has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewfsFileStatus.java:[84,8] [deprecation] write(DataOutput) in FileStatus has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewfsFileStatus.java:[88,9] [deprecation] readFields(DataInput) in FileStatus has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java:[192,11] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java:[231,22] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java:[235,22] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java:[256,13] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java:[279,20] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java:[279,39] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java:[296,41] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java:[322,20] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java:[332,18] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java:[445,18] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java:[505,18] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/sink/TestFileSink.java:[118,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestLdapGroupsMapping.java:[311,15] [deprecation] getPassword(Configuration,String,String) in LdapGroupsMapping has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestLdapGroupsMapping.java:[313,15] [deprecation] getPassword(Configuration,String,String) in LdapGroupsMapping has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestLdapGroupsMapping.java:[318,35] [deprecation] getPassword(Configuration,String,String) in LdapGroupsMapping has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileStatus.java:[75,8] [deprecation] write(DataOutput) in FileStatus has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileStatus.java:[87,10] [deprecation] readFields(DataInput) in FileStatus has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[251,14] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[253,16] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[266,14] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[268,16] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[282,14] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[284,16] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[290,14] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[292,16] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[308,14] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[310,16] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[315,14] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[317,16] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[342,14] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[344,16] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[353,14] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[355,16] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[457,14] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[816,14] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java:[818,16] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalDirAllocator.java:[511,23] [deprecation] removeContext(String) in LocalDirAllocator has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFileSerialization.java:[57,32] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFileSerialization.java:[65,20] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/web/TestWebDelegationToken.java:[361,10] [deprecation] setUseQueryStringForDelegationToken(boolean) in DelegationTokenAuthenticatedURL has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/web/TestWebDelegationToken.java:[556,36] [deprecation] readLines(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/web/TestWebDelegationToken.java:[626,36] [deprecation] readLines(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/web/TestWebDelegationToken.java:[852,32] [deprecation] readLines(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/web/TestWebDelegationToken.java:[859,19] [deprecation] readLines(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/web/TestWebDelegationToken.java:[876,36] [deprecation] readLines(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/web/TestWebDelegationToken.java:[896,23] [deprecation] readLines(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/web/TestWebDelegationToken.java:[957,36] [deprecation] readLines(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/web/TestWebDelegationToken.java:[966,23] [deprecation] readLines(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/web/TestWebDelegationToken.java:[1018,36] [deprecation] readLines(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestCredentials.java:[321,21] [unchecked] unchecked conversion
[WARNING] Text,Text)
/tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/serializer/avro/TestAvroSerialization.java:[36,10] [deprecation] intField in AvroRecord has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextCreateMkdirBaseTest.java:[60,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java:[106,17] [deprecation] addDeprecation(String,String[]) in Configuration has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java:[107,17] [deprecation] addDeprecation(String,String[]) in Configuration has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java:[108,17] [deprecation] addDeprecation(String,String[]) in Configuration has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java:[109,17] [deprecation] addDeprecation(String,String[]) in Configuration has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java:[110,17] [deprecation] addDeprecation(String,String[]) in Configuration has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java:[111,17] [deprecation] addDeprecation(String,String[]) in Configuration has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java:[112,17] [deprecation] addDeprecation(String,String[]) in Configuration has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java:[113,17] [deprecation] addDeprecation(String,String[]) in Configuration has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java:[275,17] [deprecation] addDeprecation(String,String[]) in Configuration has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java:[283,17] [deprecation] addDeprecation(String,String[]) in Configuration has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java:[291,17] [deprecation] addDeprecation(String,String[]) in Configuration has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java:[324,17] [deprecation] addDeprecation(String,String[]) in Configuration has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellReturnCode.java:[399,22] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellReturnCode.java:[401,22] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java:[190,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java:[214,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java:[236,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java:[268,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java:[295,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java:[322,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java:[350,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java:[395,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java:[413,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java:[454,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java:[485,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java:[610,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java:[639,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java:[660,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocatedFileStatus.java:[42,36] [deprecation] LocatedFileStatus(long,boolean,int,long,long,long,FsPermission,String,String,Path,Path,BlockLocation[]) in LocatedFileStatus has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocatedFileStatus.java:[48,39] [deprecation] LocatedFileStatus(long,boolean,int,long,long,long,FsPermission,String,String,Path,Path,BlockLocation[]) in LocatedFileStatus has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/AvroTestUtil.java:[44,23] [deprecation] parse(String) in Schema has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestDeprecatedKeys.java:[45,17] [deprecation] addDeprecation(String,String[]) in Configuration has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestDeprecatedKeys.java:[62,17] [deprecation] addDeprecation(String,String[]) in Configuration has been deprecated
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystemPermission.java:[51,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-common ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.conf.TestConfServlet
[INFO] Running org.apache.hadoop.conf.TestConfigRedactor
[INFO] Running org.apache.hadoop.conf.TestDeprecatedKeys
[INFO] Running org.apache.hadoop.conf.TestConfiguration
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.324 s - in org.apache.hadoop.conf.TestConfigRedactor
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.458 s - in org.apache.hadoop.conf.TestDeprecatedKeys
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.833 s - in org.apache.hadoop.conf.TestConfServlet
[INFO] Running org.apache.hadoop.conf.TestGetInstances
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.263 s - in org.apache.hadoop.conf.TestGetInstances
[INFO] Running org.apache.hadoop.conf.TestConfigurationSubclass
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.282 s - in org.apache.hadoop.conf.TestConfigurationSubclass
[INFO] Running org.apache.hadoop.conf.TestReconfiguration
[INFO] Running org.apache.hadoop.conf.TestCommonConfigurationFields
[INFO] Running org.apache.hadoop.conf.TestConfigurationDeprecation
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.457 s - in org.apache.hadoop.conf.TestCommonConfigurationFields
[INFO] Running org.apache.hadoop.conf.TestStorageUnit
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.211 s - in org.apache.hadoop.conf.TestStorageUnit
[INFO] Tests run: 82, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.866 s - in org.apache.hadoop.conf.TestConfiguration
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.917 s - in org.apache.hadoop.conf.TestReconfiguration
[INFO] Running org.apache.hadoop.metrics2.util.TestMetricsCache
[INFO] Running org.apache.hadoop.metrics2.util.TestSampleQuantiles
[INFO] Running org.apache.hadoop.metrics2.util.TestSampleStat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.181 s - in org.apache.hadoop.metrics2.util.TestSampleStat
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.959 s - in org.apache.hadoop.metrics2.util.TestSampleQuantiles
[INFO] Running org.apache.hadoop.metrics2.source.TestJvmMetrics
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.472 s - in org.apache.hadoop.metrics2.util.TestMetricsCache
[INFO] Running org.apache.hadoop.metrics2.impl.TestStatsDMetrics
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.48 s - in org.apache.hadoop.metrics2.impl.TestStatsDMetrics
[INFO] Running org.apache.hadoop.metrics2.impl.TestMetricsSystemImpl
[INFO] Running org.apache.hadoop.metrics2.impl.TestMetricsConfig
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.275 s - in org.apache.hadoop.metrics2.source.TestJvmMetrics
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.546 s - in org.apache.hadoop.metrics2.impl.TestMetricsConfig
[INFO] Running org.apache.hadoop.metrics2.impl.TestGraphiteMetrics
[INFO] Running org.apache.hadoop.metrics2.impl.TestMetricsVisitor
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.321 s - in org.apache.hadoop.metrics2.impl.TestGraphiteMetrics
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.242 s - in org.apache.hadoop.metrics2.impl.TestMetricsVisitor
[INFO] Running org.apache.hadoop.metrics2.impl.TestMetricsSourceAdapter
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.57 s - in org.apache.hadoop.conf.TestConfigurationDeprecation
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.473 s - in org.apache.hadoop.metrics2.impl.TestMetricsSystemImpl
[INFO] Running org.apache.hadoop.metrics2.impl.TestGangliaMetrics
[INFO] Running org.apache.hadoop.metrics2.impl.TestSinkQueue
[INFO] Running org.apache.hadoop.metrics2.impl.TestMetricsCollectorImpl
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.463 s - in org.apache.hadoop.metrics2.impl.TestGangliaMetrics
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.346 s - in org.apache.hadoop.metrics2.impl.TestSinkQueue
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.166 s - in org.apache.hadoop.metrics2.impl.TestMetricsCollectorImpl
[INFO] Running org.apache.hadoop.metrics2.filter.TestPatternFilter
[INFO] Running org.apache.hadoop.metrics2.lib.TestMetricsRegistry
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.242 s - in org.apache.hadoop.metrics2.lib.TestMetricsRegistry
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.333 s - in org.apache.hadoop.metrics2.filter.TestPatternFilter
[INFO] Running org.apache.hadoop.metrics2.lib.TestMetricsAnnotations
[INFO] Running org.apache.hadoop.metrics2.lib.TestInterns
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.282 s - in org.apache.hadoop.metrics2.lib.TestMetricsAnnotations
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.116 s - in org.apache.hadoop.metrics2.lib.TestInterns
[INFO] Running org.apache.hadoop.metrics2.lib.TestUniqNames
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.051 s - in org.apache.hadoop.metrics2.lib.TestUniqNames
[INFO] Running org.apache.hadoop.metrics2.lib.TestMutableRollingAverages
[INFO] Running org.apache.hadoop.metrics2.lib.TestMutableMetrics
[INFO] Running org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.359 s - in org.apache.hadoop.metrics2.impl.TestMetricsSourceAdapter
[INFO] Running org.apache.hadoop.metrics2.sink.ganglia.TestGangliaSink
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.154 s - in org.apache.hadoop.metrics2.sink.ganglia.TestGangliaSink
[INFO] Running org.apache.hadoop.metrics2.sink.TestRollingFileSystemSink
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.368 s - in org.apache.hadoop.metrics2.sink.TestRollingFileSystemSink
[INFO] Running org.apache.hadoop.metrics2.sink.TestFileSink
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.375 s - in org.apache.hadoop.metrics2.sink.TestFileSink
[INFO] Running org.apache.hadoop.util.TestClasspath
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.161 s - in org.apache.hadoop.util.TestClasspath
[INFO] Running org.apache.hadoop.util.TestFileBasedIPList
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.103 s - in org.apache.hadoop.util.TestFileBasedIPList
[INFO] Running org.apache.hadoop.util.TestSysInfoLinux
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.122 s - in org.apache.hadoop.util.TestSysInfoLinux
[INFO] Running org.apache.hadoop.util.TestJarFinder
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.723 s - in org.apache.hadoop.util.TestJarFinder
[INFO] Running org.apache.hadoop.util.TestLineReader
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.12 s - in org.apache.hadoop.util.TestLineReader
[INFO] Running org.apache.hadoop.util.TestHostsFileReader
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.127 s - in org.apache.hadoop.util.TestHostsFileReader
[INFO] Running org.apache.hadoop.util.TestDiskCheckerWithDiskIo
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.175 s - in org.apache.hadoop.util.TestDiskCheckerWithDiskIo
[INFO] Running org.apache.hadoop.util.TestStopWatch
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.047 s - in org.apache.hadoop.util.TestStopWatch
[INFO] Running org.apache.hadoop.util.TestRunJar
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.48 s - in org.apache.hadoop.util.TestRunJar
[INFO] Running org.apache.hadoop.util.TestLightWeightCache
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.765 s - in org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal
[INFO] Running org.apache.hadoop.util.TestShell
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.285 s - in org.apache.hadoop.metrics2.lib.TestMutableRollingAverages
[INFO] Running org.apache.hadoop.util.TestFastNumberFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.046 s - in org.apache.hadoop.util.TestFastNumberFormat
[INFO] Running org.apache.hadoop.util.TestApplicationClassLoader
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.358 s - in org.apache.hadoop.util.TestApplicationClassLoader
[INFO] Running org.apache.hadoop.util.TestAutoCloseableLock
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.046 s - in org.apache.hadoop.util.TestAutoCloseableLock
[INFO] Running org.apache.hadoop.util.TestShutdownHookManager
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.117 s - in org.apache.hadoop.util.TestShutdownHookManager
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.118 s - in org.apache.hadoop.util.TestLightWeightCache
[INFO] Running org.apache.hadoop.util.curator.TestChildReaper
[INFO] Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.236 s - in org.apache.hadoop.util.TestShell
[INFO] Running org.apache.hadoop.util.curator.TestZKCuratorManager
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.373 s - in org.apache.hadoop.metrics2.lib.TestMutableMetrics
[INFO] Running org.apache.hadoop.util.TestReadWriteDiskValidator
[INFO] Running org.apache.hadoop.util.TestNativeCodeLoader
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.136 s - in org.apache.hadoop.util.TestNativeCodeLoader
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.694 s - in org.apache.hadoop.util.curator.TestZKCuratorManager
[ERROR] Tests run: 8, Failures: 0, Errors: 8, Skipped: 0, Time elapsed: 0.217 s <<< FAILURE! - in org.apache.hadoop.util.TestReadWriteDiskValidator
[ERROR] testReadWriteDiskValidator(org.apache.hadoop.util.TestReadWriteDiskValidator)  Time elapsed: 0.125 s  <<< ERROR!
org.apache.hadoop.util.DiskChecker$DiskErrorException: Disk Check failed!
	at org.apache.hadoop.util.ReadWriteDiskValidator.checkStatus(ReadWriteDiskValidator.java:82)
	at org.apache.hadoop.util.TestReadWriteDiskValidator.testReadWriteDiskValidator(TestReadWriteDiskValidator.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: org.apache.hadoop.util.DiskChecker$DiskErrorException: /tdp/hadoop/hadoop-common-project/hadoop-common/target/test/data/4 is not a directory!
	at org.apache.hadoop.util.ReadWriteDiskValidator.checkStatus(ReadWriteDiskValidator.java:50)
	... 27 more

[ERROR] testCheckFailures(org.apache.hadoop.util.TestReadWriteDiskValidator)  Time elapsed: 0.027 s  <<< ERROR!
java.nio.file.NoSuchFileException: /tdp/hadoop/hadoop-common-project/hadoop-common/target/test/data/4/test1076750546574442110
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.TempFileHelper.create(TempFileHelper.java:136)
	at java.nio.file.TempFileHelper.createTempDirectory(TempFileHelper.java:173)
	at java.nio.file.Files.createTempDirectory(Files.java:950)
	at org.apache.hadoop.util.TestReadWriteDiskValidator.testCheckFailures(TestReadWriteDiskValidator.java:114)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[ERROR] testReadWriteDiskValidator(org.apache.hadoop.util.TestReadWriteDiskValidator)  Time elapsed: 0.001 s  <<< ERROR!
org.apache.hadoop.util.DiskChecker$DiskErrorException: Disk Check failed!
	at org.apache.hadoop.util.ReadWriteDiskValidator.checkStatus(ReadWriteDiskValidator.java:82)
	at org.apache.hadoop.util.TestReadWriteDiskValidator.testReadWriteDiskValidator(TestReadWriteDiskValidator.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: org.apache.hadoop.util.DiskChecker$DiskErrorException: /tdp/hadoop/hadoop-common-project/hadoop-common/target/test/data/4 is not a directory!
	at org.apache.hadoop.util.ReadWriteDiskValidator.checkStatus(ReadWriteDiskValidator.java:50)
	... 27 more

[ERROR] testCheckFailures(org.apache.hadoop.util.TestReadWriteDiskValidator)  Time elapsed: 0.001 s  <<< ERROR!
java.nio.file.NoSuchFileException: /tdp/hadoop/hadoop-common-project/hadoop-common/target/test/data/4/test5917992933766711100
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.TempFileHelper.create(TempFileHelper.java:136)
	at java.nio.file.TempFileHelper.createTempDirectory(TempFileHelper.java:173)
	at java.nio.file.Files.createTempDirectory(Files.java:950)
	at org.apache.hadoop.util.TestReadWriteDiskValidator.testCheckFailures(TestReadWriteDiskValidator.java:114)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[ERROR] testReadWriteDiskValidator(org.apache.hadoop.util.TestReadWriteDiskValidator)  Time elapsed: 0.001 s  <<< ERROR!
org.apache.hadoop.util.DiskChecker$DiskErrorException: Disk Check failed!
	at org.apache.hadoop.util.ReadWriteDiskValidator.checkStatus(ReadWriteDiskValidator.java:82)
	at org.apache.hadoop.util.TestReadWriteDiskValidator.testReadWriteDiskValidator(TestReadWriteDiskValidator.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: org.apache.hadoop.util.DiskChecker$DiskErrorException: /tdp/hadoop/hadoop-common-project/hadoop-common/target/test/data/4 is not a directory!
	at org.apache.hadoop.util.ReadWriteDiskValidator.checkStatus(ReadWriteDiskValidator.java:50)
	... 27 more

[ERROR] testCheckFailures(org.apache.hadoop.util.TestReadWriteDiskValidator)  Time elapsed: 0.002 s  <<< ERROR!
java.nio.file.NoSuchFileException: /tdp/hadoop/hadoop-common-project/hadoop-common/target/test/data/4/test1490099146374853296
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.TempFileHelper.create(TempFileHelper.java:136)
	at java.nio.file.TempFileHelper.createTempDirectory(TempFileHelper.java:173)
	at java.nio.file.Files.createTempDirectory(Files.java:950)
	at org.apache.hadoop.util.TestReadWriteDiskValidator.testCheckFailures(TestReadWriteDiskValidator.java:114)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[ERROR] testReadWriteDiskValidator(org.apache.hadoop.util.TestReadWriteDiskValidator)  Time elapsed: 0.002 s  <<< ERROR!
org.apache.hadoop.util.DiskChecker$DiskErrorException: Disk Check failed!
	at org.apache.hadoop.util.ReadWriteDiskValidator.checkStatus(ReadWriteDiskValidator.java:82)
	at org.apache.hadoop.util.TestReadWriteDiskValidator.testReadWriteDiskValidator(TestReadWriteDiskValidator.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: org.apache.hadoop.util.DiskChecker$DiskErrorException: /tdp/hadoop/hadoop-common-project/hadoop-common/target/test/data/4 is not a directory!
	at org.apache.hadoop.util.ReadWriteDiskValidator.checkStatus(ReadWriteDiskValidator.java:50)
	... 27 more

[ERROR] testCheckFailures(org.apache.hadoop.util.TestReadWriteDiskValidator)  Time elapsed: 0.001 s  <<< ERROR!
java.nio.file.NoSuchFileException: /tdp/hadoop/hadoop-common-project/hadoop-common/target/test/data/4/test8378549729384737651
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:384)
	at java.nio.file.Files.createDirectory(Files.java:674)
	at java.nio.file.TempFileHelper.create(TempFileHelper.java:136)
	at java.nio.file.TempFileHelper.createTempDirectory(TempFileHelper.java:173)
	at java.nio.file.Files.createTempDirectory(Files.java:950)
	at org.apache.hadoop.util.TestReadWriteDiskValidator.testCheckFailures(TestReadWriteDiskValidator.java:114)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[INFO] Running org.apache.hadoop.util.TestCacheableIPList
[INFO] Running org.apache.hadoop.util.TestIdentityHashStore
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.151 s - in org.apache.hadoop.util.TestIdentityHashStore
[INFO] Running org.apache.hadoop.util.TestGSet
[INFO] Running org.apache.hadoop.util.TestZKUtil
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.1 s - in org.apache.hadoop.util.TestZKUtil
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.252 s - in org.apache.hadoop.util.TestCacheableIPList
[INFO] Running org.apache.hadoop.util.TestSignalLogger
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.121 s - in org.apache.hadoop.util.TestSignalLogger
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.434 s - in org.apache.hadoop.util.TestGSet
[INFO] Running org.apache.hadoop.util.TestWinUtils
[WARNING] Tests run: 11, Failures: 0, Errors: 0, Skipped: 11, Time elapsed: 0.144 s - in org.apache.hadoop.util.TestWinUtils
[INFO] Running org.apache.hadoop.util.TestGenericOptionsParser
[INFO] Running org.apache.hadoop.util.TestAsyncDiskService
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.131 s - in org.apache.hadoop.util.TestAsyncDiskService
[INFO] Running org.apache.hadoop.util.TestBasicDiskValidator
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.617 s - in org.apache.hadoop.util.TestGenericOptionsParser
[INFO] Running org.apache.hadoop.util.TestFindClass
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.392 s - in org.apache.hadoop.util.TestFindClass
[INFO] Running org.apache.hadoop.util.TestTime
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.754 s - in org.apache.hadoop.util.TestBasicDiskValidator
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.071 s - in org.apache.hadoop.util.TestTime
[INFO] Running org.apache.hadoop.util.hash.TestHash
[INFO] Running org.apache.hadoop.util.TestClassUtil
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.058 s - in org.apache.hadoop.util.TestClassUtil
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.236 s - in org.apache.hadoop.util.hash.TestHash
[INFO] Running org.apache.hadoop.util.TestNodeHealthScriptRunner
[INFO] Running org.apache.hadoop.util.TestChunkedArrayList
[INFO] Running org.apache.hadoop.util.TestDataChecksum
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.553 s - in org.apache.hadoop.util.TestChunkedArrayList
[INFO] Running org.apache.hadoop.util.TestDiskChecker
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.644 s - in org.apache.hadoop.util.TestDiskChecker
[INFO] Running org.apache.hadoop.util.TestSysInfoWindows
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.121 s - in org.apache.hadoop.util.TestSysInfoWindows
[INFO] Running org.apache.hadoop.util.TestOptions
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.06 s - in org.apache.hadoop.util.TestOptions
[INFO] Running org.apache.hadoop.util.TestStringUtils
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.216 s - in org.apache.hadoop.util.TestStringUtils
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.491 s - in org.apache.hadoop.util.TestNodeHealthScriptRunner
[INFO] Running org.apache.hadoop.util.TestInstrumentedLock
[INFO] Running org.apache.hadoop.util.TestNativeLibraryChecker
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.222 s - in org.apache.hadoop.util.TestInstrumentedLock
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.243 s - in org.apache.hadoop.util.TestNativeLibraryChecker
[INFO] Running org.apache.hadoop.util.TestIndexedSort
[INFO] Running org.apache.hadoop.util.TestLightWeightGSet
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.185 s - in org.apache.hadoop.util.TestLightWeightGSet
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.794 s - in org.apache.hadoop.util.TestIndexedSort
[INFO] Running org.apache.hadoop.util.TestInstrumentedReadWriteLock
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.141 s - in org.apache.hadoop.util.TestInstrumentedReadWriteLock
[INFO] Running org.apache.hadoop.util.TestCrcComposer
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.165 s - in org.apache.hadoop.util.TestCrcComposer
[INFO] Running org.apache.hadoop.util.TestNativeCrc32
[INFO] Running org.apache.hadoop.util.TestMachineList
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.453 s - in org.apache.hadoop.util.TestNativeCrc32
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.338 s - in org.apache.hadoop.util.TestMachineList
[INFO] Running org.apache.hadoop.util.TestDiskValidatorFactory
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.078 s - in org.apache.hadoop.util.TestDiskValidatorFactory
[INFO] Running org.apache.hadoop.util.TestReflectionUtils
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.371 s - in org.apache.hadoop.util.TestReflectionUtils
[INFO] Running org.apache.hadoop.util.TestLightWeightResizableGSet
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.326 s - in org.apache.hadoop.util.TestLightWeightResizableGSet
[INFO] Running org.apache.hadoop.util.TestPureJavaCrc32
[INFO] Running org.apache.hadoop.util.bloom.TestBloomFilters
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.399 s - in org.apache.hadoop.util.TestPureJavaCrc32
[INFO] Running org.apache.hadoop.util.TestJsonSerialization
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.834 s - in org.apache.hadoop.util.TestJsonSerialization
[INFO] Running org.apache.hadoop.util.TestProgress
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.131 s - in org.apache.hadoop.util.TestProgress
[INFO] Running org.apache.hadoop.util.TestConfTest
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.233 s - in org.apache.hadoop.util.TestConfTest
[INFO] Running org.apache.hadoop.util.TestDirectBufferPool
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.152 s - in org.apache.hadoop.util.TestDirectBufferPool
[INFO] Running org.apache.hadoop.util.TestCrcUtil
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.216 s - in org.apache.hadoop.util.TestCrcUtil
[INFO] Running org.apache.hadoop.util.TestCpuTimeTracker
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.082 s - in org.apache.hadoop.util.TestCpuTimeTracker
[INFO] Running org.apache.hadoop.util.TestProtoUtil
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.135 s - in org.apache.hadoop.util.TestProtoUtil
[INFO] Running org.apache.hadoop.util.TestStringInterner
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.059 s - in org.apache.hadoop.util.TestStringInterner
[INFO] Running org.apache.hadoop.util.TestHttpExceptionUtils
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.53 s - in org.apache.hadoop.util.TestHttpExceptionUtils
[INFO] Running org.apache.hadoop.util.TestVersionUtil
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.142 s - in org.apache.hadoop.util.TestVersionUtil
[INFO] Running org.apache.hadoop.util.TestShutdownThreadsHelper
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.856 s - in org.apache.hadoop.util.bloom.TestBloomFilters
[INFO] Running org.apache.hadoop.util.TestGenericsUtil
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.235 s - in org.apache.hadoop.util.TestGenericsUtil
[INFO] Running org.apache.hadoop.ha.TestSshFenceByTcpPort
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.148 s - in org.apache.hadoop.util.TestShutdownThreadsHelper
[INFO] Running org.apache.hadoop.ha.TestShellCommandFencer
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.546 s - in org.apache.hadoop.ha.TestShellCommandFencer
[INFO] Running org.apache.hadoop.ha.TestFailoverController
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.609 s - in org.apache.hadoop.ha.TestFailoverController
[INFO] Running org.apache.hadoop.ha.TestNodeFencer
[WARNING] Tests run: 4, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 3.471 s - in org.apache.hadoop.ha.TestSshFenceByTcpPort
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.537 s - in org.apache.hadoop.ha.TestNodeFencer
[INFO] Running org.apache.hadoop.ha.TestZKFailoverControllerStress
[INFO] Running org.apache.hadoop.ha.TestZKFailoverController
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.221 s - in org.apache.hadoop.util.TestDataChecksum
[INFO] Running org.apache.hadoop.ha.TestActiveStandbyElector
[INFO] Tests run: 24, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.368 s - in org.apache.hadoop.ha.TestActiveStandbyElector
[INFO] Running org.apache.hadoop.ha.TestActiveStandbyElectorRealZK
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 52.741 s - in org.apache.hadoop.util.curator.TestChildReaper
[INFO] Running org.apache.hadoop.ha.TestHAAdmin
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.205 s - in org.apache.hadoop.ha.TestHAAdmin
[INFO] Running org.apache.hadoop.ha.TestHealthMonitorWithDedicatedHealthAddress
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.006 s - in org.apache.hadoop.ha.TestActiveStandbyElectorRealZK
[INFO] Running org.apache.hadoop.ha.TestHealthMonitor
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.265 s - in org.apache.hadoop.ha.TestHealthMonitorWithDedicatedHealthAddress
[INFO] Running org.apache.hadoop.io.TestVersionedWritable
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.096 s - in org.apache.hadoop.io.TestVersionedWritable
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.288 s - in org.apache.hadoop.ha.TestHealthMonitor
[INFO] Running org.apache.hadoop.io.erasurecode.TestECSchema
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.059 s - in org.apache.hadoop.io.erasurecode.TestECSchema
[INFO] Running org.apache.hadoop.io.erasurecode.codec.TestHHXORErasureCodec
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.138 s - in org.apache.hadoop.io.erasurecode.codec.TestHHXORErasureCodec
[INFO] Running org.apache.hadoop.io.erasurecode.rawcoder.TestXORRawCoderInteroperable2
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.175 s - in org.apache.hadoop.io.erasurecode.rawcoder.TestXORRawCoderInteroperable2
[INFO] Running org.apache.hadoop.io.erasurecode.rawcoder.TestDummyRawCoder
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.125 s - in org.apache.hadoop.io.erasurecode.rawcoder.TestDummyRawCoder
[INFO] Running org.apache.hadoop.io.erasurecode.rawcoder.TestRSRawCoderInteroperable1
[INFO] Running org.apache.hadoop.io.erasurecode.rawcoder.TestRSRawCoderInteroperable2
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.517 s - in org.apache.hadoop.io.erasurecode.rawcoder.TestRSRawCoderInteroperable1
[WARNING] Corrupted STDOUT by directly writing to native stream in forked JVM 4. See FAQ web page and the dump file /tdp/hadoop/hadoop-common-project/hadoop-common/target/surefire-reports/2023-08-16T17-56-12_178-jvmRun4.dumpstream
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.346 s - in org.apache.hadoop.io.erasurecode.rawcoder.TestRSRawCoderInteroperable2
[INFO] Running org.apache.hadoop.io.erasurecode.rawcoder.TestNativeRSRawCoder
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.293 s - in org.apache.hadoop.io.erasurecode.rawcoder.TestNativeRSRawCoder
[INFO] Running org.apache.hadoop.io.erasurecode.rawcoder.TestCoderUtil
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.054 s - in org.apache.hadoop.io.erasurecode.rawcoder.TestCoderUtil
[INFO] Running org.apache.hadoop.io.erasurecode.rawcoder.TestRSRawCoder
[INFO] Running org.apache.hadoop.io.erasurecode.rawcoder.TestNativeXORRawCoder
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.171 s - in org.apache.hadoop.io.erasurecode.rawcoder.TestNativeXORRawCoder
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.42 s - in org.apache.hadoop.io.erasurecode.rawcoder.TestRSRawCoder
[INFO] Running org.apache.hadoop.io.erasurecode.rawcoder.TestXORRawCoder
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.207 s - in org.apache.hadoop.io.erasurecode.rawcoder.TestXORRawCoder
[INFO] Running org.apache.hadoop.io.erasurecode.rawcoder.TestRawErasureCoderBenchmark
[INFO] Running org.apache.hadoop.io.erasurecode.rawcoder.TestRSLegacyRawCoder
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.279 s - in org.apache.hadoop.io.erasurecode.rawcoder.TestRSLegacyRawCoder
[INFO] Running org.apache.hadoop.io.erasurecode.rawcoder.TestXORRawCoderInteroperable1
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.202 s - in org.apache.hadoop.io.erasurecode.rawcoder.TestXORRawCoderInteroperable1
[INFO] Running org.apache.hadoop.io.erasurecode.TestCodecRawCoderMapping
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.319 s - in org.apache.hadoop.io.erasurecode.TestCodecRawCoderMapping
[INFO] Running org.apache.hadoop.io.erasurecode.TestCodecRegistry
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.134 s - in org.apache.hadoop.io.erasurecode.TestCodecRegistry
[INFO] Running org.apache.hadoop.io.erasurecode.coder.TestHHXORErasureCoder
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.903 s - in org.apache.hadoop.io.erasurecode.coder.TestHHXORErasureCoder
[INFO] Running org.apache.hadoop.io.erasurecode.coder.TestXORCoder
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.373 s - in org.apache.hadoop.io.erasurecode.coder.TestXORCoder
[INFO] Running org.apache.hadoop.io.erasurecode.coder.TestRSErasureCoder
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.765 s - in org.apache.hadoop.io.erasurecode.coder.TestRSErasureCoder
[INFO] Running org.apache.hadoop.io.TestText
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.602 s - in org.apache.hadoop.io.TestText
[INFO] Running org.apache.hadoop.io.TestSetFile
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.258 s - in org.apache.hadoop.io.TestSetFile
[INFO] Running org.apache.hadoop.io.TestSortedMapWritable
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.119 s - in org.apache.hadoop.io.TestSortedMapWritable
[INFO] Running org.apache.hadoop.io.retry.TestDefaultRetryPolicy
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.193 s - in org.apache.hadoop.io.retry.TestDefaultRetryPolicy
[INFO] Running org.apache.hadoop.io.retry.TestConnectionRetryPolicy
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.267 s - in org.apache.hadoop.io.retry.TestConnectionRetryPolicy
[INFO] Running org.apache.hadoop.io.retry.TestRetryProxy
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.269 s - in org.apache.hadoop.io.retry.TestRetryProxy
[INFO] Running org.apache.hadoop.io.retry.TestFailoverProxy
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.328 s - in org.apache.hadoop.io.erasurecode.rawcoder.TestRawErasureCoderBenchmark
[INFO] Running org.apache.hadoop.io.serializer.avro.TestAvroSerialization
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.349 s - in org.apache.hadoop.io.serializer.avro.TestAvroSerialization
[INFO] Running org.apache.hadoop.io.serializer.TestWritableSerialization
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.207 s - in org.apache.hadoop.io.serializer.TestWritableSerialization
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.964 s - in org.apache.hadoop.ha.TestZKFailoverController
[INFO] Running org.apache.hadoop.io.serializer.TestSerializationFactory
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.236 s - in org.apache.hadoop.io.serializer.TestSerializationFactory
[INFO] Running org.apache.hadoop.io.TestEnumSetWritable
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.274 s - in org.apache.hadoop.io.TestEnumSetWritable
[INFO] Running org.apache.hadoop.io.TestSecureIOUtils
[INFO] Running org.apache.hadoop.io.compress.TestCompressionStreamReuse
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.357 s - in org.apache.hadoop.io.TestSecureIOUtils
[INFO] Running org.apache.hadoop.io.compress.TestGzipCodec
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.155 s - in org.apache.hadoop.io.compress.TestGzipCodec
[INFO] Running org.apache.hadoop.io.compress.TestCompressorDecompressor
[ERROR] Tests run: 8, Failures: 8, Errors: 0, Skipped: 0, Time elapsed: 0.185 s <<< FAILURE! - in org.apache.hadoop.io.compress.TestCompressorDecompressor
[ERROR] testCompressorDecompressor(org.apache.hadoop.io.compress.TestCompressorDecompressor)  Time elapsed: 0.1 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'testCompressorDecompressor error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:66)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:66)
	... 25 more

[ERROR] testCompressorDecompressorWithExeedBufferLimit(org.apache.hadoop.io.compress.TestCompressorDecompressor)  Time elapsed: 0.006 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'testCompressorDecompressorWithExeedBufferLimit error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:89)
	... 25 more

[ERROR] testCompressorDecompressor(org.apache.hadoop.io.compress.TestCompressorDecompressor)  Time elapsed: 0.005 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'testCompressorDecompressor error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:66)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:66)
	... 25 more

[ERROR] testCompressorDecompressorWithExeedBufferLimit(org.apache.hadoop.io.compress.TestCompressorDecompressor)  Time elapsed: 0.005 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'testCompressorDecompressorWithExeedBufferLimit error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:89)
	... 25 more

[ERROR] testCompressorDecompressor(org.apache.hadoop.io.compress.TestCompressorDecompressor)  Time elapsed: 0.005 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'testCompressorDecompressor error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:66)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:66)
	... 25 more

[ERROR] testCompressorDecompressorWithExeedBufferLimit(org.apache.hadoop.io.compress.TestCompressorDecompressor)  Time elapsed: 0.005 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'testCompressorDecompressorWithExeedBufferLimit error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:89)
	... 25 more

[ERROR] testCompressorDecompressor(org.apache.hadoop.io.compress.TestCompressorDecompressor)  Time elapsed: 0.004 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'testCompressorDecompressor error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:66)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:66)
	... 25 more

[ERROR] testCompressorDecompressorWithExeedBufferLimit(org.apache.hadoop.io.compress.TestCompressorDecompressor)  Time elapsed: 0.007 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'testCompressorDecompressorWithExeedBufferLimit error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:89)
	... 25 more

[INFO] Running org.apache.hadoop.io.compress.zlib.TestZlibCompressorDecompressor
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.333 s - in org.apache.hadoop.io.compress.TestCompressionStreamReuse
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.574 s - in org.apache.hadoop.io.compress.zlib.TestZlibCompressorDecompressor
[INFO] Running org.apache.hadoop.io.compress.TestBlockDecompressorStream
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.049 s - in org.apache.hadoop.io.compress.TestBlockDecompressorStream
[INFO] Running org.apache.hadoop.io.compress.zstd.TestZStandardCompressorDecompressor
[INFO] Running org.apache.hadoop.io.compress.TestCompressorStream
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.055 s - in org.apache.hadoop.io.compress.TestCompressorStream
[INFO] Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.389 s - in org.apache.hadoop.io.compress.zstd.TestZStandardCompressorDecompressor
[INFO] Running org.apache.hadoop.io.compress.TestCodecFactory
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.223 s - in org.apache.hadoop.io.compress.TestCodecFactory
[INFO] Running org.apache.hadoop.io.compress.lz4.TestLz4CompressorDecompressor
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.216 s - in org.apache.hadoop.io.compress.lz4.TestLz4CompressorDecompressor
[INFO] Running org.apache.hadoop.io.compress.bzip2.TestBzip2CompressorDecompressor
[INFO] Running org.apache.hadoop.io.compress.TestCodecPool
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.366 s - in org.apache.hadoop.io.compress.bzip2.TestBzip2CompressorDecompressor
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.215 s - in org.apache.hadoop.io.compress.TestCodecPool
[INFO] Running org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor
[INFO] Running org.apache.hadoop.io.compress.TestDecompressorStream
[ERROR] Tests run: 20, Failures: 0, Errors: 8, Skipped: 0, Time elapsed: 0.432 s <<< FAILURE! - in org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor
[ERROR] testSnappyCompressDecompressInMultiThreads(org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor)  Time elapsed: 0.058 s  <<< ERROR!
java.lang.RuntimeException: Deferred
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.checkException(MultithreadedTestUtil.java:130)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.waitFor(MultithreadedTestUtil.java:121)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompressInMultiThreads(TestSnappyCompressorDecompressor.java:409)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: java.lang.InternalError: Could not decompress data. Input is invalid.
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect(Native Method)
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompress(SnappyDecompressor.java:235)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompress(TestSnappyCompressorDecompressor.java:192)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor$1.doWork(TestSnappyCompressorDecompressor.java:403)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189)

[ERROR] testSnappyCompressDecompress(org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor)  Time elapsed: 0.003 s  <<< ERROR!
java.lang.InternalError: Could not decompress data. Input is invalid.
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect(Native Method)
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompress(SnappyDecompressor.java:235)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompress(TestSnappyCompressorDecompressor.java:192)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[ERROR] testSnappyCompressDecompressInMultiThreads(org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor)  Time elapsed: 0.036 s  <<< ERROR!
java.lang.RuntimeException: Deferred
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.checkException(MultithreadedTestUtil.java:130)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.waitFor(MultithreadedTestUtil.java:121)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompressInMultiThreads(TestSnappyCompressorDecompressor.java:409)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: java.lang.InternalError: Could not decompress data. Input is invalid.
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect(Native Method)
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompress(SnappyDecompressor.java:235)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompress(TestSnappyCompressorDecompressor.java:192)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor$1.doWork(TestSnappyCompressorDecompressor.java:403)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189)

[ERROR] testSnappyCompressDecompress(org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor)  Time elapsed: 0.032 s  <<< ERROR!
java.lang.InternalError: Could not decompress data. Input is invalid.
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect(Native Method)
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompress(SnappyDecompressor.java:235)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompress(TestSnappyCompressorDecompressor.java:192)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[ERROR] testSnappyCompressDecompressInMultiThreads(org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor)  Time elapsed: 0.043 s  <<< ERROR!
java.lang.RuntimeException: Deferred
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.checkException(MultithreadedTestUtil.java:130)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.waitFor(MultithreadedTestUtil.java:121)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompressInMultiThreads(TestSnappyCompressorDecompressor.java:409)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: java.lang.InternalError: Could not decompress data. Input is invalid.
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect(Native Method)
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompress(SnappyDecompressor.java:235)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompress(TestSnappyCompressorDecompressor.java:192)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor$1.doWork(TestSnappyCompressorDecompressor.java:403)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189)

[ERROR] testSnappyCompressDecompress(org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor)  Time elapsed: 0.013 s  <<< ERROR!
java.lang.InternalError: Could not decompress data. Input is invalid.
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect(Native Method)
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompress(SnappyDecompressor.java:235)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompress(TestSnappyCompressorDecompressor.java:192)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[ERROR] testSnappyCompressDecompressInMultiThreads(org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor)  Time elapsed: 0.028 s  <<< ERROR!
java.lang.RuntimeException: Deferred
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.checkException(MultithreadedTestUtil.java:130)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.waitFor(MultithreadedTestUtil.java:121)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompressInMultiThreads(TestSnappyCompressorDecompressor.java:409)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: java.lang.InternalError: Could not decompress data. Input is invalid.
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect(Native Method)
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompress(SnappyDecompressor.java:235)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompress(TestSnappyCompressorDecompressor.java:192)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor$1.doWork(TestSnappyCompressorDecompressor.java:403)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189)

[ERROR] testSnappyCompressDecompress(org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor)  Time elapsed: 0.018 s  <<< ERROR!
java.lang.InternalError: Could not decompress data. Input is invalid.
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect(Native Method)
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompress(SnappyDecompressor.java:235)
	at org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompress(TestSnappyCompressorDecompressor.java:192)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.06 s - in org.apache.hadoop.io.compress.TestDecompressorStream
[INFO] Running org.apache.hadoop.io.compress.TestCodec
[INFO] Running org.apache.hadoop.io.TestGenericWritable
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.221 s - in org.apache.hadoop.io.TestGenericWritable
[INFO] Running org.apache.hadoop.io.TestBytesWritable
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.12 s - in org.apache.hadoop.io.TestBytesWritable
[INFO] Running org.apache.hadoop.io.TestMapFile
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.033 s - in org.apache.hadoop.io.retry.TestFailoverProxy
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.873 s - in org.apache.hadoop.io.TestMapFile
[INFO] Running org.apache.hadoop.io.TestSequenceFileSync
[INFO] Running org.apache.hadoop.io.TestWritableUtils
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.655 s - in org.apache.hadoop.io.TestSequenceFileSync
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.109 s - in org.apache.hadoop.io.TestWritableUtils
[INFO] Running org.apache.hadoop.io.TestArrayPrimitiveWritable
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.146 s - in org.apache.hadoop.io.TestArrayPrimitiveWritable
[INFO] Running org.apache.hadoop.io.TestSequenceFileAppend
[INFO] Running org.apache.hadoop.io.TestWritable
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.497 s - in org.apache.hadoop.io.TestSequenceFileAppend
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.223 s - in org.apache.hadoop.io.TestWritable
[INFO] Running org.apache.hadoop.io.TestWritableName
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.134 s - in org.apache.hadoop.io.TestWritableName
[INFO] Running org.apache.hadoop.io.TestSequenceFileSerialization
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.422 s - in org.apache.hadoop.io.TestSequenceFileSerialization
[INFO] Running org.apache.hadoop.io.TestObjectWritableProtos
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.183 s - in org.apache.hadoop.io.TestObjectWritableProtos
[INFO] Running org.apache.hadoop.io.TestUTF8
[INFO] Running org.apache.hadoop.io.file.tfile.TestTFileSplit
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.422 s - in org.apache.hadoop.io.TestUTF8
[INFO] Running org.apache.hadoop.io.file.tfile.TestTFileStreams
[INFO] Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.868 s - in org.apache.hadoop.io.file.tfile.TestTFileStreams
[INFO] Running org.apache.hadoop.io.file.tfile.TestTFileByteArrays
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.72 s - in org.apache.hadoop.io.file.tfile.TestTFileSplit
[INFO] Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.08 s - in org.apache.hadoop.io.file.tfile.TestTFileByteArrays
[INFO] Running org.apache.hadoop.io.file.tfile.TestCompression
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.174 s - in org.apache.hadoop.io.file.tfile.TestCompression
[INFO] Running org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays
[INFO] Running org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays
[INFO] Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.845 s - in org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays
[INFO] Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.219 s - in org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays
[INFO] Running org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams
[INFO] Running org.apache.hadoop.io.file.tfile.TestTFileSeqFileComparison
[INFO] Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.77 s - in org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams
[INFO] Running org.apache.hadoop.io.file.tfile.TestTFileComparators
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.401 s - in org.apache.hadoop.io.file.tfile.TestTFileComparators
[INFO] Running org.apache.hadoop.io.file.tfile.TestTFileComparator2
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.52 s - in org.apache.hadoop.io.file.tfile.TestTFileComparator2
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.614 s - in org.apache.hadoop.io.file.tfile.TestTFileSeqFileComparison
[INFO] Running org.apache.hadoop.io.file.tfile.TestTFileLzoCodecsStreams
[INFO] Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.196 s - in org.apache.hadoop.io.file.tfile.TestTFileLzoCodecsStreams
[INFO] Running org.apache.hadoop.io.file.tfile.TestVLong
[INFO] Running org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.902 s - in org.apache.hadoop.io.file.tfile.TestVLong
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.47 s - in org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays
[INFO] Running org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays
[INFO] Running org.apache.hadoop.io.file.tfile.TestTFile
[INFO] Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.728 s - in org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.666 s - in org.apache.hadoop.io.file.tfile.TestTFile
[INFO] Running org.apache.hadoop.io.file.tfile.TestTFileLzoCodecsByteArrays
[INFO] Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.207 s - in org.apache.hadoop.io.file.tfile.TestTFileLzoCodecsByteArrays
[INFO] Running org.apache.hadoop.io.file.tfile.TestTFileSeek
[INFO] Running org.apache.hadoop.io.TestDataByteBuffers
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.212 s - in org.apache.hadoop.io.TestDataByteBuffers
[INFO] Running org.apache.hadoop.io.TestSequenceFile
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.897 s - in org.apache.hadoop.io.file.tfile.TestTFileSeek
[INFO] Running org.apache.hadoop.io.TestBooleanWritable
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.203 s - in org.apache.hadoop.io.TestBooleanWritable
[INFO] Running org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.311 s - in org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory
[INFO] Running org.apache.hadoop.io.nativeio.TestNativeIO
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.992 s - in org.apache.hadoop.io.TestSequenceFile
[INFO] Running org.apache.hadoop.io.TestMapWritable
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.125 s - in org.apache.hadoop.io.TestMapWritable
[INFO] Running org.apache.hadoop.io.TestDefaultStringifier
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.207 s - in org.apache.hadoop.io.TestDefaultStringifier
[INFO] Running org.apache.hadoop.io.TestTextNonUTF8
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.11 s - in org.apache.hadoop.io.TestTextNonUTF8
[INFO] Running org.apache.hadoop.io.TestMD5Hash
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.129 s - in org.apache.hadoop.io.TestMD5Hash
[INFO] Running org.apache.hadoop.io.TestIOUtils
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.239 s - in org.apache.hadoop.io.TestIOUtils
[INFO] Running org.apache.hadoop.io.TestArrayWritable
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.116 s - in org.apache.hadoop.io.TestArrayWritable
[INFO] Running org.apache.hadoop.io.TestBloomMapFile
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.856 s - in org.apache.hadoop.io.TestBloomMapFile
[INFO] Running org.apache.hadoop.io.TestArrayFile
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.478 s - in org.apache.hadoop.io.TestArrayFile
[INFO] Running org.apache.hadoop.io.TestBoundedByteArrayOutputStream
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.046 s - in org.apache.hadoop.io.TestBoundedByteArrayOutputStream
[INFO] Running org.apache.hadoop.cli.TestCLI
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.431 s - in org.apache.hadoop.cli.TestCLI
[INFO] Running org.apache.hadoop.tracing.TestTraceUtils
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.243 s - in org.apache.hadoop.tracing.TestTraceUtils
[INFO] Running org.apache.hadoop.fs.TestLocalFSFileContextCreateMkdir
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.453 s - in org.apache.hadoop.fs.TestLocalFSFileContextCreateMkdir
[INFO] Running org.apache.hadoop.fs.TestChecksumFileSystem
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.551 s - in org.apache.hadoop.fs.TestChecksumFileSystem
[INFO] Running org.apache.hadoop.fs.TestFilterFs
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.384 s - in org.apache.hadoop.fs.TestFilterFs
[INFO] Running org.apache.hadoop.fs.TestLocalFileSystemPermission
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.389 s - in org.apache.hadoop.fs.TestLocalFileSystemPermission
[INFO] Running org.apache.hadoop.fs.TestGetSpaceUsed
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.187 s - in org.apache.hadoop.fs.TestGetSpaceUsed
[INFO] Running org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem
[WARNING] Tests run: 63, Failures: 0, Errors: 0, Skipped: 7, Time elapsed: 1.756 s - in org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem
[INFO] Running org.apache.hadoop.fs.TestFileStatus
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.137 s - in org.apache.hadoop.fs.TestFileStatus
[INFO] Running org.apache.hadoop.fs.TestCommandFormat
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.055 s - in org.apache.hadoop.fs.TestCommandFormat
[INFO] Running org.apache.hadoop.fs.TestFcLocalFsUtil
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.349 s - in org.apache.hadoop.fs.TestFcLocalFsUtil
[INFO] Running org.apache.hadoop.fs.TestHarFileSystemBasics
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 93.337 s - in org.apache.hadoop.ha.TestZKFailoverControllerStress
[INFO] Running org.apache.hadoop.fs.TestFsShellTouch
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.611 s - in org.apache.hadoop.fs.TestHarFileSystemBasics
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.566 s - in org.apache.hadoop.fs.TestFsShellTouch
[INFO] Running org.apache.hadoop.fs.TestFsShell
[INFO] Running org.apache.hadoop.fs.sftp.TestSFTPFileSystem
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.154 s - in org.apache.hadoop.fs.TestFsShell
[INFO] Running org.apache.hadoop.fs.TestFsShellReturnCode
[WARNING] Tests run: 24, Failures: 0, Errors: 0, Skipped: 3, Time elapsed: 29.369 s - in org.apache.hadoop.io.nativeio.TestNativeIO
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.022 s - in org.apache.hadoop.fs.TestFsShellReturnCode
[INFO] Running org.apache.hadoop.fs.TestListFiles
[INFO] Running org.apache.hadoop.fs.TestDU
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.5 s - in org.apache.hadoop.fs.TestListFiles
[INFO] Running org.apache.hadoop.fs.TestDelegateToFileSystem
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.234 s - in org.apache.hadoop.fs.TestDelegateToFileSystem
[INFO] Running org.apache.hadoop.fs.TestFileUtil
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.647 s - in org.apache.hadoop.fs.sftp.TestSFTPFileSystem
[INFO] Running org.apache.hadoop.fs.TestDFCachingGetSpaceUsed
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.117 s - in org.apache.hadoop.fs.TestDFCachingGetSpaceUsed
[INFO] Running org.apache.hadoop.fs.TestSymlinkLocalFSFileContext
[WARNING] Tests run: 63, Failures: 0, Errors: 0, Skipped: 3, Time elapsed: 2.153 s - in org.apache.hadoop.fs.TestSymlinkLocalFSFileContext
[INFO] Running org.apache.hadoop.fs.TestStat
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.354 s - in org.apache.hadoop.fs.TestStat
[INFO] Running org.apache.hadoop.fs.TestTrash
[INFO] Tests run: 32, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.886 s - in org.apache.hadoop.fs.TestFileUtil
[INFO] Running org.apache.hadoop.fs.TestQuotaUsage
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.096 s - in org.apache.hadoop.fs.TestQuotaUsage
[INFO] Running org.apache.hadoop.fs.shell.TestPathData
[WARNING] Tests run: 12, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 0.53 s - in org.apache.hadoop.fs.shell.TestPathData
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.272 s - in org.apache.hadoop.fs.TestDU
[INFO] Running org.apache.hadoop.fs.shell.TestCopyFromLocal
[INFO] Running org.apache.hadoop.fs.shell.TestPrintableString
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.057 s - in org.apache.hadoop.fs.shell.TestPrintableString
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.622 s - in org.apache.hadoop.fs.shell.TestCopyFromLocal
[INFO] Running org.apache.hadoop.fs.shell.TestCount
[INFO] Running org.apache.hadoop.fs.shell.TestPathExceptions
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.067 s - in org.apache.hadoop.fs.shell.TestPathExceptions
[INFO] Tests run: 26, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 64.805 s - in org.apache.hadoop.io.compress.TestCodec
[INFO] Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.582 s - in org.apache.hadoop.fs.shell.TestCount
[INFO] Running org.apache.hadoop.fs.shell.TestTextCommand
[INFO] Running org.apache.hadoop.fs.shell.TestCopyPreserveFlag
[INFO] Running org.apache.hadoop.fs.shell.TestAclCommands
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.683 s - in org.apache.hadoop.fs.shell.TestTextCommand
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.608 s - in org.apache.hadoop.fs.shell.TestCopyPreserveFlag
[INFO] Running org.apache.hadoop.fs.shell.TestXAttrCommands
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.563 s - in org.apache.hadoop.fs.shell.TestAclCommands
[INFO] Running org.apache.hadoop.fs.shell.TestLs
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.401 s - in org.apache.hadoop.fs.shell.TestXAttrCommands
[INFO] Running org.apache.hadoop.fs.shell.find.TestName
[INFO] Running org.apache.hadoop.fs.shell.find.TestPrint
[INFO] Tests run: 33, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.717 s - in org.apache.hadoop.fs.shell.TestLs
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.608 s - in org.apache.hadoop.fs.shell.find.TestName
[INFO] Running org.apache.hadoop.fs.shell.find.TestPrint0
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.518 s - in org.apache.hadoop.fs.shell.find.TestPrint
[INFO] Running org.apache.hadoop.fs.shell.find.TestFind
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.523 s - in org.apache.hadoop.fs.shell.find.TestPrint0
[INFO] Running org.apache.hadoop.fs.shell.find.TestAnd
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.211 s - in org.apache.hadoop.fs.shell.find.TestAnd
[INFO] Running org.apache.hadoop.fs.shell.find.TestResult
[INFO] Tests run: 24, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.85 s - in org.apache.hadoop.fs.shell.find.TestFind
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.075 s - in org.apache.hadoop.fs.shell.find.TestResult
[INFO] Running org.apache.hadoop.fs.shell.find.TestFilterExpression
[INFO] Running org.apache.hadoop.fs.shell.find.TestIname
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.243 s - in org.apache.hadoop.fs.shell.find.TestFilterExpression
[INFO] Running org.apache.hadoop.fs.shell.TestMove
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.561 s - in org.apache.hadoop.fs.shell.find.TestIname
[INFO] Running org.apache.hadoop.fs.shell.TestCommandFactory
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.558 s - in org.apache.hadoop.fs.shell.TestMove
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.151 s - in org.apache.hadoop.fs.shell.TestCommandFactory
[INFO] Running org.apache.hadoop.fs.shell.TestCopy
[INFO] Running org.apache.hadoop.fs.TestLocalFsFCStatistics
[INFO] Running org.apache.hadoop.fs.TestPath
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.496 s - in org.apache.hadoop.fs.TestLocalFsFCStatistics
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.628 s - in org.apache.hadoop.fs.shell.TestCopy
[INFO] Running org.apache.hadoop.fs.TestFilterFileSystem
[WARNING] Tests run: 22, Failures: 0, Errors: 0, Skipped: 3, Time elapsed: 0.716 s - in org.apache.hadoop.fs.TestPath
[INFO] Running org.apache.hadoop.fs.TestRawLocalFileSystemContract
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.554 s - in org.apache.hadoop.fs.TestFilterFileSystem
[INFO] Running org.apache.hadoop.fs.TestFileSystemStorageStatistics
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.115 s - in org.apache.hadoop.fs.TestFileSystemStorageStatistics
[INFO] Running org.apache.hadoop.fs.TestHarFileSystem
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.336 s - in org.apache.hadoop.fs.TestHarFileSystem
[INFO] Running org.apache.hadoop.fs.TestFileContextDeleteOnExit
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.366 s - in org.apache.hadoop.fs.TestFileContextDeleteOnExit
[INFO] Running org.apache.hadoop.fs.TestContentSummary
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.194 s - in org.apache.hadoop.fs.TestContentSummary
[INFO] Running org.apache.hadoop.fs.store.TestEtagChecksum
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.05 s - in org.apache.hadoop.fs.store.TestEtagChecksum
[INFO] Running org.apache.hadoop.fs.TestBlockLocation
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.049 s - in org.apache.hadoop.fs.TestBlockLocation
[INFO] Running org.apache.hadoop.fs.TestFileSystemInitialization
[INFO] Running org.apache.hadoop.fs.TestFileContextResolveAfs
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.318 s - in org.apache.hadoop.fs.TestFileSystemInitialization
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.363 s - in org.apache.hadoop.fs.TestFileContextResolveAfs
[INFO] Running org.apache.hadoop.fs.TestFileSystemCaching
[INFO] Running org.apache.hadoop.fs.TestFsShellCopy
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.52 s - in org.apache.hadoop.fs.TestFileSystemCaching
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.021 s - in org.apache.hadoop.fs.TestTrash
[WARNING] Tests run: 19, Failures: 0, Errors: 0, Skipped: 4, Time elapsed: 0.654 s - in org.apache.hadoop.fs.TestFsShellCopy
[INFO] Running org.apache.hadoop.fs.TestAvroFSInput
[INFO] Running org.apache.hadoop.fs.permission.TestAcl
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.129 s - in org.apache.hadoop.fs.permission.TestAcl
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.416 s - in org.apache.hadoop.fs.TestAvroFSInput
[INFO] Running org.apache.hadoop.fs.permission.TestFsPermission
[INFO] Running org.apache.hadoop.fs.TestDefaultUri
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.316 s - in org.apache.hadoop.fs.permission.TestFsPermission
[INFO] Running org.apache.hadoop.fs.TestDelegateToFsCheckPath
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.417 s - in org.apache.hadoop.fs.TestDefaultUri
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.218 s - in org.apache.hadoop.fs.TestDelegateToFsCheckPath
[INFO] Running org.apache.hadoop.fs.TestGetFileBlockLocations
[INFO] Running org.apache.hadoop.fs.TestTruncatedInputBug
[INFO] Running org.apache.hadoop.fs.TestGlobExpander
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.487 s - in org.apache.hadoop.fs.TestGetFileBlockLocations
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.069 s - in org.apache.hadoop.fs.TestGlobExpander
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.469 s - in org.apache.hadoop.fs.TestTruncatedInputBug
[WARNING] Tests run: 44, Failures: 0, Errors: 0, Skipped: 18, Time elapsed: 6.682 s - in org.apache.hadoop.fs.TestRawLocalFileSystemContract
[INFO] Running org.apache.hadoop.fs.http.TestHttpFileSystem
[INFO] Running org.apache.hadoop.fs.protocolPB.TestFSSerialization
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.163 s - in org.apache.hadoop.fs.protocolPB.TestFSSerialization
[INFO] Running org.apache.hadoop.fs.TestFileContext
[INFO] Running org.apache.hadoop.fs.TestLocalDirAllocator
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.462 s - in org.apache.hadoop.fs.TestFileContext
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.745 s - in org.apache.hadoop.fs.http.TestHttpFileSystem
[INFO] Running org.apache.hadoop.fs.TestFcLocalFsPermission
[INFO] Running org.apache.hadoop.fs.TestHardLink
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.281 s - in org.apache.hadoop.fs.TestHardLink
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.595 s - in org.apache.hadoop.fs.TestFcLocalFsPermission
[INFO] Running org.apache.hadoop.fs.TestFsShellList
[INFO] Tests run: 39, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.007 s - in org.apache.hadoop.fs.TestLocalDirAllocator
[INFO] Running org.apache.hadoop.fs.TestLocalFileSystem
[INFO] Running org.apache.hadoop.fs.TestFileSystemCanonicalization
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.55 s - in org.apache.hadoop.fs.TestFsShellList
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.344 s - in org.apache.hadoop.fs.TestFileSystemCanonicalization
[INFO] Running org.apache.hadoop.fs.ftp.TestFTPFileSystem
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.283 s - in org.apache.hadoop.fs.ftp.TestFTPFileSystem
[INFO] Running org.apache.hadoop.fs.TestLocalFSFileContextMainOperations
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFsConfig
[INFO] Running org.apache.hadoop.fs.viewfs.TestFcCreateMkdirLocalFs
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.427 s - in org.apache.hadoop.fs.viewfs.TestViewFsConfig
[WARNING] Tests run: 22, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 1.664 s - in org.apache.hadoop.fs.TestLocalFileSystem
[INFO] Tests run: 64, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.212 s - in org.apache.hadoop.fs.TestLocalFSFileContextMainOperations
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.722 s - in org.apache.hadoop.fs.viewfs.TestFcCreateMkdirLocalFs
[INFO] Running org.apache.hadoop.fs.viewfs.TestChRootedFs
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFsTrash
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegation
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.091 s - in org.apache.hadoop.fs.viewfs.TestChRootedFs
[WARNING] Tests run: 72, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 1.425 s - in org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.12 s - in org.apache.hadoop.fs.viewfs.TestViewFsTrash
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.764 s - in org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegation
[INFO] Running org.apache.hadoop.fs.viewfs.TestFcPermissionsLocalFs
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFsLocalFs
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.635 s - in org.apache.hadoop.fs.viewfs.TestFcPermissionsLocalFs
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewfsFileStatus
[WARNING] Tests run: 74, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 1.597 s - in org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem
[INFO] Tests run: 65, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.831 s - in org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFsURIs
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.847 s - in org.apache.hadoop.fs.viewfs.TestViewfsFileStatus
[INFO] Tests run: 65, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.74 s - in org.apache.hadoop.fs.viewfs.TestViewFsLocalFs
[INFO] Running org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs
[INFO] Running org.apache.hadoop.fs.viewfs.TestChRootedFileSystem
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.442 s - in org.apache.hadoop.fs.viewfs.TestViewFsURIs
[INFO] Running org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegationTokenSupport
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.038 s - in org.apache.hadoop.fs.viewfs.TestChRootedFileSystem
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.589 s - in org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegationTokenSupport
[INFO] Tests run: 50, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.282 s - in org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem
[INFO] Running org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem
[INFO] Tests run: 62, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.796 s - in org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs
[INFO] Running org.apache.hadoop.fs.TestDelegationTokenRenewer
[INFO] Running org.apache.hadoop.fs.TestFileSystemTokens
[INFO] Running org.apache.hadoop.fs.TestFsOptions
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.498 s - in org.apache.hadoop.fs.TestFileSystemTokens
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.072 s - in org.apache.hadoop.fs.TestFsOptions
[INFO] Tests run: 50, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.006 s - in org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem
[INFO] Running org.apache.hadoop.fs.TestAfsCheckPath
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.112 s - in org.apache.hadoop.fs.TestAfsCheckPath
[INFO] Running org.apache.hadoop.fs.TestLocatedFileStatus
[INFO] Running org.apache.hadoop.fs.TestGlobPattern
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.213 s - in org.apache.hadoop.fs.TestLocatedFileStatus
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.085 s - in org.apache.hadoop.fs.TestGlobPattern
[INFO] Running org.apache.hadoop.fs.TestDFVariations
[INFO] Running org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractMkdir
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.131 s - in org.apache.hadoop.fs.TestDFVariations
[INFO] Running org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractDelete
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.452 s - in org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractMkdir
[INFO] Running org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractSeek
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.461 s - in org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractDelete
[INFO] Running org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractGetFileStatus
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.61 s - in org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractSeek
[INFO] Running org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractSetTimes
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.6 s - in org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractGetFileStatus
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.386 s - in org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractSetTimes
[INFO] Running org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractOpen
[INFO] Running org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.496 s - in org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractOpen
[INFO] Running org.apache.hadoop.fs.contract.rawlocal.TestRawLocalContractUnderlyingFileBehavior
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.163 s - in org.apache.hadoop.fs.contract.rawlocal.TestRawLocalContractUnderlyingFileBehavior
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.554 s - in org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate
[INFO] Running org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractRename
[INFO] Running org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractAppend
[INFO] Running org.apache.hadoop.fs.contract.localfs.TestLocalFSContractGetFileStatus
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.596 s - in org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractRename
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.571 s - in org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractAppend
[INFO] Running org.apache.hadoop.fs.contract.localfs.TestLocalFSContractMkdir
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.675 s - in org.apache.hadoop.fs.contract.localfs.TestLocalFSContractGetFileStatus
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.635 s - in org.apache.hadoop.fs.TestDelegationTokenRenewer
[INFO] Running org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.551 s - in org.apache.hadoop.fs.contract.localfs.TestLocalFSContractMkdir
[INFO] Running org.apache.hadoop.fs.contract.localfs.TestLocalFSContractAppend
[INFO] Running org.apache.hadoop.fs.contract.localfs.TestLocalFSContractDelete
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.674 s - in org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate
[INFO] Running org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek
[WARNING] Tests run: 7, Failures: 0, Errors: 0, Skipped: 7, Time elapsed: 0.611 s - in org.apache.hadoop.fs.contract.localfs.TestLocalFSContractAppend
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.641 s - in org.apache.hadoop.fs.contract.localfs.TestLocalFSContractDelete
[INFO] Running org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename
[INFO] Running org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSetTimes
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.798 s - in org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek
[INFO] Running org.apache.hadoop.fs.contract.localfs.TestLocalFSContractOpen
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.612 s - in org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.503 s - in org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSetTimes
[INFO] Running org.apache.hadoop.fs.contract.localfs.TestLocalFSContractLoaded
[INFO] Running org.apache.hadoop.fs.contract.ftp.TestFTPContractDelete
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.601 s - in org.apache.hadoop.fs.contract.localfs.TestLocalFSContractOpen
[INFO] Running org.apache.hadoop.fs.contract.ftp.TestFTPContractCreate
[WARNING] Tests run: 8, Failures: 0, Errors: 0, Skipped: 8, Time elapsed: 0.364 s - in org.apache.hadoop.fs.contract.ftp.TestFTPContractDelete
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.541 s - in org.apache.hadoop.fs.contract.localfs.TestLocalFSContractLoaded
[INFO] Running org.apache.hadoop.fs.contract.ftp.TestFTPContractMkdir
[WARNING] Tests run: 11, Failures: 0, Errors: 0, Skipped: 11, Time elapsed: 0.347 s - in org.apache.hadoop.fs.contract.ftp.TestFTPContractCreate
[INFO] Running org.apache.hadoop.fs.contract.ftp.TestFTPContractOpen
[WARNING] Tests run: 7, Failures: 0, Errors: 0, Skipped: 7, Time elapsed: 0.349 s - in org.apache.hadoop.fs.contract.ftp.TestFTPContractMkdir
[INFO] Running org.apache.hadoop.fs.contract.ftp.TestFTPContractRename
[WARNING] Tests run: 6, Failures: 0, Errors: 0, Skipped: 6, Time elapsed: 0.344 s - in org.apache.hadoop.fs.contract.ftp.TestFTPContractOpen
[INFO] Running org.apache.hadoop.net.TestStaticMapping
[WARNING] Tests run: 8, Failures: 0, Errors: 0, Skipped: 8, Time elapsed: 0.323 s - in org.apache.hadoop.fs.contract.ftp.TestFTPContractRename
[INFO] Running org.apache.hadoop.net.TestScriptBasedMappingWithDependency
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.335 s - in org.apache.hadoop.net.TestStaticMapping
[INFO] Running org.apache.hadoop.net.unix.TestDomainSocketWatcher
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.339 s - in org.apache.hadoop.net.TestScriptBasedMappingWithDependency
[INFO] Running org.apache.hadoop.net.unix.TestDomainSocket
[INFO] Running org.apache.hadoop.net.TestDNS
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.174 s - in org.apache.hadoop.net.TestDNS
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.562 s - in org.apache.hadoop.net.unix.TestDomainSocketWatcher
[INFO] Running org.apache.hadoop.net.TestSocketIOWithTimeout
[INFO] Running org.apache.hadoop.net.TestClusterTopology
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.251 s - in org.apache.hadoop.net.TestClusterTopology
[INFO] Running org.apache.hadoop.net.TestNetUtils
[INFO] Running org.apache.hadoop.net.TestNetworkTopologyWithNodeGroup
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.115 s - in org.apache.hadoop.net.TestNetworkTopologyWithNodeGroup
[INFO] Running org.apache.hadoop.net.TestSwitchMapping
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.178 s - in org.apache.hadoop.net.TestSwitchMapping
[INFO] Running org.apache.hadoop.net.TestScriptBasedMapping
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.822 s - in org.apache.hadoop.net.unix.TestDomainSocket
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.215 s - in org.apache.hadoop.net.TestScriptBasedMapping
[INFO] Running org.apache.hadoop.net.TestTableMapping
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.259 s - in org.apache.hadoop.net.TestTableMapping
[INFO] Running org.apache.hadoop.service.TestServiceOperations
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.201 s - in org.apache.hadoop.service.TestServiceOperations
[INFO] Running org.apache.hadoop.service.TestCompositeService
[INFO] Tests run: 45, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.296 s - in org.apache.hadoop.net.TestNetUtils
[INFO] Tests run: 42, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.148 s - in org.apache.hadoop.service.TestCompositeService
[INFO] Running org.apache.hadoop.service.TestServiceLifecycle
[INFO] Running org.apache.hadoop.service.TestGlobalStateChangeListener
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.141 s - in org.apache.hadoop.service.TestGlobalStateChangeListener
[INFO] Running org.apache.hadoop.service.launcher.TestServiceLauncher
[INFO] Running org.apache.hadoop.service.launcher.TestServiceLauncherCreationFailures
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.171 s - in org.apache.hadoop.service.launcher.TestServiceLauncherCreationFailures
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.803 s - in org.apache.hadoop.service.launcher.TestServiceLauncher
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.226 s - in org.apache.hadoop.net.TestSocketIOWithTimeout
[INFO] Running org.apache.hadoop.service.launcher.TestServiceLauncherInnerMethods
[INFO] Running org.apache.hadoop.service.launcher.TestServiceInterruptHandling
[INFO] Running org.apache.hadoop.service.launcher.TestServiceConf
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.341 s - in org.apache.hadoop.service.launcher.TestServiceLauncherInnerMethods
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.22 s - in org.apache.hadoop.service.TestServiceLifecycle
[INFO] Running org.apache.hadoop.log.TestLogLevel
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.727 s - in org.apache.hadoop.service.launcher.TestServiceConf
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.159 s - in org.apache.hadoop.service.launcher.TestServiceInterruptHandling
[INFO] Running org.apache.hadoop.log.TestLog4Json
[INFO] Running org.apache.hadoop.jmx.TestJMXJsonServlet
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.369 s - in org.apache.hadoop.log.TestLog4Json
[INFO] Running org.apache.hadoop.crypto.TestCryptoStreamsWithJceAesCtrCryptoCodec
[INFO] Running org.apache.hadoop.crypto.TestCryptoStreams
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.123 s - in org.apache.hadoop.jmx.TestJMXJsonServlet
[INFO] Running org.apache.hadoop.crypto.TestCryptoOutputStreamClosing
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.348 s - in org.apache.hadoop.crypto.TestCryptoOutputStreamClosing
[INFO] Running org.apache.hadoop.crypto.TestCryptoCodec
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.421 s - in org.apache.hadoop.log.TestLogLevel
[INFO] Running org.apache.hadoop.crypto.TestCryptoStreamsNormal
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.082 s - in org.apache.hadoop.crypto.TestCryptoCodec
[INFO] Running org.apache.hadoop.crypto.TestCryptoStreamsForLocalFS
[WARNING] Tests run: 15, Failures: 0, Errors: 0, Skipped: 9, Time elapsed: 4.52 s - in org.apache.hadoop.crypto.TestCryptoStreamsNormal
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.614 s - in org.apache.hadoop.crypto.TestCryptoStreams
[INFO] Running org.apache.hadoop.crypto.TestCryptoStreamsWithOpensslAesCtrCryptoCodec
[INFO] Running org.apache.hadoop.crypto.random.TestOpensslSecureRandom
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.146 s - in org.apache.hadoop.crypto.random.TestOpensslSecureRandom
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.016 s - in org.apache.hadoop.crypto.TestCryptoStreamsWithJceAesCtrCryptoCodec
[INFO] Running org.apache.hadoop.crypto.random.TestOsSecureRandom
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.268 s - in org.apache.hadoop.crypto.random.TestOsSecureRandom
[INFO] Running org.apache.hadoop.crypto.TestOpensslCipher
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.104 s - in org.apache.hadoop.crypto.TestOpensslCipher
[INFO] Running org.apache.hadoop.crypto.key.TestCachingKeyProvider
[INFO] Running org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.069 s - in org.apache.hadoop.crypto.key.TestCachingKeyProvider
[INFO] Running org.apache.hadoop.crypto.key.TestKeyShell
[WARNING] Tests run: 15, Failures: 0, Errors: 0, Skipped: 6, Time elapsed: 7.041 s - in org.apache.hadoop.crypto.TestCryptoStreamsForLocalFS
[INFO] Running org.apache.hadoop.crypto.key.TestKeyProvider
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.305 s - in org.apache.hadoop.crypto.key.TestKeyProvider
[INFO] Running org.apache.hadoop.crypto.key.TestKeyProviderDelegationTokenExtension
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.425 s - in org.apache.hadoop.crypto.key.TestKeyProviderDelegationTokenExtension
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.421 s - in org.apache.hadoop.crypto.key.TestKeyShell
[INFO] Running org.apache.hadoop.crypto.key.TestValueQueue
[INFO] Running org.apache.hadoop.crypto.key.TestKeyProviderFactory
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.163 s - in org.apache.hadoop.crypto.key.TestValueQueue
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.214 s - in org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider
[INFO] Running org.apache.hadoop.crypto.key.TestKeyProviderCryptoExtension
[INFO] Running org.apache.hadoop.security.TestUGIWithSecurityOn
[WARNING] Tests run: 2, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 0.079 s - in org.apache.hadoop.security.TestUGIWithSecurityOn
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.569 s - in org.apache.hadoop.crypto.key.TestKeyProviderCryptoExtension
[INFO] Running org.apache.hadoop.security.ssl.TestSSLFactory
[INFO] Running org.apache.hadoop.security.ssl.TestReloadingX509TrustManager
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.939 s - in org.apache.hadoop.crypto.key.TestKeyProviderFactory
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.973 s - in org.apache.hadoop.security.ssl.TestSSLFactory
[INFO] Running org.apache.hadoop.security.TestCompositeGroupMapping
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.326 s - in org.apache.hadoop.security.TestCompositeGroupMapping
[INFO] Running org.apache.hadoop.security.TestUserFromEnv
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.278 s - in org.apache.hadoop.security.TestUserFromEnv
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.684 s - in org.apache.hadoop.security.ssl.TestReloadingX509TrustManager
[INFO] Running org.apache.hadoop.security.TestLdapGroupsMapping
[INFO] Running org.apache.hadoop.security.TestDoAsEffectiveUser
[INFO] Running org.apache.hadoop.security.TestLdapGroupsMappingWithOneQuery
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.427 s - in org.apache.hadoop.security.TestLdapGroupsMappingWithOneQuery
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.814 s - in org.apache.hadoop.security.TestDoAsEffectiveUser
[INFO] Running org.apache.hadoop.security.TestNetgroupCache
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.05 s - in org.apache.hadoop.security.TestNetgroupCache
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.929 s - in org.apache.hadoop.crypto.TestCryptoStreamsWithOpensslAesCtrCryptoCodec
[INFO] Running org.apache.hadoop.security.TestUGILoginFromKeytab
[INFO] Running org.apache.hadoop.security.TestKDiagNoKDC
[INFO] Running org.apache.hadoop.security.authorize.TestAccessControlList
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.486 s - in org.apache.hadoop.security.TestKDiagNoKDC
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.418 s - in org.apache.hadoop.security.authorize.TestAccessControlList
[INFO] Running org.apache.hadoop.security.authorize.TestServiceAuthorization
[INFO] Running org.apache.hadoop.security.authorize.TestProxyUsers
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.407 s - in org.apache.hadoop.security.authorize.TestServiceAuthorization
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.324 s - in org.apache.hadoop.security.authorize.TestProxyUsers
[INFO] Running org.apache.hadoop.security.authorize.TestProxyServers
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.178 s - in org.apache.hadoop.security.authorize.TestProxyServers
[INFO] Running org.apache.hadoop.security.alias.TestCredShell
[INFO] Running org.apache.hadoop.security.alias.TestCredentialProviderFactory
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.784 s - in org.apache.hadoop.security.alias.TestCredShell
[INFO] Running org.apache.hadoop.security.alias.TestCredentialProvider
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.113 s - in org.apache.hadoop.security.alias.TestCredentialProvider
[INFO] Running org.apache.hadoop.security.TestRuleBasedLdapGroupsMapping
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.313 s - in org.apache.hadoop.security.TestRuleBasedLdapGroupsMapping
[INFO] Running org.apache.hadoop.security.TestRaceWhenRelogin
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.383 s - in org.apache.hadoop.security.alias.TestCredentialProviderFactory
[INFO] Running org.apache.hadoop.security.TestFixKerberosTicketOrder
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.04 s - in org.apache.hadoop.security.TestRaceWhenRelogin
[INFO] Running org.apache.hadoop.security.TestShellBasedIdMapping
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.806 s - in org.apache.hadoop.security.TestFixKerberosTicketOrder
[INFO] Running org.apache.hadoop.security.TestHttpCrossOriginFilterInitializer
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.167 s - in org.apache.hadoop.security.TestHttpCrossOriginFilterInitializer
[INFO] Running org.apache.hadoop.security.TestUGIWithMiniKdc
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.023 s - in org.apache.hadoop.security.TestUGILoginFromKeytab
[INFO] Running org.apache.hadoop.security.TestProxyUserFromEnv
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.255 s - in org.apache.hadoop.security.TestProxyUserFromEnv
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.482 s - in org.apache.hadoop.security.TestUGIWithMiniKdc
[INFO] Running org.apache.hadoop.security.TestGroupFallback
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.305 s - in org.apache.hadoop.security.TestGroupFallback
[INFO] Running org.apache.hadoop.security.TestKDiag
[INFO] Running org.apache.hadoop.security.TestUGIWithExternalKdc
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.06 s - in org.apache.hadoop.security.TestUGIWithExternalKdc
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.795 s - in org.apache.hadoop.security.TestShellBasedIdMapping
[INFO] Running org.apache.hadoop.security.TestNullGroupsMapping
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.041 s - in org.apache.hadoop.security.TestNullGroupsMapping
[INFO] Running org.apache.hadoop.security.TestWhitelistBasedResolver
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.235 s - in org.apache.hadoop.security.TestWhitelistBasedResolver
[INFO] Running org.apache.hadoop.security.http.TestXFrameOptionsFilter
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.172 s - in org.apache.hadoop.security.http.TestXFrameOptionsFilter
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.866 s - in org.apache.hadoop.security.TestKDiag
[INFO] Running org.apache.hadoop.security.http.TestCrossOriginFilter
[INFO] Running org.apache.hadoop.security.http.TestRestCsrfPreventionFilter
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.276 s - in org.apache.hadoop.security.http.TestCrossOriginFilter
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.273 s - in org.apache.hadoop.security.http.TestRestCsrfPreventionFilter
[INFO] Running org.apache.hadoop.security.TestShellBasedUnixGroupsMapping
[INFO] Running org.apache.hadoop.security.TestSecurityUtil
[INFO] Running org.apache.hadoop.security.TestJNIGroupsMapping
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.317 s - in org.apache.hadoop.security.TestJNIGroupsMapping
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.786 s - in org.apache.hadoop.security.TestSecurityUtil
[INFO] Running org.apache.hadoop.security.TestGroupsCaching
[INFO] Running org.apache.hadoop.security.TestUserGroupInformation
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.141 s - in org.apache.hadoop.security.TestGroupsCaching
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.501 s - in org.apache.hadoop.security.TestShellBasedUnixGroupsMapping
[INFO] Running org.apache.hadoop.security.TestLdapGroupsMappingWithPosixGroup
[INFO] Running org.apache.hadoop.security.TestCredentials
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.362 s - in org.apache.hadoop.security.TestLdapGroupsMappingWithPosixGroup
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.254 s - in org.apache.hadoop.security.TestCredentials
[INFO] Running org.apache.hadoop.security.token.delegation.TestDelegationToken
[INFO] Running org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager
[INFO] Tests run: 39, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.837 s - in org.apache.hadoop.security.TestUserGroupInformation
[INFO] Running org.apache.hadoop.security.token.delegation.web.TestDelegationTokenManager
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.384 s - in org.apache.hadoop.security.token.delegation.web.TestDelegationTokenManager
[INFO] Running org.apache.hadoop.security.token.delegation.web.TestWebDelegationToken
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.347 s - in org.apache.hadoop.security.token.delegation.web.TestWebDelegationToken
[INFO] Running org.apache.hadoop.security.token.delegation.web.TestDelegationTokenAuthenticationHandlerWithMocks
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.721 s - in org.apache.hadoop.security.token.delegation.web.TestDelegationTokenAuthenticationHandlerWithMocks
[INFO] Running org.apache.hadoop.security.token.TestToken
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.171 s - in org.apache.hadoop.security.token.TestToken
[INFO] Running org.apache.hadoop.security.token.TestDtUtilShell
[ERROR] Tests run: 17, Failures: 8, Errors: 0, Skipped: 0, Time elapsed: 29.584 s <<< FAILURE! - in org.apache.hadoop.security.TestLdapGroupsMapping
[ERROR] testLdapReadTimeout(org.apache.hadoop.security.TestLdapGroupsMapping)  Time elapsed: 4.071 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'LDAP response read timed out, timeout used:4000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 4000 ms.; remaining name ''
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.getSearchReply(LdapClient.java:638)
	at com.sun.jndi.ldap.LdapClient.search(LdapClient.java:561)
	at com.sun.jndi.ldap.LdapCtx.doSearch(LdapCtx.java:2013)
	at com.sun.jndi.ldap.LdapCtx.searchAux(LdapCtx.java:1872)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1797)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1814)
	at com.sun.jndi.toolkit.ctx.ComponentDirContext.p_search(ComponentDirContext.java:418)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:396)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:378)
	at javax.naming.directory.InitialDirContext.search(InitialDirContext.java:286)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:432)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:416)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:420)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: javax.naming.NamingException: LDAP response read timed out, timeout used: 4000 ms.; remaining name ''
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.getSearchReply(LdapClient.java:638)
	at com.sun.jndi.ldap.LdapClient.search(LdapClient.java:561)
	at com.sun.jndi.ldap.LdapCtx.doSearch(LdapCtx.java:2013)
	at com.sun.jndi.ldap.LdapCtx.searchAux(LdapCtx.java:1872)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1797)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1814)
	at com.sun.jndi.toolkit.ctx.ComponentDirContext.p_search(ComponentDirContext.java:418)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:396)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:378)
	at javax.naming.directory.InitialDirContext.search(InitialDirContext.java:286)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:432)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:416)
	... 9 more

[ERROR] testLdapConnectionTimeout(org.apache.hadoop.security.TestLdapGroupsMapping)  Time elapsed: 3.013 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'LDAP response read timed out, timeout used:3000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 3000 ms.
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.ldapBind(LdapClient.java:365)
	at com.sun.jndi.ldap.LdapClient.authenticate(LdapClient.java:214)
	at com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2897)
	at com.sun.jndi.ldap.LdapCtx.<init>(LdapCtx.java:347)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxFromUrl(LdapCtxFactory.java:229)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURL(LdapCtxFactory.java:189)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURLs(LdapCtxFactory.java:247)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxInstance(LdapCtxFactory.java:154)
	at com.sun.jndi.ldap.LdapCtxFactory.getInitialContext(LdapCtxFactory.java:84)
	at javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:695)
	at javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:313)
	at javax.naming.InitialContext.init(InitialContext.java:244)
	at javax.naming.InitialContext.<init>(InitialContext.java:216)
	at javax.naming.directory.InitialDirContext.<init>(InitialDirContext.java:101)
	at org.apache.hadoop.security.LdapGroupsMapping.getDirContext(LdapGroupsMapping.java:575)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:429)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:360)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:364)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: javax.naming.NamingException: LDAP response read timed out, timeout used: 3000 ms.
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.ldapBind(LdapClient.java:365)
	at com.sun.jndi.ldap.LdapClient.authenticate(LdapClient.java:214)
	at com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2897)
	at com.sun.jndi.ldap.LdapCtx.<init>(LdapCtx.java:347)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxFromUrl(LdapCtxFactory.java:229)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURL(LdapCtxFactory.java:189)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURLs(LdapCtxFactory.java:247)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxInstance(LdapCtxFactory.java:154)
	at com.sun.jndi.ldap.LdapCtxFactory.getInitialContext(LdapCtxFactory.java:84)
	at javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:695)
	at javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:313)
	at javax.naming.InitialContext.init(InitialContext.java:244)
	at javax.naming.InitialContext.<init>(InitialContext.java:216)
	at javax.naming.directory.InitialDirContext.<init>(InitialDirContext.java:101)
	at org.apache.hadoop.security.LdapGroupsMapping.getDirContext(LdapGroupsMapping.java:575)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:429)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:360)
	... 9 more

[ERROR] testLdapReadTimeout(org.apache.hadoop.security.TestLdapGroupsMapping)  Time elapsed: 4.015 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'LDAP response read timed out, timeout used:4000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 4000 ms.; remaining name ''
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.getSearchReply(LdapClient.java:638)
	at com.sun.jndi.ldap.LdapClient.search(LdapClient.java:561)
	at com.sun.jndi.ldap.LdapCtx.doSearch(LdapCtx.java:2013)
	at com.sun.jndi.ldap.LdapCtx.searchAux(LdapCtx.java:1872)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1797)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1814)
	at com.sun.jndi.toolkit.ctx.ComponentDirContext.p_search(ComponentDirContext.java:418)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:396)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:378)
	at javax.naming.directory.InitialDirContext.search(InitialDirContext.java:286)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:432)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:416)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:420)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: javax.naming.NamingException: LDAP response read timed out, timeout used: 4000 ms.; remaining name ''
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.getSearchReply(LdapClient.java:638)
	at com.sun.jndi.ldap.LdapClient.search(LdapClient.java:561)
	at com.sun.jndi.ldap.LdapCtx.doSearch(LdapCtx.java:2013)
	at com.sun.jndi.ldap.LdapCtx.searchAux(LdapCtx.java:1872)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1797)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1814)
	at com.sun.jndi.toolkit.ctx.ComponentDirContext.p_search(ComponentDirContext.java:418)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:396)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:378)
	at javax.naming.directory.InitialDirContext.search(InitialDirContext.java:286)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:432)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:416)
	... 9 more

[ERROR] testLdapConnectionTimeout(org.apache.hadoop.security.TestLdapGroupsMapping)  Time elapsed: 3.018 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'LDAP response read timed out, timeout used:3000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 3000 ms.
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.ldapBind(LdapClient.java:365)
	at com.sun.jndi.ldap.LdapClient.authenticate(LdapClient.java:214)
	at com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2897)
	at com.sun.jndi.ldap.LdapCtx.<init>(LdapCtx.java:347)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxFromUrl(LdapCtxFactory.java:229)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURL(LdapCtxFactory.java:189)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURLs(LdapCtxFactory.java:247)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxInstance(LdapCtxFactory.java:154)
	at com.sun.jndi.ldap.LdapCtxFactory.getInitialContext(LdapCtxFactory.java:84)
	at javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:695)
	at javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:313)
	at javax.naming.InitialContext.init(InitialContext.java:244)
	at javax.naming.InitialContext.<init>(InitialContext.java:216)
	at javax.naming.directory.InitialDirContext.<init>(InitialDirContext.java:101)
	at org.apache.hadoop.security.LdapGroupsMapping.getDirContext(LdapGroupsMapping.java:575)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:429)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:360)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:364)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: javax.naming.NamingException: LDAP response read timed out, timeout used: 3000 ms.
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.ldapBind(LdapClient.java:365)
	at com.sun.jndi.ldap.LdapClient.authenticate(LdapClient.java:214)
	at com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2897)
	at com.sun.jndi.ldap.LdapCtx.<init>(LdapCtx.java:347)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxFromUrl(LdapCtxFactory.java:229)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURL(LdapCtxFactory.java:189)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURLs(LdapCtxFactory.java:247)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxInstance(LdapCtxFactory.java:154)
	at com.sun.jndi.ldap.LdapCtxFactory.getInitialContext(LdapCtxFactory.java:84)
	at javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:695)
	at javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:313)
	at javax.naming.InitialContext.init(InitialContext.java:244)
	at javax.naming.InitialContext.<init>(InitialContext.java:216)
	at javax.naming.directory.InitialDirContext.<init>(InitialDirContext.java:101)
	at org.apache.hadoop.security.LdapGroupsMapping.getDirContext(LdapGroupsMapping.java:575)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:429)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:360)
	... 9 more

[ERROR] testLdapReadTimeout(org.apache.hadoop.security.TestLdapGroupsMapping)  Time elapsed: 4.008 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'LDAP response read timed out, timeout used:4000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 4000 ms.; remaining name ''
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.getSearchReply(LdapClient.java:638)
	at com.sun.jndi.ldap.LdapClient.search(LdapClient.java:561)
	at com.sun.jndi.ldap.LdapCtx.doSearch(LdapCtx.java:2013)
	at com.sun.jndi.ldap.LdapCtx.searchAux(LdapCtx.java:1872)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1797)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1814)
	at com.sun.jndi.toolkit.ctx.ComponentDirContext.p_search(ComponentDirContext.java:418)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:396)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:378)
	at javax.naming.directory.InitialDirContext.search(InitialDirContext.java:286)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:432)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:416)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:420)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: javax.naming.NamingException: LDAP response read timed out, timeout used: 4000 ms.; remaining name ''
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.getSearchReply(LdapClient.java:638)
	at com.sun.jndi.ldap.LdapClient.search(LdapClient.java:561)
	at com.sun.jndi.ldap.LdapCtx.doSearch(LdapCtx.java:2013)
	at com.sun.jndi.ldap.LdapCtx.searchAux(LdapCtx.java:1872)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1797)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1814)
	at com.sun.jndi.toolkit.ctx.ComponentDirContext.p_search(ComponentDirContext.java:418)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:396)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:378)
	at javax.naming.directory.InitialDirContext.search(InitialDirContext.java:286)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:432)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:416)
	... 9 more

[ERROR] testLdapConnectionTimeout(org.apache.hadoop.security.TestLdapGroupsMapping)  Time elapsed: 3.024 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'LDAP response read timed out, timeout used:3000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 3000 ms.
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.ldapBind(LdapClient.java:365)
	at com.sun.jndi.ldap.LdapClient.authenticate(LdapClient.java:214)
	at com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2897)
	at com.sun.jndi.ldap.LdapCtx.<init>(LdapCtx.java:347)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxFromUrl(LdapCtxFactory.java:229)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURL(LdapCtxFactory.java:189)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURLs(LdapCtxFactory.java:247)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxInstance(LdapCtxFactory.java:154)
	at com.sun.jndi.ldap.LdapCtxFactory.getInitialContext(LdapCtxFactory.java:84)
	at javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:695)
	at javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:313)
	at javax.naming.InitialContext.init(InitialContext.java:244)
	at javax.naming.InitialContext.<init>(InitialContext.java:216)
	at javax.naming.directory.InitialDirContext.<init>(InitialDirContext.java:101)
	at org.apache.hadoop.security.LdapGroupsMapping.getDirContext(LdapGroupsMapping.java:575)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:429)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:360)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:364)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: javax.naming.NamingException: LDAP response read timed out, timeout used: 3000 ms.
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.ldapBind(LdapClient.java:365)
	at com.sun.jndi.ldap.LdapClient.authenticate(LdapClient.java:214)
	at com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2897)
	at com.sun.jndi.ldap.LdapCtx.<init>(LdapCtx.java:347)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxFromUrl(LdapCtxFactory.java:229)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURL(LdapCtxFactory.java:189)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURLs(LdapCtxFactory.java:247)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxInstance(LdapCtxFactory.java:154)
	at com.sun.jndi.ldap.LdapCtxFactory.getInitialContext(LdapCtxFactory.java:84)
	at javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:695)
	at javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:313)
	at javax.naming.InitialContext.init(InitialContext.java:244)
	at javax.naming.InitialContext.<init>(InitialContext.java:216)
	at javax.naming.directory.InitialDirContext.<init>(InitialDirContext.java:101)
	at org.apache.hadoop.security.LdapGroupsMapping.getDirContext(LdapGroupsMapping.java:575)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:429)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:360)
	... 9 more

[ERROR] testLdapReadTimeout(org.apache.hadoop.security.TestLdapGroupsMapping)  Time elapsed: 4.011 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'LDAP response read timed out, timeout used:4000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 4000 ms.; remaining name ''
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.getSearchReply(LdapClient.java:638)
	at com.sun.jndi.ldap.LdapClient.search(LdapClient.java:561)
	at com.sun.jndi.ldap.LdapCtx.doSearch(LdapCtx.java:2013)
	at com.sun.jndi.ldap.LdapCtx.searchAux(LdapCtx.java:1872)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1797)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1814)
	at com.sun.jndi.toolkit.ctx.ComponentDirContext.p_search(ComponentDirContext.java:418)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:396)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:378)
	at javax.naming.directory.InitialDirContext.search(InitialDirContext.java:286)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:432)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:416)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:420)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: javax.naming.NamingException: LDAP response read timed out, timeout used: 4000 ms.; remaining name ''
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.getSearchReply(LdapClient.java:638)
	at com.sun.jndi.ldap.LdapClient.search(LdapClient.java:561)
	at com.sun.jndi.ldap.LdapCtx.doSearch(LdapCtx.java:2013)
	at com.sun.jndi.ldap.LdapCtx.searchAux(LdapCtx.java:1872)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1797)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1814)
	at com.sun.jndi.toolkit.ctx.ComponentDirContext.p_search(ComponentDirContext.java:418)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:396)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:378)
	at javax.naming.directory.InitialDirContext.search(InitialDirContext.java:286)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:432)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:416)
	... 9 more

[ERROR] testLdapConnectionTimeout(org.apache.hadoop.security.TestLdapGroupsMapping)  Time elapsed: 3.018 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'LDAP response read timed out, timeout used:3000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 3000 ms.
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.ldapBind(LdapClient.java:365)
	at com.sun.jndi.ldap.LdapClient.authenticate(LdapClient.java:214)
	at com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2897)
	at com.sun.jndi.ldap.LdapCtx.<init>(LdapCtx.java:347)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxFromUrl(LdapCtxFactory.java:229)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURL(LdapCtxFactory.java:189)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURLs(LdapCtxFactory.java:247)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxInstance(LdapCtxFactory.java:154)
	at com.sun.jndi.ldap.LdapCtxFactory.getInitialContext(LdapCtxFactory.java:84)
	at javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:695)
	at javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:313)
	at javax.naming.InitialContext.init(InitialContext.java:244)
	at javax.naming.InitialContext.<init>(InitialContext.java:216)
	at javax.naming.directory.InitialDirContext.<init>(InitialDirContext.java:101)
	at org.apache.hadoop.security.LdapGroupsMapping.getDirContext(LdapGroupsMapping.java:575)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:429)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:360)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:364)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: javax.naming.NamingException: LDAP response read timed out, timeout used: 3000 ms.
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.ldapBind(LdapClient.java:365)
	at com.sun.jndi.ldap.LdapClient.authenticate(LdapClient.java:214)
	at com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2897)
	at com.sun.jndi.ldap.LdapCtx.<init>(LdapCtx.java:347)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxFromUrl(LdapCtxFactory.java:229)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURL(LdapCtxFactory.java:189)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURLs(LdapCtxFactory.java:247)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxInstance(LdapCtxFactory.java:154)
	at com.sun.jndi.ldap.LdapCtxFactory.getInitialContext(LdapCtxFactory.java:84)
	at javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:695)
	at javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:313)
	at javax.naming.InitialContext.init(InitialContext.java:244)
	at javax.naming.InitialContext.<init>(InitialContext.java:216)
	at javax.naming.directory.InitialDirContext.<init>(InitialDirContext.java:101)
	at org.apache.hadoop.security.LdapGroupsMapping.getDirContext(LdapGroupsMapping.java:575)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:429)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:360)
	... 9 more

[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.665 s - in org.apache.hadoop.security.token.TestDtUtilShell
[INFO] Running org.apache.hadoop.security.TestIngressPortBasedResolver
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.194 s - in org.apache.hadoop.security.TestIngressPortBasedResolver
[INFO] Running org.apache.hadoop.security.TestAuthenticationFilter
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.285 s - in org.apache.hadoop.security.TestAuthenticationFilter
[INFO] Running org.apache.hadoop.http.TestHttpServerWebapps
[INFO] Running org.apache.hadoop.http.TestHttpRequestLog
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.385 s - in org.apache.hadoop.http.TestHttpServerWebapps
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.131 s - in org.apache.hadoop.http.TestHttpRequestLog
[INFO] Running org.apache.hadoop.http.TestGlobalFilter
[INFO] Running org.apache.hadoop.http.TestHttpServerLogs
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.606 s - in org.apache.hadoop.http.TestGlobalFilter
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.592 s - in org.apache.hadoop.http.TestHttpServerLogs
[INFO] Running org.apache.hadoop.http.TestHttpServerLifecycle
[INFO] Running org.apache.hadoop.http.TestHttpServer
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.645 s - in org.apache.hadoop.http.TestHttpServerLifecycle
[INFO] Running org.apache.hadoop.http.TestHtmlQuoting
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.184 s - in org.apache.hadoop.http.TestHtmlQuoting
[INFO] Running org.apache.hadoop.http.lib.TestStaticUserWebFilter
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.421 s - in org.apache.hadoop.http.lib.TestStaticUserWebFilter
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.408 s - in org.apache.hadoop.http.TestHttpServer
[INFO] Running org.apache.hadoop.http.TestPathFilter
[INFO] Running org.apache.hadoop.http.TestHttpRequestLogAppender
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.061 s - in org.apache.hadoop.http.TestHttpRequestLogAppender
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.59 s - in org.apache.hadoop.http.TestPathFilter
[INFO] Running org.apache.hadoop.http.TestSSLHttpServer
[INFO] Running org.apache.hadoop.http.TestServletFilter
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.889 s - in org.apache.hadoop.http.TestServletFilter
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.354 s - in org.apache.hadoop.http.TestSSLHttpServer
[INFO] Running org.apache.hadoop.http.TestAuthenticationSessionCookie
[INFO] Running org.apache.hadoop.http.TestHttpCookieFlag
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.154 s - in org.apache.hadoop.http.TestAuthenticationSessionCookie
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.191 s - in org.apache.hadoop.http.TestHttpCookieFlag
[INFO] Running org.apache.hadoop.test.TestGenericTestUtils
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.112 s - in org.apache.hadoop.test.TestGenericTestUtils
[INFO] Running org.apache.hadoop.test.TestJUnitSetup
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.092 s - in org.apache.hadoop.test.TestJUnitSetup
[INFO] Running org.apache.hadoop.test.TestLambdaTestUtils
[INFO] Running org.apache.hadoop.test.TestTimedOutTestsListener
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.104 s - in org.apache.hadoop.test.TestTimedOutTestsListener
[INFO] Tests run: 34, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.623 s - in org.apache.hadoop.test.TestLambdaTestUtils
[INFO] Running org.apache.hadoop.test.TestMultithreadedTestUtil
[INFO] Running org.apache.hadoop.tools.TestCommandShell
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.103 s - in org.apache.hadoop.tools.TestCommandShell
[INFO] Running org.apache.hadoop.ipc.TestMultipleProtocolServer
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.46 s - in org.apache.hadoop.ipc.TestMultipleProtocolServer
[INFO] Running org.apache.hadoop.ipc.TestRPCCallBenchmark
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.316 s - in org.apache.hadoop.test.TestMultithreadedTestUtil
[INFO] Running org.apache.hadoop.ipc.TestProtoBufRpcServerHandoff
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.404 s - in org.apache.hadoop.ipc.TestRPCCallBenchmark
[INFO] Running org.apache.hadoop.ipc.TestSaslRPC
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.836 s - in org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager
[INFO] Running org.apache.hadoop.ipc.TestFairCallQueue
[INFO] Tests run: 26, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.629 s - in org.apache.hadoop.ipc.TestFairCallQueue
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.455 s - in org.apache.hadoop.security.token.delegation.TestDelegationToken
[INFO] Running org.apache.hadoop.ipc.TestIPCServerResponder
[INFO] Running org.apache.hadoop.ipc.TestRPC
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.028 s - in org.apache.hadoop.ipc.TestProtoBufRpcServerHandoff
[INFO] Running org.apache.hadoop.ipc.TestRPCWaitForProxy
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.027 s - in org.apache.hadoop.ipc.TestIPCServerResponder
[INFO] Running org.apache.hadoop.ipc.TestRPCCompatibility
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.159 s - in org.apache.hadoop.ipc.TestRPCCompatibility
[INFO] Running org.apache.hadoop.ipc.TestAsyncIPC
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.358 s - in org.apache.hadoop.ipc.TestRPCWaitForProxy
[INFO] Running org.apache.hadoop.ipc.TestServer
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.447 s - in org.apache.hadoop.ipc.TestServer
[INFO] Running org.apache.hadoop.ipc.TestReuseRpcConnections
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.546 s - in org.apache.hadoop.ipc.TestReuseRpcConnections
[INFO] Running org.apache.hadoop.ipc.TestRpcWritable
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.128 s - in org.apache.hadoop.ipc.TestRpcWritable
[INFO] Running org.apache.hadoop.ipc.TestRetryCacheMetrics
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.24 s - in org.apache.hadoop.ipc.TestRetryCacheMetrics
[INFO] Running org.apache.hadoop.ipc.TestRPCServerShutdown
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.594 s - in org.apache.hadoop.ipc.TestRPCServerShutdown
[INFO] Running org.apache.hadoop.ipc.TestWeightedRoundRobinMultiplexer
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.212 s - in org.apache.hadoop.ipc.TestWeightedRoundRobinMultiplexer
[INFO] Running org.apache.hadoop.ipc.TestCallQueueManager
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.915 s - in org.apache.hadoop.ipc.TestCallQueueManager
[INFO] Tests run: 90, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.083 s - in org.apache.hadoop.ipc.TestSaslRPC
[INFO] Running org.apache.hadoop.ipc.TestProtoBufRPCCompatibility
[INFO] Running org.apache.hadoop.ipc.TestRpcServerHandoff
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.499 s - in org.apache.hadoop.ipc.TestProtoBufRPCCompatibility
[INFO] Tests run: 23, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.576 s - in org.apache.hadoop.ipc.TestRPC
[INFO] Running org.apache.hadoop.ipc.TestProtoBufRpc
[INFO] Running org.apache.hadoop.ipc.TestMiniRPCBenchmark
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.45 s - in org.apache.hadoop.ipc.TestMiniRPCBenchmark
[INFO] Running org.apache.hadoop.ipc.TestResponseBuffer
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.057 s - in org.apache.hadoop.ipc.TestResponseBuffer
[INFO] Running org.apache.hadoop.ipc.TestRetryCache
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.158 s - in org.apache.hadoop.ipc.TestRetryCache
[INFO] Running org.apache.hadoop.ipc.TestSocketFactory
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.323 s - in org.apache.hadoop.ipc.TestSocketFactory
[INFO] Running org.apache.hadoop.ipc.TestIdentityProviders
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.266 s - in org.apache.hadoop.ipc.TestIdentityProviders
[INFO] Running org.apache.hadoop.ipc.TestDecayRpcScheduler
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.479 s - in org.apache.hadoop.ipc.TestRpcServerHandoff
[INFO] Running org.apache.hadoop.ipc.TestIPC
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.837 s - in org.apache.hadoop.ipc.TestDecayRpcScheduler
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.343 s - in org.apache.hadoop.ipc.TestProtoBufRpc
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.17 s - in org.apache.hadoop.ipc.TestAsyncIPC
[INFO] Tests run: 39, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 84.172 s - in org.apache.hadoop.ipc.TestIPC
[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Failures: 
[ERROR] org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(org.apache.hadoop.io.compress.TestCompressorDecompressor)
[ERROR]   Run 1: TestCompressorDecompressor.testCompressorDecompressor:69  Expected to find 'testCompressorDecompressor error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:66)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[ERROR]   Run 2: TestCompressorDecompressor.testCompressorDecompressor:69  Expected to find 'testCompressorDecompressor error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:66)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[ERROR]   Run 3: TestCompressorDecompressor.testCompressorDecompressor:69  Expected to find 'testCompressorDecompressor error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:66)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[ERROR]   Run 4: TestCompressorDecompressor.testCompressorDecompressor:69  Expected to find 'testCompressorDecompressor error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:66)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[INFO] 
[ERROR] org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(org.apache.hadoop.io.compress.TestCompressorDecompressor)
[ERROR]   Run 1: TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit:92  Expected to find 'testCompressorDecompressorWithExeedBufferLimit error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[ERROR]   Run 2: TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit:92  Expected to find 'testCompressorDecompressorWithExeedBufferLimit error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[ERROR]   Run 3: TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit:92  Expected to find 'testCompressorDecompressorWithExeedBufferLimit error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[ERROR]   Run 4: TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit:92  Expected to find 'testCompressorDecompressorWithExeedBufferLimit error !!!' but got unexpected exception: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at com.google.common.base.Joiner.toString(Joiner.java:532)
	at com.google.common.base.Joiner.appendTo(Joiner.java:124)
	at com.google.common.base.Joiner.appendTo(Joiner.java:181)
	at com.google.common.base.Joiner.join(Joiner.java:237)
	at com.google.common.base.Joiner.join(Joiner.java:226)
	at com.google.common.base.Joiner.join(Joiner.java:253)
	at org.apache.hadoop.io.compress.CompressDecompressTester$CompressionTestStrategy$2.assertCompression(CompressDecompressTester.java:329)
	at org.apache.hadoop.io.compress.CompressDecompressTester.test(CompressDecompressTester.java:135)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit(TestCompressorDecompressor.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[INFO] 
[ERROR] org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(org.apache.hadoop.security.TestLdapGroupsMapping)
[ERROR]   Run 1: TestLdapGroupsMapping.testLdapConnectionTimeout:364  Expected to find 'LDAP response read timed out, timeout used:3000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 3000 ms.
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.ldapBind(LdapClient.java:365)
	at com.sun.jndi.ldap.LdapClient.authenticate(LdapClient.java:214)
	at com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2897)
	at com.sun.jndi.ldap.LdapCtx.<init>(LdapCtx.java:347)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxFromUrl(LdapCtxFactory.java:229)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURL(LdapCtxFactory.java:189)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURLs(LdapCtxFactory.java:247)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxInstance(LdapCtxFactory.java:154)
	at com.sun.jndi.ldap.LdapCtxFactory.getInitialContext(LdapCtxFactory.java:84)
	at javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:695)
	at javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:313)
	at javax.naming.InitialContext.init(InitialContext.java:244)
	at javax.naming.InitialContext.<init>(InitialContext.java:216)
	at javax.naming.directory.InitialDirContext.<init>(InitialDirContext.java:101)
	at org.apache.hadoop.security.LdapGroupsMapping.getDirContext(LdapGroupsMapping.java:575)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:429)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:360)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR]   Run 2: TestLdapGroupsMapping.testLdapConnectionTimeout:364  Expected to find 'LDAP response read timed out, timeout used:3000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 3000 ms.
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.ldapBind(LdapClient.java:365)
	at com.sun.jndi.ldap.LdapClient.authenticate(LdapClient.java:214)
	at com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2897)
	at com.sun.jndi.ldap.LdapCtx.<init>(LdapCtx.java:347)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxFromUrl(LdapCtxFactory.java:229)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURL(LdapCtxFactory.java:189)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURLs(LdapCtxFactory.java:247)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxInstance(LdapCtxFactory.java:154)
	at com.sun.jndi.ldap.LdapCtxFactory.getInitialContext(LdapCtxFactory.java:84)
	at javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:695)
	at javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:313)
	at javax.naming.InitialContext.init(InitialContext.java:244)
	at javax.naming.InitialContext.<init>(InitialContext.java:216)
	at javax.naming.directory.InitialDirContext.<init>(InitialDirContext.java:101)
	at org.apache.hadoop.security.LdapGroupsMapping.getDirContext(LdapGroupsMapping.java:575)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:429)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:360)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR]   Run 3: TestLdapGroupsMapping.testLdapConnectionTimeout:364  Expected to find 'LDAP response read timed out, timeout used:3000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 3000 ms.
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.ldapBind(LdapClient.java:365)
	at com.sun.jndi.ldap.LdapClient.authenticate(LdapClient.java:214)
	at com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2897)
	at com.sun.jndi.ldap.LdapCtx.<init>(LdapCtx.java:347)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxFromUrl(LdapCtxFactory.java:229)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURL(LdapCtxFactory.java:189)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURLs(LdapCtxFactory.java:247)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxInstance(LdapCtxFactory.java:154)
	at com.sun.jndi.ldap.LdapCtxFactory.getInitialContext(LdapCtxFactory.java:84)
	at javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:695)
	at javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:313)
	at javax.naming.InitialContext.init(InitialContext.java:244)
	at javax.naming.InitialContext.<init>(InitialContext.java:216)
	at javax.naming.directory.InitialDirContext.<init>(InitialDirContext.java:101)
	at org.apache.hadoop.security.LdapGroupsMapping.getDirContext(LdapGroupsMapping.java:575)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:429)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:360)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR]   Run 4: TestLdapGroupsMapping.testLdapConnectionTimeout:364  Expected to find 'LDAP response read timed out, timeout used:3000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 3000 ms.
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.ldapBind(LdapClient.java:365)
	at com.sun.jndi.ldap.LdapClient.authenticate(LdapClient.java:214)
	at com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2897)
	at com.sun.jndi.ldap.LdapCtx.<init>(LdapCtx.java:347)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxFromUrl(LdapCtxFactory.java:229)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURL(LdapCtxFactory.java:189)
	at com.sun.jndi.ldap.LdapCtxFactory.getUsingURLs(LdapCtxFactory.java:247)
	at com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxInstance(LdapCtxFactory.java:154)
	at com.sun.jndi.ldap.LdapCtxFactory.getInitialContext(LdapCtxFactory.java:84)
	at javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:695)
	at javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:313)
	at javax.naming.InitialContext.init(InitialContext.java:244)
	at javax.naming.InitialContext.<init>(InitialContext.java:216)
	at javax.naming.directory.InitialDirContext.<init>(InitialDirContext.java:101)
	at org.apache.hadoop.security.LdapGroupsMapping.getDirContext(LdapGroupsMapping.java:575)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:429)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:360)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[INFO] 
[ERROR] org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(org.apache.hadoop.security.TestLdapGroupsMapping)
[ERROR]   Run 1: TestLdapGroupsMapping.testLdapReadTimeout:420  Expected to find 'LDAP response read timed out, timeout used:4000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 4000 ms.; remaining name ''
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.getSearchReply(LdapClient.java:638)
	at com.sun.jndi.ldap.LdapClient.search(LdapClient.java:561)
	at com.sun.jndi.ldap.LdapCtx.doSearch(LdapCtx.java:2013)
	at com.sun.jndi.ldap.LdapCtx.searchAux(LdapCtx.java:1872)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1797)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1814)
	at com.sun.jndi.toolkit.ctx.ComponentDirContext.p_search(ComponentDirContext.java:418)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:396)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:378)
	at javax.naming.directory.InitialDirContext.search(InitialDirContext.java:286)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:432)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:416)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR]   Run 2: TestLdapGroupsMapping.testLdapReadTimeout:420  Expected to find 'LDAP response read timed out, timeout used:4000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 4000 ms.; remaining name ''
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.getSearchReply(LdapClient.java:638)
	at com.sun.jndi.ldap.LdapClient.search(LdapClient.java:561)
	at com.sun.jndi.ldap.LdapCtx.doSearch(LdapCtx.java:2013)
	at com.sun.jndi.ldap.LdapCtx.searchAux(LdapCtx.java:1872)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1797)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1814)
	at com.sun.jndi.toolkit.ctx.ComponentDirContext.p_search(ComponentDirContext.java:418)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:396)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:378)
	at javax.naming.directory.InitialDirContext.search(InitialDirContext.java:286)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:432)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:416)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR]   Run 3: TestLdapGroupsMapping.testLdapReadTimeout:420  Expected to find 'LDAP response read timed out, timeout used:4000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 4000 ms.; remaining name ''
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.getSearchReply(LdapClient.java:638)
	at com.sun.jndi.ldap.LdapClient.search(LdapClient.java:561)
	at com.sun.jndi.ldap.LdapCtx.doSearch(LdapCtx.java:2013)
	at com.sun.jndi.ldap.LdapCtx.searchAux(LdapCtx.java:1872)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1797)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1814)
	at com.sun.jndi.toolkit.ctx.ComponentDirContext.p_search(ComponentDirContext.java:418)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:396)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:378)
	at javax.naming.directory.InitialDirContext.search(InitialDirContext.java:286)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:432)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:416)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR]   Run 4: TestLdapGroupsMapping.testLdapReadTimeout:420  Expected to find 'LDAP response read timed out, timeout used:4000ms' but got unexpected exception: javax.naming.NamingException: LDAP response read timed out, timeout used: 4000 ms.; remaining name ''
	at com.sun.jndi.ldap.LdapRequest.getReplyBer(LdapRequest.java:129)
	at com.sun.jndi.ldap.Connection.readReply(Connection.java:469)
	at com.sun.jndi.ldap.LdapClient.getSearchReply(LdapClient.java:638)
	at com.sun.jndi.ldap.LdapClient.search(LdapClient.java:561)
	at com.sun.jndi.ldap.LdapCtx.doSearch(LdapCtx.java:2013)
	at com.sun.jndi.ldap.LdapCtx.searchAux(LdapCtx.java:1872)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1797)
	at com.sun.jndi.ldap.LdapCtx.c_search(LdapCtx.java:1814)
	at com.sun.jndi.toolkit.ctx.ComponentDirContext.p_search(ComponentDirContext.java:418)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:396)
	at com.sun.jndi.toolkit.ctx.PartialCompositeDirContext.search(PartialCompositeDirContext.java:378)
	at javax.naming.directory.InitialDirContext.search(InitialDirContext.java:286)
	at org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:432)
	at org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:416)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[INFO] 
[ERROR] Errors: 
[ERROR] org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompress(org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor)
[ERROR]   Run 1: TestSnappyCompressorDecompressor.testSnappyCompressDecompress:192 ? Internal C...
[ERROR]   Run 2: TestSnappyCompressorDecompressor.testSnappyCompressDecompress:192 ? Internal C...
[ERROR]   Run 3: TestSnappyCompressorDecompressor.testSnappyCompressDecompress:192 ? Internal C...
[ERROR]   Run 4: TestSnappyCompressorDecompressor.testSnappyCompressDecompress:192 ? Internal C...
[INFO] 
[ERROR] org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompressInMultiThreads(org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor)
[ERROR]   Run 1: TestSnappyCompressorDecompressor.testSnappyCompressDecompressInMultiThreads:409 ? Runtime
[ERROR]   Run 2: TestSnappyCompressorDecompressor.testSnappyCompressDecompressInMultiThreads:409 ? Runtime
[ERROR]   Run 3: TestSnappyCompressorDecompressor.testSnappyCompressDecompressInMultiThreads:409 ? Runtime
[ERROR]   Run 4: TestSnappyCompressorDecompressor.testSnappyCompressDecompressInMultiThreads:409 ? Runtime
[INFO] 
[ERROR] org.apache.hadoop.util.TestReadWriteDiskValidator.testCheckFailures(org.apache.hadoop.util.TestReadWriteDiskValidator)
[ERROR]   Run 1: TestReadWriteDiskValidator.testCheckFailures:114 ? NoSuchFile /tdp/hadoop/hado...
[ERROR]   Run 2: TestReadWriteDiskValidator.testCheckFailures:114 ? NoSuchFile /tdp/hadoop/hado...
[ERROR]   Run 3: TestReadWriteDiskValidator.testCheckFailures:114 ? NoSuchFile /tdp/hadoop/hado...
[ERROR]   Run 4: TestReadWriteDiskValidator.testCheckFailures:114 ? NoSuchFile /tdp/hadoop/hado...
[INFO] 
[ERROR] org.apache.hadoop.util.TestReadWriteDiskValidator.testReadWriteDiskValidator(org.apache.hadoop.util.TestReadWriteDiskValidator)
[ERROR]   Run 1: TestReadWriteDiskValidator.testReadWriteDiskValidator:62 ? DiskError Disk Chec...
[ERROR]   Run 2: TestReadWriteDiskValidator.testReadWriteDiskValidator:62 ? DiskError Disk Chec...
[ERROR]   Run 3: TestReadWriteDiskValidator.testReadWriteDiskValidator:62 ? DiskError Disk Chec...
[ERROR]   Run 4: TestReadWriteDiskValidator.testReadWriteDiskValidator:62 ? DiskError Disk Chec...
[INFO] 
[INFO] 
[ERROR] Tests run: 4052, Failures: 4, Errors: 4, Skipped: 120
[INFO] 
[INFO] 
[INFO] --------------------< org.apache.hadoop:hadoop-nfs >--------------------
[INFO] Building Apache Hadoop NFS 3.1.1-TDP-0.1.0-SNAPSHOT              [12/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-nfs ---
[INFO] Deleting /tdp/hadoop/hadoop-common-project/hadoop-nfs/target
[INFO] Deleting /tdp/hadoop/hadoop-common-project/hadoop-nfs (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-nfs ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-common-project/hadoop-nfs/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-nfs ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-nfs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-common-project/hadoop-nfs/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-nfs ---
[INFO] Compiling 94 source files to /tdp/hadoop/hadoop-common-project/hadoop-nfs/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-nfs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-nfs ---
[INFO] Compiling 14 source files to /tdp/hadoop/hadoop-common-project/hadoop-nfs/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-nfs ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.portmap.TestPortmap
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.493 s - in org.apache.hadoop.portmap.TestPortmap
[INFO] Running org.apache.hadoop.oncrpc.TestRpcMessage
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.052 s - in org.apache.hadoop.oncrpc.TestRpcMessage
[INFO] Running org.apache.hadoop.oncrpc.TestRpcCall
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.099 s - in org.apache.hadoop.oncrpc.TestRpcCall
[INFO] Running org.apache.hadoop.oncrpc.TestRpcDeniedReply
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.054 s - in org.apache.hadoop.oncrpc.TestRpcDeniedReply
[INFO] Running org.apache.hadoop.oncrpc.TestRpcReply
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.052 s - in org.apache.hadoop.oncrpc.TestRpcReply
[INFO] Running org.apache.hadoop.oncrpc.TestFrameDecoder
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.352 s - in org.apache.hadoop.oncrpc.TestFrameDecoder
[INFO] Running org.apache.hadoop.oncrpc.TestRpcAcceptedReply
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.05 s - in org.apache.hadoop.oncrpc.TestRpcAcceptedReply
[INFO] Running org.apache.hadoop.oncrpc.security.TestRpcAuthInfo
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.05 s - in org.apache.hadoop.oncrpc.security.TestRpcAuthInfo
[INFO] Running org.apache.hadoop.oncrpc.security.TestCredentialsSys
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.096 s - in org.apache.hadoop.oncrpc.security.TestCredentialsSys
[INFO] Running org.apache.hadoop.oncrpc.TestRpcCallCache
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.146 s - in org.apache.hadoop.oncrpc.TestRpcCallCache
[INFO] Running org.apache.hadoop.oncrpc.TestXDR
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.3 s - in org.apache.hadoop.oncrpc.TestXDR
[INFO] Running org.apache.hadoop.nfs.nfs3.TestFileHandle
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.1 s - in org.apache.hadoop.nfs.nfs3.TestFileHandle
[INFO] Running org.apache.hadoop.nfs.TestNfsExports
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.119 s - in org.apache.hadoop.nfs.TestNfsExports
[INFO] Running org.apache.hadoop.nfs.TestNfsTime
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.052 s - in org.apache.hadoop.nfs.TestNfsTime
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 54, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] --------------------< org.apache.hadoop:hadoop-kms >--------------------
[INFO] Building Apache Hadoop KMS 3.1.1-TDP-0.1.0-SNAPSHOT              [13/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-kms ---
[INFO] Deleting /tdp/hadoop/hadoop-common-project/hadoop-kms/target
[INFO] Deleting /tdp/hadoop/hadoop-common-project/hadoop-kms (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-kms ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-common-project/hadoop-kms/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-kms ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-kms ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-kms ---
[INFO] Compiling 16 source files to /tdp/hadoop/hadoop-common-project/hadoop-kms/target/classes
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-kms/src/main/java/org/apache/hadoop/crypto/key/kms/server/KMS.java:[589,19] [unchecked] unchecked call to add(E) as a member of the raw type List
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-kms ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-kms ---
[INFO] Compiling 6 source files to /tdp/hadoop/hadoop-common-project/hadoop-kms/target/test-classes
[WARNING] /tdp/hadoop/hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java:[893,41] [unchecked] unchecked cast
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-kms ---
[WARNING] The parameter forkMode is deprecated since version 2.14. Use forkCount and reuseForks instead.
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.crypto.key.kms.server.TestKeyAuthorizationKeyProvider
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.441 s - in org.apache.hadoop.crypto.key.kms.server.TestKeyAuthorizationKeyProvider
[INFO] Running org.apache.hadoop.crypto.key.kms.server.TestKMSAudit
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.374 s - in org.apache.hadoop.crypto.key.kms.server.TestKMSAudit
[INFO] Running org.apache.hadoop.crypto.key.kms.server.TestKMSACLs
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.285 s - in org.apache.hadoop.crypto.key.kms.server.TestKMSACLs
[INFO] Running org.apache.hadoop.crypto.key.kms.server.TestKMSWithZK
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.033 s - in org.apache.hadoop.crypto.key.kms.server.TestKMSWithZK
[INFO] Running org.apache.hadoop.crypto.key.kms.server.TestKMS
[INFO] Tests run: 30, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 125.45 s - in org.apache.hadoop.crypto.key.kms.server.TestKMS
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 43, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] --------------< org.apache.hadoop:hadoop-common-project >---------------
[INFO] Building Apache Hadoop Common Project 3.1.1-TDP-0.1.0-SNAPSHOT   [14/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-common-project ---
[INFO] Deleting /tdp/hadoop/hadoop-common-project/target
[INFO] Deleting /tdp/hadoop/hadoop-common-project (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-common-project ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-common-project/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-common-project ---
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-hdfs-client >----------------
[INFO] Building Apache Hadoop HDFS Client 3.1.1-TDP-0.1.0-SNAPSHOT      [15/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-hdfs-client ---
[INFO] Deleting /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/target
[INFO] Deleting /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-hdfs-client ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/target/test/data
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:protoc (compile-protoc) @ hadoop-hdfs-client ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdfs-client ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdfs-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdfs-client ---
[INFO] Compiling 288 source files to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/target/classes
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java:[92,38] [deprecation] FsPermissionExtension in org.apache.hadoop.hdfs.protocol has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitShm.java:[40,15] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/HdfsFileStatus.java:[498,21] [deprecation] FsPermissionExtension in org.apache.hadoop.hdfs.protocol has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/HdfsFileStatus.java:[500,14] [deprecation] getAclBit() in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/HdfsFileStatus.java:[501,14] [deprecation] getEncryptedBit() in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/HdfsFileStatus.java:[502,14] [deprecation] getErasureCodedBit() in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/HdfsFileStatus.java:[514,15] [deprecation] FsPermissionExtension in org.apache.hadoop.hdfs.protocol has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitShm.java:[57,23] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitShm.java:[59,17] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitShm.java:[61,16] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitShm.java:[63,14] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java:[1796,25] [deprecation] FsPermissionExtension in org.apache.hadoop.hdfs.protocol has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java:[1797,9] [deprecation] getAclBit() in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java:[1800,9] [deprecation] getEncryptedBit() in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java:[1803,9] [deprecation] getErasureCodedBit() in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java:[1928,31] [deprecation] getStorageUuid() in StorageReportProto has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java:[1976,25] [deprecation] GET_STATS_UNDER_REPLICATED_IDX in ClientProtocol has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java:[2392,40] [deprecation] GET_STATS_UNDER_REPLICATED_IDX in ClientProtocol has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java:[2394,32] [deprecation] GET_STATS_UNDER_REPLICATED_IDX in ClientProtocol has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java:[2608,8] [deprecation] setStorageUuid(String) in Builder has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/NameNodeProxiesClient.java:[357,36] [deprecation] getTimeout(Configuration) in Client has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java:[197,14] [deprecation] getDefaultBlockSize() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java:[202,15] [deprecation] getDefaultReplication() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java:[602,33] [deprecation] primitiveCreate(Path,FsPermission,EnumSet<CreateFlag>,int,short,long,Progressable,ChecksumOpt) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java:[1563,26] [deprecation] getServerDefaults() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java:[2121,48] [unchecked] unchecked conversion
[WARNING]   required: List<DiffReportListingEntry>
  found:    TreeList
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java:[148,38] [unchecked] unchecked conversion
[WARNING]   required: Map<String,Object>
  found:    Map
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java:[151,41] [unchecked] unchecked conversion
[WARNING]   required: Map<String,String>
  found:    Map
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java:[1408,14] [deprecation] getDefaultBlockSize() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java:[1414,15] [deprecation] getDefaultReplication() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java:[1909,26] [deprecation] getServerDefaults() in FileSystem has been deprecated
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-hdfs-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-hdfs-client ---
[INFO] Compiling 26 source files to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/target/test-classes
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/util/TestByteArrayManager.java:[52,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/util/TestByteArrayManager.java:[562,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java:[66,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-hdfs-client ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.fs.TestXAttr
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.049 s - in org.apache.hadoop.fs.TestXAttr
[INFO] Running org.apache.hadoop.fs.TestUrlStreamHandlerFactory
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.612 s - in org.apache.hadoop.fs.TestUrlStreamHandlerFactory
[INFO] Running org.apache.hadoop.hdfs.TestDFSOpsCountStatistics
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.125 s - in org.apache.hadoop.hdfs.TestDFSOpsCountStatistics
[INFO] Running org.apache.hadoop.hdfs.util.TestByteArrayManager
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.162 s - in org.apache.hadoop.hdfs.util.TestByteArrayManager
[INFO] Running org.apache.hadoop.hdfs.util.TestECPolicyLoader
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.17 s - in org.apache.hadoop.hdfs.util.TestECPolicyLoader
[INFO] Running org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.948 s - in org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer
[INFO] Running org.apache.hadoop.hdfs.TestPeerCache
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.233 s - in org.apache.hadoop.hdfs.TestPeerCache
[INFO] Running org.apache.hadoop.hdfs.protocol.TestHdfsFileStatusMethods
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.063 s - in org.apache.hadoop.hdfs.protocol.TestHdfsFileStatusMethods
[INFO] Running org.apache.hadoop.hdfs.protocol.TestErasureCodingPolicy
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.054 s - in org.apache.hadoop.hdfs.protocol.TestErasureCodingPolicy
[INFO] Running org.apache.hadoop.hdfs.protocol.TestErasureCodingPolicyInfo
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.051 s - in org.apache.hadoop.hdfs.protocol.TestErasureCodingPolicyInfo
[INFO] Running org.apache.hadoop.hdfs.protocol.TestBlockType
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.048 s - in org.apache.hadoop.hdfs.protocol.TestBlockType
[INFO] Running org.apache.hadoop.hdfs.protocol.TestExtendedBlock
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.051 s - in org.apache.hadoop.hdfs.protocol.TestExtendedBlock
[INFO] Running org.apache.hadoop.hdfs.TestDefaultNameNodePort
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.25 s - in org.apache.hadoop.hdfs.TestDefaultNameNodePort
[INFO] Running org.apache.hadoop.hdfs.web.oauth2.TestRefreshTokenTimeBasedTokenRefresher
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.053 s - in org.apache.hadoop.hdfs.web.oauth2.TestRefreshTokenTimeBasedTokenRefresher
[INFO] Running org.apache.hadoop.hdfs.web.oauth2.TestAccessTokenTimer
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.152 s - in org.apache.hadoop.hdfs.web.oauth2.TestAccessTokenTimer
[INFO] Running org.apache.hadoop.hdfs.web.oauth2.TestClientCredentialTimeBasedTokenRefresher
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.04 s - in org.apache.hadoop.hdfs.web.oauth2.TestClientCredentialTimeBasedTokenRefresher
[INFO] Running org.apache.hadoop.hdfs.web.TestTokenAspect
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.774 s - in org.apache.hadoop.hdfs.web.TestTokenAspect
[INFO] Running org.apache.hadoop.hdfs.web.TestWebHDFSOAuth2
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.199 s - in org.apache.hadoop.hdfs.web.TestWebHDFSOAuth2
[INFO] Running org.apache.hadoop.hdfs.web.TestByteRangeInputStream
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.252 s - in org.apache.hadoop.hdfs.web.TestByteRangeInputStream
[INFO] Running org.apache.hadoop.hdfs.web.TestURLConnectionFactory
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.372 s - in org.apache.hadoop.hdfs.web.TestURLConnectionFactory
[INFO] Running org.apache.hadoop.hdfs.web.TestOffsetUrlInputStream
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.321 s - in org.apache.hadoop.hdfs.web.TestOffsetUrlInputStream
[INFO] Running org.apache.hadoop.hdfs.web.TestWebHdfsContentLength
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.7 s - in org.apache.hadoop.hdfs.web.TestWebHdfsContentLength
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.735 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.81 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider
[INFO] Running org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.231 s - in org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm
[INFO] Running org.apache.hadoop.hdfs.TestDFSPacket
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.067 s - in org.apache.hadoop.hdfs.TestDFSPacket
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 83, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -------------------< org.apache.hadoop:hadoop-hdfs >--------------------
[INFO] Building Apache Hadoop HDFS 3.1.1-TDP-0.1.0-SNAPSHOT             [16/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-hdfs ---
[INFO] Deleting /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target
[INFO] Deleting /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/site/resources (includes = [configuration.xsl, hdfs-default.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-hdfs ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:protoc (compile-protoc) @ hadoop-hdfs ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdfs ---
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:resource-gz (resource-gz) @ hadoop-hdfs ---
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/d3-v4.1.1.min.js to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/d3-v4.1.1.min.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/json-bignum.js to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/json-bignum.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dataTables.bootstrap.css to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/dataTables.bootstrap.css.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dust-full-2.0.0.min.js to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/dust-full-2.0.0.min.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/hadoop.css to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/hadoop.css.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dataTables.bootstrap.js to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/dataTables.bootstrap.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/moment.min.js to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/moment.min.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/rest-csrf.js to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/rest-csrf.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/js/bootstrap.js to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/js/bootstrap.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/js/bootstrap-editable.min.js to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/js/bootstrap-editable.min.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/js/npm.js to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/js/npm.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/js/bootstrap.min.js to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/js/bootstrap.min.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/css/bootstrap.css to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/css/bootstrap.css.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/css/bootstrap.min.css to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/css/bootstrap.min.css.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/css/bootstrap-theme.css to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/css/bootstrap-theme.css.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/css/bootstrap-theme.min.css to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/css/bootstrap-theme.min.css.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/css/bootstrap-editable.css to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/css/bootstrap-editable.css.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/jquery.dataTables.min.js to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/jquery.dataTables.min.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dust-helpers-1.1.1.min.js to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/dust-helpers-1.1.1.min.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dfs-dust.js to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/dfs-dust.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/jquery-3.3.1.min.js to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/jquery-3.3.1.min.js.gz
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdfs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdfs ---
[INFO] Compiling 632 source files to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/classes
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/NameNodeConnector.java:[42,46] [deprecation] StreamCapability in StreamCapabilities has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ReencryptionHandler.java:[244,24] [unchecked] unchecked conversion
[WARNING]   required: ExecutorCompletionService<ReencryptionTask>
  found:    ExecutorCompletionService
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ReencryptionUpdater.java:[387,47] [unchecked] unchecked conversion
[WARNING]   required: Future<ReencryptionTask>
  found:    Future
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java:[990,17] [deprecation] Saver in FSImageFormat has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java:[990,49] [deprecation] Saver in FSImageFormat has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java:[1387,52] [unchecked] unchecked conversion
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java:[1974,17] [deprecation] write(DataOutput) in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java:[234,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/SlowDiskTracker.java:[222,13] [unchecked] unchecked call to ArrayList(Collection<? extends E>) as a member of the raw type ArrayList
[WARNING]   where E is a type-variable:
    E extends Object declared in class ArrayList
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/SlowDiskTracker.java:[222,13] [unchecked] unchecked conversion
[WARNING]   required: ArrayList<DiskLatency>
  found:    ArrayList
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:[833,17] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:[837,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:[1180,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:[1312,19] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:[1403,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:[1495,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:[1641,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/InvalidateBlocks.java:[141,24] [unchecked] unchecked method invocation: method put in interface Map is applied to given types
[WARNING]   required: K,V
  found: DatanodeInfo,LightWeightHashSet
  where K,V are type-variables:
    K extends Object declared in interface Map
    V extends Object declared in interface Map
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/InvalidateBlocks.java:[141,29] [unchecked] unchecked conversion
[WARNING]   required: V
  found:    LightWeightHashSet
  where V is a type-variable:
    V extends Object declared in interface Map
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/InvalidateBlocks.java:[144,22] [unchecked] unchecked method invocation: method put in interface Map is applied to given types
[WARNING]   required: K,V
  found: DatanodeInfo,LightWeightHashSet
  where K,V are type-variables:
    K extends Object declared in interface Map
    V extends Object declared in interface Map
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/InvalidateBlocks.java:[144,27] [unchecked] unchecked conversion
[WARNING]   required: V
  found:    LightWeightHashSet
  where V is a type-variable:
    V extends Object declared in interface Map
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java:[156,28] [unchecked] unchecked conversion
[WARNING]   required: Reader<BlockAlias>
  found:    Reader
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java:[767,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java:[300,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetAsyncDiskService.java:[337,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/ReplicaInputStreams.java:[133,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/ReplicaInputStreams.java:[149,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/DiffList.java:[31,24] [unchecked] unchecked call to DiffListByArrayList(List<T>) as a member of the raw type DiffListByArrayList
[WARNING]   where T is a type-variable:
    T extends Comparable<Integer> declared in class DiffListByArrayList
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/DiffList.java:[37,11] [unchecked] unchecked conversion
[WARNING]   required: DiffList<T>
  found:    DiffList
  where T is a type-variable:
    T extends Comparable<Integer> declared in method <T>emptyList()
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java:[167,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java:[170,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java:[242,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java:[283,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.java:[455,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.java:[646,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.java:[651,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.java:[737,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockScanner.java:[231,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java:[405,20] [deprecation] shaHex(byte[]) in DigestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/DatasetVolumeChecker.java:[232,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/DatasetVolumeChecker.java:[309,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/DatasetVolumeChecker.java:[396,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java:[257,16] [deprecation] setStorageUuid(String) in Builder has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java:[431,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java:[554,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java:[588,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java:[589,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java:[974,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java:[369,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java:[489,35] [deprecation] getReplica(String,long) in FsDatasetSpi has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.java:[298,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java:[237,38] [deprecation] getStorageUuid() in StorageReceivedDeletedBlocksProto has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockReader.java:[158,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImagePreTransactionalStorageInspector.java:[139,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/EditLogFileOutputStream.java:[164,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/EditLogFileOutputStream.java:[177,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/EditsDoubleBuffer.java:[78,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/AbstractFuture.java:[1044,25] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/AbstractFuture.java:[1052,14] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/AbstractFuture.java:[1054,25] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/AbstractFuture.java:[1059,56] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/AbstractFuture.java:[1061,35] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/AbstractFuture.java:[1062,36] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/AbstractFuture.java:[1062,57] Unsafe is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/ExecuteCommand.java:[72,24] [deprecation] toString(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/ExecuteCommand.java:[102,33] [deprecation] shaHex(String) in DigestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StartupProgressServlet.java:[106,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java:[661,19] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java:[684,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java:[722,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/NameNodeConnector.java:[252,30] [deprecation] StreamCapability in StreamCapabilities has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/NameNodeConnector.java:[253,33] [deprecation] StreamCapability in StreamCapabilities has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetUtil.java:[114,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/ProvidedVolumeImpl.java:[142,44] [unchecked] unchecked conversion
[WARNING]   required: BlockAliasMap<FileRegion>
  found:    CAP#1
  where CAP#1 is a fresh type-variable:
    CAP#1 extends BlockAliasMap from capture of ? extends BlockAliasMap
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java:[288,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java:[1048,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java:[1090,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java:[1112,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/PersistentLongFile.java:[102,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/HdfsWriter.java:[85,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/HdfsWriter.java:[86,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/CancelCommand.java:[79,26] [deprecation] toString(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/CancelCommand.java:[97,33] [deprecation] shaHex(String) in DigestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/OfflineEditsBinaryLoader.java:[105,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/OfflineImageViewer.java:[148,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DebugAdmin.java:[204,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DebugAdmin.java:[289,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java:[727,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/MD5FileUtils.java:[87,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageXmlWriter.java:[660,61] [deprecation] toExtendedShort() in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/OfflineImageReconstructor.java:[1842,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/EditLogFileInputStream.java:[164,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java:[654,10] [deprecation] write(DataOutput) in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageTextWriter.java:[242,17] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageTextWriter.java:[245,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageTextWriter.java:[310,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageTextWriter.java:[316,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageTextWriter.java:[416,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/RedundantEditLogInputStream.java:[155,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-web-xmls) @ hadoop-hdfs ---
[INFO] Executing tasks

main:
     [copy] Copying 1 file to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/hdfs/WEB-INF
     [copy] Copying 1 file to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/secondary/WEB-INF
     [copy] Copying 1 file to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/datanode/WEB-INF
     [copy] Copying 1 file to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/journal/WEB-INF
     [copy] Copying 1 file to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps/nfs3/WEB-INF
     [copy] Copying 46 files to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/webapps
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:parallel-tests-createdir (parallel-tests-createdir) @ hadoop-hdfs ---
[INFO] Creating /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-dir/1
[INFO] Creating /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-dir/2
[INFO] Creating /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-dir/3
[INFO] Creating /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-dir/4
[INFO] Creating /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/tmp/1
[INFO] Creating /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/tmp/2
[INFO] Creating /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/tmp/3
[INFO] Creating /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/tmp/4
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-hdfs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 57 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-log-dir) @ hadoop-hdfs ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data
    [mkdir] Created dir: /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data
    [mkdir] Created dir: /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log
     [copy] Copying 72 files to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-hdfs ---
[INFO] Compiling 751 source files to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSAclBaseTest.java:[46,38] [deprecation] FsPermissionExtension in org.apache.hadoop.hdfs.protocol has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSStripedOutputStream.java:[32,46] [deprecation] StreamCapability in StreamCapabilities has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientFailover.java:[66,30] NameService is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSOutputStream.java:[40,46] [deprecation] StreamCapability in StreamCapabilities has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java:[1049,21] [deprecation] getStatistics(String,Class<? extends FileSystem>) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java:[1775,38] [deprecation] GET_STATS_UNDER_REPLICATED_IDX in ClientProtocol has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java:[1984,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java:[1985,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java:[1986,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java:[1987,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java:[1988,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java:[1989,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImplTestUtils.java:[503,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForXAttr.java:[128,30] [deprecation] toString(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForXAttr.java:[153,30] [deprecation] toString(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForXAttr.java:[186,30] [deprecation] toString(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForXAttr.java:[208,30] [deprecation] toString(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDatanodeProtocolRetryPolicy.java:[87,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestMetaSave.java:[214,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/TestSaslDataTransfer.java:[252,52] [unchecked] unchecked method invocation: method peerFromSocketAndKey in class DFSUtilClient is applied to given types
[WARNING]   required: SaslDataTransferClient,Socket,DataEncryptionKeyFactory,Token<BlockTokenIdentifier>,DatanodeID,int
  found: SaslDataTransferClient,Socket,DataEncryptionKeyFactory,Token,DatanodeID,int
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/TestSaslDataTransfer.java:[253,29] [unchecked] unchecked conversion
[WARNING]   required: Token<BlockTokenIdentifier>
  found:    Token
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/TestSaslDataTransfer.java:[259,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockTokenWithDFS.java:[80,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/TestDelegationToken.java:[173,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java:[1467,8] [unchecked] unchecked conversion
[WARNING]   required: List<DiffReportListingEntry>
  found:    TreeList
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/token/block/TestBlockToken.java:[101,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/token/block/TestBlockToken.java:[102,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/token/block/TestBlockToken.java:[103,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/token/block/TestBlockToken.java:[104,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/token/block/TestBlockToken.java:[105,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/QJMTestUtil.java:[176,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQJMWithFaults.java:[228,22] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSAclBaseTest.java:[111,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSAclBaseTest.java:[882,10] [deprecation] FsPermissionExtension in org.apache.hadoop.hdfs.protocol has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSAclBaseTest.java:[895,27] [deprecation] toExtendedShort() in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAclConfigFlag.java:[58,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRollingUpgrade.java:[723,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSafeMode.java:[236,51] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSafeMode.java:[242,48] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSafeMode.java:[276,24] [deprecation] getPendingReplicationBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReconstructStripedBlocksWithRackAwareness.java:[56,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReconstructStripedBlocksWithRackAwareness.java:[57,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReconstructStripedBlocksWithRackAwareness.java:[58,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestReencryption.java:[1084,29] [unchecked] unchecked cast
[WARNING]   required: Map<Long,ZoneSubmissionTracker>
  found:    Object
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlocksWithNotEnoughRacks.java:[50,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReconstructStripedFile.java:[80,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReconstructStripedFile.java:[81,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReconstructStripedFile.java:[82,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockScanner.java:[75,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockScanner.java:[76,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockScanner.java:[77,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockScanner.java:[888,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockScanner.java:[944,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java:[338,51] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java:[430,32] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java:[470,38] [deprecation] getPendingReplicationBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java:[481,38] [deprecation] getPendingReplicationBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java:[528,46] [deprecation] getPendingReplicationBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java:[571,34] [deprecation] getPendingReplicationBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java:[813,61] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java:[817,65] [deprecation] getPendingReplicationBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java:[881,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java:[882,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyPersistTestCase.java:[81,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAuditLogger.java:[88,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLogFileOutputStream.java:[157,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSaveNamespace.java:[82,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSaveNamespace.java:[628,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfs.java:[52,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeDeath.java:[46,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeDeath.java:[47,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerRPC.java:[320,28] [deprecation] shaHex(String) in DigestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/TestBlackListBasedTrustedChannelResolver.java:[52,15] [deprecation] write(File,CharSequence) in FileUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/TestBlackListBasedTrustedChannelResolver.java:[66,13] [deprecation] write(File,CharSequence,boolean) in FileUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFS.java:[299,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFS.java:[354,28] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFS.java:[355,28] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFS.java:[1281,29] [deprecation] toString(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java:[130,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/checker/TestThrottledAsyncCheckerTimeout.java:[138,49] [unchecked] unchecked conversion
[WARNING]   required: FutureCallback<Boolean>
  found:    FutureCallback
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHAStateTransitions.java:[76,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHAStateTransitions.java:[423,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHAMetrics.java:[120,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHAMetrics.java:[173,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/BaseReplicationPolicyTest.java:[45,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/TestSecureNNWithQJM.java:[160,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/TestSecureNNWithQJM.java:[210,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestNameNodePrunesMissingStorages.java:[321,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRetryCacheWithHA.java:[1318,17] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerWithMockMover.java:[128,31] [deprecation] shaHex(String) in DigestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerWithMockMover.java:[217,31] [deprecation] shaHex(String) in DigestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerWithMockMover.java:[234,31] [deprecation] shaHex(String) in DigestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerWithMockMover.java:[264,31] [deprecation] shaHex(String) in DigestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java:[142,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java:[430,18] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancerWithMultipleNameNodes.java:[63,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/shell/TestHdfsTextCommand.java:[109,11] [deprecation] copy(InputStream,Writer) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTokens.java:[185,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTokens.java:[236,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestQuotaByStorageType.java:[832,18] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestQuotaByStorageType.java:[899,18] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestPendingInvalidateBlock.java:[49,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestPendingInvalidateBlock.java:[195,39] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestPendingInvalidateBlock.java:[202,34] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFavoredNodesEndToEnd.java:[55,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHFlush.java:[45,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHFlush.java:[46,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHFlush.java:[180,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFSForHA.java:[98,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFSForHA.java:[133,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFSForHA.java:[202,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFSForHA.java:[241,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFSForHA.java:[267,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFSForHA.java:[307,19] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestEditLogTailer.java:[85,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestEditLogTailer.java:[87,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQuorumJournalManagerUnit.java:[58,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileTruncate.java:[75,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileTruncate.java:[76,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestBackupNode.java:[69,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestBackupNode.java:[70,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeLifeline.java:[85,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHAFsck.java:[41,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeHotSwapVolumes.java:[540,30] [unchecked] unchecked method invocation: method addVolume in interface FsDatasetSpi is applied to given types
[WARNING]   required: StorageLocation,List<NamespaceInfo>
  found: StorageLocation,List
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeHotSwapVolumes.java:[540,62] [unchecked] unchecked conversion
[WARNING]   required: List<NamespaceInfo>
  found:    List
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientRetries.java:[526,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientRetries.java:[970,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestMover.java:[705,30] [deprecation] DFS_CLIENT_SOCKET_TIMEOUT_KEY in DFSConfigKeys has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLog.java:[108,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLog.java:[1449,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLog.java:[1499,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLog.java:[1599,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLog.java:[1608,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/util/TestAtomicFileOutputStream.java:[145,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithSnapshot.java:[63,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend2.java:[56,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend2.java:[57,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancer.java:[142,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancer.java:[143,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancer.java:[1025,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancer.java:[1598,30] [deprecation] DFS_CLIENT_SOCKET_TIMEOUT_KEY in DFSConfigKeys has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java:[341,18] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java:[1430,18] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestDiffListBySkipList.java:[219,22] [unchecked] unchecked call to addLast(T) as a member of the raw type DiffList
[WARNING]   where T is a type-variable:
    T extends Comparable<Integer> declared in interface DiffList
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestDiffListBySkipList.java:[220,23] [unchecked] unchecked call to addLast(T) as a member of the raw type DiffList
[WARNING]   where T is a type-variable:
    T extends Comparable<Integer> declared in interface DiffList
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestWriteStripedFileWithFailure.java:[44,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestWriteStripedFileWithFailure.java:[45,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecoveryStriped.java:[74,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecoveryStriped.java:[75,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecoveryStriped.java:[76,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecoveryStriped.java:[77,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestClientBlockVerification.java:[45,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/permission/TestStickyBit.java:[99,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/permission/TestStickyBit.java:[124,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/permission/TestStickyBit.java:[503,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDirectoryScanner.java:[140,19] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/BenchmarkThroughput.java:[177,22] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancer.java:[581,33] [deprecation] shaHex(String) in DigestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancer.java:[679,33] [deprecation] shaHex(String) in DigestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdminMiniCluster.java:[55,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestWriteConfigurationToDFS.java:[57,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestAclWithSnapshot.java:[89,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockReportRateLimiting.java:[62,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockReportRateLimiting.java:[63,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSetUMask.java:[106,22] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestQuotaWithStripedBlocks.java:[143,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestWriteReadStripedFile.java:[66,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestWriteReadStripedFile.java:[67,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestWriteReadStripedFile.java:[68,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeleteRace.java:[413,52] [unchecked] unchecked cast
[WARNING]   required: TreeSet<LeaseManager.Lease>
  found:    Object
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java:[129,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java:[903,26] [unchecked] unchecked method invocation: method setBlockToken in class BlockReaderFactory is applied to given types
[WARNING]   required: Token<BlockTokenIdentifier>
  found: Token
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java:[903,27] [unchecked] unchecked conversion
[WARNING]   required: Token<BlockTokenIdentifier>
  found:    Token
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java:[176,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java:[177,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImage.java:[150,19] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestFSMainOperationsWebHdfs.java:[55,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSStripedOutputStream.java:[52,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSStripedOutputStream.java:[53,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSStripedOutputStream.java:[201,16] [deprecation] StreamCapability in StreamCapabilities has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSStripedOutputStream.java:[204,16] [deprecation] StreamCapability in StreamCapabilities has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend4.java:[73,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend4.java:[74,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestEnhancedByteBufferAccess.java:[578,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestEnhancedByteBufferAccess.java:[844,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendSnapshotTruncate.java:[63,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileJournalManager.java:[110,17] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileJournalManager.java:[114,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileJournalManager.java:[423,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileJournalManager.java:[424,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileJournalManager.java:[448,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileJournalManager.java:[478,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileJournalManager.java:[505,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestIncrementalBrVariations.java:[82,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestIncrementalBrVariations.java:[83,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestIncrementalBrVariations.java:[84,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestIncrementalBrVariations.java:[86,8] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestIncrementalBrVariations.java:[87,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestIncrementalBrVariations.java:[88,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestIncrementalBrVariations.java:[140,38] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQuorumJournalManager.java:[86,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQuorumJournalManager.java:[111,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQuorumJournalManager.java:[175,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQuorumJournalManager.java:[190,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQuorumJournalManager.java:[208,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQuorumJournalManager.java:[237,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestINodeFileUnderConstructionWithSnapshot.java:[61,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSEditLogLoader.java:[97,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSEditLogLoader.java:[98,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/ErasureCodeBenchmarkThroughput.java:[404,32] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestMaintenanceState.java:[1058,41] [deprecation] getPendingReplicationBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestMaintenanceState.java:[1059,44] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencing.java:[177,39] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencing.java:[178,39] [deprecation] getPendingReplicationBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencing.java:[270,39] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencing.java:[271,39] [deprecation] getPendingReplicationBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencing.java:[370,39] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencing.java:[371,39] [deprecation] getPendingReplicationBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestRBWBlockInvalidation.java:[239,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestEditLogsDuringFailover.java:[162,17] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java:[174,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java:[180,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java:[566,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeMetrics.java:[256,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/checker/TestDatasetVolumeChecker.java:[200,50] [unchecked] unchecked conversion
[WARNING]   required: FsDatasetSpi<FsVolumeSpi>
  found:    FsDatasetSpi
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestSpaceReservation.java:[104,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestSpaceReservation.java:[105,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDecommissioningStatus.java:[166,27] [deprecation] toString() in ByteArrayOutputStream has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSPermission.java:[1007,10] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestPipelines.java:[162,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestPipelines.java:[163,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientSocketSize.java:[40,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestPread.java:[281,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestPread.java:[366,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestPread.java:[367,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestPread.java:[664,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestUnbuffer.java:[90,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestUnbuffer.java:[125,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBPOfferService.java:[97,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReplaceDatanodeOnFailure.java:[56,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithMultipleNameNodes.java:[48,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsWithMultipleNameNodes.java:[49,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestXAttrConfigFlag.java:[51,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java:[110,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestStorageMover.java:[77,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestStorageMover.java:[79,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestStorageMover.java:[81,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestStorageMover.java:[231,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestStorageMover.java:[571,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestStorageMover.java:[586,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataTransferKeepalive.java:[230,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestPipelinesFailover.java:[73,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestPipelinesFailover.java:[180,25] [deprecation] getPendingReplicationBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestTransferRbw.java:[50,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCommitBlockWithInvalidGenStamp.java:[98,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientFailover.java:[233,10] NameService is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientFailover.java:[239,11] NameService is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientFailover.java:[239,39] NameService is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientFailover.java:[241,6] NameService is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientFailover.java:[244,24] NameService is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientFailover.java:[264,4] NameService is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientFailover.java:[282,4] NameService is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientFailover.java:[302,10] NameService is internal proprietary API and may be removed in a future release
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailureReporting.java:[74,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailureReporting.java:[106,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsFileStatusHdfs.java:[88,8] [deprecation] write(DataOutput) in FileStatus has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsFileStatusHdfs.java:[92,9] [deprecation] readFields(DataInput) in FileStatus has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSecureEncryptionZoneWithKMS.java:[276,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestCachingStrategy.java:[335,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java:[1321,16] [unchecked] unchecked call to add(E) as a member of the raw type ArrayList
[WARNING]   where E is a type-variable:
    E extends Object declared in class ArrayList
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java:[1323,49] [unchecked] unchecked method invocation: method isOrdered in class Ordering is applied to given types
[WARNING]   required: Iterable<? extends T>
  found: ArrayList
  where T is a type-variable:
    T extends Object declared in class Ordering
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java:[1323,50] [unchecked] unchecked conversion
[WARNING]   required: Iterable<? extends T>
  found:    ArrayList
  where T is a type-variable:
    T extends Object declared in class Ordering
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeMXBean.java:[362,55] [unchecked] unchecked cast
[WARNING]   required: Map<String,Map<String,Object>>
  found:    Object
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeMXBean.java:[384,61] [unchecked] unchecked cast
[WARNING]   required: Map<String,Map<String,Object>>
  found:    Object
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeMXBean.java:[399,55] [unchecked] unchecked cast
[WARNING]   required: Map<String,Map<String,Object>>
  found:    Object
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeMXBean.java:[419,55] [unchecked] unchecked cast
[WARNING]   required: Map<String,Map<String,Object>>
  found:    Object
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeMXBean.java:[468,55] [unchecked] unchecked cast
[WARNING]   required: Map<String,Map<String,Object>>
  found:    Object
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeMXBean.java:[490,57] [unchecked] unchecked cast
[WARNING]   required: Map<String,Map<String,Object>>
  found:    Object
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeMXBean.java:[517,55] [unchecked] unchecked cast
[WARNING]   required: Map<String,Map<String,Object>>
  found:    Object
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBatchIbr.java:[68,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestXAttrWithSnapshot.java:[82,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java:[116,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java:[636,14] [deprecation] getStatistics(String,Class<? extends FileSystem>) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java:[641,18] [deprecation] getStatistics(String,Class<? extends FileSystem>) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java:[775,14] [deprecation] getStatistics(String,Class<? extends FileSystem>) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShellGenericOptions.java:[107,19] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestStandbyIsHot.java:[170,41] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestStandbyIsHot.java:[174,41] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestStandbyIsHot.java:[190,41] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestStandbyIsHot.java:[191,41] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSOutputStream.java:[362,25] [deprecation] StreamCapability in StreamCapabilities has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSOutputStream.java:[364,25] [deprecation] StreamCapability in StreamCapabilities has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshot.java:[76,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCorruption.java:[68,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCorruption.java:[69,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/metrics/TestDataNodeOutlierDetectionViaMetrics.java:[66,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/metrics/TestDataNodeOutlierDetectionViaMetrics.java:[67,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java:[151,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java:[153,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencingWithReplication.java:[48,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencingWithReplication.java:[49,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencingWithReplication.java:[50,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAuditLogAtDebug.java:[63,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestPersistBlocks.java:[55,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeRecovery.java:[167,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java:[1931,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/metrics/TestSlowNodeDetector.java:[242,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAddStripedBlocks.java:[206,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAddStripedBlocks.java:[271,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAddStripedBlocks.java:[327,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataXceiverBackwardsCompat.java:[82,44] [unchecked] unchecked cast
[WARNING]   required: FsDatasetSpi<FsVolumeSpi>
  found:    FsDatasetSpi
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataXceiverBackwardsCompat.java:[89,50] [unchecked] unchecked conversion
[WARNING]   required: Token<BlockTokenIdentifier>
  found:    Token
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataXceiverBackwardsCompat.java:[164,73] [unchecked] unchecked cast
[WARNING]   required: Token<BlockTokenIdentifier>
  found:    Token
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHASafeMode.java:[87,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHASafeMode.java:[719,40] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHASafeMode.java:[720,40] [deprecation] getPendingReplicationBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailure.java:[573,24] [deprecation] getUnderReplicatedBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailure.java:[574,23] [deprecation] getPendingReplicationBlocks() in FSNamesystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCache.java:[266,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileStatus.java:[52,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTimeouts.java:[129,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTimeouts.java:[130,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTimeouts.java:[250,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTimeouts.java:[270,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTimeouts.java:[334,17] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockReplacement.java:[482,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInFileContext.java:[50,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestListFilesInDFS.java:[33,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewer.java:[722,20] [deprecation] setLogLevel(Log,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java:[59,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java:[60,20] [deprecation] setLogLevel(Logger,Level) in GenericTestUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java:[837,19] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java:[846,20] [deprecation] isDirectory(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java:[1069,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestTrashWithSecureEncryptionZones.java:[232,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-hdfs ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithSecureHdfs
[INFO] Running org.apache.hadoop.cli.TestAclCLIWithPosixAclInheritance
[INFO] Running org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithHdfs
[INFO] Running org.apache.hadoop.TestGenericRefresh
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.281 s - in org.apache.hadoop.TestGenericRefresh
[INFO] Running org.apache.hadoop.cli.TestDeleteCLI
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.5 s - in org.apache.hadoop.cli.TestAclCLIWithPosixAclInheritance
[INFO] Running org.apache.hadoop.cli.TestAclCLI
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.627 s - in org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithSecureHdfs
[INFO] Running org.apache.hadoop.cli.TestCacheAdminCLI
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.555 s - in org.apache.hadoop.cli.TestAclCLI
[INFO] Running org.apache.hadoop.cli.TestXAttrCLI
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.615 s - in org.apache.hadoop.cli.TestDeleteCLI
[INFO] Running org.apache.hadoop.cli.TestHDFSCLI
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.174 s - in org.apache.hadoop.cli.TestCacheAdminCLI
[INFO] Running org.apache.hadoop.cli.TestErasureCodingCLI
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.066 s - in org.apache.hadoop.cli.TestXAttrCLI
[INFO] Running org.apache.hadoop.cli.TestCryptoAdminCLI
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.357 s - in org.apache.hadoop.cli.TestErasureCodingCLI
[INFO] Running org.apache.hadoop.tracing.TestTracingShortCircuitLocalRead
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.921 s - in org.apache.hadoop.tracing.TestTracingShortCircuitLocalRead
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.385 s - in org.apache.hadoop.cli.TestCryptoAdminCLI
[INFO] Running org.apache.hadoop.tracing.TestTraceAdmin
[INFO] Running org.apache.hadoop.tracing.TestTracing
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.807 s - in org.apache.hadoop.tracing.TestTracing
[INFO] Running org.apache.hadoop.fs.TestFcHdfsCreateMkdir
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.985 s - in org.apache.hadoop.tracing.TestTraceAdmin
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.425 s - in org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithHdfs
[INFO] Running org.apache.hadoop.fs.TestFcHdfsPermission
[INFO] Running org.apache.hadoop.fs.TestWebHdfsFileContextMainOperations
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.691 s - in org.apache.hadoop.fs.TestFcHdfsCreateMkdir
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.133 s - in org.apache.hadoop.fs.TestFcHdfsPermission
[INFO] Running org.apache.hadoop.fs.TestSymlinkHdfsFileContext
[INFO] Running org.apache.hadoop.fs.TestHdfsNativeCodeLoader
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.165 s - in org.apache.hadoop.fs.TestHdfsNativeCodeLoader
[INFO] Running org.apache.hadoop.fs.TestSymlinkHdfsDisable
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.713 s - in org.apache.hadoop.fs.TestSymlinkHdfsDisable
[INFO] Running org.apache.hadoop.fs.TestFcHdfsSetUMask
[INFO] Tests run: 62, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.66 s - in org.apache.hadoop.fs.TestWebHdfsFileContextMainOperations
[INFO] Running org.apache.hadoop.fs.loadGenerator.TestLoadGenerator
[INFO] Tests run: 71, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.153 s - in org.apache.hadoop.fs.TestSymlinkHdfsFileContext
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.927 s - in org.apache.hadoop.fs.TestFcHdfsSetUMask
[INFO] Running org.apache.hadoop.fs.TestHDFSFileContextMainOperations
[INFO] Running org.apache.hadoop.fs.shell.TestHdfsTextCommand
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.983 s - in org.apache.hadoop.fs.shell.TestHdfsTextCommand
[INFO] Running org.apache.hadoop.fs.TestSWebHdfsFileContextMainOperations
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.853 s - in org.apache.hadoop.fs.loadGenerator.TestLoadGenerator
[INFO] Running org.apache.hadoop.fs.TestEnhancedByteBufferAccess
[INFO] Tests run: 71, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.707 s - in org.apache.hadoop.fs.TestHDFSFileContextMainOperations
[INFO] Running org.apache.hadoop.fs.TestSymlinkHdfsFileSystem
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 51.602 s - in org.apache.hadoop.cli.TestHDFSCLI
[INFO] Running org.apache.hadoop.fs.TestGlobPaths
[WARNING] Tests run: 37, Failures: 0, Errors: 0, Skipped: 6, Time elapsed: 5.501 s - in org.apache.hadoop.fs.TestGlobPaths
[INFO] Running org.apache.hadoop.fs.permission.TestStickyBit
[WARNING] Tests run: 74, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 12.854 s - in org.apache.hadoop.fs.TestSymlinkHdfsFileSystem
[WARNING] Tests run: 10, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 15.166 s - in org.apache.hadoop.fs.TestEnhancedByteBufferAccess
[INFO] Running org.apache.hadoop.fs.TestUrlStreamHandler
[INFO] Tests run: 62, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.112 s - in org.apache.hadoop.fs.TestSWebHdfsFileContextMainOperations
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFileSystemLinkMergeSlash
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFileSystemHdfs
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.013 s - in org.apache.hadoop.fs.permission.TestStickyBit
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFsWithAcls
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.194 s - in org.apache.hadoop.fs.TestUrlStreamHandler
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFsWithXAttrs
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.206 s - in org.apache.hadoop.fs.viewfs.TestViewFsWithAcls
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFsHdfs
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.06 s - in org.apache.hadoop.fs.viewfs.TestViewFsWithXAttrs
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFileSystemWithXAttrs
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.657 s - in org.apache.hadoop.fs.viewfs.TestViewFileSystemWithXAttrs
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFsFileStatusHdfs
[INFO] Tests run: 65, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.591 s - in org.apache.hadoop.fs.viewfs.TestViewFsHdfs
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFsAtHdfsRoot
[INFO] Tests run: 76, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.033 s - in org.apache.hadoop.fs.viewfs.TestViewFileSystemLinkMergeSlash
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.897 s - in org.apache.hadoop.fs.viewfs.TestViewFsFileStatusHdfs
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFileSystemLinkFallback
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFileSystemWithTruncate
[INFO] Tests run: 65, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.803 s - in org.apache.hadoop.fs.viewfs.TestViewFsAtHdfsRoot
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAcls
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.938 s - in org.apache.hadoop.fs.viewfs.TestViewFileSystemWithTruncate
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFsDefaultValue
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.324 s - in org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAcls
[INFO] Running org.apache.hadoop.fs.viewfs.TestViewFileSystemAtHdfsRoot
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.417 s - in org.apache.hadoop.fs.viewfs.TestViewFsDefaultValue
[INFO] Running org.apache.hadoop.fs.TestUnbuffer
[INFO] Tests run: 75, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.917 s - in org.apache.hadoop.fs.viewfs.TestViewFileSystemLinkFallback
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.91 s - in org.apache.hadoop.fs.TestUnbuffer
[INFO] Running org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRename
[INFO] Running org.apache.hadoop.fs.contract.hdfs.TestHDFSContractConcat
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.467 s - in org.apache.hadoop.fs.contract.hdfs.TestHDFSContractConcat
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.706 s - in org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRename
[INFO] Running org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSetTimes
[INFO] Running org.apache.hadoop.fs.contract.hdfs.TestHDFSContractPathHandle
[INFO] Tests run: 78, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 42.22 s - in org.apache.hadoop.fs.viewfs.TestViewFileSystemHdfs
[INFO] Tests run: 72, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.386 s - in org.apache.hadoop.fs.viewfs.TestViewFileSystemAtHdfsRoot
[INFO] Running org.apache.hadoop.fs.contract.hdfs.TestHDFSContractDelete
[INFO] Running org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.715 s - in org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSetTimes
[INFO] Running org.apache.hadoop.fs.contract.hdfs.TestHDFSContractCreate
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.719 s - in org.apache.hadoop.fs.contract.hdfs.TestHDFSContractDelete
[INFO] Running org.apache.hadoop.fs.contract.hdfs.TestHDFSContractOpen
[INFO] Tests run: 32, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.889 s - in org.apache.hadoop.fs.contract.hdfs.TestHDFSContractPathHandle
[INFO] Running org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMkdir
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.971 s - in org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.399 s - in org.apache.hadoop.fs.contract.hdfs.TestHDFSContractCreate
[INFO] Running org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus
[INFO] Running org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRootDirectory
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.523 s - in org.apache.hadoop.fs.contract.hdfs.TestHDFSContractOpen
[INFO] Running org.apache.hadoop.fs.contract.hdfs.TestHDFSContractAppend
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.378 s - in org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMkdir
[INFO] Running org.apache.hadoop.fs.TestResolveHdfsSymlink
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.969 s - in org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRootDirectory
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.363 s - in org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus
[INFO] Running org.apache.hadoop.net.TestNetworkTopology
[INFO] Running org.apache.hadoop.hdfs.TestHDFSPolicyProvider
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.272 s - in org.apache.hadoop.hdfs.TestHDFSPolicyProvider
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.689 s - in org.apache.hadoop.fs.TestResolveHdfsSymlink
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.291 s - in org.apache.hadoop.fs.contract.hdfs.TestHDFSContractAppend
[INFO] Running org.apache.hadoop.hdfs.TestWriteRead
[INFO] Running org.apache.hadoop.hdfs.TestWriteReadStripedFile
[INFO] Running org.apache.hadoop.hdfs.TestDFSInputStream
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.816 s - in org.apache.hadoop.net.TestNetworkTopology
[INFO] Running org.apache.hadoop.hdfs.TestRenameWhileOpen
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.977 s - in org.apache.hadoop.hdfs.TestDFSInputStream
[INFO] Running org.apache.hadoop.hdfs.TestErasureCodeBenchmarkThroughput
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.36 s - in org.apache.hadoop.hdfs.TestWriteRead
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.188 s - in org.apache.hadoop.hdfs.TestErasureCodeBenchmarkThroughput
[INFO] Running org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique
[INFO] Running org.apache.hadoop.hdfs.qjournal.client.TestQJMWithFaults
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.245 s - in org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique
[INFO] Running org.apache.hadoop.hdfs.qjournal.client.TestIPCLoggerChannel
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.765 s - in org.apache.hadoop.hdfs.qjournal.client.TestIPCLoggerChannel
[INFO] Running org.apache.hadoop.hdfs.qjournal.client.TestSegmentRecoveryComparator
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.199 s - in org.apache.hadoop.hdfs.qjournal.client.TestSegmentRecoveryComparator
[INFO] Running org.apache.hadoop.hdfs.qjournal.client.TestQuorumCall
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.194 s - in org.apache.hadoop.hdfs.qjournal.client.TestQuorumCall
[INFO] Running org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManagerUnit
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.867 s - in org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManagerUnit
[INFO] Running org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.077 s - in org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager
[INFO] Running org.apache.hadoop.hdfs.qjournal.TestNNWithQJM
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 46.298 s - in org.apache.hadoop.hdfs.TestRenameWhileOpen
[INFO] Running org.apache.hadoop.hdfs.qjournal.server.TestJournal
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.493 s - in org.apache.hadoop.hdfs.qjournal.server.TestJournal
[INFO] Running org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeSync
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.44 s - in org.apache.hadoop.hdfs.qjournal.TestNNWithQJM
[INFO] Running org.apache.hadoop.hdfs.qjournal.server.TestJournalNode
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.564 s - in org.apache.hadoop.hdfs.qjournal.server.TestJournalNode
[INFO] Running org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeRespectsBindHostKeys
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.567 s - in org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeRespectsBindHostKeys
[INFO] Running org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeMXBean
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.687 s - in org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeMXBean
[INFO] Running org.apache.hadoop.hdfs.qjournal.TestMiniJournalCluster
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.796 s - in org.apache.hadoop.hdfs.qjournal.TestMiniJournalCluster
[INFO] Running org.apache.hadoop.hdfs.qjournal.TestSecureNNWithQJM
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 29.894 s - in org.apache.hadoop.hdfs.qjournal.TestSecureNNWithQJM
[INFO] Running org.apache.hadoop.hdfs.TestDatanodeDeath
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 54.054 s - in org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeSync
[INFO] Running org.apache.hadoop.hdfs.TestDFSClientExcludedNodes
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.15 s - in org.apache.hadoop.hdfs.TestDFSClientExcludedNodes
[INFO] Running org.apache.hadoop.hdfs.TestParallelUnixDomainRead
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.435 s - in org.apache.hadoop.hdfs.TestParallelUnixDomainRead
[INFO] Running org.apache.hadoop.hdfs.TestBlocksScheduledCounter
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 135.404 s - in org.apache.hadoop.hdfs.qjournal.client.TestQJMWithFaults
[INFO] Running org.apache.hadoop.hdfs.TestDistributedFileSystemWithECFileWithRandomECPolicy
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.332 s - in org.apache.hadoop.hdfs.TestBlocksScheduledCounter
[INFO] Running org.apache.hadoop.hdfs.util.TestBestEffortLongFile
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.182 s - in org.apache.hadoop.hdfs.util.TestBestEffortLongFile
[INFO] Running org.apache.hadoop.hdfs.util.TestAtomicFileOutputStream
[WARNING] Tests run: 4, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.251 s - in org.apache.hadoop.hdfs.util.TestAtomicFileOutputStream
[INFO] Running org.apache.hadoop.hdfs.util.TestStripedBlockUtil
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 58.951 s - in org.apache.hadoop.hdfs.TestDatanodeDeath
[INFO] Running org.apache.hadoop.hdfs.util.TestLightWeightHashSet
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.17 s - in org.apache.hadoop.hdfs.util.TestLightWeightHashSet
[INFO] Running org.apache.hadoop.hdfs.util.TestMD5FileUtils
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.286 s - in org.apache.hadoop.hdfs.util.TestMD5FileUtils
[INFO] Running org.apache.hadoop.hdfs.util.TestDiff
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.645 s - in org.apache.hadoop.hdfs.util.TestDiff
[INFO] Running org.apache.hadoop.hdfs.util.TestCyclicIteration
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.096 s - in org.apache.hadoop.hdfs.util.TestCyclicIteration
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.408 s - in org.apache.hadoop.hdfs.TestDistributedFileSystemWithECFileWithRandomECPolicy
[INFO] Running org.apache.hadoop.hdfs.util.TestXMLUtils
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.063 s - in org.apache.hadoop.hdfs.util.TestXMLUtils
[INFO] Running org.apache.hadoop.hdfs.util.TestLightWeightLinkedSet
[INFO] Running org.apache.hadoop.hdfs.util.TestCombinedHostsFileReader
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.188 s - in org.apache.hadoop.hdfs.util.TestLightWeightLinkedSet
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.347 s - in org.apache.hadoop.hdfs.util.TestCombinedHostsFileReader
[INFO] Running org.apache.hadoop.hdfs.TestDFSClientRetries
[INFO] Running org.apache.hadoop.hdfs.client.impl.TestBlockReaderIoProvider
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.507 s - in org.apache.hadoop.hdfs.client.impl.TestBlockReaderIoProvider
[INFO] Running org.apache.hadoop.hdfs.client.impl.TestBlockReaderFactory
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.088 s - in org.apache.hadoop.hdfs.client.impl.TestBlockReaderFactory
[INFO] Running org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocalMetrics
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.578 s - in org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocalMetrics
[INFO] Running org.apache.hadoop.hdfs.client.impl.TestClientBlockVerification
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.514 s - in org.apache.hadoop.hdfs.util.TestStripedBlockUtil
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.188 s - in org.apache.hadoop.hdfs.client.impl.TestClientBlockVerification
[INFO] Running org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocalLegacy
[INFO] Running org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.981 s - in org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocalLegacy
[INFO] Running org.apache.hadoop.hdfs.client.impl.TestBlockReaderRemote
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.868 s - in org.apache.hadoop.hdfs.client.impl.TestBlockReaderRemote
[INFO] Running org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 208.952 s - in org.apache.hadoop.hdfs.TestWriteReadStripedFile
[INFO] Running org.apache.hadoop.hdfs.TestDFSClientFailover
[INFO] Tests run: 37, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.632 s - in org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal
[INFO] Running org.apache.hadoop.hdfs.TestFileAppend2
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.929 s - in org.apache.hadoop.hdfs.TestDFSClientFailover
[INFO] Running org.apache.hadoop.hdfs.TestGetBlocks
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.512 s - in org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks
[INFO] Running org.apache.hadoop.hdfs.TestHDFSServerPorts
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.826 s - in org.apache.hadoop.hdfs.TestHDFSServerPorts
[INFO] Running org.apache.hadoop.hdfs.TestQuota
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.253 s - in org.apache.hadoop.hdfs.TestFileAppend2
[INFO] Running org.apache.hadoop.hdfs.TestFSInputChecker
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.174 s - in org.apache.hadoop.hdfs.TestQuota
[INFO] Running org.apache.hadoop.hdfs.TestHDFSFileSystemContract
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.27 s - in org.apache.hadoop.hdfs.TestFSInputChecker
[INFO] Running org.apache.hadoop.hdfs.TestSetrepDecreasing
[INFO] Tests run: 44, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.109 s - in org.apache.hadoop.hdfs.TestHDFSFileSystemContract
[INFO] Running org.apache.hadoop.hdfs.TestModTime
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.29 s - in org.apache.hadoop.hdfs.TestSetrepDecreasing
[INFO] Running org.apache.hadoop.hdfs.TestFileChecksum
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 50.597 s - in org.apache.hadoop.hdfs.TestGetBlocks
[INFO] Running org.apache.hadoop.hdfs.TestDataTransferKeepalive
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.035 s - in org.apache.hadoop.hdfs.TestModTime
[INFO] Running org.apache.hadoop.hdfs.TestPipelines
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.586 s - in org.apache.hadoop.hdfs.TestPipelines
[INFO] Running org.apache.hadoop.hdfs.TestFileStatus
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.114 s - in org.apache.hadoop.hdfs.TestFileStatus
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.168 s - in org.apache.hadoop.hdfs.TestDataTransferKeepalive
[INFO] Running org.apache.hadoop.hdfs.TestFileCorruption
[INFO] Running org.apache.hadoop.hdfs.TestDistributedFileSystem
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.985 s - in org.apache.hadoop.hdfs.TestFileCorruption
[INFO] Running org.apache.hadoop.hdfs.TestConnCache
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.25 s - in org.apache.hadoop.hdfs.TestConnCache
[INFO] Running org.apache.hadoop.hdfs.TestDecommissionWithStriped
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 145.583 s - in org.apache.hadoop.hdfs.TestDFSClientRetries
[INFO] Running org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure
[INFO] Tests run: 32, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 59.021 s - in org.apache.hadoop.hdfs.TestDistributedFileSystem
[INFO] Running org.apache.hadoop.hdfs.TestFileAppend4
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.065 s - in org.apache.hadoop.hdfs.TestFileAppend4
[INFO] Running org.apache.hadoop.hdfs.TestPersistBlocks
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.598 s - in org.apache.hadoop.hdfs.TestPersistBlocks
[INFO] Running org.apache.hadoop.hdfs.TestParallelReadUtil
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.046 s - in org.apache.hadoop.hdfs.TestParallelReadUtil
[INFO] Running org.apache.hadoop.hdfs.TestRollingUpgradeRollback
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 99.954 s - in org.apache.hadoop.hdfs.TestDecommissionWithStriped
[INFO] Running org.apache.hadoop.hdfs.TestDatanodeReport
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.154 s - in org.apache.hadoop.hdfs.TestRollingUpgradeRollback
[INFO] Running org.apache.hadoop.hdfs.TestLease
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.143 s - in org.apache.hadoop.hdfs.TestLease
[INFO] Running org.apache.hadoop.hdfs.TestFSOutputSummer
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.148 s - in org.apache.hadoop.hdfs.TestFSOutputSummer
[INFO] Running org.apache.hadoop.hdfs.TestCrcCorruption
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.442 s - in org.apache.hadoop.hdfs.TestDatanodeReport
[INFO] Running org.apache.hadoop.hdfs.TestWriteBlockGetsBlockLengthHint
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.383 s - in org.apache.hadoop.hdfs.TestWriteBlockGetsBlockLengthHint
[INFO] Running org.apache.hadoop.hdfs.TestDFSShellGenericOptions
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.473 s - in org.apache.hadoop.hdfs.TestDFSShellGenericOptions
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.263 s - in org.apache.hadoop.hdfs.TestCrcCorruption
[INFO] Running org.apache.hadoop.hdfs.TestSafeMode
[INFO] Running org.apache.hadoop.hdfs.TestErasureCodingPoliciesWithRandomECPolicy
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.868 s - in org.apache.hadoop.hdfs.TestErasureCodingPoliciesWithRandomECPolicy
[INFO] Running org.apache.hadoop.hdfs.TestDatanodeConfig
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.377 s - in org.apache.hadoop.hdfs.TestDatanodeConfig
[INFO] Running org.apache.hadoop.hdfs.TestHdfsAdmin
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 37.348 s - in org.apache.hadoop.hdfs.TestSafeMode
[INFO] Running org.apache.hadoop.hdfs.TestDeprecatedKeys
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.433 s - in org.apache.hadoop.hdfs.TestDeprecatedKeys
[INFO] Running org.apache.hadoop.hdfs.TestDFSClientSocketSize
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.395 s - in org.apache.hadoop.hdfs.TestDFSClientSocketSize
[INFO] Running org.apache.hadoop.hdfs.TestEncryptedTransfer
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.543 s - in org.apache.hadoop.hdfs.TestHdfsAdmin
[INFO] Running org.apache.hadoop.hdfs.TestFileAppendRestart
[ERROR] Tests run: 57, Failures: 0, Errors: 32, Skipped: 0, Time elapsed: 222.141 s <<< FAILURE! - in org.apache.hadoop.hdfs.TestFileChecksum
[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery10(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 6.328 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33552010-172.19.0.3-1692209811854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42701,DS-bd8d1d9d-e11c-4bbe-adcd-54640f8b8233,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-ea2a178f-abb0-43f7-a63e-85f5671d1bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-76c5e36a-ddd6-4264-8aa4-232b9fd1c92b,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-7860ed22-0ea3-491f-83ec-5b9a508e3942,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-45645073-f8f7-4c00-99a6-bc48451fcd18,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-d8828f55-e894-48da-9a06-24b7841d0c42,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-f1fc9b5f-c399-472e-9f22-433c0dd431d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-08d4f728-26e4-46c6-9d1f-188c46361c18,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery10(TestFileChecksum.java:410)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery12(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.761 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098054832-172.19.0.3-1692209821703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40955,DS-4affc344-e21f-44cb-9baf-3dfc88dc1f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-fa5af598-a516-43b7-be25-213e55924f16,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-87e280bc-856f-469a-b6fc-b566c5c819d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-925b91f4-a3b6-4336-b0f6-d53eee2da243,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-479aa368-987f-408e-b225-074b72c784cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-ad11685a-e7c4-47ef-b056-be912a2ae2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-93664602-9950-4e01-8fc0-694d29ca2ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-6fa1b7ee-0449-45d7-9023-c05b09cda91c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery12(TestFileChecksum.java:432)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery13(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.875 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316656052-172.19.0.3-1692209825459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:34347,DS-0a4455e9-f5a5-4009-8fb7-6f248c26651e,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-d4d6920e-ade4-4f5f-962f-544207703544,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-ec9689f7-e812-466f-80db-e47c6d7e39ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-6b9ba559-a002-46a6-a86c-93e3ddd6cfad,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-9bafb9c5-bd48-4ff1-be88-5da49c24a5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-b12a0015-2cc3-4a3a-abcf-83048d6d6b36,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-4b3cdd2f-3fcb-4d0b-9197-87e7344250fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-3e5dd7fb-ecf6-477d-9e0e-57f23bbd7fa4,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery14(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.691 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-276394198-172.19.0.3-1692209829335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36131,DS-f9bb3a0b-161e-408c-a707-5e4858c7201a,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-c65ae3a3-07be-453c-881d-6f3b30531f26,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-81466474-2ba9-48d4-87bc-75a124a534c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-427d1f39-74d5-433b-9fca-f3a22a62bcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-af664a84-6950-4acb-890f-0d940b65bc70,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-0bd94c26-4e3e-4ccd-9ed4-8344572b4b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-b7525480-b176-4938-ac99-9d942eb96545,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-7d9cde4e-01e6-49ff-b252-72b7cf0fe63c,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery15(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.806 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808209214-172.19.0.3-1692209833027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:40155,DS-8f7a6a05-9992-494a-864c-15ea3ff815de,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-103ef498-ed4c-4817-850c-b289e5613746,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-bff57c04-d7ad-4b05-a456-b58202ce8a43,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-ac6ff1ca-bf67-4b2f-92ca-ea1fde9239e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-19ecaffd-3030-46ac-b651-e1cb4d8b1d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-f64b6cfc-f07f-4f6c-9dcd-80d65cd2991b,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-b51b0b89-fd2f-42f6-ae71-da41b6b3328e,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-40c7772d-0d70-46ac-9f5b-6d7ee71f435f,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15(TestFileChecksum.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery16(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.067 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067252032-172.19.0.3-1692209836855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45251,DS-97983455-634e-40eb-90c1-3fdd1fdd2b71,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-e45b2e71-1b10-4df1-8724-989d3675eb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-9114e8e7-83db-4441-bd20-1280acf821fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-cacceb67-aeb0-4161-b0cb-6ddefa3cdc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-17c33f13-bad8-44cf-bdfa-61ec8d057cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-087432b3-9042-4eab-9d71-1e4805363135,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-62096fa9-8fda-4b48-84dc-e5fa9b51e32e,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-a663a282-045a-4c1c-94e3-624eb8850509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery20(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.595 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957828466-172.19.0.3-1692209849417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39203,DS-071ba208-3673-47c6-a9b7-1ae3fabcfe39,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-c714daa9-f2ef-49ba-bda1-57db609d36ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-764231ce-ce0c-4cd0-82f5-6dde5846da39,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-0fa65c40-cb84-40b7-9100-6b1d182f441c,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-92b9724f-8710-4806-9c9b-2d627649ae34,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-e6c32fec-aa34-4f07-801c-5a2752512510,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-4ead5bc7-9df5-4320-9b8d-175761399dac,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-8969cba0-f8ed-43b4-b7e6-fe108a0826f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks1(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.072 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122098561-172.19.0.3-1692209858015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41365,DS-3f86f756-0b9d-4327-8c8e-6885330b3d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-d0d23643-ed71-41d1-bd18-40040bf284af,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-db672da2-e0e1-4279-ad85-07304dab30d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-257e35c1-5ab3-46ce-9c46-206b47be1dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-42f446c2-9f44-4ce4-8975-e7bf9e5d94b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-8808f3eb-e424-4397-80b3-83c509c83656,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-71da083e-cd6a-4d06-a1ab-29a6e1083ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-75483448-df46-4ff1-872b-4b2870e43e07,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1(TestFileChecksum.java:256)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks2(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 4.701 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1415302195-172.19.0.3-1692209861061:blk_-9223372036854775632_1011; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34285,DS-ddc131fb-10ab-4ce8-9fb9-93b32cb3b854,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-282e5e00-8a6a-4bc5-8500-fe9742f530ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-290882a2-a596-456f-a763-342e28926468,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-1d497bce-6849-4c13-bd27-a02996bcb8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-379387e4-4da3-45ff-acdd-d4492945ec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-2d57ea81-197f-4195-a9b4-c3ad474f4a51,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-7d3bb6de-aac8-4ae3-a703-3cc668249d07,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-0bdd44b6-d4d4-4627-ac9a-35d1736d660f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1694)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1703)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2(TestFileChecksum.java:273)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery8(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 2.703 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987679711-172.19.0.3-1692209936009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44531,DS-6421c9b0-9b09-4291-bc50-0be946e66c70,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-bfcf0a7b-ac6a-49d7-8791-6cbbdf5f1296,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-56ea1901-63d4-4c09-9df1-b5372ee12516,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-02c5c654-e1af-4801-ad24-9b13ac6540c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-f2ad8c95-242e-47ad-92e7-87c5afcd78df,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-40be96fe-49ca-4ac3-b642-86fbbf5531a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-0b144c41-a197-4351-ac9f-01126b8b0004,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-8a11b05b-ed39-474f-af7b-7193b565c568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery8(TestFileChecksum.java:388)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery9(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 2.77 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972910950-172.19.0.3-1692209938714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42203,DS-0bb048fb-e903-408a-8900-b0aa34d501a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-e26620b8-ca5e-45e7-848e-fd951ad55ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-d2218b98-adbd-4d40-9f96-8543544ea224,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-1e1d2530-0a54-4269-affd-31c7cf4b7dab,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-2332fb1e-ab97-49ee-af42-40fd6e6bce46,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-31fd01da-d27a-42be-8334-cf8618ff149e,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-f0d1de80-a46c-45ee-b7bb-78a1478584ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-c3d10faf-0e92-4b1f-9876-da545a4a2eba,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery9(TestFileChecksum.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery10(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.521 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295277359-172.19.0.3-1692209941490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33989,DS-49f1671b-2911-470d-975a-f126f76a77f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-70ba59d3-0740-4153-813b-2bbe068ba718,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-9e18c39e-15ab-420a-a122-c14cc8db1947,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-f770a00f-4f45-438f-9a1c-faa00cb2af19,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-05367f68-7f03-43d7-b48a-15ad53049fae,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-f3618405-3d7e-4df7-9f97-89da2f0accc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-b8281f11-a671-449a-8f1b-20e47a54142e,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-2ae32505-238e-4e94-ad39-b5686e0a88cd,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery10(TestFileChecksum.java:410)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery12(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.121 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905494256-172.19.0.3-1692209945009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43579,DS-0739bbf0-563c-4fa2-9fd7-ffe2033ae7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-a07ebd5c-1d26-4666-b626-c944388fb40c,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-62b32f38-e907-4b16-8d48-c8a2229fe270,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-b891160f-dba7-4890-a68f-c7d14595bbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-e1be033b-d3db-4232-a4cc-4f2efc04d3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-5c0a7f94-e09d-4c9b-9c5b-33391e01ca41,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-2dd979ad-55e2-4491-a111-d018a0a1e704,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-a4a8cfd6-f16c-47de-8878-ecd84b5e868b,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery12(TestFileChecksum.java:432)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery13(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.012 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615156062-172.19.0.3-1692209948133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40359,DS-0776a55d-88d4-4301-8479-bb7030772d29,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-290f6ab4-4e31-4df1-a1a1-ff49647297f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-6c56962d-b6ec-4807-b1c6-02ac9e3b6a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-26663597-1c1a-4d18-9621-2e0d0d9a4002,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-551592f1-9bf9-4299-8af4-36081a6e2173,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-3f54fba5-05fd-452a-ba05-6cd2fc1d3d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-eeab532c-d735-48ef-88a6-f44adb6e80e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-fb499423-ba6c-4721-bc9f-81ced8d3445f,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery14(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.7 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239955009-172.19.0.3-1692209951148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:46363,DS-0a6381a0-5db5-4d71-baed-391b14dd5ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-867a4f81-ff6d-4dce-b24e-8335964968f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-d268f413-72d1-49de-b943-62db539c5d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-b97923f7-634e-48ab-bb6c-6896f5bc2287,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-026cdc7a-fb9a-4a52-863e-dd15d9fb8391,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-1d9fc45a-9511-45f9-b340-b03e616e9136,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-d7b35b84-2510-480a-bba5-381a0e0b0063,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-9a35df9d-3960-4975-a8e2-cad8d94fd62a,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery15(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.307 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873704803-172.19.0.3-1692209954848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:41705,DS-0f9a7814-ca1a-4c80-85a2-920fefa78e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-04efc991-17fa-428a-b879-c6a7c0440b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-99fe7a1a-0fda-4750-8701-c0b9867fee08,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-d314943b-d0f0-4cd4-bd20-8b4127da2cff,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-beb68b82-0945-4542-879f-197ec5bca739,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-16bf985c-6900-4a2f-8c72-180139f1b9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-7ead4e44-9fb2-43c1-9a3e-7e2ce6224af0,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-fbc5eb11-867c-405a-aa52-ddea1dede668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15(TestFileChecksum.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks1(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.006 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312650708-172.19.0.3-1692209963719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:35565,DS-869322e1-825d-4482-9708-3decc1607612,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-d95fa817-7d6f-4deb-8a0e-ef42b0fcda29,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-e1b9a148-d6bb-4966-92e9-a0841bd3b5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-3afee1a5-2eb5-4eeb-84a7-5d086fe49d76,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-f9436a77-612a-4b86-9a21-83cc3e564fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-a4cac341-4151-421b-98fb-c3ce6c2286bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-8e23363f-de17-4f0a-823e-1938fce88be0,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-07f4fa6f-28ba-4b3b-85c4-c19bda3dea83,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1(TestFileChecksum.java:256)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks2(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 4.853 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1928330354-172.19.0.3-1692209966722:blk_-9223372036854775632_1011; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33789,DS-137e41db-cff8-440f-bf0e-9649aff106e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-b805a369-a0aa-4c75-9940-a22f74e4e32e,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-54c3c9e4-70b9-4a61-8aed-2694fff14792,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-389caa5d-167f-451b-a434-4470b827eba4,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-9d811ac2-8c58-4423-b398-6ed14498030a,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-38d9b0ab-a5d7-428c-a578-246f4663ded9,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-045b324e-ada9-499d-9bf3-7f202bc09eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-423bd0d2-9d0b-453e-ae04-15de04869e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1694)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1703)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2(TestFileChecksum.java:273)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery10(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.578 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707048858-172.19.0.3-1692209978904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38121,DS-d07c51f4-e42f-4694-8aeb-0b9191959a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-1c7bda0f-68c6-4a6e-a240-b05986098b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-3d83b833-632c-46df-90e9-8dbcb048cd97,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-47b788bf-4112-4ada-81fe-d6ffe1ff47b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-669eab15-a0e4-46d0-8674-aef08e56c07b,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-c86c9f27-bf0b-4f0b-844f-784edf7dab8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-251cd6ba-57c6-4455-8f4b-0cbaae941488,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-c9fbacca-013d-448f-a571-45c25b40aa8f,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery10(TestFileChecksum.java:410)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery12(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 4.441 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56302172-172.19.0.3-1692209982485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34861,DS-cfcc2ba1-c3ad-406a-843e-f9526b34092d,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-cee2af4a-8227-4d76-8161-6807e6325f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-26ed57ee-a3c2-41db-b44f-603287ff9661,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-b6b643e9-1411-48bd-9ecc-8f026f3ee09f,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-4102b091-94f6-45b0-ac65-cdca39e89b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-3fbb3999-6bf8-4a8a-a741-4ba88b920517,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-539f2505-3f6c-44ca-9f53-57ca445e3f82,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-7ffe7ec8-9e0f-4643-85db-144a7addb8f5,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery12(TestFileChecksum.java:432)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery13(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 2.975 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220371214-172.19.0.3-1692209986926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35339,DS-2d89d5c8-e6da-43c9-8172-8d7b7c0eea8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-3fe62403-594a-4929-93df-355f6c149b13,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-84aa075f-6d10-4ebb-b6a3-df9500ac1ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-0fcb2972-945b-489a-aa26-5e740ec3a76f,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-5ec5b22d-554d-47e5-81b0-20b3957f6301,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-db949ec6-f534-4c64-8861-ece346c6e319,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-6941aaa2-a4f1-4ade-a6d6-2cce397aa032,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-8d1335f0-d1d1-4565-a6c5-7247ff9ee70e,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery14(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 2.47 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940747137-172.19.0.3-1692209989896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46543,DS-94e16c54-47b5-4ba2-8782-81692656284f,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-73540784-a4fb-40b3-a36c-e8cb82a3a6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-fd046341-dba2-468c-974c-510694994c56,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-c6d63ec4-b57a-4fce-bdb4-e02a7027ba56,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-79ff08af-cb50-42a7-8c6c-34cd067ce0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-c30a1dcd-6467-40f3-9516-73bfdf09f2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-d9944e27-78af-4780-b7b2-4d1fb823a182,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-26c0d3d1-fb1b-4306-aac1-5ddcc046c2a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery15(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.237 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184089362-172.19.0.3-1692209992368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33877,DS-d3f1154b-4387-4b08-880a-b05a5c563a04,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-1f50480a-27fb-4907-9398-2270a133efc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-ab986390-58ec-4f2e-b4da-18c245651917,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-9e8106ab-2784-4cd9-81bf-63ead1b03b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-3649aee8-f557-48b9-b759-490eb6f69ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-570be9e2-15d8-4ce9-b8e5-c3f851960577,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-b60feb1f-bace-45c7-84e2-0bd3cff284ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-52cb5a49-6685-40bc-bc77-c8dfba73bfbe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15(TestFileChecksum.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks1(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 2.659 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292709907-172.19.0.3-1692209995604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39363,DS-ecc966af-4ae9-4cc4-a038-1a2261d98b45,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-2608af09-337e-4963-ac51-dc0b0baecd22,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-8957d6e5-4510-480e-85ef-b0a1f29c8dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-15c3e05e-0111-4e8b-91f9-2e3bc74ee228,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-60186411-f785-4432-ae7a-aefa4bcdcf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-35c68936-693c-44a7-9e45-1b71e33c7a22,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-1e878e77-1d5e-4b7b-9e3d-d6ed193afef4,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-c73d36e5-8812-4728-a329-ebf3db00d8e8,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1(TestFileChecksum.java:256)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks2(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 4.199 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1530633076-172.19.0.3-1692209998265:blk_-9223372036854775632_1011; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46553,DS-b5430376-81ed-4e1d-affb-5e811eb5983d,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-d1d87913-5ccd-41ef-a8c8-8e1dd255128c,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-b6f23e5e-9705-4210-af99-8c3feefd9ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-007b7b2c-985d-4bf5-94e2-ecfb8f330387,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-827f3b8b-6335-496b-a146-c33e0824e685,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-6a132229-7a97-4616-abf3-53c6eae9c0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-499bb84b-02ef-4dfe-b019-7c6fe3049b55,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-f5ee596c-7ba0-417b-912f-c9a69d46dd66,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1694)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1703)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2(TestFileChecksum.java:273)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery10(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.928 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206107896-172.19.0.3-1692210002467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40541,DS-723871c4-268c-407e-9dc6-c081ff4aecd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-e8c06627-220e-4033-b606-e3a51c477186,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-9a49c0c1-640f-4f3b-bb18-aeea7a97ba6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-42f6c396-6289-4d2b-9755-6cd0faf44e32,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-afdbdf34-a731-4c17-9745-5319e0e84802,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-c46c8799-0eff-4320-9535-8d898369b05b,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-173350ae-cec3-459f-959a-4e238333339c,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-71f543ed-c002-416c-b0d7-301683d7a473,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery10(TestFileChecksum.java:410)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery12(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 2.959 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931948869-172.19.0.3-1692210006397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34127,DS-9293a459-8709-480b-bbde-6288dce7a905,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-a1ca92e0-fda2-45c6-912f-f1a8bcc19cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-4554545c-4cf3-4908-818e-b26027c33d63,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-bf9c47f1-c2a3-4848-a0df-0850ab5ea110,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-3eee0dad-62d9-4627-8acd-a9d52bc01f11,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-335a8a6d-1fd1-487a-b1b4-485f545e2e41,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-06c2e409-245a-44c1-865f-cc8787ba0131,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-cc09900c-ea97-4097-900b-8686a188a5a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery12(TestFileChecksum.java:432)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery13(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.42 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007326651-172.19.0.3-1692210009419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:36323,DS-c73be6be-39ae-4d76-b78a-f3190790ae5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-f23a83fb-a7f0-4130-b820-67905b6dbf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-aac44c04-0a31-4a43-ac74-b171b4941bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-93a88cc7-a1b4-4b85-95ac-609f2e5afa05,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-b27db432-e8e7-47b9-a8de-fdc3a02d246a,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-20077e05-dc1f-4b57-90d3-0123de5a1998,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-158d16d8-5add-4d3e-9ef3-2b246bd01c11,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-17c13872-8449-45b0-b5eb-01e2e7461e4e,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery14(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 4.095 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200021738-172.19.0.3-1692210012769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43147,DS-0333beaf-9f23-4661-b7e7-ee2383e60fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-e31644e0-9b16-4306-8495-9b10dea0dab8,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-5f50b3fc-c6bc-4d6f-90fb-eb09b95cca46,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-d3fc3540-2651-4d95-98d1-213dde539021,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-a2d8f2a2-fa85-4b02-a241-1da28ab6b8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-772e7977-9cbb-4e67-9aaa-5e242aa4c855,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-728847b6-44a4-4ecb-a1be-e752acf38512,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-5d3468b8-58ea-418b-a61a-5421f9e37664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery15(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.998 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467624651-172.19.0.3-1692210016955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:41487,DS-089b6de4-e48f-4709-9488-25b1fc063c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-f1a9f98f-b6f5-48e9-8716-766dc9c178e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-9ef330a8-cc73-4c31-8ad9-cce197e41ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-b5aa9405-dbe0-4d8d-8899-493dbc57a8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-a8db5e3e-3b02-4ec5-b869-0408b65e7a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-91aa380d-d478-4310-80f3-f755f3078291,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-628c2a2c-3fcd-4079-8bb8-31403eb40e60,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-2aeffa9a-092b-4dd3-bd89-b512cd0217dd,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15(TestFileChecksum.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks1(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 3.409 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597082745-172.19.0.3-1692210020861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33587,DS-ef691b38-26be-4a22-8e19-99ddb6e340f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-82e79c01-92c7-44ef-a1b0-6dcbc3bfc8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-da640eae-d83f-4bc6-a230-55a5535d35ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-d38ceca6-8783-408c-b747-999b9c22c36d,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-ecc356ae-a973-4b94-8da6-324bcf235143,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-66b8b809-3592-4e47-b131-47fcfc40c614,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-c99f72ae-e399-400f-8f85-b30298ffe701,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-c13a248a-e6ae-4c1d-bea2-694ba9e1fa1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1(TestFileChecksum.java:256)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks2(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 8.799 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-734564063-172.19.0.3-1692210024274:blk_-9223372036854775632_1011; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38683,DS-be5b6169-12c0-428e-90c3-ab18c05b967a,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-09c1e319-57cb-481b-8b0b-3482c07844ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-f1cd1ebd-3396-4b7f-8849-43a46608460a,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-fd919b7f-5f9d-424e-8090-c8602816dbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-600d334b-4c7b-475d-9950-7291a6c46103,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-db850f5c-360a-47b6-9b32-2a3d94956a02,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-96573c0b-6d48-49ea-bf8e-a193c7b76977,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-f6d1169c-eb5a-4aff-8dd9-38d83fd1be90,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1694)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1703)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2(TestFileChecksum.java:273)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[INFO] Running org.apache.hadoop.hdfs.TestRestartDFS
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.654 s - in org.apache.hadoop.hdfs.TestRestartDFS
[INFO] Running org.apache.hadoop.hdfs.TestReplication
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.891 s - in org.apache.hadoop.hdfs.TestFileAppendRestart
[INFO] Running org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 195.456 s - in org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure
[INFO] Running org.apache.hadoop.hdfs.TestMaintenanceState
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.595 s - in org.apache.hadoop.hdfs.TestReplication
[INFO] Running org.apache.hadoop.hdfs.TestSeekBug
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.344 s - in org.apache.hadoop.hdfs.TestSeekBug
[INFO] Running org.apache.hadoop.hdfs.TestMissingBlocksAlert
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.249 s - in org.apache.hadoop.hdfs.TestMissingBlocksAlert
[INFO] Running org.apache.hadoop.hdfs.TestErasureCodingPolicyWithSnapshotWithRandomECPolicy
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.301 s - in org.apache.hadoop.hdfs.TestErasureCodingPolicyWithSnapshotWithRandomECPolicy
[INFO] Running org.apache.hadoop.hdfs.TestFileConcurrentReader
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.111 s - in org.apache.hadoop.hdfs.TestFileConcurrentReader
[INFO] Running org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 87.482 s - in org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure
[INFO] Running org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks
[INFO] Tests run: 30, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 119.27 s - in org.apache.hadoop.hdfs.TestEncryptedTransfer
[INFO] Running org.apache.hadoop.hdfs.net.TestDFSNetworkTopologyPerformance
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.027 s - in org.apache.hadoop.hdfs.net.TestDFSNetworkTopologyPerformance
[INFO] Running org.apache.hadoop.hdfs.net.TestDFSNetworkTopology
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.541 s - in org.apache.hadoop.hdfs.net.TestDFSNetworkTopology
[INFO] Running org.apache.hadoop.hdfs.TestSetTimes
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.654 s - in org.apache.hadoop.hdfs.TestSetTimes
[INFO] Running org.apache.hadoop.hdfs.TestParallelShortCircuitReadUnCached
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.905 s - in org.apache.hadoop.hdfs.TestParallelShortCircuitReadUnCached
[INFO] Running org.apache.hadoop.hdfs.TestSnapshotCommands
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.374 s - in org.apache.hadoop.hdfs.TestSnapshotCommands
[INFO] Running org.apache.hadoop.hdfs.TestFsShellPermission
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.471 s - in org.apache.hadoop.hdfs.TestFsShellPermission
[INFO] Running org.apache.hadoop.hdfs.TestLargeBlock
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.422 s - in org.apache.hadoop.hdfs.TestLargeBlock
[INFO] Running org.apache.hadoop.hdfs.TestFileStatusWithRandomECPolicy
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.032 s - in org.apache.hadoop.hdfs.TestFileStatusWithRandomECPolicy
[INFO] Running org.apache.hadoop.hdfs.TestLeaseRecovery
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.812 s - in org.apache.hadoop.hdfs.TestLeaseRecovery
[INFO] Running org.apache.hadoop.hdfs.TestBalancerBandwidth
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.761 s - in org.apache.hadoop.hdfs.TestBalancerBandwidth
[INFO] Running org.apache.hadoop.hdfs.TestWriteStripedFileWithFailure
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.06 s - in org.apache.hadoop.hdfs.TestWriteStripedFileWithFailure
[INFO] Running org.apache.hadoop.hdfs.TestDataTransferProtocol
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.603 s - in org.apache.hadoop.hdfs.TestDataTransferProtocol
[INFO] Running org.apache.hadoop.hdfs.TestHDFSTrash
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.587 s - in org.apache.hadoop.hdfs.TestHDFSTrash
[INFO] Running org.apache.hadoop.hdfs.TestAppendDifferentChecksum
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 124.835 s - in org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks
[INFO] Running org.apache.hadoop.hdfs.TestDisableConnCache
[WARNING] Tests run: 3, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 8.285 s - in org.apache.hadoop.hdfs.TestAppendDifferentChecksum
[INFO] Running org.apache.hadoop.hdfs.TestTrashWithSecureEncryptionZones
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.654 s - in org.apache.hadoop.hdfs.TestDisableConnCache
[INFO] Running org.apache.hadoop.hdfs.TestDFSMkdirs
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.214 s - in org.apache.hadoop.hdfs.TestDFSMkdirs
[INFO] Running org.apache.hadoop.hdfs.TestLeaseRecoveryStriped
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.314 s - in org.apache.hadoop.hdfs.TestTrashWithSecureEncryptionZones
[INFO] Running org.apache.hadoop.hdfs.TestLeaseRecovery2
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 40.272 s - in org.apache.hadoop.hdfs.TestLeaseRecoveryStriped
[INFO] Running org.apache.hadoop.hdfs.TestDFSShell
[INFO] Tests run: 49, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.992 s - in org.apache.hadoop.hdfs.TestDFSShell
[INFO] Running org.apache.hadoop.hdfs.TestFileCreationClient
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 65.686 s - in org.apache.hadoop.hdfs.TestLeaseRecovery2
[INFO] Running org.apache.hadoop.hdfs.TestDatanodeStartupFixesLegacyStorageIDs
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.025 s - in org.apache.hadoop.hdfs.TestDatanodeStartupFixesLegacyStorageIDs
[INFO] Running org.apache.hadoop.hdfs.TestDFSStartupVersions
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.174 s - in org.apache.hadoop.hdfs.TestDFSStartupVersions
[INFO] Running org.apache.hadoop.hdfs.TestDistributedFileSystemWithECFile
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.982 s - in org.apache.hadoop.hdfs.TestDistributedFileSystemWithECFile
[INFO] Running org.apache.hadoop.hdfs.protocol.datatransfer.TestPacketReceiver
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.264 s - in org.apache.hadoop.hdfs.protocol.datatransfer.TestPacketReceiver
[INFO] Running org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.33 s - in org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer
[INFO] Running org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestBlackListBasedTrustedChannelResolver
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.229 s - in org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestBlackListBasedTrustedChannelResolver
[INFO] Running org.apache.hadoop.hdfs.protocol.TestLocatedBlock
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.17 s - in org.apache.hadoop.hdfs.protocol.TestLocatedBlock
[INFO] Running org.apache.hadoop.hdfs.protocol.TestBlockListAsLongs
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.698 s - in org.apache.hadoop.hdfs.protocol.TestBlockListAsLongs
[INFO] Running org.apache.hadoop.hdfs.protocol.TestAnnotations
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.088 s - in org.apache.hadoop.hdfs.protocol.TestAnnotations
[INFO] Running org.apache.hadoop.hdfs.protocol.TestLayoutVersion
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.165 s - in org.apache.hadoop.hdfs.protocol.TestLayoutVersion
[INFO] Running org.apache.hadoop.hdfs.TestDFSFinalize
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 59.164 s - in org.apache.hadoop.hdfs.TestFileCreationClient
[INFO] Running org.apache.hadoop.hdfs.TestListFilesInDFS
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 264.2 s - in org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData
[INFO] Running org.apache.hadoop.hdfs.crypto.TestHdfsCryptoStreams
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.289 s - in org.apache.hadoop.hdfs.TestDFSFinalize
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.671 s - in org.apache.hadoop.hdfs.TestListFilesInDFS
[INFO] Running org.apache.hadoop.hdfs.TestGetFileChecksum
[INFO] Running org.apache.hadoop.hdfs.TestEncryptionZones
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.706 s - in org.apache.hadoop.hdfs.TestGetFileChecksum
[INFO] Running org.apache.hadoop.hdfs.TestDFSRemove
[INFO] Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 343.994 s - in org.apache.hadoop.hdfs.TestMaintenanceState
[INFO] Running org.apache.hadoop.hdfs.TestParallelShortCircuitRead
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.768 s - in org.apache.hadoop.hdfs.TestDFSRemove
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.223 s - in org.apache.hadoop.hdfs.crypto.TestHdfsCryptoStreams
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.983 s - in org.apache.hadoop.hdfs.TestParallelShortCircuitRead
[INFO] Running org.apache.hadoop.hdfs.TestFileCreationEmpty
[INFO] Running org.apache.hadoop.hdfs.TestRollingUpgrade
[INFO] Running org.apache.hadoop.hdfs.TestSafeModeWithStripedFile
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.874 s - in org.apache.hadoop.hdfs.TestFileCreationEmpty
[INFO] Running org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.784 s - in org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage
[INFO] Running org.apache.hadoop.hdfs.TestSetrepIncreasing
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.442 s - in org.apache.hadoop.hdfs.TestSafeModeWithStripedFile
[INFO] Running org.apache.hadoop.hdfs.TestWriteConfigurationToDFS
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.53 s - in org.apache.hadoop.hdfs.TestWriteConfigurationToDFS
[INFO] Running org.apache.hadoop.hdfs.TestParallelRead
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.677 s - in org.apache.hadoop.hdfs.TestSetrepIncreasing
[INFO] Running org.apache.hadoop.hdfs.TestDecommission
[INFO] Tests run: 42, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 73.003 s - in org.apache.hadoop.hdfs.TestEncryptionZones
[INFO] Running org.apache.hadoop.hdfs.TestMiniDFSCluster
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.248 s - in org.apache.hadoop.hdfs.TestParallelRead
[INFO] Running org.apache.hadoop.hdfs.TestUnsetAndChangeDirectoryEcPolicy
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.074 s - in org.apache.hadoop.hdfs.TestMiniDFSCluster
[INFO] Running org.apache.hadoop.hdfs.security.TestDelegationToken
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.965 s - in org.apache.hadoop.hdfs.TestUnsetAndChangeDirectoryEcPolicy
[INFO] Running org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.159 s - in org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser
[INFO] Running org.apache.hadoop.hdfs.security.token.block.TestBlockToken
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 92.756 s - in org.apache.hadoop.hdfs.TestRollingUpgrade
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.853 s - in org.apache.hadoop.hdfs.security.token.block.TestBlockToken
[INFO] Running org.apache.hadoop.hdfs.TestFileAppend3
[INFO] Running org.apache.hadoop.hdfs.TestListFilesInFileContext
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.838 s - in org.apache.hadoop.hdfs.security.TestDelegationToken
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.967 s - in org.apache.hadoop.hdfs.TestListFilesInFileContext
[INFO] Running org.apache.hadoop.hdfs.TestFileAppend
[INFO] Running org.apache.hadoop.hdfs.TestDFSStripedOutputStream
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.635 s - in org.apache.hadoop.hdfs.TestFileAppend3
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.884 s - in org.apache.hadoop.hdfs.TestFileAppend
[INFO] Running org.apache.hadoop.hdfs.TestParallelShortCircuitReadNoChecksum
[INFO] Running org.apache.hadoop.hdfs.web.TestHttpsFileSystem
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.347 s - in org.apache.hadoop.hdfs.web.TestHttpsFileSystem
[INFO] Running org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.948 s - in org.apache.hadoop.hdfs.TestParallelShortCircuitReadNoChecksum
[INFO] Running org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.668 s - in org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts
[INFO] Running org.apache.hadoop.hdfs.web.TestWebHDFSXAttr
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 50.182 s - in org.apache.hadoop.hdfs.TestDFSStripedOutputStream
[INFO] Tests run: 53, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.831 s - in org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs
[INFO] Running org.apache.hadoop.hdfs.web.resources.TestParam
[INFO] Tests run: 33, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.365 s - in org.apache.hadoop.hdfs.web.resources.TestParam
[INFO] Running org.apache.hadoop.hdfs.web.TestWebHDFS
[INFO] Running org.apache.hadoop.hdfs.web.TestWebHdfsTokens
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.558 s - in org.apache.hadoop.hdfs.web.TestWebHDFSXAttr
[INFO] Running org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.738 s - in org.apache.hadoop.hdfs.web.TestWebHdfsTokens
[INFO] Running org.apache.hadoop.hdfs.web.TestAuthFilter
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.378 s - in org.apache.hadoop.hdfs.web.TestAuthFilter
[INFO] Running org.apache.hadoop.hdfs.web.TestWebHDFSAcl
[INFO] Tests run: 53, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.876 s - in org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract
[INFO] Running org.apache.hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.515 s - in org.apache.hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes
[INFO] Running org.apache.hadoop.hdfs.web.TestWebHDFSForHA
[WARNING] Tests run: 66, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 22.885 s - in org.apache.hadoop.hdfs.web.TestWebHDFSAcl
[INFO] Running org.apache.hadoop.hdfs.web.TestJsonUtil
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.454 s - in org.apache.hadoop.hdfs.web.TestJsonUtil
[INFO] Running org.apache.hadoop.hdfs.web.TestWebHdfsUrl
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.671 s - in org.apache.hadoop.hdfs.web.TestWebHDFSForHA
[INFO] Running org.apache.hadoop.hdfs.web.TestWebHdfsWithAuthenticationFilter
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.482 s - in org.apache.hadoop.hdfs.web.TestWebHdfsUrl
[INFO] Running org.apache.hadoop.hdfs.web.TestWebHdfsWithRestCsrfPreventionFilter
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.064 s - in org.apache.hadoop.hdfs.web.TestWebHdfsWithAuthenticationFilter
[INFO] Running org.apache.hadoop.hdfs.TestEncryptionZonesWithHA
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.704 s - in org.apache.hadoop.hdfs.TestEncryptionZonesWithHA
[INFO] Running org.apache.hadoop.hdfs.TestDFSStripedInputStream
[WARNING] Tests run: 23, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 174.776 s - in org.apache.hadoop.hdfs.TestDecommission
[INFO] Running org.apache.hadoop.hdfs.TestTrashWithEncryptionZones
[INFO] Tests run: 32, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 40.823 s - in org.apache.hadoop.hdfs.web.TestWebHdfsWithRestCsrfPreventionFilter
[INFO] Running org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.401 s - in org.apache.hadoop.hdfs.TestTrashWithEncryptionZones
[INFO] Running org.apache.hadoop.hdfs.TestClientReportBadBlock
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.211 s - in org.apache.hadoop.hdfs.TestClientReportBadBlock
[INFO] Running org.apache.hadoop.hdfs.server.diskbalancer.TestPlanner
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.852 s - in org.apache.hadoop.hdfs.server.diskbalancer.TestPlanner
[INFO] Running org.apache.hadoop.hdfs.server.diskbalancer.TestDiskBalancerRPC
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 70.675 s - in org.apache.hadoop.hdfs.TestDFSStripedInputStream
[INFO] Running org.apache.hadoop.hdfs.server.diskbalancer.TestConnectors
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.469 s - in org.apache.hadoop.hdfs.server.diskbalancer.TestDiskBalancerRPC
[INFO] Running org.apache.hadoop.hdfs.server.diskbalancer.TestDataModels
[INFO] Tests run: 31, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 124.941 s - in org.apache.hadoop.hdfs.web.TestWebHDFS
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.73 s - in org.apache.hadoop.hdfs.server.diskbalancer.TestDataModels
[INFO] Running org.apache.hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand
[INFO] Running org.apache.hadoop.hdfs.server.diskbalancer.TestDiskBalancerWithMockMover
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.292 s - in org.apache.hadoop.hdfs.server.diskbalancer.TestConnectors
[INFO] Running org.apache.hadoop.hdfs.server.diskbalancer.TestDiskBalancer
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.589 s - in org.apache.hadoop.hdfs.server.diskbalancer.TestDiskBalancerWithMockMover
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestBlockPlacementStatusWithUpgradeDomain
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.232 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestBlockPlacementStatusWithUpgradeDomain
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestSequentialBlockGroupId
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.575 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestSequentialBlockGroupId
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.641 s - in org.apache.hadoop.hdfs.server.diskbalancer.TestDiskBalancer
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestHostFileManager
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.375 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestHostFileManager
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestBlockReportRateLimiting
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.187 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestOverReplicatedBlocks
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.93 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestBlockReportRateLimiting
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestBlockInfoStriped
[INFO] Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.664 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestBlockInfoStriped
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestPendingRecoveryBlocks
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.639 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestPendingRecoveryBlocks
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestSlowPeerTracker
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.871 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestSlowPeerTracker
[INFO] Tests run: 29, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 53.368 s - in org.apache.hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestCorruptReplicaInfo
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.568 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestCorruptReplicaInfo
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestHeartbeatHandling
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.674 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestHeartbeatHandling
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicyWithNodeGroup
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.834 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicyWithNodeGroup
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestHost2NodesMap
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.295 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestHost2NodesMap
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestPendingDataNodeMessages
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.266 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestPendingDataNodeMessages
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicyWithUpgradeDomain
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.805 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicyWithUpgradeDomain
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.788 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestOverReplicatedBlocks
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestReconstructStripedBlocksWithRackAwareness
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.361 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.668 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.407 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestReconstructStripedBlocksWithRackAwareness
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestSequentialBlockId
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.379 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestSequentialBlockId
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestComputeInvalidateWork
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.469 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManagerSafeMode
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.051 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestComputeInvalidateWork
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestBlockInfo
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.41 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestBlockInfo
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestNodeCount
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.023 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManagerSafeMode
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestPendingReconstruction
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.587 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestNodeCount
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.357 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestProvidedStorageMap
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.627 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestProvidedStorageMap
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestAvailableSpaceBlockPlacementPolicy
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.483 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestAvailableSpaceBlockPlacementPolicy
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeDescriptor
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.181 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeDescriptor
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestNameNodePrunesMissingStorages
[ERROR] Tests run: 48, Failures: 0, Errors: 21, Skipped: 0, Time elapsed: 196.266 s <<< FAILURE! - in org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc
[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery13(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 7.702 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183672970-172.19.0.3-1692210675642:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:35413,DS-7b8adb6e-89de-48bf-9048-e48999908a49,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-8a25c3ac-dcb0-4cae-857e-23125534144a,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-cc000493-0c45-406c-b85f-3dd40df1e20f,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-16d3d850-0cad-4833-a93b-e2d4e0e96338,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-b484b4a8-cf00-417d-bb2e-5ee2edea6f46,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-bc0d5b4a-a41f-438e-a888-c8b16cb75374,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-c2a981b4-8f13-477c-944b-8d7fc4319201,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-28538ed2-15b5-4fc2-b5d8-f1a3ab9cbac5,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery14(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 4.325 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046331260-172.19.0.3-1692210683329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:33535,DS-7f99429e-bb2f-4244-8138-75117b1bf90f,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-d92aec51-3972-4385-b767-7b28d2bf84e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-ab7d8abc-0435-48db-ae11-5b40a852bca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-86278c26-722d-4bcf-9234-2ee52b890f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-2557695f-621a-41fb-a873-d50cbcc8115c,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-64e826ae-c2b3-4f9d-9345-3b36d4630a27,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-dccaf27d-6a42-48b9-8562-3d365c862707,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-2ca9ff7c-e247-46ff-8ab6-3d04b9e9fabf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery15(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 4.579 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015588569-172.19.0.3-1692210687650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46869,DS-074fe108-0ec5-455b-b07b-d35ba40d6c35,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-afb40b64-6dc2-4b12-87b4-4ab6c2316a71,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-b4dc90d9-4e73-49b8-ad05-9ce9fb9211df,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-279a8d76-72ab-43dd-9b4e-cc01925ddb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-3766c586-9f5e-4f30-9c5c-00bcf0090d22,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-53a7ed31-8ac8-44d6-99a5-fd8ced11319e,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-323f6138-91ca-4424-983a-45fb8d345b08,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-d33e9d2d-9e81-46ea-9089-1a899078b4ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15(TestFileChecksum.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks1(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 4.24 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587672878-172.19.0.3-1692210718388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40153,DS-1c4e5144-ca98-4268-acd4-0190d6a7d3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-3ee9ff2d-d4d6-428e-9c98-15cd3bbd8df4,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-81ef70cc-12f2-46f0-a93b-328ee13035e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-b8553120-e97a-48c2-ab99-2ef8e4049ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-2ee3573b-d1bf-4e1c-9c52-34d713656550,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-7d4671c0-8480-40de-9841-f3d2a8ca8bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-98e412c5-bc3f-4774-b8f9-66125223ddac,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-b3f67cee-4c80-4583-b7d5-c2f16612dfe0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1(TestFileChecksum.java:256)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks2(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 5.081 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-454400319-172.19.0.3-1692210722631:blk_-9223372036854775632_1011; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38125,DS-1523fa1c-cd01-4938-9467-2948f90bd2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-460df59f-dcad-4171-b4ab-f30ae415e93d,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-bfceb2c9-3105-4026-b77f-355b887ad9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-8efdbb58-65c2-42da-858e-587d5f01eebb,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-35458e17-79c8-4faf-90a4-93b7f2a9a74e,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-1438df64-1a92-4108-aaef-14e8511ec175,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-1303af6d-36d1-4af4-81f8-dbaa746f1600,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-79f351d4-97e2-4e63-ac5e-83f8417c6a30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1694)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1703)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2(TestFileChecksum.java:273)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery3(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 2.699 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008802219-172.19.0.3-1692210775339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37029,DS-54e5f543-09f4-4cd9-bbfb-64c13ca919a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-ed5602a0-51a1-47b5-af9e-fc344fb7fb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-f85084f1-68a2-42ce-ba9f-81c994837a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-b2503123-c790-4f48-b090-77dec9af4c96,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-d210bb7c-0a77-41b5-8eb7-2ce219528f16,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-6eb20c52-e9eb-4a22-bc7e-a18b12dabba7,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-994fdc83-c3bd-446c-b525-eadb5c00acc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-8b0aba26-e76f-486d-b364-dd5177cc3a1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery13(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 2.563 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275560590-172.19.0.3-1692210794625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:33063,DS-53aa3591-efad-401f-a3b3-db50706b5b75,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-9242d883-b04b-43bd-81dc-d68814afcded,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-f2aa1f95-15b6-4488-8467-79bcdbb2067f,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-057a28db-254a-4ce7-9d9d-64cb55e7a9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-c2376f5b-b165-49b4-b06a-d170a4d06d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-93c51c7b-c18b-4fc2-bfde-860c1946d469,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-8da6de33-71bd-4b89-9c62-425a7ec9d474,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-0240a38a-bb62-4a90-81e3-e5ec1544b079,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery14(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 2.85 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312574086-172.19.0.3-1692210797191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37071,DS-e7c9e43e-925c-404f-81c0-de3a01b9c0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-362b56bb-9e59-4e8a-ad8c-e8c679d7cfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-e77e06f6-e13d-417e-be7a-f176ad0b8e00,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-7164af0c-3d1a-40c4-8d10-d164e98333ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-da323f0c-bd85-4caa-aa09-d55493a05367,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-3cb83e88-1636-4a84-aaa6-29f5c3ae635b,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-527dd20a-992b-40e3-a136-4769f3ad5f35,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-27220186-ecea-4fbe-90dc-f2c320bdbdca,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery15(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 2.923 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478465321-172.19.0.3-1692210800039:blk_-9223372036854775760_1003; getBlockSize()=37748736; corrupt=false; offset=75497472; locs=[DatanodeInfoWithStorage[127.0.0.1:33787,DS-9b751611-a809-4746-bef6-5eb19a651061,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-259b6d1e-f932-4905-9da6-94694d85b796,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-903a6631-6396-442c-a3bc-5fb0c44ce657,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-f013775b-b2de-4618-ad36-429fcda8eb09,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-362889ef-b7fd-4094-b24b-086d06dbdee5,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-f2003212-5d4a-4fa0-98e0-4b045ba272b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-a0d5e997-c936-452f-a5e1-df75e69c7d78,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-ea0625bd-138e-434a-9d62-f4086e1b990d,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15(TestFileChecksum.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks1(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 3.249 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58590144-172.19.0.3-1692210802962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:41169,DS-ebdb9850-8ef7-42d3-b85b-37e4f4078ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-73ebebed-2779-498c-baff-1cf54c446fce,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-8f972934-def2-4531-b7be-07d31d5bcd50,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-a51d693a-0db0-4e3a-9a8e-d4b64c68a044,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-d14051e0-a74d-4dcf-ba0d-3f0ceaaa73bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-0a193f8a-aa9a-4ecf-969d-c1817c05ba30,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-c8432e31-020d-41da-af16-3926a5e0070c,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-65c21dff-5903-4646-85e0-fc4521b657bc,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1(TestFileChecksum.java:256)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks2(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 3.901 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1368715520-172.19.0.3-1692210806209:blk_-9223372036854775632_1011; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40353,DS-bf9ee6fd-10cd-4feb-b90f-bf0ff5ed506c,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-a3975f93-5c27-4432-8d52-d2573e160623,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-a7e74568-ba19-4fb7-810a-6ff469fbe6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-fedfd32e-7c65-4fff-9286-adfa0e133470,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-758f7c3b-1efe-4493-bd30-90ee0dfcaf87,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-b34614a1-c4e3-485d-8ffc-a5100dfe4619,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-acc0c9a5-d066-4fa5-aa44-424151f6b41a,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-1e331540-69d3-4ae7-a0a6-18c736867702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1694)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1703)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2(TestFileChecksum.java:273)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery13(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 2.646 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417402900-172.19.0.3-1692210812445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37381,DS-431920ed-c16b-4b72-86e7-d36e8c5a8a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-3a767e5c-4418-43fb-b839-1fc7e9fe0b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-d54e04ab-ce7b-4f61-b13b-ecca69d30811,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-d517f481-fe25-4382-9442-d01cf0a4034e,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-42abd4dc-8f6f-4810-bac0-07fdf884290f,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-09070842-5e2f-426c-a5f4-7f52b2ad5e12,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-b4cb34f4-4bfb-47bb-bead-128d7588ebd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-6b4f3208-2293-446b-ac73-10c2b9184cc2,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery14(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 2.714 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111803599-172.19.0.3-1692210815089:blk_-9223372036854775728_1005; getBlockSize()=37748736; corrupt=false; offset=150994944; locs=[DatanodeInfoWithStorage[127.0.0.1:41639,DS-e3f2bdeb-5083-476e-a290-75da65ddbc72,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-98a2fe78-6e40-40f1-b1f5-757daaaa0cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-2e76965a-cfea-438e-aec6-eadff8efafea,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-3cf67dfd-f463-4955-b4dd-644a8006f62e,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-bd6de3ad-a51f-4058-9251-643bc5794ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-1600d214-c2c4-4743-afdf-f75a606d1547,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-078e0ee4-f918-45a8-903f-5b6a3f2a8dde,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-c2cbd990-f159-499d-825e-44e346852d72,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery15(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 2.812 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140924577-172.19.0.3-1692210817800:blk_-9223372036854775760_1003; getBlockSize()=37748736; corrupt=false; offset=75497472; locs=[DatanodeInfoWithStorage[127.0.0.1:43345,DS-1fa38a02-e413-46d2-8bb8-a6dca4cfde82,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-b886ec2c-87cb-4e1e-8728-a77bc8715c37,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-cee2372c-5043-45d4-bb29-5ff53d480baf,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-dffc0037-f803-4997-84f4-84f89382c2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-736ba8a2-e613-4186-8221-5a9ec6a805bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-3e0e44b4-e95b-43ba-9fef-0e4db760c95b,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-2a3a5dcc-7fa5-45a2-9552-66f861054181,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-5e53a479-d35a-4e33-94f6-209b88413af8,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15(TestFileChecksum.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks1(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 2.448 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362188899-172.19.0.3-1692210820614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44161,DS-2d999d61-0b5a-40ed-b004-de620047eedb,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-e30a7645-367c-4ec3-9ebc-0a985009415b,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-08a39386-6e98-435b-b675-e11793dcbe77,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-bf73f65a-4cc6-49d1-9208-1d5c1c7b9c08,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-4c2e4298-de94-473b-8d36-0fdfa961756a,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-fdcfd3f1-dc2c-4623-81f9-be5ace9b28f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-6c01badc-6d95-47da-9911-61487de6f0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-27494765-448d-43cd-8b3d-5ff23809dfdf,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1(TestFileChecksum.java:256)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks2(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 3.509 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-186752877-172.19.0.3-1692210823063:blk_-9223372036854775632_1011; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38653,DS-3c056ca3-7cca-4922-9fcb-9972e0d1d1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-9ab9c4f0-7661-4d3d-a5b7-f59b84e0e8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-90cae1c9-39e1-403e-9e03-00f94fd8bc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-73c1aace-7f4e-409a-b9f7-8c44261a4951,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-9aa05b77-4f0b-435f-99af-f0c7e3853fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-0af97477-24b1-41bd-a3be-921c96d737de,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-8e15d33a-cf0c-4480-8948-fe5c34519d93,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-21bb8e66-f813-45d1-bac3-5e9ffcc9d21e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1694)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1703)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2(TestFileChecksum.java:273)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery13(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 2.386 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674792944-172.19.0.3-1692210826569:blk_-9223372036854775760_1003; getBlockSize()=37748736; corrupt=false; offset=75497472; locs=[DatanodeInfoWithStorage[127.0.0.1:37363,DS-2902d080-03ab-4edb-b9b3-934f965aeb44,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-e190f8a9-7030-4fae-8691-ab0a2f0f5e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-a28479bb-231f-44db-94a6-c465a65bea66,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-88396d3a-1102-4665-9505-a5e3855d684b,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-fb6b2940-da3b-43cd-a354-ecee5a1c45c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-6c71ed2d-9a90-43cc-8923-86463edc9b58,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-749d2e68-b41a-4e7d-972e-8bc7bec85591,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-670f007f-6528-480d-8477-93854aee3a1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery14(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 2.706 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391186105-172.19.0.3-1692210828956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:35691,DS-14bb5478-633a-4794-b044-bdd6d4f4af6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-f57c8090-062b-41e8-bd0a-f9c94da288fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-47424db0-093d-4de0-8cbf-1897955b20ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-61b884e2-1eda-417b-991a-20dc9abaf5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-2878943b-3b93-4e1e-996e-eb0a1039d2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-6e048a8e-f257-4236-aea4-1c900f63d18e,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-e2c9c4fc-19ee-41c0-83bb-8f4e750a2981,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-05035e77-2d76-4398-ba43-0f0d1efccffc,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocksRangeQuery15(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 3.172 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22967107-172.19.0.3-1692210831662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39195,DS-54293d21-2791-4282-bab2-2350d33eea23,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-2e8ee076-cfc0-4c94-9b37-47983163237b,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-b792cd95-f546-4a40-8e3e-01a3f17e7af3,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-61938439-9a47-46c0-977e-5dcfce67ea19,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-5be3ab23-ce73-4d59-81a9-ad7126c32141,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-ffc5e3e3-dbde-4ced-a4e7-9d0fd87e5139,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-60be39e5-23f9-44dc-b218-4e11d0814584,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-523d5607-7a09-44a2-8d4b-43692289d0d1,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15(TestFileChecksum.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks1(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 3.481 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743318436-172.19.0.3-1692210834834:blk_-9223372036854775744_1004; getBlockSize()=37748736; corrupt=false; offset=113246208; locs=[DatanodeInfoWithStorage[127.0.0.1:43263,DS-e7b32b0c-8b29-4f78-b0a4-31723487fff9,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-c1cc4d8d-5edf-4d53-9a8c-13c5e1406425,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-7070f38a-5ed8-4362-b94f-e143225850f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-6a06a878-a48c-4dd1-b55c-686b38e95cac,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-821c4232-3141-4d55-ac21-820dcff78b04,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-a6e94489-6ed5-40b8-a909-4a639371e5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-0aa34500-d4b9-48e4-8bb1-022c5061a3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-67c7c6dd-04a1-488a-bfe9-f76264814a14,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1715)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1729)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1(TestFileChecksum.java:256)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testStripedFileChecksumWithMissedDataBlocks2(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 4.239 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2035717487-172.19.0.3-1692210838315:blk_-9223372036854775584_1014; getBlockSize()=37748736; corrupt=false; offset=113246208; locs=[DatanodeInfoWithStorage[127.0.0.1:39809,DS-c6eadcf7-43b9-40ec-91d2-af24b8038239,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-3476988e-a3f9-4aa2-a244-3b16c84e5a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-869f11b0-48ed-4db5-bae6-ab52c76bdd58,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-1c2d5b86-644f-49f0-8cb7-0c6e4d8bfffb,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-f5643b60-aab5-43e5-b352-b87f951a7ace,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-e4b25810-d781-4bc1-b552-f2a7d708c46c,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-0c1838f0-f1d5-4c54-b048-29632a6e395b,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-0681ce70-cf09-4e1a-a789-9c422007f61e,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1778)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1798)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1694)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1703)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2(TestFileChecksum.java:273)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.678 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestPendingReconstruction
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestBlockUnderConstructionFeature
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.292 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestBlockUnderConstructionFeature
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestSlowDiskTracker
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.141 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestNameNodePrunesMissingStorages
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicyConsiderLoad
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.716 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicyConsiderLoad
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.393 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestSlowDiskTracker
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestBlocksWithNotEnoughRacks
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 94.063 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestCachedBlocksList
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.309 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestCachedBlocksList
[INFO] Tests run: 26, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.904 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedStripedBlock
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestLowRedundancyBlockQueues
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.332 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestLowRedundancyBlockQueues
[INFO] Running org.apache.hadoop.hdfs.server.blockmanagement.TestPendingInvalidateBlock
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.212 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedStripedBlock
[INFO] Running org.apache.hadoop.hdfs.server.common.TestJspHelper
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.73 s - in org.apache.hadoop.hdfs.server.common.TestJspHelper
[INFO] Running org.apache.hadoop.hdfs.server.common.TestGetUriFromString
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.77 s - in org.apache.hadoop.hdfs.server.common.TestGetUriFromString
[INFO] Running org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestLevelDbMockAliasMapClient
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.161 s - in org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestLevelDbMockAliasMapClient
[INFO] Running org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestLevelDBFileRegionAliasMap
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.385 s - in org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestLevelDBFileRegionAliasMap
[INFO] Running org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient
[INFO] Tests run: 66, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.163 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy
[INFO] Running org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestTextBlockAliasMap
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.261 s - in org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestTextBlockAliasMap
[INFO] Running org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.435 s - in org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient
[INFO] Running org.apache.hadoop.hdfs.server.balancer.TestBalancerRPCDelay
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.597 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestPendingInvalidateBlock
[INFO] Running org.apache.hadoop.hdfs.server.balancer.TestKeyManager
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.492 s - in org.apache.hadoop.hdfs.server.balancer.TestKeyManager
[INFO] Running org.apache.hadoop.hdfs.server.balancer.TestBalancerWithEncryptedTransfer
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.322 s - in org.apache.hadoop.hdfs.server.balancer.TestBalancerRPCDelay
[INFO] Running org.apache.hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 46.271 s - in org.apache.hadoop.hdfs.server.blockmanagement.TestBlocksWithNotEnoughRacks
[INFO] Running org.apache.hadoop.hdfs.server.balancer.TestBalancer
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 37.498 s - in org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer
[INFO] Running org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.409 s - in org.apache.hadoop.hdfs.server.balancer.TestBalancerWithEncryptedTransfer
[INFO] Running org.apache.hadoop.hdfs.server.balancer.TestBalancerWithHANameNodes
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.768 s - in org.apache.hadoop.hdfs.server.balancer.TestBalancerWithHANameNodes
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodePeerMetrics
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.564 s - in org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeExit
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.679 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeExit
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestIncrementalBrVariations
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.212 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodePeerMetrics
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeTcpNoDelay
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.412 s - in org.apache.hadoop.hdfs.server.datanode.TestIncrementalBrVariations
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDatanodeProtocolRetryPolicy
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.424 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeTcpNoDelay
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestBlockCountersInPendingIBR
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.491 s - in org.apache.hadoop.hdfs.server.datanode.TestDatanodeProtocolRetryPolicy
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.903 s - in org.apache.hadoop.hdfs.server.datanode.TestBlockCountersInPendingIBR
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.982 s - in org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeMXBean
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.497 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeMXBean
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.434 s - in org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestIncrementalBlockReports
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.798 s - in org.apache.hadoop.hdfs.server.datanode.TestIncrementalBlockReports
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataDirs
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.266 s - in org.apache.hadoop.hdfs.server.datanode.TestDataDirs
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestNNHandlesBlockReportPerStorage
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 138.223 s - in org.apache.hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestStorageReport
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.948 s - in org.apache.hadoop.hdfs.server.datanode.TestStorageReport
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 46.65 s - in org.apache.hadoop.hdfs.server.datanode.TestNNHandlesBlockReportPerStorage
[INFO] Running org.apache.hadoop.hdfs.server.datanode.checker.TestStorageLocationChecker
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.905 s - in org.apache.hadoop.hdfs.server.datanode.checker.TestStorageLocationChecker
[INFO] Running org.apache.hadoop.hdfs.server.datanode.checker.TestThrottledAsyncChecker
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.756 s - in org.apache.hadoop.hdfs.server.datanode.checker.TestThrottledAsyncChecker
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.247 s - in org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold
[INFO] Running org.apache.hadoop.hdfs.server.datanode.checker.TestDatasetVolumeCheckerTimeout
[INFO] Running org.apache.hadoop.hdfs.server.datanode.checker.TestDatasetVolumeChecker
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.511 s - in org.apache.hadoop.hdfs.server.datanode.checker.TestDatasetVolumeCheckerTimeout
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.517 s - in org.apache.hadoop.hdfs.server.datanode.checker.TestDatasetVolumeChecker
[INFO] Running org.apache.hadoop.hdfs.server.datanode.checker.TestDatasetVolumeCheckerFailures
[INFO] Running org.apache.hadoop.hdfs.server.datanode.checker.TestThrottledAsyncCheckerTimeout
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.264 s - in org.apache.hadoop.hdfs.server.datanode.checker.TestThrottledAsyncCheckerTimeout
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.461 s - in org.apache.hadoop.hdfs.server.datanode.checker.TestDatasetVolumeCheckerFailures
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestTransferRbw
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.874 s - in org.apache.hadoop.hdfs.server.datanode.TestTransferRbw
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting
[INFO] Tests run: 21, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 102.675 s - in org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestBlockHasMultipleReplicasOnSameDN
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.893 s - in org.apache.hadoop.hdfs.server.datanode.TestBlockHasMultipleReplicasOnSameDN
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetrics
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 43.839 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.412 s - in org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestSimulatedFSDatasetWithMultipleStorages
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.355 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetrics
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.091 s - in org.apache.hadoop.hdfs.server.datanode.TestSimulatedFSDatasetWithMultipleStorages
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeLifeline
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeFaultInjector
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.476 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeFaultInjector
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetricsLogger
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.989 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetricsLogger
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeReconfiguration
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.053 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeReconfiguration
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDeleteBlockPool
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 81.348 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.196 s - in org.apache.hadoop.hdfs.server.datanode.TestDeleteBlockPool
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeErasureCodingMetrics
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 37.08 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeLifeline
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.04 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeErasureCodingMetrics
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.TestRoundRobinVolumeChoosingPolicy
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.297 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.TestRoundRobinVolumeChoosingPolicy
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.TestAvailableSpaceVolumeChoosingPolicy
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.888 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.TestAvailableSpaceVolumeChoosingPolicy
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReplicaMap
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.129 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReplicaMap
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 41.417 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestWriteToReplica
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.882 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.525 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.547 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestWriteToReplica
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 43.672 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyWriter
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.301 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistPolicy
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.421 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaPlacement
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.747 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistPolicy
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.672 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.79 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestInterDatanodeProtocol
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.539 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaPlacement
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestSpaceReservation
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.279 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestInterDatanodeProtocol
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistFiles
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 101.259 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyWriter
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistLockedMemory
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.303 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistLockedMemory
[INFO] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 84.316 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestSpaceReservation
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeTransferSocketSize
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.027 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeTransferSocketSize
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestProvidedReplicaImpl
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.964 s - in org.apache.hadoop.hdfs.server.datanode.TestProvidedReplicaImpl
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.742 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestHdfsServerConstants
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.062 s - in org.apache.hadoop.hdfs.server.datanode.TestHdfsServerConstants
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade
[INFO] Tests run: 33, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 431.702 s - in org.apache.hadoop.hdfs.server.balancer.TestBalancer
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 110.065 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistFiles
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeECN
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.711 s - in org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement
[INFO] Running org.apache.hadoop.hdfs.server.datanode.web.webhdfs.TestParameterParser
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.391 s - in org.apache.hadoop.hdfs.server.datanode.web.webhdfs.TestParameterParser
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.296 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeECN
[INFO] Running org.apache.hadoop.hdfs.server.datanode.web.webhdfs.TestDataNodeUGIProvider
[INFO] Running org.apache.hadoop.hdfs.server.datanode.web.TestDatanodeHttpXFrame
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.093 s - in org.apache.hadoop.hdfs.server.datanode.web.TestDatanodeHttpXFrame
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCacheRevocation
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.411 s - in org.apache.hadoop.hdfs.server.datanode.web.webhdfs.TestDataNodeUGIProvider
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestStartSecureDataNode
[WARNING] Tests run: 3, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.507 s - in org.apache.hadoop.hdfs.server.datanode.TestStartSecureDataNode
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestCachingStrategy
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.669 s - in org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCacheRevocation
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataStorage
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.591 s - in org.apache.hadoop.hdfs.server.datanode.TestDataStorage
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestBlockPoolSliceStorage
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.435 s - in org.apache.hadoop.hdfs.server.datanode.TestBlockPoolSliceStorage
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeInitStorage
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.955 s - in org.apache.hadoop.hdfs.server.datanode.TestCachingStrategy
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestNNHandlesCombinedBlockReport
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.201 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeInitStorage
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestBPOfferService
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 38.27 s - in org.apache.hadoop.hdfs.server.datanode.TestBPOfferService
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestBlockScanner
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 49.257 s - in org.apache.hadoop.hdfs.server.datanode.TestNNHandlesCombinedBlockReport
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 98.445 s - in org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner
[INFO] Running org.apache.hadoop.hdfs.server.datanode.extdataset.TestExternalDataset
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.074 s - in org.apache.hadoop.hdfs.server.datanode.extdataset.TestExternalDataset
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataXceiverLazyPersistHint
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.747 s - in org.apache.hadoop.hdfs.server.datanode.TestDataXceiverLazyPersistHint
[INFO] Running org.apache.hadoop.hdfs.server.datanode.metrics.TestSlowNodeDetector
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.16 s - in org.apache.hadoop.hdfs.server.datanode.metrics.TestSlowNodeDetector
[INFO] Running org.apache.hadoop.hdfs.server.datanode.metrics.TestDataNodeOutlierDetectionViaMetrics
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.306 s - in org.apache.hadoop.hdfs.server.datanode.metrics.TestDataNodeOutlierDetectionViaMetrics
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeFSDataSetSink
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 116.177 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.558 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.824 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeFSDataSetSink
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestTriggerBlockReport
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeMetrics
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.684 s - in org.apache.hadoop.hdfs.server.datanode.TestTriggerBlockReport
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDiskError
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.089 s - in org.apache.hadoop.hdfs.server.datanode.TestDiskError
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestBatchIbr
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.781 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeMetrics
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestBpServiceActorScheduler
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.597 s - in org.apache.hadoop.hdfs.server.datanode.TestBpServiceActorScheduler
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestLargeBlockReport
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.048 s - in org.apache.hadoop.hdfs.server.datanode.TestBatchIbr
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestSimulatedFSDataset
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.358 s - in org.apache.hadoop.hdfs.server.datanode.TestSimulatedFSDataset
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestBlockPoolManager
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.838 s - in org.apache.hadoop.hdfs.server.datanode.TestBlockPoolManager
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDataNodeUUID
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.965 s - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeUUID
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestHSync
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.307 s - in org.apache.hadoop.hdfs.server.datanode.TestHSync
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestDatanodeStartupOptions
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.458 s - in org.apache.hadoop.hdfs.server.datanode.TestDatanodeStartupOptions
[INFO] Running org.apache.hadoop.hdfs.server.datanode.TestReadOnlySharedStorage
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.046 s - in org.apache.hadoop.hdfs.server.datanode.TestLargeBlockReport
[INFO] Running org.apache.hadoop.hdfs.server.aliasmap.TestInMemoryAliasMap
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.229 s - in org.apache.hadoop.hdfs.server.aliasmap.TestInMemoryAliasMap
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestBackupNode
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 117.557 s - in org.apache.hadoop.hdfs.server.datanode.TestBlockScanner
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestAuditLoggerWithCommands
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.399 s - in org.apache.hadoop.hdfs.server.datanode.TestReadOnlySharedStorage
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFSPermissionChecker
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.113 s - in org.apache.hadoop.hdfs.server.namenode.TestFSPermissionChecker
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestSecondaryNameNodeUpgrade
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.452 s - in org.apache.hadoop.hdfs.server.namenode.TestBackupNode
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestQuotaWithStripedBlocks
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.436 s - in org.apache.hadoop.hdfs.server.namenode.TestQuotaWithStripedBlocks
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.485 s - in org.apache.hadoop.hdfs.server.namenode.TestSecondaryNameNodeUpgrade
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeOptionParsing
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.285 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeOptionParsing
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestEncryptionZoneManager
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.567 s - in org.apache.hadoop.hdfs.server.namenode.TestEncryptionZoneManager
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestUpgradeDomainBlockPlacementPolicy
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 96.632 s - in org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestClientNameNodeAddress
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.497 s - in org.apache.hadoop.hdfs.server.namenode.TestClientNameNodeAddress
[INFO] Running org.apache.hadoop.hdfs.server.namenode.top.window.TestRollingWindowManager
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.364 s - in org.apache.hadoop.hdfs.server.namenode.top.window.TestRollingWindowManager
[INFO] Running org.apache.hadoop.hdfs.server.namenode.top.window.TestRollingWindow
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.154 s - in org.apache.hadoop.hdfs.server.namenode.top.window.TestRollingWindow
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.538 s - in org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFSImage
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestMetadataVersionOutput
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.984 s - in org.apache.hadoop.hdfs.server.namenode.TestUpgradeDomainBlockPlacementPolicy
[INFO] Tests run: 40, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.785 s - in org.apache.hadoop.hdfs.server.namenode.TestAuditLoggerWithCommands
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.915 s - in org.apache.hadoop.hdfs.server.namenode.TestMetadataVersionOutput
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestProtectedDirectories
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestSecureNameNode
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestSecureNameNodeWithExternalKdc
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.083 s - in org.apache.hadoop.hdfs.server.namenode.TestSecureNameNodeWithExternalKdc
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNamenodeStorageDirectives
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.33 s - in org.apache.hadoop.hdfs.server.namenode.TestSecureNameNode
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestStripedINodeFile
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.46 s - in org.apache.hadoop.hdfs.server.namenode.TestProtectedDirectories
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFSDirectory
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.869 s - in org.apache.hadoop.hdfs.server.namenode.TestNamenodeStorageDirectives
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.017 s - in org.apache.hadoop.hdfs.server.namenode.TestStripedINodeFile
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestQuotaWithStripedBlocksWithRandomECPolicy
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.436 s - in org.apache.hadoop.hdfs.server.namenode.TestQuotaWithStripedBlocksWithRandomECPolicy
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.576 s - in org.apache.hadoop.hdfs.server.namenode.TestFSDirectory
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeConfiguration
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.28 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeConfiguration
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.387 s - in org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.454 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.657 s - in org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestCreateEditsLog
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.517 s - in org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestAuditLogAtDebug
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.543 s - in org.apache.hadoop.hdfs.server.namenode.TestAuditLogAtDebug
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestDeduplicationMap
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.078 s - in org.apache.hadoop.hdfs.server.namenode.TestDeduplicationMap
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.337 s - in org.apache.hadoop.hdfs.server.namenode.TestCreateEditsLog
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeRecovery
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestLargeDirectoryDelete
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.685 s - in org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestGenericJournalConf
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.795 s - in org.apache.hadoop.hdfs.server.namenode.TestGenericJournalConf
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.4 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeRecovery
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.52 s - in org.apache.hadoop.hdfs.server.namenode.TestLargeDirectoryDelete
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestXAttrsWithHA
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.919 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestXAttrsWithHA
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapStandbyWithQJM
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.086 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapStandbyWithQJM
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestRemoteNameNodeInfo
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.315 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestRemoteNameNodeInfo
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 115.108 s - in org.apache.hadoop.hdfs.server.namenode.TestFSImage
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 57.16 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 85.905 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.883 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyInProgressTail
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.932 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyInProgressTail
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestSeveralNameNodes
[INFO] Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 71.204 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencing
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.365 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestSeveralNameNodes
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 84.908 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestFailoverWithBlockTokensEnabled
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.313 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.499 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.813 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestHAConfiguration
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.611 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestFailoverWithBlockTokensEnabled
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestHAFsck
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.096 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestHAConfiguration
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestEditLogTailer
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.667 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestHAFsck
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestNNHealthCheck
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.056 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestNNHealthCheck
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 36.387 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencing
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestHAMetrics
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 182.205 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestQuotasWithHA
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.144 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestEditLogsDuringFailover
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.646 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestHAMetrics
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.485 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestQuotasWithHA
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.879 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestEditLogsDuringFailover
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestInitializeSharedEdits
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.764 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestInitializeSharedEdits
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestFailureOfSharedDir
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 42.273 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestEditLogTailer
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestPendingCorruptDnMessages
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.105 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestFailureOfSharedDir
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapStandby
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.738 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestPendingCorruptDnMessages
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestStateTransitionFailure
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.832 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestStateTransitionFailure
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestLossyRetryInvocationHandler
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.956 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestLossyRetryInvocationHandler
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.866 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA
[INFO] Running org.apache.hadoop.hdfs.server.namenode.ha.TestHAAppend
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.493 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestHAAppend
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFSDirAttrOp
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.419 s - in org.apache.hadoop.hdfs.server.namenode.TestFSDirAttrOp
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.172 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapStandby
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestEnabledECPolicies
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.392 s - in org.apache.hadoop.hdfs.server.namenode.TestEnabledECPolicies
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFsLimits
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.258 s - in org.apache.hadoop.hdfs.server.namenode.TestFsLimits
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestMetaSave
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.539 s - in org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestDeadDatanode
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.307 s - in org.apache.hadoop.hdfs.server.namenode.TestMetaSave
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestClusterId
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.285 s - in org.apache.hadoop.hdfs.server.namenode.TestClusterId
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestGetContentSummaryWithPermission
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 68.182 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.526 s - in org.apache.hadoop.hdfs.server.namenode.TestGetContentSummaryWithPermission
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestEditLogRace
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.204 s - in org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestDefaultBlockPlacementPolicy
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 81.339 s - in org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFSImageStorageInspector
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.295 s - in org.apache.hadoop.hdfs.server.namenode.TestFSImageStorageInspector
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.864 s - in org.apache.hadoop.hdfs.server.namenode.TestDefaultBlockPlacementPolicy
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeRpcServerMethods
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestStartupProgressServlet
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.435 s - in org.apache.hadoop.hdfs.server.namenode.TestStartupProgressServlet
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestINodeAttributeProvider
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.906 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeRpcServerMethods
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestStorageRestore
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.848 s - in org.apache.hadoop.hdfs.server.namenode.TestINodeAttributeProvider
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestCheckpoint
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 33.952 s - in org.apache.hadoop.hdfs.server.namenode.TestDeadDatanode
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemLock
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.537 s - in org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemLock
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.854 s - in org.apache.hadoop.hdfs.server.namenode.TestStorageRestore
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestAclConfigFlag
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.3 s - in org.apache.hadoop.hdfs.server.namenode.TestEditLogRace
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestListCorruptFileBlocks
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.496 s - in org.apache.hadoop.hdfs.server.namenode.TestAclConfigFlag
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.004 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameCache
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.115 s - in org.apache.hadoop.hdfs.server.namenode.TestNameCache
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl
[INFO] Tests run: 66, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.57 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl
[INFO] Tests run: 38, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 48.786 s - in org.apache.hadoop.hdfs.server.namenode.TestCheckpoint
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestAddBlockRetry
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.623 s - in org.apache.hadoop.hdfs.server.namenode.TestAddBlockRetry
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestEditLogFileInputStream
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.65 s - in org.apache.hadoop.hdfs.server.namenode.TestEditLogFileInputStream
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestEditLogAutoroll
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.556 s - in org.apache.hadoop.hdfs.server.namenode.TestEditLogAutoroll
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestDeleteRace
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.525 s - in org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFSImageWithSnapshot
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 62.747 s - in org.apache.hadoop.hdfs.server.namenode.TestListCorruptFileBlocks
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestINodeFile
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.94 s - in org.apache.hadoop.hdfs.server.namenode.TestFSImageWithSnapshot
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestStartup
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.801 s - in org.apache.hadoop.hdfs.server.namenode.TestStartup
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestCommitBlockSynchronization
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.214 s - in org.apache.hadoop.hdfs.server.namenode.TestCommitBlockSynchronization
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.488 s - in org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeRpcServer
[INFO] Tests run: 28, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 38.465 s - in org.apache.hadoop.hdfs.server.namenode.TestINodeFile
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.772 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeRpcServer
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotBlocksMap
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestCheckpointsWithSnapshots
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.751 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestCheckpointsWithSnapshots
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestFileWithSnapshotFeature
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.418 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestFileWithSnapshotFeature
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 65.465 s - in org.apache.hadoop.hdfs.server.namenode.TestDeleteRace
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestRandomOpsWithSnapshots
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.933 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotBlocksMap
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion
[WARNING] Tests run: 18, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 35.027 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots
[INFO] Tests run: 33, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 173.539 s - in org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.967 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestFileContextSnapshot
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 57.241 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestRandomOpsWithSnapshots
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotMetrics
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.843 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestFileContextSnapshot
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshottableDirListing
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.886 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotMetrics
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotManager
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.639 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotManager
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestGetContentSummaryWithSnapshot
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.046 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshottableDirListing
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestDiffListBySkipList
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.442 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestGetContentSummaryWithSnapshot
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 69.774 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotListing
[INFO] Tests run: 36, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 48.732 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotStatsMXBean
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.424 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotListing
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestSetQuotaWithSnapshot
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.488 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotStatsMXBean
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.292 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestDiffListBySkipList
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotReplication
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.2 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSetQuotaWithSnapshot
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestUpdatePipelineWithSnapshots
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.982 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.476 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotReplication
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.533 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestUpdatePipelineWithSnapshots
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.064 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.439 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 43.395 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestINodeFileUnderConstructionWithSnapshot
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 35.269 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestDisallowModifyROSnapshot
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.224 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestDisallowModifyROSnapshot
[INFO] Running org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotRename
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.941 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestINodeFileUnderConstructionWithSnapshot
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeRetryCacheMetrics
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 36.26 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.585 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeRetryCacheMetrics
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.224 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotRename
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestBlockUnderConstruction
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFileLimit
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 77.553 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestPathComponents
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.242 s - in org.apache.hadoop.hdfs.server.namenode.TestPathComponents
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestAuditLogger
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.948 s - in org.apache.hadoop.hdfs.server.namenode.TestFileLimit
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestTruncateQuotaUpdate
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.27 s - in org.apache.hadoop.hdfs.server.namenode.TestTruncateQuotaUpdate
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeReconfigure
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.627 s - in org.apache.hadoop.hdfs.server.namenode.TestAuditLogger
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestHostsFiles
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.404 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeReconfigure
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestAclTransformation
[INFO] Tests run: 55, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.274 s - in org.apache.hadoop.hdfs.server.namenode.TestAclTransformation
[INFO] Running org.apache.hadoop.hdfs.server.namenode.startupprogress.TestStartupProgressMetrics
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.503 s - in org.apache.hadoop.hdfs.server.namenode.startupprogress.TestStartupProgressMetrics
[INFO] Running org.apache.hadoop.hdfs.server.namenode.startupprogress.TestStartupProgress
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.385 s - in org.apache.hadoop.hdfs.server.namenode.startupprogress.TestStartupProgress
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.978 s - in org.apache.hadoop.hdfs.server.namenode.TestBlockUnderConstruction
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFsck
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.847 s - in org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeRespectsBindHostKeys
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.364 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestAllowFormat
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.112 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeRespectsBindHostKeys
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestStoragePolicySummary
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.192 s - in org.apache.hadoop.hdfs.server.namenode.TestStoragePolicySummary
[INFO] Running org.apache.hadoop.hdfs.server.namenode.web.resources.TestWebHdfsDataLocality
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.076 s - in org.apache.hadoop.hdfs.server.namenode.TestAllowFormat
[INFO] Running org.apache.hadoop.hdfs.server.namenode.web.resources.TestWebHdfsCreatePermissions
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.065 s - in org.apache.hadoop.hdfs.server.namenode.TestHostsFiles
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.67 s - in org.apache.hadoop.hdfs.server.namenode.web.resources.TestWebHdfsDataLocality
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourcePolicy
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.349 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourcePolicy
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.446 s - in org.apache.hadoop.hdfs.server.namenode.web.resources.TestWebHdfsCreatePermissions
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestValidateConfigurationSettings
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestCommitBlockWithInvalidGenStamp
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.323 s - in org.apache.hadoop.hdfs.server.namenode.TestValidateConfigurationSettings
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestGetImageServlet
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.747 s - in org.apache.hadoop.hdfs.server.namenode.TestGetImageServlet
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.541 s - in org.apache.hadoop.hdfs.server.namenode.TestCommitBlockWithInvalidGenStamp
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.474 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionFunctional
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.186 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFSImageWithXAttr
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.092 s - in org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionFunctional
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestReconstructStripedBlocks
[INFO] Tests run: 66, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.418 s - in org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNNThroughputBenchmark
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.878 s - in org.apache.hadoop.hdfs.server.namenode.TestNNThroughputBenchmark
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFSEditLogLoader
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.054 s - in org.apache.hadoop.hdfs.server.namenode.TestReconstructStripedBlocks
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.298 s - in org.apache.hadoop.hdfs.server.namenode.TestFSImageWithXAttr
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestAddStripedBlocks
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 36.096 s - in org.apache.hadoop.hdfs.server.namenode.TestAddStripedBlocks
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestXAttrConfigFlag
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.325 s - in org.apache.hadoop.hdfs.server.namenode.TestXAttrConfigFlag
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestListOpenFiles
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 64.958 s - in org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency
[INFO] Tests run: 32, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 122.795 s - in org.apache.hadoop.hdfs.server.namenode.TestFsck
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestAddOverReplicatedStripedBlocks
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.942 s - in org.apache.hadoop.hdfs.server.namenode.TestListOpenFiles
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestAuditLogs
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.186 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestEditLogJournalFailures
[INFO] Tests run: 24, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 95.984 s - in org.apache.hadoop.hdfs.server.namenode.TestFSEditLogLoader
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestEditLogFileOutputStream
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.528 s - in org.apache.hadoop.hdfs.server.namenode.TestEditLogFileOutputStream
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFileJournalManager
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.227 s - in org.apache.hadoop.hdfs.server.namenode.TestFileJournalManager
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestLeaseManager
[WARNING] Tests run: 4, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 21.424 s - in org.apache.hadoop.hdfs.server.namenode.TestAddOverReplicatedStripedBlocks
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestAddStripedBlockInFBR
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.144 s - in org.apache.hadoop.hdfs.server.namenode.TestEditLogJournalFailures
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestStartupOptionUpgrade
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.939 s - in org.apache.hadoop.hdfs.server.namenode.TestStartupOptionUpgrade
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestBlockPlacementPolicyRackFaultTolerant
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.473 s - in org.apache.hadoop.hdfs.server.namenode.TestAddStripedBlockInFBR
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.743 s - in org.apache.hadoop.hdfs.server.namenode.TestBlockPlacementPolicyRackFaultTolerant
[INFO] Tests run: 32, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.088 s - in org.apache.hadoop.hdfs.server.namenode.TestAuditLogs
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives
[INFO] Running org.apache.hadoop.hdfs.server.namenode.metrics.TestTopMetrics
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.47 s - in org.apache.hadoop.hdfs.server.namenode.metrics.TestTopMetrics
[INFO] Running org.apache.hadoop.hdfs.server.namenode.metrics.TestNNMetricFilesInGetListingOps
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.954 s - in org.apache.hadoop.hdfs.server.namenode.TestLeaseManager
[INFO] Running org.apache.hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.902 s - in org.apache.hadoop.hdfs.server.namenode.metrics.TestNNMetricFilesInGetListingOps
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.299 s - in org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestXAttrFeature
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.167 s - in org.apache.hadoop.hdfs.server.namenode.TestXAttrFeature
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestReencryptionHandler
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.402 s - in org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestAddBlock
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.116 s - in org.apache.hadoop.hdfs.server.namenode.TestReencryptionHandler
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFSNamesystem
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.116 s - in org.apache.hadoop.hdfs.server.namenode.TestAddBlock
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.805 s - in org.apache.hadoop.hdfs.server.namenode.TestFSNamesystem
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestMalformedURLs
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.596 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestSecurityTokenEditLog
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.321 s - in org.apache.hadoop.hdfs.server.namenode.TestMalformedURLs
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemMBean
[INFO] Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 54.807 s - in org.apache.hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestSecondaryWebUi
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.975 s - in org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemMBean
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestEditsDoubleBuffer
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.641 s - in org.apache.hadoop.hdfs.server.namenode.TestSecondaryWebUi
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.326 s - in org.apache.hadoop.hdfs.server.namenode.TestEditsDoubleBuffer
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.639 s - in org.apache.hadoop.hdfs.server.namenode.TestSecurityTokenEditLog
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestReencryption
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNameNodeStatusMXBean
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFsckWithMultipleNameNodes
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.711 s - in org.apache.hadoop.hdfs.server.namenode.TestFsckWithMultipleNameNodes
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFSImageWithAcl
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.544 s - in org.apache.hadoop.hdfs.server.namenode.TestNameNodeStatusMXBean
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestEditLog
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 77.246 s - in org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFileTruncate
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 69.896 s - in org.apache.hadoop.hdfs.server.namenode.TestFSImageWithAcl
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestHDFSConcat
[INFO] Tests run: 48, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 75.924 s - in org.apache.hadoop.hdfs.server.namenode.TestEditLog
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNestedEncryptionZones
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.079 s - in org.apache.hadoop.hdfs.server.namenode.TestHDFSConcat
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.534 s - in org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestQuotaByStorageType
[INFO] Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 82.874 s - in org.apache.hadoop.hdfs.server.namenode.TestFileTruncate
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestParallelImageWrite
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.853 s - in org.apache.hadoop.hdfs.server.namenode.TestNestedEncryptionZones
[INFO] Running org.apache.hadoop.hdfs.server.mover.TestMover
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.182 s - in org.apache.hadoop.hdfs.server.namenode.TestParallelImageWrite
[INFO] Running org.apache.hadoop.hdfs.server.mover.TestStorageMover
[INFO] Tests run: 23, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.025 s - in org.apache.hadoop.hdfs.server.namenode.TestQuotaByStorageType
[INFO] Running org.apache.hadoop.hdfs.TestSmallBlock
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.05 s - in org.apache.hadoop.hdfs.TestSmallBlock
[INFO] Running org.apache.hadoop.hdfs.TestReplaceDatanodeOnFailure
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.391 s - in org.apache.hadoop.hdfs.TestReplaceDatanodeOnFailure
[INFO] Running org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData
[INFO] Tests run: 32, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 247.023 s - in org.apache.hadoop.hdfs.server.namenode.TestReencryption
[INFO] Running org.apache.hadoop.hdfs.TestAbandonBlock
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.379 s - in org.apache.hadoop.hdfs.TestAbandonBlock
[INFO] Running org.apache.hadoop.hdfs.TestRollingUpgradeDowngrade
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 150.29 s - in org.apache.hadoop.hdfs.server.mover.TestStorageMover
[INFO] Running org.apache.hadoop.hdfs.TestFileStatusSerialization
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.335 s - in org.apache.hadoop.hdfs.TestFileStatusSerialization
[INFO] Running org.apache.hadoop.hdfs.protocolPB.TestPBHelper
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.484 s - in org.apache.hadoop.hdfs.TestRollingUpgradeDowngrade
[INFO] Tests run: 40, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.574 s - in org.apache.hadoop.hdfs.protocolPB.TestPBHelper
[INFO] Running org.apache.hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy
[INFO] Running org.apache.hadoop.hdfs.TestDFSRollback
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.613 s - in org.apache.hadoop.hdfs.TestDFSRollback
[INFO] Running org.apache.hadoop.hdfs.TestPread
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 43.212 s - in org.apache.hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy
[INFO] Running org.apache.hadoop.hdfs.TestReconstructStripedFile
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 207.057 s - in org.apache.hadoop.hdfs.server.mover.TestMover
[INFO] Running org.apache.hadoop.hdfs.TestIsMethodSupported
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.296 s - in org.apache.hadoop.hdfs.TestIsMethodSupported
[INFO] Running org.apache.hadoop.hdfs.TestReadWhileWriting
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.353 s - in org.apache.hadoop.hdfs.TestReadWhileWriting
[INFO] Running org.apache.hadoop.hdfs.TestDFSOutputStream
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.121 s - in org.apache.hadoop.hdfs.TestDFSOutputStream
[INFO] Running org.apache.hadoop.hdfs.TestDFSRename
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.677 s - in org.apache.hadoop.hdfs.TestDFSRename
[INFO] Running org.apache.hadoop.hdfs.TestErasureCodingExerciseAPIs
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.587 s - in org.apache.hadoop.hdfs.TestErasureCodingExerciseAPIs
[INFO] Running org.apache.hadoop.hdfs.TestExternalBlockReader
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.168 s - in org.apache.hadoop.hdfs.TestExternalBlockReader
[INFO] Running org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 84.658 s - in org.apache.hadoop.hdfs.TestReconstructStripedFile
[INFO] Running org.apache.hadoop.hdfs.TestBlockStoragePolicy
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 263.587 s - in org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.928 s - in org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy
[INFO] Running org.apache.hadoop.hdfs.tools.TestDebugAdmin
[INFO] Running org.apache.hadoop.hdfs.tools.TestDFSAdminWithHA
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 115.614 s - in org.apache.hadoop.hdfs.TestPread
[INFO] Running org.apache.hadoop.hdfs.tools.TestGetGroups
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.755 s - in org.apache.hadoop.hdfs.tools.TestDebugAdmin
[INFO] Running org.apache.hadoop.hdfs.tools.TestDFSZKFailoverController
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.614 s - in org.apache.hadoop.hdfs.tools.TestGetGroups
[INFO] Running org.apache.hadoop.hdfs.tools.TestDFSHAAdmin
[INFO] Tests run: 21, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.245 s - in org.apache.hadoop.hdfs.tools.TestDFSHAAdmin
[INFO] Running org.apache.hadoop.hdfs.tools.TestDFSHAAdminMiniCluster
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.53 s - in org.apache.hadoop.hdfs.tools.TestDFSHAAdminMiniCluster
[INFO] Running org.apache.hadoop.hdfs.tools.TestGetConf
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.014 s - in org.apache.hadoop.hdfs.tools.TestGetConf
[INFO] Running org.apache.hadoop.hdfs.tools.TestWebHDFSStoragePolicyCommands
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.375 s - in org.apache.hadoop.hdfs.tools.TestWebHDFSStoragePolicyCommands
[INFO] Running org.apache.hadoop.hdfs.tools.TestDelegationTokenFetcher
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.666 s - in org.apache.hadoop.hdfs.tools.TestDelegationTokenFetcher
[INFO] Running org.apache.hadoop.hdfs.tools.TestViewFSStoragePolicyCommands
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.22 s - in org.apache.hadoop.hdfs.TestBlockStoragePolicy
[INFO] Running org.apache.hadoop.hdfs.tools.TestDFSAdmin
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.612 s - in org.apache.hadoop.hdfs.tools.TestDFSZKFailoverController
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.82 s - in org.apache.hadoop.hdfs.tools.TestViewFSStoragePolicyCommands
[INFO] Running org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer
[INFO] Running org.apache.hadoop.hdfs.tools.TestStoragePolicyCommands
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.341 s - in org.apache.hadoop.hdfs.tools.TestStoragePolicyCommands
[INFO] Running org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForContentSummary
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.006 s - in org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForContentSummary
[INFO] Running org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.698 s - in org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer
[INFO] Running org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForAcl
[INFO] Tests run: 46, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 53.704 s - in org.apache.hadoop.hdfs.tools.TestDFSAdminWithHA
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.789 s - in org.apache.hadoop.hdfs.tools.TestDFSAdmin
[INFO] Running org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerWithStripedBlocks
[INFO] Running org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForXAttr
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.672 s - in org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForAcl
[INFO] Running org.apache.hadoop.hdfs.TestDFSConfigKeys
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.122 s - in org.apache.hadoop.hdfs.TestDFSConfigKeys
[INFO] Running org.apache.hadoop.hdfs.TestDatanodeRegistration
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.859 s - in org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForXAttr
[INFO] Running org.apache.hadoop.hdfs.TestDFSUpgradeFromImage
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.562 s - in org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer
[INFO] Running org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.073 s - in org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerWithStripedBlocks
[INFO] Running org.apache.hadoop.hdfs.TestExtendedAcls
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.906 s - in org.apache.hadoop.hdfs.TestDatanodeRegistration
[INFO] Running org.apache.hadoop.hdfs.TestDFSPermission
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.929 s - in org.apache.hadoop.hdfs.TestExtendedAcls
[INFO] Running org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.668 s - in org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.51 s - in org.apache.hadoop.hdfs.TestDFSPermission
[INFO] Running org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy
[INFO] Running org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.633 s - in org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead
[INFO] Running org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitCache
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.678 s - in org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitCache
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 49.069 s - in org.apache.hadoop.hdfs.TestDFSUpgradeFromImage
[INFO] Running org.apache.hadoop.hdfs.TestFileCreation
[INFO] Running org.apache.hadoop.hdfs.TestParallelShortCircuitLegacyRead
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.522 s - in org.apache.hadoop.hdfs.TestParallelShortCircuitLegacyRead
[INFO] Running org.apache.hadoop.hdfs.TestDFSUtil
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 61.22 s - in org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication
[INFO] Running org.apache.hadoop.hdfs.TestDFSUpgrade
[INFO] Tests run: 33, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.937 s - in org.apache.hadoop.hdfs.TestDFSUtil
[INFO] Running org.apache.hadoop.hdfs.TestFileStatusWithDefaultECPolicy
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.254 s - in org.apache.hadoop.hdfs.TestFileStatusWithDefaultECPolicy
[INFO] Running org.apache.hadoop.hdfs.TestDFSInotifyEventInputStream
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.216 s - in org.apache.hadoop.hdfs.TestDFSUpgrade
[INFO] Running org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.039 s - in org.apache.hadoop.hdfs.TestDFSInotifyEventInputStream
[INFO] Running org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy
[ERROR] Tests run: 21, Failures: 6, Errors: 0, Skipped: 1, Time elapsed: 100.642 s <<< FAILURE! - in org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy
[ERROR] testRecoverAnyBlocks1(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)  Time elapsed: 6.556 s  <<< FAILURE!
arrays first differed at element [1048064]; expected:<1> but was:<0>
	at org.junit.internal.ComparisonCriteria.arrayEquals(ComparisonCriteria.java:50)
	at org.junit.Assert.internalArrayEquals(Assert.java:473)
	at org.junit.Assert.assertArrayEquals(Assert.java:294)
	at org.junit.Assert.assertArrayEquals(Assert.java:305)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.assertFileBlocksReconstruction(TestReconstructStripedFile.java:398)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.testRecoverAnyBlocks1(TestReconstructStripedFile.java:228)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testRecoverOneDataBlock(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)  Time elapsed: 3.997 s  <<< FAILURE!
arrays first differed at element [0]; expected:<1> but was:<0>
	at org.junit.internal.ComparisonCriteria.arrayEquals(ComparisonCriteria.java:50)
	at org.junit.Assert.internalArrayEquals(Assert.java:473)
	at org.junit.Assert.assertArrayEquals(Assert.java:294)
	at org.junit.Assert.assertArrayEquals(Assert.java:305)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.assertFileBlocksReconstruction(TestReconstructStripedFile.java:398)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.testRecoverOneDataBlock(TestReconstructStripedFile.java:200)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testRecoverOneParityBlock(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)  Time elapsed: 3.809 s  <<< FAILURE!
arrays first differed at element [0]; expected:<0> but was:<1>
	at org.junit.internal.ComparisonCriteria.arrayEquals(ComparisonCriteria.java:50)
	at org.junit.Assert.internalArrayEquals(Assert.java:473)
	at org.junit.Assert.assertArrayEquals(Assert.java:294)
	at org.junit.Assert.assertArrayEquals(Assert.java:305)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.assertFileBlocksReconstruction(TestReconstructStripedFile.java:398)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.testRecoverOneParityBlock(TestReconstructStripedFile.java:151)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testRecoverOneDataBlock(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)  Time elapsed: 3.651 s  <<< FAILURE!
arrays first differed at element [0]; expected:<1> but was:<0>
	at org.junit.internal.ComparisonCriteria.arrayEquals(ComparisonCriteria.java:50)
	at org.junit.Assert.internalArrayEquals(Assert.java:473)
	at org.junit.Assert.assertArrayEquals(Assert.java:294)
	at org.junit.Assert.assertArrayEquals(Assert.java:305)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.assertFileBlocksReconstruction(TestReconstructStripedFile.java:398)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.testRecoverOneDataBlock(TestReconstructStripedFile.java:200)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testRecoverOneParityBlock(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)  Time elapsed: 3.585 s  <<< FAILURE!
arrays first differed at element [0]; expected:<0> but was:<1>
	at org.junit.internal.ComparisonCriteria.arrayEquals(ComparisonCriteria.java:50)
	at org.junit.Assert.internalArrayEquals(Assert.java:473)
	at org.junit.Assert.assertArrayEquals(Assert.java:294)
	at org.junit.Assert.assertArrayEquals(Assert.java:305)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.assertFileBlocksReconstruction(TestReconstructStripedFile.java:398)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.testRecoverOneParityBlock(TestReconstructStripedFile.java:151)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[ERROR] testRecoverOneDataBlock(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)  Time elapsed: 3.547 s  <<< FAILURE!
arrays first differed at element [0]; expected:<1> but was:<0>
	at org.junit.internal.ComparisonCriteria.arrayEquals(ComparisonCriteria.java:50)
	at org.junit.Assert.internalArrayEquals(Assert.java:473)
	at org.junit.Assert.assertArrayEquals(Assert.java:294)
	at org.junit.Assert.assertArrayEquals(Assert.java:305)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.assertFileBlocksReconstruction(TestReconstructStripedFile.java:398)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.testRecoverOneDataBlock(TestReconstructStripedFile.java:200)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[INFO] Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 78.855 s - in org.apache.hadoop.hdfs.TestFileCreation
[INFO] Running org.apache.hadoop.hdfs.TestHFlush
[INFO] Running org.apache.hadoop.hdfs.TestHttpPolicy
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.259 s - in org.apache.hadoop.hdfs.TestHttpPolicy
[INFO] Running org.apache.hadoop.hdfs.TestKeyProviderCache
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.272 s - in org.apache.hadoop.hdfs.TestKeyProviderCache
[INFO] Running org.apache.hadoop.hdfs.TestMultiThreadedHflush
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.483 s - in org.apache.hadoop.hdfs.TestMultiThreadedHflush
[INFO] Running org.apache.hadoop.hdfs.TestFileCreationDelete
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.989 s - in org.apache.hadoop.hdfs.TestHFlush
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.275 s - in org.apache.hadoop.hdfs.TestFileCreationDelete
[INFO] Running org.apache.hadoop.hdfs.TestAppendSnapshotTruncate
[INFO] Running org.apache.hadoop.hdfs.TestRead
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.865 s - in org.apache.hadoop.hdfs.TestRead
[INFO] Running org.apache.hadoop.hdfs.TestDFSStorageStateRecovery
[INFO] Tests run: 45, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 89.418 s - in org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS
[INFO] Running org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithRandomECPolicy
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.559 s - in org.apache.hadoop.hdfs.TestAppendSnapshotTruncate
[INFO] Running org.apache.hadoop.hdfs.TestErasureCodingPolicyWithSnapshot
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 100.948 s - in org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy
[INFO] Running org.apache.hadoop.hdfs.TestErasureCodingPolicies
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.801 s - in org.apache.hadoop.hdfs.TestErasureCodingPolicyWithSnapshot
[INFO] Running org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 44.182 s - in org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithRandomECPolicy
[INFO] Running org.apache.hadoop.hdfs.TestFetchImage
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 50.514 s - in org.apache.hadoop.hdfs.TestDFSStorageStateRecovery
[INFO] Running org.apache.hadoop.hdfs.TestApplyingStoragePolicy
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.915 s - in org.apache.hadoop.hdfs.TestFetchImage
[INFO] Running org.apache.hadoop.hdfs.TestSecureEncryptionZoneWithKMS
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.274 s - in org.apache.hadoop.hdfs.TestApplyingStoragePolicy
[INFO] Running org.apache.hadoop.hdfs.TestReadStripedFileWithDecoding
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 33.276 s - in org.apache.hadoop.hdfs.TestErasureCodingPolicies
[INFO] Running org.apache.hadoop.hdfs.TestClose
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.325 s - in org.apache.hadoop.hdfs.TestReadStripedFileWithDecoding
[INFO] Running org.apache.hadoop.hdfs.TestBlockMissingException
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.741 s - in org.apache.hadoop.hdfs.TestClose
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.048 s - in org.apache.hadoop.hdfs.TestSecureEncryptionZoneWithKMS
[INFO] Running org.apache.hadoop.hdfs.TestLocalDFS
[INFO] Running org.apache.hadoop.hdfs.TestDFSAddressConfig
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.717 s - in org.apache.hadoop.hdfs.TestBlockMissingException
[INFO] Running org.apache.hadoop.hdfs.TestDatanodeLayoutUpgrade
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.321 s - in org.apache.hadoop.hdfs.TestDFSAddressConfig
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.263 s - in org.apache.hadoop.hdfs.TestLocalDFS
[INFO] Running org.apache.hadoop.hdfs.TestDataStream
[INFO] Running org.apache.hadoop.hdfs.TestReservedRawPaths
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.275 s - in org.apache.hadoop.hdfs.TestDatanodeLayoutUpgrade
[INFO] Running org.apache.hadoop.hdfs.TestDFSInotifyEventInputStreamKerberized
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.793 s - in org.apache.hadoop.hdfs.TestReservedRawPaths
[INFO] Running org.apache.hadoop.hdfs.TestAclsEndToEnd
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.968 s - in org.apache.hadoop.hdfs.TestDFSInotifyEventInputStreamKerberized
[INFO] Running org.apache.hadoop.security.TestPermission
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.112 s - in org.apache.hadoop.hdfs.TestDataStream
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.21 s - in org.apache.hadoop.security.TestPermission
[INFO] Running org.apache.hadoop.security.TestPermissionSymlinks
[INFO] Running org.apache.hadoop.security.TestRefreshUserMappings
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.986 s - in org.apache.hadoop.security.TestPermissionSymlinks
[INFO] Running org.apache.hadoop.tools.TestTools
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.778 s - in org.apache.hadoop.security.TestRefreshUserMappings
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.912 s - in org.apache.hadoop.tools.TestTools
[INFO] Running org.apache.hadoop.tools.TestJMXGet
[INFO] Running org.apache.hadoop.tools.TestHdfsConfigFields
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.653 s - in org.apache.hadoop.tools.TestHdfsConfigFields
[INFO] Running org.apache.hadoop.TestRefreshCallQueue
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.636 s - in org.apache.hadoop.TestRefreshCallQueue
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.84 s - in org.apache.hadoop.tools.TestJMXGet
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 69.407 s - in org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 42.903 s - in org.apache.hadoop.hdfs.TestAclsEndToEnd
[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Errors: 
[ERROR] org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1(org.apache.hadoop.hdfs.TestFileChecksum)
[ERROR]   Run 1: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1:256->getFileChecksum:584 ? PathIO
[ERROR]   Run 2: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1:256->getFileChecksum:584 ? PathIO
[ERROR]   Run 3: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1:256->getFileChecksum:584 ? PathIO
[ERROR]   Run 4: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1:256->getFileChecksum:584 ? PathIO
[INFO] 
[ERROR] org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2(org.apache.hadoop.hdfs.TestFileChecksum)
[ERROR]   Run 1: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2:273->getFileChecksum:586 ? PathIO
[ERROR]   Run 2: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2:273->getFileChecksum:586 ? PathIO
[ERROR]   Run 3: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2:273->getFileChecksum:586 ? PathIO
[ERROR]   Run 4: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2:273->getFileChecksum:586 ? PathIO
[INFO] 
[ERROR] org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery10(org.apache.hadoop.hdfs.TestFileChecksum)
[ERROR]   Run 1: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery10:410->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[ERROR]   Run 2: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery10:410->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[ERROR]   Run 3: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery10:410->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[ERROR]   Run 4: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery10:410->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[INFO] 
[ERROR] org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery12(org.apache.hadoop.hdfs.TestFileChecksum)
[ERROR]   Run 1: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery12:432->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[ERROR]   Run 2: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery12:432->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[ERROR]   Run 3: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery12:432->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[ERROR]   Run 4: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery12:432->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[INFO] 
[ERROR] org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(org.apache.hadoop.hdfs.TestFileChecksum)
[ERROR]   Run 1: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13:443->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[ERROR]   Run 2: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13:443->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[ERROR]   Run 3: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13:443->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[ERROR]   Run 4: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13:443->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[INFO] 
[ERROR] org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(org.apache.hadoop.hdfs.TestFileChecksum)
[ERROR]   Run 1: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14:454->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[ERROR]   Run 2: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14:454->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[ERROR]   Run 3: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14:454->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[ERROR]   Run 4: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14:454->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[INFO] 
[ERROR] org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15(org.apache.hadoop.hdfs.TestFileChecksum)
[ERROR]   Run 1: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15:465->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[ERROR]   Run 2: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15:465->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[ERROR]   Run 3: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15:465->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[ERROR]   Run 4: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15:465->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[INFO] 
[ERROR] org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc.testStripedFileChecksumWithMissedDataBlocks1(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)
[ERROR]   Run 1: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1:256->TestFileChecksum.getFileChecksum:584 ? PathIO
[ERROR]   Run 2: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1:256->TestFileChecksum.getFileChecksum:584 ? PathIO
[ERROR]   Run 3: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1:256->TestFileChecksum.getFileChecksum:584 ? PathIO
[ERROR]   Run 4: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1:256->TestFileChecksum.getFileChecksum:584 ? PathIO
[INFO] 
[ERROR] org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc.testStripedFileChecksumWithMissedDataBlocks2(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)
[ERROR]   Run 1: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2:273->TestFileChecksum.getFileChecksum:586 ? PathIO
[ERROR]   Run 2: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2:273->TestFileChecksum.getFileChecksum:586 ? PathIO
[ERROR]   Run 3: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2:273->TestFileChecksum.getFileChecksum:586 ? PathIO
[ERROR]   Run 4: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2:273->TestFileChecksum.getFileChecksum:586 ? PathIO
[INFO] 
[ERROR] org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)
[ERROR]   Run 1: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13:443->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO
[ERROR]   Run 2: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13:443->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO
[ERROR]   Run 3: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13:443->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO
[ERROR]   Run 4: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13:443->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO
[INFO] 
[ERROR] org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)
[ERROR]   Run 1: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14:454->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO
[ERROR]   Run 2: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14:454->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO
[ERROR]   Run 3: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14:454->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO
[ERROR]   Run 4: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14:454->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO
[INFO] 
[ERROR] org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc.testStripedFileChecksumWithMissedDataBlocksRangeQuery15(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)
[ERROR]   Run 1: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15:465->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO
[ERROR]   Run 2: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15:465->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO
[ERROR]   Run 3: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15:465->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO
[ERROR]   Run 4: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15:465->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO
[INFO] 
[WARNING] Flakes: 
[WARNING] org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(org.apache.hadoop.hdfs.TestFileChecksum)
[ERROR]   Run 1: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16:479->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[INFO]   Run 2: PASS
[INFO] 
[WARNING] org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(org.apache.hadoop.hdfs.TestFileChecksum)
[ERROR]   Run 1: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20:533->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[INFO]   Run 2: PASS
[INFO] 
[WARNING] org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery8(org.apache.hadoop.hdfs.TestFileChecksum)
[ERROR]   Run 1: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery8:388->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[INFO]   Run 2: PASS
[INFO] 
[WARNING] org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery9(org.apache.hadoop.hdfs.TestFileChecksum)
[ERROR]   Run 1: TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery9:399->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO
[INFO]   Run 2: PASS
[INFO] 
[WARNING] org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)
[ERROR]   Run 1: TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3:333->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO
[INFO]   Run 2: PASS
[INFO] 
[WARNING] org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy.testRecoverAnyBlocks1(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)
[ERROR]   Run 1: TestReconstructStripedFileWithRandomECPolicy>TestReconstructStripedFile.testRecoverAnyBlocks1:228->TestReconstructStripedFile.assertFileBlocksReconstruction:398 arrays first differed at element [1048064]; expected:<1> but was:<0>
[INFO]   Run 2: PASS
[INFO] 
[WARNING] org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy.testRecoverOneDataBlock(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)
[ERROR]   Run 1: TestReconstructStripedFileWithRandomECPolicy>TestReconstructStripedFile.testRecoverOneDataBlock:200->TestReconstructStripedFile.assertFileBlocksReconstruction:398 arrays first differed at element [0]; expected:<1> but was:<0>
[ERROR]   Run 2: TestReconstructStripedFileWithRandomECPolicy>TestReconstructStripedFile.testRecoverOneDataBlock:200->TestReconstructStripedFile.assertFileBlocksReconstruction:398 arrays first differed at element [0]; expected:<1> but was:<0>
[ERROR]   Run 3: TestReconstructStripedFileWithRandomECPolicy>TestReconstructStripedFile.testRecoverOneDataBlock:200->TestReconstructStripedFile.assertFileBlocksReconstruction:398 arrays first differed at element [0]; expected:<1> but was:<0>
[INFO]   Run 4: PASS
[INFO] 
[WARNING] org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy.testRecoverOneParityBlock(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)
[ERROR]   Run 1: TestReconstructStripedFileWithRandomECPolicy>TestReconstructStripedFile.testRecoverOneParityBlock:151->TestReconstructStripedFile.assertFileBlocksReconstruction:398 arrays first differed at element [0]; expected:<0> but was:<1>
[ERROR]   Run 2: TestReconstructStripedFileWithRandomECPolicy>TestReconstructStripedFile.testRecoverOneParityBlock:151->TestReconstructStripedFile.assertFileBlocksReconstruction:398 arrays first differed at element [0]; expected:<0> but was:<1>
[INFO]   Run 3: PASS
[INFO] 
[INFO] 
[ERROR] Tests run: 5572, Failures: 0, Errors: 12, Skipped: 22, Flakes: 8
[INFO] 
[INFO] 
[INFO] ------------< org.apache.hadoop:hadoop-hdfs-native-client >-------------
[INFO] Building Apache Hadoop HDFS Native Client 3.1.1-TDP-0.1.0-SNAPSHOT [17/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-hdfs-native-client ---
[INFO] Deleting /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-native-client/target
[INFO] Deleting /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-native-client (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-hdfs-native-client ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-native-client/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-native-client/target/test/data
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdfs-native-client ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdfs-native-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdfs-native-client ---
[INFO] No sources to compile
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:cmake-compile (cmake-compile) @ hadoop-hdfs-native-client ---
[INFO] Running cmake /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-native-client/src -DGENERATED_JAVAH=/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-native-client/target/native/javah -DJVM_ARCH_DATA_MODEL=64 -DREQUIRE_FUSE=true -G Unix Makefiles
[INFO] with extra environment variables {}
[INFO] Running make -j 8 VERBOSE=1
[INFO] cmake compilation finished successfully in 3815 millisecond(s).
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-hdfs-native-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-native-client/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-hdfs-native-client ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-hdfs-native-client ---
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (native_tests) @ hadoop-hdfs-native-client ---
[INFO] Executing tasks

main:
     [exec] Test project /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-native-client/target
     [exec]     Start 1: test_test_libhdfs_threaded_hdfs_static
     [exec] 1/3 Test #1: test_test_libhdfs_threaded_hdfs_static ...   Passed    3.71 sec
     [exec]     Start 2: test_test_libhdfs_zerocopy_hdfs_static
     [exec] 2/3 Test #2: test_test_libhdfs_zerocopy_hdfs_static ...   Passed    3.67 sec
     [exec]     Start 3: test_test_native_mini_dfs
     [exec] 3/3 Test #3: test_test_native_mini_dfs ................   Passed    2.93 sec
     [exec] 
     [exec] 100% tests passed, 0 tests failed out of 3
     [exec] 
     [exec] Total Test time (real) =  10.31 sec
[INFO] Executed tasks
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-hdfs-httpfs >----------------
[INFO] Building Apache Hadoop HttpFS 3.1.1-TDP-0.1.0-SNAPSHOT           [18/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-hdfs-httpfs ---
[INFO] Deleting /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/target
[INFO] Deleting /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-hdfs-httpfs ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdfs-httpfs ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdfs-httpfs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 4 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdfs-httpfs ---
[INFO] Compiling 49 source files to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/target/classes
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSFileSystem.java:[47,38] [deprecation] FsPermissionExtension in org.apache.hadoop.hdfs.protocol has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/lib/service/instrumentation/InstrumentationService.java:[329,10] [unchecked] unchecked assignment to variable var as member of raw type VariableHolder
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSFileSystem.java:[1085,6] [deprecation] FsPermissionExtension in org.apache.hadoop.hdfs.protocol has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSFileSystem.java:[1086,14] [deprecation] FsPermissionExtension in org.apache.hadoop.hdfs.protocol has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/server/FSOperations.java:[114,34] [deprecation] getAclBit() in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/server/FSOperations.java:[117,34] [deprecation] getEncryptedBit() in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/server/FSOperations.java:[120,34] [deprecation] getErasureCodedBit() in FsPermission has been deprecated
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-web-xmls) @ hadoop-hdfs-httpfs ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/target/test-classes/webapp
     [copy] Copying 1 file to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/target/test-classes/webapp
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-hdfs-httpfs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 9 resources
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-hdfs-httpfs ---
[INFO] Compiling 46 source files to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/target/test-classes
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/org/apache/hadoop/fs/http/client/BaseTestHttpFSWith.java:[862,49] [deprecation] getAclBit() in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/org/apache/hadoop/fs/http/client/BaseTestHttpFSWith.java:[863,42] [deprecation] getAclBit() in FsPermission has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-hdfs-httpfs ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.fs.http.client.TestHttpFSFileSystemLocalFileSystem
[WARNING] Tests run: 62, Failures: 0, Errors: 0, Skipped: 6, Time elapsed: 11.673 s - in org.apache.hadoop.fs.http.client.TestHttpFSFileSystemLocalFileSystem
[INFO] Running org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem
[INFO] Tests run: 62, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.56 s - in org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem
[INFO] Running org.apache.hadoop.fs.http.client.TestHttpFSWithHttpFSFileSystem
[INFO] Tests run: 62, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.381 s - in org.apache.hadoop.fs.http.client.TestHttpFSWithHttpFSFileSystem
[INFO] Running org.apache.hadoop.fs.http.client.TestHttpFSFWithWebhdfsFileSystem
[INFO] Tests run: 62, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.862 s - in org.apache.hadoop.fs.http.client.TestHttpFSFWithWebhdfsFileSystem
[INFO] Running org.apache.hadoop.fs.http.server.TestHttpFSServerWebServer
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.802 s - in org.apache.hadoop.fs.http.server.TestHttpFSServerWebServer
[INFO] Running org.apache.hadoop.fs.http.server.TestHttpFSServer
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.552 s - in org.apache.hadoop.fs.http.server.TestHttpFSServer
[INFO] Running org.apache.hadoop.fs.http.server.TestHttpFSServerNoACLs
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.1 s - in org.apache.hadoop.fs.http.server.TestHttpFSServerNoACLs
[INFO] Running org.apache.hadoop.fs.http.server.TestCheckUploadContentTypeFilter
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.209 s - in org.apache.hadoop.fs.http.server.TestCheckUploadContentTypeFilter
[INFO] Running org.apache.hadoop.fs.http.server.TestHttpFSServerNoXAttrs
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.777 s - in org.apache.hadoop.fs.http.server.TestHttpFSServerNoXAttrs
[INFO] Running org.apache.hadoop.lib.util.TestCheck
[INFO] Tests run: 21, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.061 s - in org.apache.hadoop.lib.util.TestCheck
[INFO] Running org.apache.hadoop.lib.util.TestConfigurationUtils
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.13 s - in org.apache.hadoop.lib.util.TestConfigurationUtils
[INFO] Running org.apache.hadoop.lib.servlet.TestMDCFilter
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.189 s - in org.apache.hadoop.lib.servlet.TestMDCFilter
[INFO] Running org.apache.hadoop.lib.servlet.TestHostnameFilter
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.205 s - in org.apache.hadoop.lib.servlet.TestHostnameFilter
[INFO] Running org.apache.hadoop.lib.servlet.TestServerWebApp
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.151 s - in org.apache.hadoop.lib.servlet.TestServerWebApp
[INFO] Running org.apache.hadoop.lib.service.security.TestGroupsService
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.224 s - in org.apache.hadoop.lib.service.security.TestGroupsService
[INFO] Running org.apache.hadoop.lib.service.scheduler.TestSchedulerService
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.144 s - in org.apache.hadoop.lib.service.scheduler.TestSchedulerService
[INFO] Running org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.515 s - in org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService
[INFO] Running org.apache.hadoop.lib.service.instrumentation.TestInstrumentationService
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.605 s - in org.apache.hadoop.lib.service.instrumentation.TestInstrumentationService
[INFO] Running org.apache.hadoop.lib.wsrs.TestJSONMapProvider
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.038 s - in org.apache.hadoop.lib.wsrs.TestJSONMapProvider
[INFO] Running org.apache.hadoop.lib.wsrs.TestJSONProvider
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.042 s - in org.apache.hadoop.lib.wsrs.TestJSONProvider
[INFO] Running org.apache.hadoop.lib.wsrs.TestInputStreamEntity
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.086 s - in org.apache.hadoop.lib.wsrs.TestInputStreamEntity
[INFO] Running org.apache.hadoop.lib.wsrs.TestParam
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.111 s - in org.apache.hadoop.lib.wsrs.TestParam
[INFO] Running org.apache.hadoop.lib.lang.TestXException
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.043 s - in org.apache.hadoop.lib.lang.TestXException
[INFO] Running org.apache.hadoop.lib.lang.TestRunnableCallable
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.043 s - in org.apache.hadoop.lib.lang.TestRunnableCallable
[INFO] Running org.apache.hadoop.lib.server.TestServerConstructor
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.137 s - in org.apache.hadoop.lib.server.TestServerConstructor
[INFO] Running org.apache.hadoop.lib.server.TestServer
[INFO] Tests run: 30, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.252 s - in org.apache.hadoop.lib.server.TestServer
[INFO] Running org.apache.hadoop.lib.server.TestBaseService
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.224 s - in org.apache.hadoop.lib.server.TestBaseService
[INFO] Running org.apache.hadoop.test.TestExceptionHelper
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.032 s - in org.apache.hadoop.test.TestExceptionHelper
[INFO] Running org.apache.hadoop.test.TestDirHelper
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.036 s - in org.apache.hadoop.test.TestDirHelper
[INFO] Running org.apache.hadoop.test.TestHTestCase
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.154 s - in org.apache.hadoop.test.TestHTestCase
[INFO] Running org.apache.hadoop.test.TestHdfsHelper
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.106 s - in org.apache.hadoop.test.TestHdfsHelper
[INFO] Running org.apache.hadoop.test.TestHFSTestCase
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.743 s - in org.apache.hadoop.test.TestHFSTestCase
[INFO] 
[INFO] Results:
[INFO] 
[WARNING] Tests run: 429, Failures: 0, Errors: 0, Skipped: 6
[INFO] 
[INFO] 
[INFO] -----------------< org.apache.hadoop:hadoop-hdfs-nfs >------------------
[INFO] Building Apache Hadoop HDFS-NFS 3.1.1-TDP-0.1.0-SNAPSHOT         [19/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-hdfs-nfs ---
[INFO] Deleting /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-nfs/target
[INFO] Deleting /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-nfs (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-hdfs-nfs ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-nfs/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdfs-nfs ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdfs-nfs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdfs-nfs ---
[INFO] Compiling 17 source files to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-nfs/target/classes
[WARNING] /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/mount/RpcProgramMountd.java:[250,43] [unchecked] unchecked method invocation: method writeExportList in class MountResponse is applied to given types
[WARNING]   required: XDR,int,List<String>,List<NfsExports>
  found: XDR,int,List,List<NfsExports>
/tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/mount/RpcProgramMountd.java:[251,44] [unchecked] unchecked conversion
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-hdfs-nfs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-hdfs-nfs ---
[INFO] Compiling 14 source files to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-nfs/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-hdfs-nfs ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.hdfs.nfs.TestMountd
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.565 s - in org.apache.hadoop.hdfs.nfs.TestMountd
[INFO] Running org.apache.hadoop.hdfs.nfs.nfs3.TestNfs3HttpServer
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.09 s - in org.apache.hadoop.hdfs.nfs.nfs3.TestNfs3HttpServer
[INFO] Running org.apache.hadoop.hdfs.nfs.nfs3.TestOffsetRange
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.056 s - in org.apache.hadoop.hdfs.nfs.nfs3.TestOffsetRange
[INFO] Running org.apache.hadoop.hdfs.nfs.nfs3.TestDFSClientCache
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.94 s - in org.apache.hadoop.hdfs.nfs.nfs3.TestDFSClientCache
[INFO] Running org.apache.hadoop.hdfs.nfs.nfs3.TestOpenFileCtxCache
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.536 s - in org.apache.hadoop.hdfs.nfs.nfs3.TestOpenFileCtxCache
[INFO] Running org.apache.hadoop.hdfs.nfs.nfs3.TestWrites
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.092 s - in org.apache.hadoop.hdfs.nfs.nfs3.TestWrites
[INFO] Running org.apache.hadoop.hdfs.nfs.nfs3.TestExportsTable
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.788 s - in org.apache.hadoop.hdfs.nfs.nfs3.TestExportsTable
[INFO] Running org.apache.hadoop.hdfs.nfs.nfs3.TestReaddir
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.025 s - in org.apache.hadoop.hdfs.nfs.nfs3.TestReaddir
[INFO] Running org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.285 s - in org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3
[INFO] Running org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.182 s - in org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3
[INFO] Running org.apache.hadoop.hdfs.nfs.nfs3.TestClientAccessPrivilege
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.698 s - in org.apache.hadoop.hdfs.nfs.nfs3.TestClientAccessPrivilege
[INFO] Running org.apache.hadoop.hdfs.nfs.nfs3.TestNfs3Utils
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.163 s - in org.apache.hadoop.hdfs.nfs.nfs3.TestNfs3Utils
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 64, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -----------------< org.apache.hadoop:hadoop-hdfs-rbf >------------------
[INFO] Building Apache Hadoop HDFS-RBF 3.1.1-TDP-0.1.0-SNAPSHOT         [20/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-hdfs-rbf ---
[INFO] Deleting /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-rbf/target
[INFO] Deleting /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-rbf/src/site/resources (includes = [hdfs-rbf-default.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-hdfs-rbf ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:protoc (compile-protoc) @ hadoop-hdfs-rbf ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-rbf/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdfs-rbf ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdfs-rbf ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdfs-rbf ---
[INFO] Compiling 197 source files to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-rbf/target/classes
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-web-xmls) @ hadoop-hdfs-rbf ---
[INFO] Executing tasks

main:
     [copy] Copying 1 file to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-rbf/target/webapps/router/WEB-INF
     [copy] Copying 5 files to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-rbf/target/webapps
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-hdfs-rbf ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-log-dir) @ hadoop-hdfs-rbf ---
[INFO] Executing tasks

main:
     [copy] Copying 6 files to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test-classes/webapps
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-hdfs-rbf ---
[INFO] Compiling 69 source files to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-hdfs-rbf ---
[WARNING] The parameter forkMode is deprecated since version 2.14. Use forkCount and reuseForks instead.
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.113 s - in org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete
[INFO] Running org.apache.hadoop.fs.contract.router.TestRouterHDFSContractRootDirectory
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.576 s - in org.apache.hadoop.fs.contract.router.TestRouterHDFSContractRootDirectory
[INFO] Running org.apache.hadoop.fs.contract.router.TestRouterHDFSContractOpen
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.115 s - in org.apache.hadoop.fs.contract.router.TestRouterHDFSContractOpen
[INFO] Running org.apache.hadoop.fs.contract.router.TestRouterHDFSContractSetTimes
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.281 s - in org.apache.hadoop.fs.contract.router.TestRouterHDFSContractSetTimes
[INFO] Running org.apache.hadoop.fs.contract.router.TestRouterHDFSContractAppend
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.341 s - in org.apache.hadoop.fs.contract.router.TestRouterHDFSContractAppend
[INFO] Running org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.613 s - in org.apache.hadoop.fs.contract.router.TestRouterHDFSContractCreate
[INFO] Running org.apache.hadoop.fs.contract.router.TestRouterHDFSContractMkdir
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.227 s - in org.apache.hadoop.fs.contract.router.TestRouterHDFSContractMkdir
[INFO] Running org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractConcat
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.631 s - in org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractConcat
[INFO] Running org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractSeek
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.457 s - in org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractSeek
[INFO] Running org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractOpen
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.355 s - in org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractOpen
[INFO] Running org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractDelete
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.486 s - in org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractDelete
[INFO] Running org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractRename
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.804 s - in org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractRename
[INFO] Running org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractRootDirectory
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.06 s - in org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractRootDirectory
[INFO] Running org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.981 s - in org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend
[INFO] Running org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractCreate
[WARNING] Tests run: 11, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 10.506 s - in org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractCreate
[INFO] Running org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.823 s - in org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractMkdir
[INFO] Running org.apache.hadoop.fs.contract.router.TestRouterHDFSContractRename
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.235 s - in org.apache.hadoop.fs.contract.router.TestRouterHDFSContractRename
[INFO] Running org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.227 s - in org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat
[INFO] Running org.apache.hadoop.fs.contract.router.TestRouterHDFSContractGetFileStatus
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.762 s - in org.apache.hadoop.fs.contract.router.TestRouterHDFSContractGetFileStatus
[INFO] Running org.apache.hadoop.fs.contract.router.TestRouterHDFSContractSeek
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.895 s - in org.apache.hadoop.fs.contract.router.TestRouterHDFSContractSeek
[INFO] Running org.apache.hadoop.hdfs.server.federation.resolver.TestMultipleDestinationResolver
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.187 s - in org.apache.hadoop.hdfs.server.federation.resolver.TestMultipleDestinationResolver
[INFO] Running org.apache.hadoop.hdfs.server.federation.resolver.TestNamenodeResolver
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.397 s - in org.apache.hadoop.hdfs.server.federation.resolver.TestNamenodeResolver
[INFO] Running org.apache.hadoop.hdfs.server.federation.resolver.order.TestAvailableSpaceResolver
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.506 s - in org.apache.hadoop.hdfs.server.federation.resolver.order.TestAvailableSpaceResolver
[INFO] Running org.apache.hadoop.hdfs.server.federation.resolver.order.TestLocalResolver
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.49 s - in org.apache.hadoop.hdfs.server.federation.resolver.order.TestLocalResolver
[INFO] Running org.apache.hadoop.hdfs.server.federation.resolver.TestMountTableResolver
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.658 s - in org.apache.hadoop.hdfs.server.federation.resolver.TestMountTableResolver
[INFO] Running org.apache.hadoop.hdfs.server.federation.store.TestStateStoreMountTable
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.559 s - in org.apache.hadoop.hdfs.server.federation.store.TestStateStoreMountTable
[INFO] Running org.apache.hadoop.hdfs.server.federation.store.TestStateStoreRouterState
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.449 s - in org.apache.hadoop.hdfs.server.federation.store.TestStateStoreRouterState
[INFO] Running org.apache.hadoop.hdfs.server.federation.store.TestStateStoreDisabledNameservice
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.39 s - in org.apache.hadoop.hdfs.server.federation.store.TestStateStoreDisabledNameservice
[INFO] Running org.apache.hadoop.hdfs.server.federation.store.TestStateStoreMembershipState
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.758 s - in org.apache.hadoop.hdfs.server.federation.store.TestStateStoreMembershipState
[INFO] Running org.apache.hadoop.hdfs.server.federation.store.records.TestMembershipState
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.198 s - in org.apache.hadoop.hdfs.server.federation.store.records.TestMembershipState
[INFO] Running org.apache.hadoop.hdfs.server.federation.store.records.TestMountTable
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.353 s - in org.apache.hadoop.hdfs.server.federation.store.records.TestMountTable
[INFO] Running org.apache.hadoop.hdfs.server.federation.store.records.TestRouterState
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.21 s - in org.apache.hadoop.hdfs.server.federation.store.records.TestRouterState
[INFO] Running org.apache.hadoop.hdfs.server.federation.store.driver.TestStateStoreFile
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.593 s - in org.apache.hadoop.hdfs.server.federation.store.driver.TestStateStoreFile
[INFO] Running org.apache.hadoop.hdfs.server.federation.store.driver.TestStateStoreFileBase
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.098 s - in org.apache.hadoop.hdfs.server.federation.store.driver.TestStateStoreFileBase
[INFO] Running org.apache.hadoop.hdfs.server.federation.store.driver.TestStateStoreFileSystem
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.89 s - in org.apache.hadoop.hdfs.server.federation.store.driver.TestStateStoreFileSystem
[INFO] Running org.apache.hadoop.hdfs.server.federation.store.driver.TestStateStoreZK
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.641 s - in org.apache.hadoop.hdfs.server.federation.store.driver.TestStateStoreZK
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRouterAdminCLI
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.363 s - in org.apache.hadoop.hdfs.server.federation.router.TestRouterAdminCLI
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRouterRpc
[INFO] Tests run: 30, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.85 s - in org.apache.hadoop.hdfs.server.federation.router.TestRouterRpc
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestDisableRouterQuota
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.472 s - in org.apache.hadoop.hdfs.server.federation.router.TestDisableRouterQuota
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRouterRPCClientRetries
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 40.409 s - in org.apache.hadoop.hdfs.server.federation.router.TestRouterRPCClientRetries
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestSafeMode
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.202 s - in org.apache.hadoop.hdfs.server.federation.router.TestSafeMode
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRouterAdmin
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.101 s - in org.apache.hadoop.hdfs.server.federation.router.TestRouterAdmin
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestDisableNameservices
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.122 s - in org.apache.hadoop.hdfs.server.federation.router.TestDisableNameservices
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRouterQuotaManager
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.103 s - in org.apache.hadoop.hdfs.server.federation.router.TestRouterQuotaManager
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRouterRpcMultiDestination
[INFO] Tests run: 30, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.894 s - in org.apache.hadoop.hdfs.server.federation.router.TestRouterRpcMultiDestination
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRouterMountTable
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.709 s - in org.apache.hadoop.hdfs.server.federation.router.TestRouterMountTable
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRouterQuota
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 93.874 s - in org.apache.hadoop.hdfs.server.federation.router.TestRouterQuota
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRouterNamenodeHeartbeat
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.015 s - in org.apache.hadoop.hdfs.server.federation.router.TestRouterNamenodeHeartbeat
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRouterClientRejectOverload
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 68.521 s - in org.apache.hadoop.hdfs.server.federation.router.TestRouterClientRejectOverload
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRouterNamenodeMonitoring
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.211 s - in org.apache.hadoop.hdfs.server.federation.router.TestRouterNamenodeMonitoring
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRouterHeartbeatService
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.814 s - in org.apache.hadoop.hdfs.server.federation.router.TestRouterHeartbeatService
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRBFConfigFields
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.207 s - in org.apache.hadoop.hdfs.server.federation.router.TestRBFConfigFields
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRouterAllResolver
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.086 s - in org.apache.hadoop.hdfs.server.federation.router.TestRouterAllResolver
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestConnectionManager
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.57 s - in org.apache.hadoop.hdfs.server.federation.router.TestConnectionManager
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRouterSafemode
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.912 s - in org.apache.hadoop.hdfs.server.federation.router.TestRouterSafemode
[INFO] Running org.apache.hadoop.hdfs.server.federation.router.TestRouter
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.62 s - in org.apache.hadoop.hdfs.server.federation.router.TestRouter
[INFO] Running org.apache.hadoop.hdfs.server.federation.metrics.TestFederationMetrics
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.189 s - in org.apache.hadoop.hdfs.server.federation.metrics.TestFederationMetrics
[INFO] 
[INFO] Results:
[INFO] 
[WARNING] Tests run: 387, Failures: 0, Errors: 0, Skipped: 2
[INFO] 
[INFO] 
[INFO] ---------------< org.apache.hadoop:hadoop-hdfs-project >----------------
[INFO] Building Apache Hadoop HDFS Project 3.1.1-TDP-0.1.0-SNAPSHOT     [21/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-hdfs-project ---
[INFO] Deleting /tdp/hadoop/hadoop-hdfs-project/target
[INFO] Deleting /tdp/hadoop/hadoop-hdfs-project (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-hdfs-project ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-hdfs-project/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdfs-project ---
[INFO] 
[INFO] -------------------< org.apache.hadoop:hadoop-yarn >--------------------
[INFO] Building Apache Hadoop YARN 3.1.1-TDP-0.1.0-SNAPSHOT             [22/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn ---
[INFO] 
[INFO] -----------------< org.apache.hadoop:hadoop-yarn-api >------------------
[INFO] Building Apache Hadoop YARN API 3.1.1-TDP-0.1.0-SNAPSHOT         [23/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-api ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-api ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:protoc (compile-protoc) @ hadoop-yarn-api ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-api ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-api ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-api ---
[INFO] Compiling 315 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/conf/HAUtil.java:[94,44] [deprecation] AUTO_FAILOVER_EMBEDDED in YarnConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/conf/HAUtil.java:[95,25] [deprecation] DEFAULT_AUTO_FAILOVER_EMBEDDED in YarnConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/conf/HAUtil.java:[173,42] [deprecation] CURATOR_LEADER_ELECTOR in YarnConfiguration has been deprecated
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-api ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-api ---
[INFO] Compiling 9 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/test-classes
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-yarn-api ---
[INFO] Building jar: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/hadoop-yarn-api-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-api ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.conf.TestYarnConfigurationFields
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.306 s - in org.apache.hadoop.yarn.conf.TestYarnConfigurationFields
[INFO] Running org.apache.hadoop.yarn.conf.TestResourceInformation
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.064 s - in org.apache.hadoop.yarn.conf.TestResourceInformation
[INFO] Running org.apache.hadoop.yarn.util.TestUnitsConversionUtil
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.045 s - in org.apache.hadoop.yarn.util.TestUnitsConversionUtil
[INFO] Running org.apache.hadoop.yarn.api.resource.TestPlacementConstraints
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.058 s - in org.apache.hadoop.yarn.api.resource.TestPlacementConstraints
[INFO] Running org.apache.hadoop.yarn.api.resource.TestPlacementConstraintParser
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.083 s - in org.apache.hadoop.yarn.api.resource.TestPlacementConstraintParser
[INFO] Running org.apache.hadoop.yarn.api.records.TestResource
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.049 s - in org.apache.hadoop.yarn.api.records.TestResource
[INFO] Running org.apache.hadoop.yarn.api.records.timelineservice.TestTimelineMetric
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.05 s - in org.apache.hadoop.yarn.api.records.timelineservice.TestTimelineMetric
[INFO] Running org.apache.hadoop.yarn.api.records.timelineservice.TestApplicationEntity
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.053 s - in org.apache.hadoop.yarn.api.records.timelineservice.TestApplicationEntity
[INFO] Running org.apache.hadoop.yarn.api.records.TestURL
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.176 s - in org.apache.hadoop.yarn.api.records.TestURL
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 25, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-yarn-common >----------------
[INFO] Building Apache Hadoop YARN Common 3.1.1-TDP-0.1.0-SNAPSHOT      [24/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-common ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:protoc (compile-protoc) @ hadoop-yarn-common ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-common ---
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:version-info (version-info) @ hadoop-yarn-common ---
[INFO] SCM: GIT
[INFO] Computed MD5: c62bb169a9a43e4f5ca85d5f56aff16
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:resource-gz (resource-gz) @ hadoop-yarn-common ---
[INFO] Compressing /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/jquery/jquery-ui-1.9.1.custom.min.js to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/jquery/jquery-ui-1.9.1.custom.min.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/jquery/themes-1.9.1/base/jquery-ui.css to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/jquery/themes-1.9.1/base/jquery-ui.css.gz
[INFO] Compressing /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/jquery/jquery-3.3.1.min.js to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/jquery/jquery-3.3.1.min.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/jt/jquery.jstree.js to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/jt/jquery.jstree.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/dt-1.9.4/js/jquery.dataTables.min.js to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/dt-1.9.4/js/jquery.dataTables.min.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/dt-1.9.4/css/jui-dt.css to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/dt-1.9.4/css/jui-dt.css.gz
[INFO] Compressing /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/dt-1.9.4/css/demo_page.css to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/dt-1.9.4/css/demo_page.css.gz
[INFO] Compressing /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/dt-1.9.4/css/demo_table.css to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/dt-1.9.4/css/demo_table.css.gz
[INFO] Compressing /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/dt-sorting/natural.js to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/dt-sorting/natural.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/yarn.dt.plugins.js to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/yarn.dt.plugins.js.gz
[INFO] Compressing /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/yarn.css to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/yarn.css.gz
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 51 resources
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-common ---
[INFO] Compiling 427 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/webapp/hamlet/HamletImpl.java:[32,50] [deprecation] HamletImpl in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/webapp/hamlet/Hamlet.java:[22,50] [deprecation] HamletImpl in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/webapp/hamlet/Hamlet.java:[23,50] [deprecation] HamletImpl in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/webapp/hamlet/Hamlet.java:[24,50] [deprecation] HamletImpl in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/nodelabels/FileSystemNodeLabelsStore.java:[92,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/client/api/impl/FileSystemTimelineWriter.java:[269,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/client/api/impl/FileSystemTimelineWriter.java:[357,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/client/api/impl/FileSystemTimelineWriter.java:[358,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/DockerClientConfigHandler.java:[90,26] [deprecation] toString(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/state/StateMachineFactory.java:[471,41] [unchecked] unchecked conversion
[WARNING]   required: StateTransitionListener<OPERAND,EVENT,STATE>
  found:    NoopStateTransitionListener
  where OPERAND,EVENT,STATE are type-variables:
    OPERAND extends Object declared in class StateMachineFactory
    EVENT extends Object declared in class StateMachineFactory
    STATE extends Enum<STATE> declared in class StateMachineFactory
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/client/api/AppAdminClient.java:[81,67] [unchecked] unchecked cast
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 21 resources
[INFO] Copying 11 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-common ---
[INFO] Compiling 94 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/test-classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestParseSelector.java:[26,50] [deprecation] HamletImpl in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamlet.java:[28,43] [deprecation] Hamlet in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamlet.java:[30,50] [deprecation] HamletSpec in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamletImpl.java:[26,43] [deprecation] HamletImpl in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamletImpl.java:[27,43] [deprecation] HamletSpec in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/conf/TestHAUtil.java:[193,39] [deprecation] AUTO_FAILOVER_EMBEDDED in YarnConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/conf/TestHAUtil.java:[194,39] [deprecation] CURATOR_LEADER_ELECTOR in YarnConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/security/TestDockerClientConfigHandler.java:[122,35] [deprecation] readFileToString(File) in FileUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamlet.java:[35,4] [deprecation] Hamlet in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamlet.java:[75,4] [deprecation] Hamlet in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamlet.java:[96,4] [deprecation] Hamlet in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamlet.java:[115,4] [deprecation] Hamlet in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamlet.java:[127,4] [deprecation] Hamlet in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamlet.java:[150,4] [deprecation] Hamlet in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamlet.java:[162,9] [deprecation] Hamlet in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamlet.java:[164,15] [deprecation] Hamlet in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamletImpl.java:[36,4] [deprecation] HamletImpl in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamletImpl.java:[36,24] [deprecation] HamletImpl in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamletImpl.java:[72,4] [deprecation] HamletImpl in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamletImpl.java:[78,4] [deprecation] HamletImpl in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamletImpl.java:[87,4] [deprecation] HamletImpl in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamletImpl.java:[88,4] [deprecation] HamletImpl in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamletImpl.java:[99,4] [deprecation] HamletImpl in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/webapp/hamlet/TestHamletImpl.java:[100,4] [deprecation] HamletImpl in org.apache.hadoop.yarn.webapp.hamlet has been deprecated
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-yarn-common ---
[INFO] Building jar: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/hadoop-yarn-common-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-common ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.conf.TestYarnConfiguration
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.3 s - in org.apache.hadoop.yarn.conf.TestYarnConfiguration
[INFO] Running org.apache.hadoop.yarn.conf.TestHAUtil
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.258 s - in org.apache.hadoop.yarn.conf.TestHAUtil
[INFO] Running org.apache.hadoop.yarn.util.TestBoundedAppender
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.068 s - in org.apache.hadoop.yarn.util.TestBoundedAppender
[INFO] Running org.apache.hadoop.yarn.util.TestRackResolver
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.195 s - in org.apache.hadoop.yarn.util.TestRackResolver
[INFO] Running org.apache.hadoop.yarn.util.TestTimelineServiceHelper
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.064 s - in org.apache.hadoop.yarn.util.TestTimelineServiceHelper
[INFO] Running org.apache.hadoop.yarn.util.TestApps
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.106 s - in org.apache.hadoop.yarn.util.TestApps
[INFO] Running org.apache.hadoop.yarn.util.resource.TestResourceUtils
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.486 s - in org.apache.hadoop.yarn.util.resource.TestResourceUtils
[INFO] Running org.apache.hadoop.yarn.util.resource.TestResourceCalculator
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.318 s - in org.apache.hadoop.yarn.util.resource.TestResourceCalculator
[INFO] Running org.apache.hadoop.yarn.util.resource.TestResources
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.333 s - in org.apache.hadoop.yarn.util.resource.TestResources
[INFO] Running org.apache.hadoop.yarn.util.TestRackResolverScriptBasedMapping
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.169 s - in org.apache.hadoop.yarn.util.TestRackResolverScriptBasedMapping
[INFO] Running org.apache.hadoop.yarn.util.TestConverterUtils
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.206 s - in org.apache.hadoop.yarn.util.TestConverterUtils
[INFO] Running org.apache.hadoop.yarn.util.TestWindowsBasedProcessTree
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.114 s - in org.apache.hadoop.yarn.util.TestWindowsBasedProcessTree
[INFO] Running org.apache.hadoop.yarn.util.TestTimes
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.099 s - in org.apache.hadoop.yarn.util.TestTimes
[INFO] Running org.apache.hadoop.yarn.util.TestFSDownload
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.785 s - in org.apache.hadoop.yarn.util.TestFSDownload
[INFO] Running org.apache.hadoop.yarn.util.TestLRUCacheHashMap
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.071 s - in org.apache.hadoop.yarn.util.TestLRUCacheHashMap
[INFO] Running org.apache.hadoop.yarn.util.TestYarnVersionInfo
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.096 s - in org.apache.hadoop.yarn.util.TestYarnVersionInfo
[INFO] Running org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.085 s - in org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree
[INFO] Running org.apache.hadoop.yarn.util.TestResourceCalculatorProcessTree
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.118 s - in org.apache.hadoop.yarn.util.TestResourceCalculatorProcessTree
[INFO] Running org.apache.hadoop.yarn.util.TestLog4jWarningErrorMetricsAppender
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.138 s - in org.apache.hadoop.yarn.util.TestLog4jWarningErrorMetricsAppender
[INFO] Running org.apache.hadoop.yarn.util.TestAdHocLogDumper
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.104 s - in org.apache.hadoop.yarn.util.TestAdHocLogDumper
[INFO] Running org.apache.hadoop.yarn.client.api.impl.TestTimelineClientV2Impl
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.433 s - in org.apache.hadoop.yarn.client.api.impl.TestTimelineClientV2Impl
[INFO] Running org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.244 s - in org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5
[INFO] Running org.apache.hadoop.yarn.client.api.impl.TestTimelineClient
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.597 s - in org.apache.hadoop.yarn.client.api.impl.TestTimelineClient
[INFO] Running org.apache.hadoop.yarn.client.TestClientRMProxy
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.56 s - in org.apache.hadoop.yarn.client.TestClientRMProxy
[INFO] Running org.apache.hadoop.yarn.webapp.util.TestWebAppUtils
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.105 s - in org.apache.hadoop.yarn.webapp.util.TestWebAppUtils
[INFO] Running org.apache.hadoop.yarn.webapp.hamlet.TestHamletImpl
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.31 s - in org.apache.hadoop.yarn.webapp.hamlet.TestHamletImpl
[INFO] Running org.apache.hadoop.yarn.webapp.hamlet.TestHamlet
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.323 s - in org.apache.hadoop.yarn.webapp.hamlet.TestHamlet
[INFO] Running org.apache.hadoop.yarn.webapp.hamlet.TestParseSelector
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.081 s - in org.apache.hadoop.yarn.webapp.hamlet.TestParseSelector
[INFO] Running org.apache.hadoop.yarn.webapp.TestParseRoute
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.139 s - in org.apache.hadoop.yarn.webapp.TestParseRoute
[INFO] Running org.apache.hadoop.yarn.webapp.TestWebApp
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.494 s - in org.apache.hadoop.yarn.webapp.TestWebApp
[INFO] Running org.apache.hadoop.yarn.webapp.TestSubViews
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.514 s - in org.apache.hadoop.yarn.webapp.TestSubViews
[INFO] Running org.apache.hadoop.yarn.webapp.test.TestWebAppTests
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.461 s - in org.apache.hadoop.yarn.webapp.test.TestWebAppTests
[INFO] Running org.apache.hadoop.yarn.webapp.view.TestHtmlPage
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.521 s - in org.apache.hadoop.yarn.webapp.view.TestHtmlPage
[INFO] Running org.apache.hadoop.yarn.webapp.view.TestHtmlBlock
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.535 s - in org.apache.hadoop.yarn.webapp.view.TestHtmlBlock
[INFO] Running org.apache.hadoop.yarn.webapp.view.TestTwoColumnCssPage
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.695 s - in org.apache.hadoop.yarn.webapp.view.TestTwoColumnCssPage
[INFO] Running org.apache.hadoop.yarn.webapp.view.TestCommonViews
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.567 s - in org.apache.hadoop.yarn.webapp.view.TestCommonViews
[INFO] Running org.apache.hadoop.yarn.webapp.view.TestTwoColumnLayout
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.671 s - in org.apache.hadoop.yarn.webapp.view.TestTwoColumnLayout
[INFO] Running org.apache.hadoop.yarn.webapp.view.TestInfoBlock
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.471 s - in org.apache.hadoop.yarn.webapp.view.TestInfoBlock
[INFO] Running org.apache.hadoop.yarn.api.TestResourcePBImpl
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.256 s - in org.apache.hadoop.yarn.api.TestResourcePBImpl
[INFO] Running org.apache.hadoop.yarn.api.TestApplicationAttemptId
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.178 s - in org.apache.hadoop.yarn.api.TestApplicationAttemptId
[INFO] Running org.apache.hadoop.yarn.api.TestResourceRequest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.234 s - in org.apache.hadoop.yarn.api.TestResourceRequest
[INFO] Running org.apache.hadoop.yarn.api.TestPlacementConstraintPBConversion
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.093 s - in org.apache.hadoop.yarn.api.TestPlacementConstraintPBConversion
[INFO] Running org.apache.hadoop.yarn.api.TestTimelineEntityGroupId
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.181 s - in org.apache.hadoop.yarn.api.TestTimelineEntityGroupId
[INFO] Running org.apache.hadoop.yarn.api.TestContainerId
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.206 s - in org.apache.hadoop.yarn.api.TestContainerId
[INFO] Running org.apache.hadoop.yarn.api.resource.TestPlacementConstraintTransformations
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.093 s - in org.apache.hadoop.yarn.api.resource.TestPlacementConstraintTransformations
[INFO] Running org.apache.hadoop.yarn.api.TestApplicationId
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.174 s - in org.apache.hadoop.yarn.api.TestApplicationId
[INFO] Running org.apache.hadoop.yarn.api.TestApplicatonReport
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.199 s - in org.apache.hadoop.yarn.api.TestApplicatonReport
[INFO] Running org.apache.hadoop.yarn.api.TestPBImplRecords
[WARNING] Tests run: 132, Failures: 0, Errors: 0, Skipped: 5, Time elapsed: 1.025 s - in org.apache.hadoop.yarn.api.TestPBImplRecords
[INFO] Running org.apache.hadoop.yarn.api.TestNodeId
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.177 s - in org.apache.hadoop.yarn.api.TestNodeId
[INFO] Running org.apache.hadoop.yarn.api.records.timeline.TestTimelineRecords
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.339 s - in org.apache.hadoop.yarn.api.records.timeline.TestTimelineRecords
[INFO] Running org.apache.hadoop.yarn.api.records.impl.pb.TestApplicationClientProtocolRecords
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.278 s - in org.apache.hadoop.yarn.api.records.impl.pb.TestApplicationClientProtocolRecords
[INFO] Running org.apache.hadoop.yarn.api.records.impl.pb.TestSerializedExceptionPBImpl
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.069 s - in org.apache.hadoop.yarn.api.records.impl.pb.TestSerializedExceptionPBImpl
[INFO] Running org.apache.hadoop.yarn.api.records.TestResourceUtilization
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.166 s - in org.apache.hadoop.yarn.api.records.TestResourceUtilization
[INFO] Running org.apache.hadoop.yarn.api.records.timelineservice.TestTimelineServiceRecords
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.427 s - in org.apache.hadoop.yarn.api.records.timelineservice.TestTimelineServiceRecords
[INFO] Running org.apache.hadoop.yarn.api.TestGetApplicationsRequest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.233 s - in org.apache.hadoop.yarn.api.TestGetApplicationsRequest
[INFO] Running org.apache.hadoop.yarn.TestYarnUncaughtExceptionHandler
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.253 s - in org.apache.hadoop.yarn.TestYarnUncaughtExceptionHandler
[INFO] Running org.apache.hadoop.yarn.event.TestAsyncDispatcher
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.404 s - in org.apache.hadoop.yarn.event.TestAsyncDispatcher
[INFO] Running org.apache.hadoop.yarn.TestRpcFactoryProvider
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.192 s - in org.apache.hadoop.yarn.TestRpcFactoryProvider
[INFO] Running org.apache.hadoop.yarn.security.TestDockerClientConfigHandler
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.606 s - in org.apache.hadoop.yarn.security.TestDockerClientConfigHandler
[INFO] Running org.apache.hadoop.yarn.security.TestYARNTokenIdentifier
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.374 s - in org.apache.hadoop.yarn.security.TestYARNTokenIdentifier
[INFO] Running org.apache.hadoop.yarn.server.security.TestApplicationACLsManager
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.32 s - in org.apache.hadoop.yarn.server.security.TestApplicationACLsManager
[INFO] Running org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.675 s - in org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock
[INFO] Running org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.631 s - in org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat
[INFO] Running org.apache.hadoop.yarn.logaggregation.TestAggregatedLogDeletionService
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.586 s - in org.apache.hadoop.yarn.logaggregation.TestAggregatedLogDeletionService
[INFO] Running org.apache.hadoop.yarn.logaggregation.filecontroller.TestLogAggregationFileControllerFactory
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.453 s - in org.apache.hadoop.yarn.logaggregation.filecontroller.TestLogAggregationFileControllerFactory
[INFO] Running org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.TestLogAggregationIndexFileController
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.681 s - in org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.TestLogAggregationIndexFileController
[INFO] Running org.apache.hadoop.yarn.TestContainerLogAppender
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.088 s - in org.apache.hadoop.yarn.TestContainerLogAppender
[INFO] Running org.apache.hadoop.yarn.TestContainerLaunchRPC
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.565 s - in org.apache.hadoop.yarn.TestContainerLaunchRPC
[INFO] Running org.apache.hadoop.yarn.nodelabels.TestCommonNodeLabelsManager
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.504 s - in org.apache.hadoop.yarn.nodelabels.TestCommonNodeLabelsManager
[INFO] Running org.apache.hadoop.yarn.nodelabels.TestFileSystemNodeLabelsStore
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.823 s - in org.apache.hadoop.yarn.nodelabels.TestFileSystemNodeLabelsStore
[INFO] Running org.apache.hadoop.yarn.TestRecordFactory
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.158 s - in org.apache.hadoop.yarn.TestRecordFactory
[INFO] Running org.apache.hadoop.yarn.factories.impl.pb.TestRpcServerFactoryPBImpl
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.252 s - in org.apache.hadoop.yarn.factories.impl.pb.TestRpcServerFactoryPBImpl
[INFO] Running org.apache.hadoop.yarn.factories.impl.pb.TestRpcClientFactoryPBImpl
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.284 s - in org.apache.hadoop.yarn.factories.impl.pb.TestRpcClientFactoryPBImpl
[INFO] Running org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.555 s - in org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC
[INFO] Running org.apache.hadoop.yarn.ipc.TestRPCUtil
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.083 s - in org.apache.hadoop.yarn.ipc.TestRPCUtil
[INFO] Running org.apache.hadoop.yarn.TestRPCFactories
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.38 s - in org.apache.hadoop.yarn.TestRPCFactories
[INFO] 
[INFO] Results:
[INFO] 
[WARNING] Tests run: 433, Failures: 0, Errors: 0, Skipped: 6
[INFO] 
[INFO] 
[INFO] ---------------< org.apache.hadoop:hadoop-yarn-registry >---------------
[INFO] Building Apache Hadoop YARN Registry 3.1.1-TDP-0.1.0-SNAPSHOT    [25/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-registry ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-registry/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-registry (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-registry ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-registry/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-registry ---
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:version-info (version-info) @ hadoop-yarn-registry ---
[INFO] SCM: GIT
[INFO] Computed MD5: 5feeadf43b236ee11b65b3233a78d
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-registry ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 0 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-registry ---
[INFO] Compiling 65 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-registry/target/classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-registry/src/main/java/org/apache/hadoop/registry/client/types/Endpoint.java:[162,25] [unchecked] Possible heap pollution from parameterized vararg type Map<String,String>
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-registry/src/main/java/org/apache/hadoop/registry/server/dns/RegistryDNS.java:[516,38] [deprecation] getAddressCount() in SubnetUtils.SubnetInfo has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-registry/src/main/java/org/apache/hadoop/registry/server/dns/ReverseZoneUtils.java:[103,37] [deprecation] getAddressCount() in SubnetUtils.SubnetInfo has been deprecated
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-registry ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-registry ---
[INFO] Compiling 21 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-registry/target/test-classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-registry/src/test/java/org/apache/hadoop/registry/secure/AbstractSecureRegistryTest.java:[222,13] [deprecation] write(File,CharSequence) in FileUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-registry/src/test/java/org/apache/hadoop/registry/secure/TestSecureLogins.java:[91,31] [deprecation] readFileToString(File) in FileUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-registry/src/test/java/org/apache/hadoop/registry/secure/TestSecureLogins.java:[130,32] [deprecation] readFileToString(File) in FileUtils has been deprecated
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-yarn-registry ---
[INFO] Building jar: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-registry/target/hadoop-yarn-registry-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-registry ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.registry.client.binding.TestMarshalling
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.373 s - in org.apache.hadoop.registry.client.binding.TestMarshalling
[INFO] Running org.apache.hadoop.registry.client.binding.TestRegistryOperationUtils
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.271 s - in org.apache.hadoop.registry.client.binding.TestRegistryOperationUtils
[INFO] Running org.apache.hadoop.registry.client.binding.TestRegistryPathUtils
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.223 s - in org.apache.hadoop.registry.client.binding.TestRegistryPathUtils
[INFO] Running org.apache.hadoop.registry.client.impl.TestCuratorService
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.026 s - in org.apache.hadoop.registry.client.impl.TestCuratorService
[INFO] Running org.apache.hadoop.registry.client.impl.TestFSRegistryOperationsService
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.614 s - in org.apache.hadoop.registry.client.impl.TestFSRegistryOperationsService
[INFO] Running org.apache.hadoop.registry.client.impl.TestMicroZookeeperService
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.322 s - in org.apache.hadoop.registry.client.impl.TestMicroZookeeperService
[INFO] Running org.apache.hadoop.registry.cli.TestRegistryCli
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.086 s - in org.apache.hadoop.registry.cli.TestRegistryCli
[INFO] Running org.apache.hadoop.registry.integration.TestYarnPolicySelector
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.224 s - in org.apache.hadoop.registry.integration.TestYarnPolicySelector
[INFO] Running org.apache.hadoop.registry.secure.TestRegistrySecurityHelper
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.328 s - in org.apache.hadoop.registry.secure.TestRegistrySecurityHelper
[INFO] Running org.apache.hadoop.registry.secure.TestSecureRegistry
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.123 s - in org.apache.hadoop.registry.secure.TestSecureRegistry
[INFO] Running org.apache.hadoop.registry.secure.TestSecureLogins
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.76 s - in org.apache.hadoop.registry.secure.TestSecureLogins
[INFO] Running org.apache.hadoop.registry.server.dns.TestReverseZoneUtils
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.129 s - in org.apache.hadoop.registry.server.dns.TestReverseZoneUtils
[INFO] Running org.apache.hadoop.registry.server.dns.TestSecureRegistryDNS
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.279 s - in org.apache.hadoop.registry.server.dns.TestSecureRegistryDNS
[INFO] Running org.apache.hadoop.registry.server.dns.TestRegistryDNS
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.809 s - in org.apache.hadoop.registry.server.dns.TestRegistryDNS
[INFO] Running org.apache.hadoop.registry.operations.TestRegistryOperations
[INFO] Tests run: 24, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.932 s - in org.apache.hadoop.registry.operations.TestRegistryOperations
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 165, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-yarn-server >----------------
[INFO] Building Apache Hadoop YARN Server 3.1.1-TDP-0.1.0-SNAPSHOT      [26/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server ---
[INFO] 
[INFO] ------------< org.apache.hadoop:hadoop-yarn-server-common >-------------
[INFO] Building Apache Hadoop YARN Server Common 3.1.1-TDP-0.1.0-SNAPSHOT [27/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-common ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/target
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:protoc (compile-protoc) @ hadoop-yarn-server-common ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-common ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-server-common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-server-common ---
[INFO] Compiling 261 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-server-common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-server-common ---
[INFO] Compiling 49 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/target/test-classes
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-yarn-server-common ---
[INFO] Building jar: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/target/hadoop-yarn-server-common-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-server-common ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.TestResourceTrackerPBClientImpl
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.534 s - in org.apache.hadoop.yarn.TestResourceTrackerPBClientImpl
[INFO] Running org.apache.hadoop.yarn.TestRPC
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.758 s - in org.apache.hadoop.yarn.TestRPC
[INFO] Running org.apache.hadoop.yarn.lib.TestZKClient
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.302 s - in org.apache.hadoop.yarn.lib.TestZKClient
[INFO] Running org.apache.hadoop.yarn.server.timeline.security.TestTimelineAuthenticationFilterInitializer
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.34 s - in org.apache.hadoop.yarn.server.timeline.security.TestTimelineAuthenticationFilterInitializer
[INFO] Running org.apache.hadoop.yarn.server.api.TestServerRMProxy
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.385 s - in org.apache.hadoop.yarn.server.api.TestServerRMProxy
[INFO] Running org.apache.hadoop.yarn.server.api.protocolrecords.TestProtocolRecords
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.361 s - in org.apache.hadoop.yarn.server.api.protocolrecords.TestProtocolRecords
[INFO] Running org.apache.hadoop.yarn.server.api.protocolrecords.TestRegisterNodeManagerRequest
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.301 s - in org.apache.hadoop.yarn.server.api.protocolrecords.TestRegisterNodeManagerRequest
[INFO] Running org.apache.hadoop.yarn.server.api.protocolrecords.TestRegisterNodeManagerResponse
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.208 s - in org.apache.hadoop.yarn.server.api.protocolrecords.TestRegisterNodeManagerResponse
[INFO] Running org.apache.hadoop.yarn.server.scheduler.TestOpportunisticContainerAllocator
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.292 s - in org.apache.hadoop.yarn.server.scheduler.TestOpportunisticContainerAllocator
[INFO] Running org.apache.hadoop.yarn.server.federation.resolver.TestDefaultSubClusterResolver
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.27 s - in org.apache.hadoop.yarn.server.federation.resolver.TestDefaultSubClusterResolver
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.TestFederationPolicyInitializationContextValidator
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.757 s - in org.apache.hadoop.yarn.server.federation.policies.TestFederationPolicyInitializationContextValidator
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.manager.TestHashBasedBroadcastPolicyManager
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.653 s - in org.apache.hadoop.yarn.server.federation.policies.manager.TestHashBasedBroadcastPolicyManager
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.manager.TestRejectAllPolicyManager
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.709 s - in org.apache.hadoop.yarn.server.federation.policies.manager.TestRejectAllPolicyManager
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.manager.TestUniformBroadcastPolicyManager
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.669 s - in org.apache.hadoop.yarn.server.federation.policies.manager.TestUniformBroadcastPolicyManager
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.manager.TestPriorityBroadcastPolicyManager
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.812 s - in org.apache.hadoop.yarn.server.federation.policies.manager.TestPriorityBroadcastPolicyManager
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.manager.TestWeightedLocalityPolicyManager
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.828 s - in org.apache.hadoop.yarn.server.federation.policies.manager.TestWeightedLocalityPolicyManager
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.router.TestPriorityRouterPolicy
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.214 s - in org.apache.hadoop.yarn.server.federation.policies.router.TestPriorityRouterPolicy
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.router.TestUniformRandomRouterPolicy
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.127 s - in org.apache.hadoop.yarn.server.federation.policies.router.TestUniformRandomRouterPolicy
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.router.TestHashBasedRouterPolicy
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.251 s - in org.apache.hadoop.yarn.server.federation.policies.router.TestHashBasedRouterPolicy
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.router.TestRejectRouterPolicy
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.079 s - in org.apache.hadoop.yarn.server.federation.policies.router.TestRejectRouterPolicy
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.router.TestLoadBasedRouterPolicy
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.107 s - in org.apache.hadoop.yarn.server.federation.policies.router.TestLoadBasedRouterPolicy
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.router.TestWeightedRandomRouterPolicy
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.661 s - in org.apache.hadoop.yarn.server.federation.policies.router.TestWeightedRandomRouterPolicy
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.amrmproxy.TestRejectAMRMProxyPolicy
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.984 s - in org.apache.hadoop.yarn.server.federation.policies.amrmproxy.TestRejectAMRMProxyPolicy
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.amrmproxy.TestBroadcastAMRMProxyFederationPolicy
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.003 s - in org.apache.hadoop.yarn.server.federation.policies.amrmproxy.TestBroadcastAMRMProxyFederationPolicy
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.amrmproxy.TestLocalityMulticastAMRMProxyPolicy
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.442 s - in org.apache.hadoop.yarn.server.federation.policies.amrmproxy.TestLocalityMulticastAMRMProxyPolicy
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.TestFederationPolicyUtils
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.474 s - in org.apache.hadoop.yarn.server.federation.policies.TestFederationPolicyUtils
[INFO] Running org.apache.hadoop.yarn.server.federation.policies.TestRouterPolicyFacade
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.864 s - in org.apache.hadoop.yarn.server.federation.policies.TestRouterPolicyFacade
[INFO] Running org.apache.hadoop.yarn.server.federation.store.impl.TestZookeeperFederationStateStore
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.781 s - in org.apache.hadoop.yarn.server.federation.store.impl.TestZookeeperFederationStateStore
[INFO] Running org.apache.hadoop.yarn.server.federation.store.impl.TestMemoryFederationStateStore
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.311 s - in org.apache.hadoop.yarn.server.federation.store.impl.TestMemoryFederationStateStore
[INFO] Running org.apache.hadoop.yarn.server.federation.store.impl.TestSQLFederationStateStore
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.154 s - in org.apache.hadoop.yarn.server.federation.store.impl.TestSQLFederationStateStore
[INFO] Running org.apache.hadoop.yarn.server.federation.store.metrics.TestFederationStateStoreClientMetrics
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.159 s - in org.apache.hadoop.yarn.server.federation.store.metrics.TestFederationStateStoreClientMetrics
[INFO] Running org.apache.hadoop.yarn.server.federation.store.utils.TestFederationStateStoreInputValidator
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.27 s - in org.apache.hadoop.yarn.server.federation.store.utils.TestFederationStateStoreInputValidator
[INFO] Running org.apache.hadoop.yarn.server.federation.store.records.TestFederationProtocolRecords
[INFO] Tests run: 28, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.39 s - in org.apache.hadoop.yarn.server.federation.store.records.TestFederationProtocolRecords
[INFO] Running org.apache.hadoop.yarn.server.federation.utils.TestFederationStateStoreFacadeRetry
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.501 s - in org.apache.hadoop.yarn.server.federation.utils.TestFederationStateStoreFacadeRetry
[INFO] Running org.apache.hadoop.yarn.server.federation.utils.TestFederationStateStoreFacade
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.676 s - in org.apache.hadoop.yarn.server.federation.utils.TestFederationStateStoreFacade
[INFO] Running org.apache.hadoop.yarn.server.federation.utils.TestFederationRegistryClient
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.645 s - in org.apache.hadoop.yarn.server.federation.utils.TestFederationRegistryClient
[INFO] Running org.apache.hadoop.yarn.server.utils.TestLeveldbIterator
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.047 s - in org.apache.hadoop.yarn.server.utils.TestLeveldbIterator
[INFO] Running org.apache.hadoop.yarn.server.uam.TestUnmanagedApplicationManager
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.702 s - in org.apache.hadoop.yarn.server.uam.TestUnmanagedApplicationManager
[INFO] Running org.apache.hadoop.yarn.TestYSCRecordFactory
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.14 s - in org.apache.hadoop.yarn.TestYSCRecordFactory
[INFO] Running org.apache.hadoop.yarn.TestYarnServerApiClasses
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.437 s - in org.apache.hadoop.yarn.TestYarnServerApiClasses
[INFO] Running org.apache.hadoop.yarn.TestYSCRPCFactories
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.418 s - in org.apache.hadoop.yarn.TestYSCRPCFactories
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 316, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ----------< org.apache.hadoop:hadoop-yarn-server-nodemanager >----------
[INFO] Building Apache Hadoop YARN NodeManager 3.1.1-TDP-0.1.0-SNAPSHOT [28/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-nodemanager ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-nodemanager ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:protoc (compile-protoc) @ hadoop-yarn-server-nodemanager ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-nodemanager ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-server-nodemanager ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-server-nodemanager ---
[INFO] Compiling 306 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/resources/ResourceHandlerModule.java:[33,53] [deprecation] CgroupsLCEResourcesHandler in org.apache.hadoop.yarn.server.nodemanager.util has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/ContainerExecutor.java:[312,39] [deprecation] readFileToString(File) in FileUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java:[110,10] [deprecation] LCEResourcesHandler in org.apache.hadoop.yarn.server.nodemanager.util has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java:[215,10] [deprecation] LCEResourcesHandler in org.apache.hadoop.yarn.server.nodemanager.util has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java:[216,4] [deprecation] LCEResourcesHandler in org.apache.hadoop.yarn.server.nodemanager.util has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java:[218,12] [deprecation] DefaultLCEResourcesHandler in org.apache.hadoop.yarn.server.nodemanager.util has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java:[218,46] [deprecation] LCEResourcesHandler in org.apache.hadoop.yarn.server.nodemanager.util has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java:[224,27] [deprecation] CgroupsLCEResourcesHandler in org.apache.hadoop.yarn.server.nodemanager.util has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java:[226,38] [deprecation] DefaultLCEResourcesHandler in org.apache.hadoop.yarn.server.nodemanager.util has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/resources/ResourceHandlerModule.java:[132,20] [deprecation] CgroupsLCEResourcesHandler in org.apache.hadoop.yarn.server.nodemanager.util has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/resources/ResourceHandlerModule.java:[131,12] [deprecation] DefaultLCEResourcesHandler in org.apache.hadoop.yarn.server.nodemanager.util has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/WindowsSecureContainerExecutor.java:[377,19] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:cmake-compile (cmake-compile) @ hadoop-yarn-server-nodemanager ---
[INFO] mkdirs '/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/native'
[INFO] Running cmake /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src -DHADOOP_CONF_DIR=../etc/hadoop -DJVM_ARCH_DATA_MODEL=64 -G Unix Makefiles
[INFO] with extra environment variables {
  CFLAGS = ''
}
[INFO] Running make -j 8 VERBOSE=1
[INFO] cmake compilation finished successfully in 17146 millisecond(s).
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (make) @ hadoop-yarn-server-nodemanager ---
[INFO] Executing tasks

main:
     [copy] Copying 4 files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/native/test
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-server-nodemanager ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 7 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-server-nodemanager ---
[INFO] Compiling 135 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/test-classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestLinuxContainerExecutor.java:[77,53] [deprecation] LCEResourcesHandler in org.apache.hadoop.yarn.server.nodemanager.util has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestLinuxContainerExecutorWithMocks.java:[558,63] [unchecked] unchecked method invocation: method executePrivilegedOperation in class PrivilegedOperationExecutor is applied to given types
[WARNING]   required: List<String>,PrivilegedOperation,File,Map<String,String>,boolean,boolean
  found: List,PrivilegedOperation,File,Map,boolean,boolean
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestLinuxContainerExecutorWithMocks.java:[559,15] [unchecked] unchecked conversion
[WARNING]   required: List<String>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestLinuxContainerExecutorWithMocks.java:[560,32] [unchecked] unchecked conversion
[WARNING]   required: Map<String,String>
  found:    Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/TestLogAggregationService.java:[1723,44] [deprecation] toString(ApplicationId) in ConverterUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/resources/TestCGroupsCpuResourceHandlerImpl.java:[105,15] [deprecation] write(File,CharSequence) in FileUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/TestContainerLocalizer.java:[386,37] [unchecked] unchecked conversion
[WARNING]   required: CompletionService<Path>
  found:    CompletionService
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/TestContainerLocalizer.java:[392,36] [unchecked] unchecked conversion
[WARNING]   required: Future<Path>
  found:    Future
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/TestContainerLocalizer.java:[387,18] [unchecked] unchecked method invocation: method submit in interface CompletionService is applied to given types
[WARNING]   required: Callable<V>
  found: Callable
  where V is a type-variable:
    V extends Object declared in interface CompletionService
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/TestContainerLocalizer.java:[387,22] [unchecked] unchecked conversion
[WARNING]   required: Callable<V>
  found:    Callable
  where V is a type-variable:
    V extends Object declared in interface CompletionService
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/resources/gpu/TestGpuResourceHandler.java:[342,60] [unchecked] unchecked method invocation: method storeAssignedResources in class NMStateStoreService is applied to given types
[WARNING]   required: Container,String,List<Serializable>
  found: Container,String,List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/resources/gpu/TestGpuResourceHandler.java:[343,63] [unchecked] unchecked conversion
[WARNING]   required: List<Serializable>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestLinuxContainerExecutor.java:[635,33] [deprecation] LCEResourcesHandler in org.apache.hadoop.yarn.server.nodemanager.util has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestLinuxContainerExecutor.java:[697,54] [deprecation] LCEResourcesHandler in org.apache.hadoop.yarn.server.nodemanager.util has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/resources/fpga/TestFpgaResourceHandler.java:[279,49] [unchecked] unchecked method invocation: method downloadIP in class IntelFpgaOpenclPlugin is applied to given types
[WARNING]   required: String,String,Map<Path,List<String>>
  found: String,String,Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/resources/fpga/TestFpgaResourceHandler.java:[279,82] [unchecked] unchecked conversion
[WARNING]   required: Map<Path,List<String>>
  found:    Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/resources/fpga/TestFpgaResourceHandler.java:[299,60] [unchecked] unchecked method invocation: method storeAssignedResources in class NMStateStoreService is applied to given types
[WARNING]   required: Container,String,List<Serializable>
  found: Container,String,List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/resources/fpga/TestFpgaResourceHandler.java:[300,65] [unchecked] unchecked conversion
[WARNING]   required: List<Serializable>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/resources/fpga/TestFpgaResourceHandler.java:[411,26] [unchecked] unchecked method invocation: method downloadIP in class IntelFpgaOpenclPlugin is applied to given types
[WARNING]   required: String,String,Map<Path,List<String>>
  found: String,String,Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/resources/fpga/TestFpgaResourceHandler.java:[411,83] [unchecked] unchecked conversion
[WARNING]   required: Map<Path,List<String>>
  found:    Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[285,12] [unchecked] unchecked conversion
[WARNING]   required: ConcurrentMap<ContainerId,Container>
  found:    ConcurrentMap
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1513,35] [unchecked] unchecked method invocation: method executePrivilegedOperation in class PrivilegedOperationExecutor is applied to given types
[WARNING]   required: List<String>,PrivilegedOperation,File,Map<String,String>,boolean,boolean
  found: List,PrivilegedOperation,File,Map,boolean,boolean
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1513,43] [unchecked] unchecked conversion
[WARNING]   required: List<String>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1514,31] [unchecked] unchecked conversion
[WARNING]   required: Map<String,String>
  found:    Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1571,35] [unchecked] unchecked method invocation: method executePrivilegedOperation in class PrivilegedOperationExecutor is applied to given types
[WARNING]   required: List<String>,PrivilegedOperation,File,Map<String,String>,boolean,boolean
  found: List,PrivilegedOperation,File,Map,boolean,boolean
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1571,43] [unchecked] unchecked conversion
[WARNING]   required: List<String>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1572,31] [unchecked] unchecked conversion
[WARNING]   required: Map<String,String>
  found:    Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1593,35] [unchecked] unchecked method invocation: method executePrivilegedOperation in class PrivilegedOperationExecutor is applied to given types
[WARNING]   required: List<String>,PrivilegedOperation,File,Map<String,String>,boolean,boolean
  found: List,PrivilegedOperation,File,Map,boolean,boolean
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1593,43] [unchecked] unchecked conversion
[WARNING]   required: List<String>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1594,31] [unchecked] unchecked conversion
[WARNING]   required: Map<String,String>
  found:    Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1615,35] [unchecked] unchecked method invocation: method executePrivilegedOperation in class PrivilegedOperationExecutor is applied to given types
[WARNING]   required: List<String>,PrivilegedOperation,File,Map<String,String>,boolean,boolean
  found: List,PrivilegedOperation,File,Map,boolean,boolean
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1615,43] [unchecked] unchecked conversion
[WARNING]   required: List<String>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1616,31] [unchecked] unchecked conversion
[WARNING]   required: Map<String,String>
  found:    Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1642,35] [unchecked] unchecked method invocation: method executePrivilegedOperation in class PrivilegedOperationExecutor is applied to given types
[WARNING]   required: List<String>,PrivilegedOperation,File,Map<String,String>,boolean,boolean
  found: List,PrivilegedOperation,File,Map,boolean,boolean
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1642,43] [unchecked] unchecked conversion
[WARNING]   required: List<String>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1643,31] [unchecked] unchecked conversion
[WARNING]   required: Map<String,String>
  found:    Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1659,35] [unchecked] unchecked method invocation: method executePrivilegedOperation in class PrivilegedOperationExecutor is applied to given types
[WARNING]   required: List<String>,PrivilegedOperation,File,Map<String,String>,boolean,boolean
  found: List,PrivilegedOperation,File,Map,boolean,boolean
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1659,43] [unchecked] unchecked conversion
[WARNING]   required: List<String>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1660,31] [unchecked] unchecked conversion
[WARNING]   required: Map<String,String>
  found:    Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1869,35] [unchecked] unchecked method invocation: method executePrivilegedOperation in class PrivilegedOperationExecutor is applied to given types
[WARNING]   required: List<String>,PrivilegedOperation,File,Map<String,String>,boolean,boolean
  found: List,PrivilegedOperation,File,Map,boolean,boolean
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1869,43] [unchecked] unchecked conversion
[WARNING]   required: List<String>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1870,35] [unchecked] unchecked conversion
[WARNING]   required: Map<String,String>
  found:    Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1873,35] [unchecked] unchecked method invocation: method executePrivilegedOperation in class PrivilegedOperationExecutor is applied to given types
[WARNING]   required: List<String>,PrivilegedOperation,File,Map<String,String>,boolean,boolean
  found: List,PrivilegedOperation,File,Map,boolean,boolean
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1873,43] [unchecked] unchecked conversion
[WARNING]   required: List<String>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1874,35] [unchecked] unchecked conversion
[WARNING]   required: Map<String,String>
  found:    Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1966,35] [unchecked] unchecked method invocation: method executePrivilegedOperation in class PrivilegedOperationExecutor is applied to given types
[WARNING]   required: List<String>,PrivilegedOperation,File,Map<String,String>,boolean,boolean
  found: List,PrivilegedOperation,File,Map,boolean,boolean
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1966,43] [unchecked] unchecked conversion
[WARNING]   required: List<String>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1967,35] [unchecked] unchecked conversion
[WARNING]   required: Map<String,String>
  found:    Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1970,35] [unchecked] unchecked method invocation: method executePrivilegedOperation in class PrivilegedOperationExecutor is applied to given types
[WARNING]   required: List<String>,PrivilegedOperation,File,Map<String,String>,boolean,boolean
  found: List,PrivilegedOperation,File,Map,boolean,boolean
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1970,43] [unchecked] unchecked conversion
[WARNING]   required: List<String>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[1971,35] [unchecked] unchecked conversion
[WARNING]   required: Map<String,String>
  found:    Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[2191,35] [unchecked] unchecked method invocation: method executePrivilegedOperation in class PrivilegedOperationExecutor is applied to given types
[WARNING]   required: List<String>,PrivilegedOperation,File,Map<String,String>,boolean,boolean
  found: List,PrivilegedOperation,File,Map,boolean,boolean
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[2191,43] [unchecked] unchecked conversion
[WARNING]   required: List<String>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestDockerContainerRuntime.java:[2192,31] [unchecked] unchecked conversion
[WARNING]   required: Map<String,String>
  found:    Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/TestContainerLaunch.java:[1683,49] [unchecked] unchecked method invocation: method thenReturn in interface OngoingStubbing is applied to given types
[WARNING]   required: T
  found: EventHandler
  where T is a type-variable:
    T extends Object declared in interface OngoingStubbing
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/TestContainerLaunch.java:[1683,50] [unchecked] unchecked conversion
[WARNING]   required: T
  found:    EventHandler
  where T is a type-variable:
    T extends Object declared in interface OngoingStubbing
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/TestJavaSandboxLinuxContainerRuntime.java:[154,10] [unchecked] unchecked conversion
[WARNING]   required: Map<String,String>
  found:    HashMap
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/docker/TestDockerCommandExecutor.java:[121,12] [unchecked] unchecked conversion
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-server-nodemanager ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestNodeManager
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.472 s - in org.apache.hadoop.yarn.server.nodemanager.TestNodeManager
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestDefaultContainerExecutor
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.77 s - in org.apache.hadoop.yarn.server.nodemanager.TestDefaultContainerExecutor
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestLocalDirsHandlerService
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.443 s - in org.apache.hadoop.yarn.server.nodemanager.TestLocalDirsHandlerService
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.util.TestNodeManagerHardwareUtils
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.322 s - in org.apache.hadoop.yarn.server.nodemanager.util.TestNodeManagerHardwareUtils
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.util.TestCgroupsLCEResourcesHandler
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.784 s - in org.apache.hadoop.yarn.server.nodemanager.util.TestCgroupsLCEResourcesHandler
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.util.TestProcessIdFileReader
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.098 s - in org.apache.hadoop.yarn.server.nodemanager.util.TestProcessIdFileReader
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestNodeResourceMonitor
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.754 s - in org.apache.hadoop.yarn.server.nodemanager.TestNodeResourceMonitor
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestDirectoryCollection
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.541 s - in org.apache.hadoop.yarn.server.nodemanager.TestDirectoryCollection
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.TestGpuDeviceInformationParser
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.295 s - in org.apache.hadoop.yarn.server.nodemanager.webapp.dao.gpu.TestGpuDeviceInformationParser
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesContainers
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.776 s - in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesContainers
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMAppsPage
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.793 s - in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMAppsPage
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesApps
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.54 s - in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesApps
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.087 s - in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebFilter
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.367 s - in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebFilter
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.179 s - in org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServices
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.656 s - in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServices
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.api.impl.pb.TestNMProtoUtils
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.429 s - in org.apache.hadoop.yarn.server.nodemanager.api.impl.pb.TestNMProtoUtils
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.TestPBRecordImpl
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.288 s - in org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.TestPBRecordImpl
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.TestPBLocalizerRPC
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.46 s - in org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.TestPBLocalizerRPC
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerReboot
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.327 s - in org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerReboot
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.252 s - in org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.executor.TestContainerReapContext
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.164 s - in org.apache.hadoop.yarn.server.nodemanager.executor.TestContainerReapContext
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.651 s - in org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestNetworkTagMappingJsonManager
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.567 s - in org.apache.hadoop.yarn.server.nodemanager.TestNetworkTagMappingJsonManager
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerResync
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.538 s - in org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerResync
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutorWithMocks
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.852 s - in org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutorWithMocks
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.container.TestContainer
[INFO] Tests run: 34, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.376 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.container.TestContainer
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.container.TestSlidingWindowRetryPolicy
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.181 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.container.TestSlidingWindowRetryPolicy
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitorResourceChange
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.281 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitorResourceChange
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.331 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainerMetrics
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.142 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainerMetrics
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.deletion.task.TestFileDeletionTask
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.427 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.deletion.task.TestFileDeletionTask
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.deletion.task.TestDockerContainerDeletionTask
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.216 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.deletion.task.TestDockerContainerDeletionTask
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManagerRecovery
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 80.348 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManagerRecovery
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.TestNonAggregatingLogHandler
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.81 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.TestNonAggregatingLogHandler
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.801 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.TestPrivilegedOperationExecutor
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.23 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.TestPrivilegedOperationExecutor
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestJavaSandboxLinuxContainerRuntime
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.492 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestJavaSandboxLinuxContainerRuntime
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerLoadCommand
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.1 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerLoadCommand
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerPullCommand
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.1 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerPullCommand
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerStopCommand
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.102 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerStopCommand
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerInspectCommand
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.107 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerInspectCommand
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerStartCommand
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.106 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerStartCommand
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerRmCommand
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.103 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerRmCommand
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerClient
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.522 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerClient
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerRunCommand
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.096 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerRunCommand
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerCommandExecutor
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.541 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerCommandExecutor
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerKillCommand
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.102 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerKillCommand
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerVolumeCommand
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.043 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.TestDockerVolumeCommand
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDockerContainerRuntime
[INFO] Tests run: 46, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.652 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDockerContainerRuntime
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDelegatingLinuxContainerRuntime
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.324 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDelegatingLinuxContainerRuntime
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestResourceHandlerModule
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.337 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestResourceHandlerModule
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestTrafficControlBandwidthHandlerImpl
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.415 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestTrafficControlBandwidthHandlerImpl
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestCGroupsCpuResourceHandlerImpl
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.44 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestCGroupsCpuResourceHandlerImpl
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.TestGpuResourceHandler
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.501 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.TestGpuResourceHandler
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestCGroupsBlkioResourceHandlerImpl
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.29 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestCGroupsBlkioResourceHandlerImpl
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestTrafficController
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.403 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestTrafficController
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestNetworkPacketTaggingHandlerImpl
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.333 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestNetworkPacketTaggingHandlerImpl
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestCGroupsHandlerImpl
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.451 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestCGroupsHandlerImpl
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.numa.TestNumaResourceAllocator
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.512 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.numa.TestNumaResourceAllocator
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.numa.TestNumaResourceHandlerImpl
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.494 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.numa.TestNumaResourceHandlerImpl
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.fpga.TestFpgaResourceHandler
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.568 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.fpga.TestFpgaResourceHandler
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestCGroupsResourceCalculator
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.248 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestCGroupsResourceCalculator
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestCompareResourceCalculators
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.055 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestCompareResourceCalculators
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestCGroupsMemoryResourceHandlerImpl
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.422 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.TestCGroupsMemoryResourceHandlerImpl
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestAppLogAggregatorImpl
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.707 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestAppLogAggregatorImpl
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService
[INFO] Tests run: 43, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 201.174 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.gpu.TestNvidiaDockerV1CommandPlugin
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.381 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.gpu.TestNvidiaDockerV1CommandPlugin
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.gpu.TestGpuDiscoverer
[WARNING] Tests run: 3, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 0.136 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.gpu.TestGpuDiscoverer
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.TestResourcePluginManager
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.352 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.TestResourcePluginManager
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.TestFpgaDiscoverer
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.247 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.TestFpgaDiscoverer
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestAllocationBasedResourceUtilizationTracker
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.466 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestAllocationBasedResourceUtilizationTracker
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerRecovery
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.439 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerRecovery
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerBehaviorCompatibility
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.118 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerBehaviorCompatibility
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 180.556 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.TestSharedCacheUploader
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.503 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.TestSharedCacheUploader
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.TestSharedCacheUploadService
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.368 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.TestSharedCacheUploadService
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestLocalizedResource
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.271 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestLocalizedResource
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestLocalResourcesTrackerImpl
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.63 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestLocalResourcesTrackerImpl
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestContainerLocalizer
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.78 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestContainerLocalizer
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestLocalCacheCleanup
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.32 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestLocalCacheCleanup
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.192 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestLocalCacheDirectoryManager
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.642 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestLocalCacheDirectoryManager
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestLocalResource
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.198 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestLocalResource
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager
[INFO] Tests run: 28, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 92.925 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.application.TestApplication
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.722 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.application.TestApplication
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.TestNMProxy
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.705 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.TestNMProxy
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch
[WARNING] Tests run: 34, Failures: 0, Errors: 0, Skipped: 5, Time elapsed: 19.425 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainersLauncher
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.429 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainersLauncher
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerRelaunch
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.389 s - in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerRelaunch
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.timelineservice.TestNMTimelinePublisher
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.86 s - in org.apache.hadoop.yarn.server.nodemanager.timelineservice.TestNMTimelinePublisher
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.security.TestNMTokenSecretManagerInNM
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.387 s - in org.apache.hadoop.yarn.server.nodemanager.security.TestNMTokenSecretManagerInNM
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.security.TestNMContainerTokenSecretManager
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.481 s - in org.apache.hadoop.yarn.server.nodemanager.security.TestNMContainerTokenSecretManager
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestContainerExecutor
[WARNING] Tests run: 6, Failures: 0, Errors: 0, Skipped: 3, Time elapsed: 0.437 s - in org.apache.hadoop.yarn.server.nodemanager.TestContainerExecutor
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.TestNMLogAggregationStatusTracker
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.322 s - in org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.TestNMLogAggregationStatusTracker
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutor
[WARNING] Tests run: 11, Failures: 0, Errors: 0, Skipped: 8, Time elapsed: 0.612 s - in org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutor
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestNodeStatusUpdaterForLabels
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.314 s - in org.apache.hadoop.yarn.server.nodemanager.TestNodeStatusUpdaterForLabels
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.884 s - in org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.nodelabels.TestScriptBasedNodeLabelsProvider
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.019 s - in org.apache.hadoop.yarn.server.nodemanager.nodelabels.TestScriptBasedNodeLabelsProvider
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.nodelabels.TestConfigurationNodeLabelsProvider
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.139 s - in org.apache.hadoop.yarn.server.nodemanager.nodelabels.TestConfigurationNodeLabelsProvider
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.scheduler.TestDistributedScheduler
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.716 s - in org.apache.hadoop.yarn.server.nodemanager.scheduler.TestDistributedScheduler
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestRecordFactory
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.133 s - in org.apache.hadoop.yarn.server.nodemanager.TestRecordFactory
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestNMAuditLogger
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.644 s - in org.apache.hadoop.yarn.server.nodemanager.TestNMAuditLogger
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestAMRMProxyTokenSecretManager
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.301 s - in org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestAMRMProxyTokenSecretManager
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestAMRMProxyService
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.751 s - in org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestAMRMProxyService
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestFederationInterceptor
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.376 s - in org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestFederationInterceptor
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestEventFlow
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.842 s - in org.apache.hadoop.yarn.server.nodemanager.TestEventFlow
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestDeletionService
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.991 s - in org.apache.hadoop.yarn.server.nodemanager.TestDeletionService
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.metrics.TestNodeManagerMetrics
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.618 s - in org.apache.hadoop.yarn.server.nodemanager.metrics.TestNodeManagerMetrics
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestRPCFactories
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.348 s - in org.apache.hadoop.yarn.server.nodemanager.TestRPCFactories
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestNodeStatusUpdater
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 73.494 s - in org.apache.hadoop.yarn.server.nodemanager.TestNodeStatusUpdater
[INFO] Running org.apache.hadoop.yarn.server.nodemanager.TestContainerManagerWithLCE
[WARNING] Tests run: 28, Failures: 0, Errors: 0, Skipped: 28, Time elapsed: 0.737 s - in org.apache.hadoop.yarn.server.nodemanager.TestContainerManagerWithLCE
[INFO] 
[INFO] Results:
[INFO] 
[WARNING] Tests run: 746, Failures: 0, Errors: 0, Skipped: 47
[INFO] 
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:cmake-test (test-container-executor) @ hadoop-yarn-server-nodemanager ---
[INFO] -------------------------------------------------------
[INFO]  C M A K E B U I L D E R    T E S T
[INFO] -------------------------------------------------------
[INFO] test-container-executor: running /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/native/target/usr/local/bin/test-container-executor
[INFO] with extra environment variables {}
[INFO] STATUS: SUCCESS after 4808 millisecond(s).
[INFO] -------------------------------------------------------
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:cmake-test (cetest) @ hadoop-yarn-server-nodemanager ---
[INFO] -------------------------------------------------------
[INFO]  C M A K E B U I L D E R    T E S T
[INFO] -------------------------------------------------------
[INFO] cetest: running /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/native/test/cetest --gtest_filter=-Perf. --gtest_output=xml:/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/surefire-reports/TEST-cetest.xml
[INFO] with extra environment variables {}
[INFO] STATUS: SUCCESS after 74 millisecond(s).
[INFO] -------------------------------------------------------
[INFO] 
[INFO] -----------< org.apache.hadoop:hadoop-yarn-server-web-proxy >-----------
[INFO] Building Apache Hadoop YARN Web Proxy 3.1.1-TDP-0.1.0-SNAPSHOT   [29/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-web-proxy ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-web-proxy ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-web-proxy ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-server-web-proxy ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-server-web-proxy ---
[INFO] Compiling 10 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/target/classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/java/org/apache/hadoop/yarn/server/webproxy/WebAppProxyServlet.java:[69,36] [deprecation] ClientPNames in org.apache.http.client.params has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/java/org/apache/hadoop/yarn/server/webproxy/WebAppProxyServlet.java:[70,36] [deprecation] CookiePolicy in org.apache.http.client.params has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/java/org/apache/hadoop/yarn/server/webproxy/WebAppProxyServlet.java:[72,34] [deprecation] ConnRoutePNames in org.apache.http.conn.params has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/java/org/apache/hadoop/yarn/server/webproxy/WebAppProxyServlet.java:[74,34] [deprecation] DefaultHttpClient in org.apache.http.impl.client has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/java/org/apache/hadoop/yarn/server/webproxy/WebAppProxyServlet.java:[194,4] [deprecation] DefaultHttpClient in org.apache.http.impl.client has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/java/org/apache/hadoop/yarn/server/webproxy/WebAppProxyServlet.java:[194,35] [deprecation] DefaultHttpClient in org.apache.http.impl.client has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/java/org/apache/hadoop/yarn/server/webproxy/WebAppProxyServlet.java:[199,29] [deprecation] ClientPNames in org.apache.http.client.params has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/java/org/apache/hadoop/yarn/server/webproxy/WebAppProxyServlet.java:[197,22] [deprecation] ClientPNames in org.apache.http.client.params has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/java/org/apache/hadoop/yarn/server/webproxy/WebAppProxyServlet.java:[198,12] [deprecation] CookiePolicy in org.apache.http.client.params has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/java/org/apache/hadoop/yarn/server/webproxy/WebAppProxyServlet.java:[208,22] [deprecation] ConnRoutePNames in org.apache.http.conn.params has been deprecated
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-server-web-proxy ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-server-web-proxy ---
[INFO] Compiling 7 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/target/test-classes
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-yarn-server-web-proxy ---
[INFO] Building jar: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/target/hadoop-yarn-server-web-proxy-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-server-web-proxy ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.server.webproxy.TestProxyUriUtils
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.198 s - in org.apache.hadoop.yarn.server.webproxy.TestProxyUriUtils
[INFO] Running org.apache.hadoop.yarn.server.webproxy.amfilter.TestSecureAmFilter
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.78 s - in org.apache.hadoop.yarn.server.webproxy.amfilter.TestSecureAmFilter
[INFO] Running org.apache.hadoop.yarn.server.webproxy.amfilter.TestAmFilter
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.47 s - in org.apache.hadoop.yarn.server.webproxy.amfilter.TestAmFilter
[INFO] Running org.apache.hadoop.yarn.server.webproxy.amfilter.TestAmFilterInitializer
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.201 s - in org.apache.hadoop.yarn.server.webproxy.amfilter.TestAmFilterInitializer
[INFO] Running org.apache.hadoop.yarn.server.webproxy.TestWebAppProxyServer
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.87 s - in org.apache.hadoop.yarn.server.webproxy.TestWebAppProxyServer
[INFO] Running org.apache.hadoop.yarn.server.webproxy.TestWebAppProxyServlet
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.315 s - in org.apache.hadoop.yarn.server.webproxy.TestWebAppProxyServlet
[INFO] Running org.apache.hadoop.yarn.server.webproxy.TestAppReportFetcher
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.335 s - in org.apache.hadoop.yarn.server.webproxy.TestAppReportFetcher
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ---< org.apache.hadoop:hadoop-yarn-server-applicationhistoryservice >---
[INFO] Building Apache Hadoop YARN ApplicationHistoryService 3.1.1-TDP-0.1.0-SNAPSHOT [30/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-applicationhistoryservice ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-applicationhistoryservice ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:protoc (compile-protoc) @ hadoop-yarn-server-applicationhistoryservice ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-applicationhistoryservice ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-server-applicationhistoryservice ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-server-applicationhistoryservice ---
[INFO] Compiling 65 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/target/classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/GenericObjectMapper.java:[46,26] [deprecation] reader(Class<?>) in ObjectMapper has been deprecated
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-server-applicationhistoryservice ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-server-applicationhistoryservice ---
[INFO] Compiling 21 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/target/test-classes
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-yarn-server-applicationhistoryservice ---
[INFO] Building jar: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/target/hadoop-yarn-server-applicationhistoryservice-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-server-applicationhistoryservice ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.827 s - in org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager
[INFO] Running org.apache.hadoop.yarn.server.timeline.webapp.TestTimelineWebServices
[INFO] Tests run: 26, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.765 s - in org.apache.hadoop.yarn.server.timeline.webapp.TestTimelineWebServices
[INFO] Running org.apache.hadoop.yarn.server.timeline.webapp.TestTimelineWebServicesWithSSL
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.561 s - in org.apache.hadoop.yarn.server.timeline.webapp.TestTimelineWebServicesWithSSL
[INFO] Running org.apache.hadoop.yarn.server.timeline.TestMemoryTimelineStore
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.188 s - in org.apache.hadoop.yarn.server.timeline.TestMemoryTimelineStore
[INFO] Running org.apache.hadoop.yarn.server.timeline.TestGenericObjectMapper
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.284 s - in org.apache.hadoop.yarn.server.timeline.TestGenericObjectMapper
[INFO] Running org.apache.hadoop.yarn.server.timeline.security.TestTimelineACLsManager
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.37 s - in org.apache.hadoop.yarn.server.timeline.security.TestTimelineACLsManager
[INFO] Running org.apache.hadoop.yarn.server.timeline.security.TestTimelineAuthenticationFilterForV1
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.561 s - in org.apache.hadoop.yarn.server.timeline.security.TestTimelineAuthenticationFilterForV1
[INFO] Running org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.439 s - in org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore
[INFO] Running org.apache.hadoop.yarn.server.timeline.recovery.TestLeveldbTimelineStateStore
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.581 s - in org.apache.hadoop.yarn.server.timeline.recovery.TestLeveldbTimelineStateStore
[INFO] Running org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.787 s - in org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore
[INFO] Running org.apache.hadoop.yarn.server.timeline.TestRollingLevelDB
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.58 s - in org.apache.hadoop.yarn.server.timeline.TestRollingLevelDB
[INFO] Running org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.TestAHSWebServices
[INFO] Tests run: 36, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.145 s - in org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.TestAHSWebServices
[INFO] Running org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.TestAHSWebApp
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.303 s - in org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.TestAHSWebApp
[INFO] Running org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryManagerOnTimelineStore
[INFO] Tests run: 40, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.765 s - in org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryManagerOnTimelineStore
[INFO] Running org.apache.hadoop.yarn.server.applicationhistoryservice.TestFileSystemApplicationHistoryStore
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.651 s - in org.apache.hadoop.yarn.server.applicationhistoryservice.TestFileSystemApplicationHistoryStore
[INFO] Running org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryServer
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.118 s - in org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryServer
[INFO] Running org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryClientService
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.518 s - in org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryClientService
[INFO] Running org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryManagerImpl
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.293 s - in org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryManagerImpl
[INFO] Running org.apache.hadoop.yarn.server.applicationhistoryservice.TestMemoryApplicationHistoryStore
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.546 s - in org.apache.hadoop.yarn.server.applicationhistoryservice.TestMemoryApplicationHistoryStore
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 205, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] --------< org.apache.hadoop:hadoop-yarn-server-timelineservice >--------
[INFO] Building Apache Hadoop YARN Timeline Service 3.1.1-TDP-0.1.0-SNAPSHOT [31/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-timelineservice ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-timelineservice ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-timelineservice ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-server-timelineservice ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-server-timelineservice ---
[INFO] Compiling 58 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-server-timelineservice ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-server-timelineservice ---
[INFO] Compiling 14 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/target/test-classes
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-yarn-server-timelineservice ---
[INFO] Building jar: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/target/hadoop-yarn-server-timelineservice-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-server-timelineservice ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.storage.TestFileSystemTimelineWriterImpl
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.461 s - in org.apache.hadoop.yarn.server.timelineservice.storage.TestFileSystemTimelineWriterImpl
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.storage.TestFileSystemTimelineReaderImpl
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.607 s - in org.apache.hadoop.yarn.server.timelineservice.storage.TestFileSystemTimelineReaderImpl
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.collector.TestNMTimelineCollectorManager
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.903 s - in org.apache.hadoop.yarn.server.timelineservice.collector.TestNMTimelineCollectorManager
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.collector.TestPerNodeTimelineCollectorsAuxService
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.075 s - in org.apache.hadoop.yarn.server.timelineservice.collector.TestPerNodeTimelineCollectorsAuxService
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.collector.TestTimelineCollector
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.415 s - in org.apache.hadoop.yarn.server.timelineservice.collector.TestTimelineCollector
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.collector.TestTimelineCollectorManager
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.24 s - in org.apache.hadoop.yarn.server.timelineservice.collector.TestTimelineCollectorManager
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderServer
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.728 s - in org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderServer
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesUtils
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.294 s - in org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesUtils
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.351 s - in org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWhitelistAuthorizationFilter
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.414 s - in org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWhitelistAuthorizationFilter
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderUtils
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.059 s - in org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderUtils
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineUIDConverter
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.076 s - in org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineUIDConverter
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices
[INFO] Tests run: 21, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.695 s - in org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 73, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] --------< org.apache.hadoop:hadoop-yarn-server-resourcemanager >--------
[INFO] Building Apache Hadoop YARN ResourceManager 3.1.1-TDP-0.1.0-SNAPSHOT [32/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-resourcemanager ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-resourcemanager ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:protoc (compile-protoc) @ hadoop-yarn-server-resourcemanager ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-resourcemanager ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-server-resourcemanager ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-server-resourcemanager ---
[INFO] Compiling 567 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/target/classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java:[245,38] [deprecation] RM_SCHEDULER_INCREMENT_ALLOCATION_MB in FairSchedulerConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java:[272,38] [deprecation] RM_SCHEDULER_INCREMENT_ALLOCATION_VCORES in FairSchedulerConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java:[1221,8] [unchecked] unchecked method invocation: constructor <init> in class VisitedResourceRequestTracker is applied to given types
[WARNING]   required: ClusterNodeTracker<FSSchedulerNode>
  found: ClusterNodeTracker
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java:[1221,66] [unchecked] unchecked conversion
[WARNING]   required: ClusterNodeTracker<FSSchedulerNode>
  found:    ClusterNodeTracker
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ResourceManager.java:[352,41] [deprecation] CURATOR_LEADER_ELECTOR in YarnConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/ClusterNodeTracker.java:[364,19] [unchecked] unchecked call to ArrayList(Collection<? extends E>) as a member of the raw type ArrayList
[WARNING]   where E is a type-variable:
    E extends Object declared in class ArrayList
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/ClusterNodeTracker.java:[364,19] [unchecked] unchecked conversion
[WARNING]   required: List<N>
  found:    ArrayList
  where N is a type-variable:
    N extends SchedulerNode declared in class ClusterNodeTracker
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AppSchedulingInfo.java:[471,18] [unchecked] unchecked method invocation: method addAll in interface List is applied to given types
[WARNING]   required: Collection<? extends E>
  found: Collection
  where E is a type-variable:
    E extends Object declared in interface List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AppSchedulingInfo.java:[471,50] [unchecked] unchecked conversion
[WARNING]   required: Collection<? extends E>
  found:    Collection
  where E is a type-variable:
    E extends Object declared in interface List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AppSchedulingInfo.java:[722,77] [unchecked] unchecked cast
[WARNING]   required: AppPlacementAllocator<N>
  found:    AppPlacementAllocator<SchedulerNode>
  where N is a type-variable:
    N extends SchedulerNode declared in method <N>getAppPlacementAllocator(SchedulerRequestKey)
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/distributed/NodeQueueLoadMonitor.java:[316,17] [unchecked] unchecked method invocation: method sort in class Arrays is applied to given types
[WARNING] Comparator<? super T>)
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/distributed/NodeQueueLoadMonitor.java:[316,25] [unchecked] unchecked conversion
[WARNING] Comparator<? super T>)
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/AllocationTagsManager.java:[69,56] [unchecked] unchecked conversion
[WARNING]   required: TypeToCountedTags<NodeId>
  found:    TypeToCountedTags
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/AllocationTagsManager.java:[71,56] [unchecked] unchecked conversion
[WARNING]   required: TypeToCountedTags<String>
  found:    TypeToCountedTags
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/AllocationTagsManager.java:[262,13] [unchecked] unchecked call to TypeToCountedTags(Map<T,Map<String,Long>>) as a member of the raw type TypeToCountedTags
[WARNING]   where T is a type-variable:
    T extends Object declared in class TypeToCountedTags
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/AllocationTagsManager.java:[323,23] [unchecked] unchecked call to absorb(TypeToCountedTags<T>) as a member of the raw type TypeToCountedTags
[WARNING]   where T is a type-variable:
    T extends Object declared in class TypeToCountedTags
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/AllocationTagsManager.java:[368,31] [unchecked] unchecked call to addTags(T,Set<String>) as a member of the raw type TypeToCountedTags
[WARNING]   where T is a type-variable:
    T extends Object declared in class TypeToCountedTags
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/AllocationTagsManager.java:[369,35] [unchecked] unchecked call to addTags(T,Set<String>) as a member of the raw type TypeToCountedTags
[WARNING]   where T is a type-variable:
    T extends Object declared in class TypeToCountedTags
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/AllocationTagsManager.java:[423,34] [unchecked] unchecked call to removeTags(T,Set<String>) as a member of the raw type TypeToCountedTags
[WARNING]   where T is a type-variable:
    T extends Object declared in class TypeToCountedTags
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/AllocationTagsManager.java:[424,38] [unchecked] unchecked call to removeTags(T,Set<String>) as a member of the raw type TypeToCountedTags
[WARNING]   where T is a type-variable:
    T extends Object declared in class TypeToCountedTags
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/AllocationTagsManager.java:[476,35] [unchecked] unchecked call to getCardinality(T,String) as a member of the raw type TypeToCountedTags
[WARNING]   where T is a type-variable:
    T extends Object declared in class TypeToCountedTags
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/AllocationTagsManager.java:[517,35] [unchecked] unchecked call to getCardinality(T,String) as a member of the raw type TypeToCountedTags
[WARNING]   where T is a type-variable:
    T extends Object declared in class TypeToCountedTags
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/AllocationTagsManager.java:[587,32] [unchecked] unchecked call to getCardinality(T,Set<String>,LongBinaryOperator) as a member of the raw type TypeToCountedTags
[WARNING]   where T is a type-variable:
    T extends Object declared in class TypeToCountedTags
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/AllocationTagsManager.java:[632,32] [unchecked] unchecked call to getCardinality(T,Set<String>,LongBinaryOperator) as a member of the raw type TypeToCountedTags
[WARNING]   where T is a type-variable:
    T extends Object declared in class TypeToCountedTags
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java:[155,33] [unchecked] unchecked conversion
[WARNING]   required: OrderingPolicy<FiCaSchedulerApp>
  found:    FifoOrderingPolicyForPendingApps
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractManagedParentQueue.java:[184,46] [unchecked] unchecked call to TreeMap(Comparator<? super K>) as a member of the raw type TreeMap
[WARNING]   where K is a type-variable:
    K extends Object declared in class TreeMap
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractManagedParentQueue.java:[184,46] [unchecked] unchecked conversion
[WARNING]   required: SortedMap<String,String>
  found:    TreeMap
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/processor/PlacementDispatcher.java:[134,42] [unchecked] unchecked method invocation: method computeIfAbsent in interface Map is applied to given types
[WARNING]   required: K,Function<? super K,? extends V>
  found: ApplicationId,Function<ApplicationId,List<SchedulingRequestWithPlacementAttempt>>
  where K,V are type-variables:
    K extends Object declared in interface Map
    V extends Object declared in interface Map
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/processor/PlacementDispatcher.java:[134,42] [unchecked] unchecked conversion
[WARNING]   required: List<SchedulingRequestWithPlacementAttempt>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/RMWebServices.java:[579,60] [unchecked] unchecked conversion
[WARNING]   required: List<FiCaSchedulerNode>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/conf/LeveldbConfigurationStore.java:[231,55] [unchecked] unchecked cast
[WARNING]   required: LinkedList<LogMutation>
  found:    Object
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/conf/ZKConfigurationStore.java:[115,25] [unchecked] unchecked cast
[WARNING]   required: LinkedList<LogMutation>
  found:    Object
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/conf/ZKConfigurationStore.java:[153,56] [unchecked] unchecked cast
[WARNING]   required: LinkedList<LogMutation>
  found:    Object
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/conf/ZKConfigurationStore.java:[198,53] [unchecked] unchecked cast
[WARNING]   required: HashMap<String,String>
  found:    Object
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/LeveldbRMStateStore.java:[369,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/LeveldbRMStateStore.java:[415,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/LeveldbRMStateStore.java:[433,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/algorithm/DefaultPlacementAlgorithm.java:[77,21] [unchecked] unchecked conversion
[WARNING]   required: List<SchedulerNode>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/algorithm/DefaultPlacementAlgorithm.java:[150,10] [unchecked] unchecked call to CircularIterator(T,Iterator<T>,Iterable<T>) as a member of the raw type CircularIterator
[WARNING]   where T is a type-variable:
    T extends Object declared in class CircularIterator
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/algorithm/DefaultPlacementAlgorithm.java:[150,10] [unchecked] unchecked conversion
[WARNING]   required: CircularIterator<SchedulerNode>
  found:    CircularIterator
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSPreemptionThread.java:[118,37] [unchecked] unchecked conversion
[WARNING]   required: List<FSSchedulerNode>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSPreemptionThread.java:[129,69] [unchecked] unchecked method invocation: method identifyContainersToPreemptForOneContainer in class FSPreemptionThread is applied to given types
[WARNING]   required: List<FSSchedulerNode>,ResourceRequest
  found: List,ResourceRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSPreemptionThread.java:[130,56] [unchecked] unchecked conversion
[WARNING]   required: List<FSSchedulerNode>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/FileSystemRMStateStore.java:[768,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/FileSystemRMStateStore.java:[802,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:test-protoc (compile-test-protoc) @ hadoop-yarn-server-resourcemanager ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-server-resourcemanager ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 16 resources
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-server-resourcemanager ---
[INFO] Compiling 273 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/target/test-classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/TestRMWebServicesReservation.java:[1106,17] [deprecation] readFileToString(File) in FileUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRMEmbeddedElector.java:[68,37] [deprecation] AUTO_FAILOVER_EMBEDDED in YarnConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairSchedulerTestBase.java:[92,42] [deprecation] RM_SCHEDULER_INCREMENT_ALLOCATION_MB in FairSchedulerConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestLeaderElectorService.java:[65,37] [deprecation] CURATOR_LEADER_ELECTOR in YarnConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRMRestart.java:[2340,32] [unchecked] Possible heap pollution from parameterized vararg type E
[WARNING]   where E is a type-variable:
    E extends Object declared in method <E>toSet(E...)
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFairSchedulerPreemption.java:[378,57] [unchecked] unchecked conversion
[WARNING]   required: List<FSSchedulerNode>
  found:    List
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacityScheduler.java:[1134,23] [unchecked] unchecked method invocation: method setOrderingPolicy in class LeafQueue is applied to given types
[WARNING]   required: OrderingPolicy<FiCaSchedulerApp>
  found: FairOrderingPolicy
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacityScheduler.java:[1134,24] [unchecked] unchecked conversion
[WARNING]   required: OrderingPolicy<FiCaSchedulerApp>
  found:    FairOrderingPolicy
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacityScheduler.java:[4914,28] [unchecked] unchecked method invocation: method apply in class FiCaSchedulerApp is applied to given types
[WARNING]   required: Resource,ResourceCommitRequest<FiCaSchedulerApp,FiCaSchedulerNode>,boolean
  found: Resource,ResourceCommitRequest,Boolean
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacityScheduler.java:[4915,14] [unchecked] unchecked conversion
[WARNING]   required: ResourceCommitRequest<FiCaSchedulerApp,FiCaSchedulerNode>
  found:    ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFairScheduler.java:[244,32] [deprecation] RM_SCHEDULER_INCREMENT_ALLOCATION_MB in FairSchedulerConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFairScheduler.java:[246,32] [deprecation] RM_SCHEDULER_INCREMENT_ALLOCATION_VCORES in FairSchedulerConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFairScheduler.java:[262,32] [deprecation] RM_SCHEDULER_INCREMENT_ALLOCATION_MB in FairSchedulerConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFairScheduler.java:[264,32] [deprecation] RM_SCHEDULER_INCREMENT_ALLOCATION_VCORES in FairSchedulerConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestResourceTrackerService.java:[313,23] [unchecked] unchecked generic array creation for varargs parameter of type Pair<String,Integer>[]
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestResourceTrackerService.java:[340,23] [unchecked] unchecked generic array creation for varargs parameter of type Pair<String,Integer>[]
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestResourceTrackerService.java:[357,23] [unchecked] unchecked generic array creation for varargs parameter of type Pair<String,Integer>[]
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestResourceTrackerService.java:[2070,11] [unchecked] Possible heap pollution from parameterized vararg type Pair<String,Integer>
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacitySchedulerAsyncScheduling.java:[259,8] [unchecked] unchecked call to SchedulerContainer(A,N,RMContainer,String,boolean) as a member of the raw type SchedulerContainer
[WARNING]   where A,N are type-variables:
    A extends SchedulerApplicationAttempt declared in class SchedulerContainer
    N extends SchedulerNode declared in class SchedulerContainer
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacitySchedulerAsyncScheduling.java:[262,8] [unchecked] unchecked call to ContainerAllocationProposal(SchedulerContainer<A,N>,List<SchedulerContainer<A,N>>,SchedulerContainer<A,N>,NodeType,NodeType,SchedulingMode,Resource) as a member of the raw type ContainerAllocationProposal
[WARNING]   where A,N are type-variables:
    A extends SchedulerApplicationAttempt declared in class ContainerAllocationProposal
    N extends SchedulerNode declared in class ContainerAllocationProposal
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacitySchedulerAsyncScheduling.java:[268,8] [unchecked] unchecked call to ResourceCommitRequest(List<ContainerAllocationProposal<A,N>>,List<ContainerAllocationProposal<A,N>>,List<SchedulerContainer<A,N>>) as a member of the raw type ResourceCommitRequest
[WARNING]   where A,N are type-variables:
    A extends SchedulerApplicationAttempt declared in class ResourceCommitRequest
    N extends SchedulerNode declared in class ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacitySchedulerAsyncScheduling.java:[468,40] [unchecked] unchecked call to SchedulerContainer(A,N,RMContainer,String,boolean) as a member of the raw type SchedulerContainer
[WARNING]   where A,N are type-variables:
    A extends SchedulerApplicationAttempt declared in class SchedulerContainer
    N extends SchedulerNode declared in class SchedulerContainer
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacitySchedulerAsyncScheduling.java:[471,10] [unchecked] unchecked call to ContainerAllocationProposal(SchedulerContainer<A,N>,List<SchedulerContainer<A,N>>,SchedulerContainer<A,N>,NodeType,NodeType,SchedulingMode,Resource) as a member of the raw type ContainerAllocationProposal
[WARNING]   where A,N are type-variables:
    A extends SchedulerApplicationAttempt declared in class ContainerAllocationProposal
    N extends SchedulerNode declared in class ContainerAllocationProposal
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacitySchedulerAsyncScheduling.java:[477,10] [unchecked] unchecked call to ResourceCommitRequest(List<ContainerAllocationProposal<A,N>>,List<ContainerAllocationProposal<A,N>>,List<SchedulerContainer<A,N>>) as a member of the raw type ResourceCommitRequest
[WARNING]   where A,N are type-variables:
    A extends SchedulerApplicationAttempt declared in class ResourceCommitRequest
    N extends SchedulerNode declared in class ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacitySchedulerAsyncScheduling.java:[762,8] [unchecked] unchecked call to SchedulerContainer(A,N,RMContainer,String,boolean) as a member of the raw type SchedulerContainer
[WARNING]   where A,N are type-variables:
    A extends SchedulerApplicationAttempt declared in class SchedulerContainer
    N extends SchedulerNode declared in class SchedulerContainer
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacitySchedulerAsyncScheduling.java:[764,8] [unchecked] unchecked call to SchedulerContainer(A,N,RMContainer,String,boolean) as a member of the raw type SchedulerContainer
[WARNING]   where A,N are type-variables:
    A extends SchedulerApplicationAttempt declared in class SchedulerContainer
    N extends SchedulerNode declared in class SchedulerContainer
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacitySchedulerAsyncScheduling.java:[769,8] [unchecked] unchecked call to ContainerAllocationProposal(SchedulerContainer<A,N>,List<SchedulerContainer<A,N>>,SchedulerContainer<A,N>,NodeType,NodeType,SchedulingMode,Resource) as a member of the raw type ContainerAllocationProposal
[WARNING]   where A,N are type-variables:
    A extends SchedulerApplicationAttempt declared in class ContainerAllocationProposal
    N extends SchedulerNode declared in class ContainerAllocationProposal
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacitySchedulerAsyncScheduling.java:[774,11] [unchecked] unchecked call to ResourceCommitRequest(List<ContainerAllocationProposal<A,N>>,List<ContainerAllocationProposal<A,N>>,List<SchedulerContainer<A,N>>) as a member of the raw type ResourceCommitRequest
[WARNING]   where A,N are type-variables:
    A extends SchedulerApplicationAttempt declared in class ResourceCommitRequest
    N extends SchedulerNode declared in class ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/TestDominantResourceFairnessPolicy.java:[97,17] [unchecked] unchecked call to compare(T,T) as a member of the raw type Comparator
[WARNING]   where T is a type-variable:
    T extends Object declared in interface Comparator
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/TestDominantResourceFairnessPolicy.java:[113,17] [unchecked] unchecked call to compare(T,T) as a member of the raw type Comparator
[WARNING]   where T is a type-variable:
    T extends Object declared in interface Comparator
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/TestDominantResourceFairnessPolicy.java:[129,17] [unchecked] unchecked call to compare(T,T) as a member of the raw type Comparator
[WARNING]   where T is a type-variable:
    T extends Object declared in interface Comparator
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/TestDominantResourceFairnessPolicy.java:[147,17] [unchecked] unchecked call to compare(T,T) as a member of the raw type Comparator
[WARNING]   where T is a type-variable:
    T extends Object declared in interface Comparator
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/TestDominantResourceFairnessPolicy.java:[155,17] [unchecked] unchecked call to compare(T,T) as a member of the raw type Comparator
[WARNING]   where T is a type-variable:
    T extends Object declared in interface Comparator
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestReservations.java:[199,40] [unchecked] unchecked method invocation: method accept in class AbstractCSQueue is applied to given types
[WARNING]   required: Resource,ResourceCommitRequest<FiCaSchedulerApp,FiCaSchedulerNode>
  found: Resource,ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestReservations.java:[200,13] [unchecked] unchecked conversion
[WARNING]   required: ResourceCommitRequest<FiCaSchedulerApp,FiCaSchedulerNode>
  found:    ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestReservations.java:[201,36] [unchecked] unchecked method invocation: method apply in class ParentQueue is applied to given types
[WARNING]   required: Resource,ResourceCommitRequest<FiCaSchedulerApp,FiCaSchedulerNode>
  found: Resource,ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestReservations.java:[202,13] [unchecked] unchecked conversion
[WARNING]   required: ResourceCommitRequest<FiCaSchedulerApp,FiCaSchedulerNode>
  found:    ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestContinuousScheduling.java:[311,32] [unchecked] unchecked conversion
[WARNING]   required: ClusterNodeTracker<FSSchedulerNode>
  found:    ClusterNodeTracker
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[166,20] [unchecked] unchecked method invocation: method accept in interface CSQueue is applied to given types
[WARNING]   required: Resource,ResourceCommitRequest<FiCaSchedulerApp,FiCaSchedulerNode>
  found: Resource,ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[166,38] [unchecked] unchecked conversion
[WARNING]   required: ResourceCommitRequest<FiCaSchedulerApp,FiCaSchedulerNode>
  found:    ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[167,17] [unchecked] unchecked method invocation: method apply in interface CSQueue is applied to given types
[WARNING]   required: Resource,ResourceCommitRequest<FiCaSchedulerApp,FiCaSchedulerNode>
  found: Resource,ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[167,35] [unchecked] unchecked conversion
[WARNING]   required: ResourceCommitRequest<FiCaSchedulerApp,FiCaSchedulerNode>
  found:    ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[206,21] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[218,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[302,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[308,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[323,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[326,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[339,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[342,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[359,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[362,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[585,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[593,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[601,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[627,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[630,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[638,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[646,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[766,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[772,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[786,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[789,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[853,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[856,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[870,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java:[873,11] [unchecked] unchecked conversion
[WARNING]   required: CandidateNodeSet<FiCaSchedulerNode>
  found:    CandidateNodeSet
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestLeafQueue.java:[288,38] [unchecked] unchecked method invocation: method accept in interface CSQueue is applied to given types
[WARNING]   required: Resource,ResourceCommitRequest<FiCaSchedulerApp,FiCaSchedulerNode>
  found: Resource,ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestLeafQueue.java:[289,11] [unchecked] unchecked conversion
[WARNING]   required: ResourceCommitRequest<FiCaSchedulerApp,FiCaSchedulerNode>
  found:    ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestLeafQueue.java:[290,34] [unchecked] unchecked method invocation: method apply in interface CSQueue is applied to given types
[WARNING]   required: Resource,ResourceCommitRequest<FiCaSchedulerApp,FiCaSchedulerNode>
  found: Resource,ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestLeafQueue.java:[291,11] [unchecked] unchecked conversion
[WARNING]   required: ResourceCommitRequest<FiCaSchedulerApp,FiCaSchedulerNode>
  found:    ResourceCommitRequest
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRMAdminService.java:[895,37] [deprecation] AUTO_FAILOVER_EMBEDDED in YarnConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRMAdminService.java:[896,37] [deprecation] CURATOR_LEADER_ELECTOR in YarnConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRMAdminService.java:[924,37] [deprecation] AUTO_FAILOVER_EMBEDDED in YarnConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRMAdminService.java:[950,37] [deprecation] AUTO_FAILOVER_EMBEDDED in YarnConfiguration has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRMAdminService.java:[1388,6] [deprecation] delete(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestQueuePlacementPolicy.java:[425,40] [deprecation] toInputStream(String) in IOUtils has been deprecated
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-yarn-server-resourcemanager ---
[INFO] Building jar: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/target/hadoop-yarn-server-resourcemanager-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-server-resourcemanager ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.webapp.TestRMWithCSRFFilter
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.002 s - in org.apache.hadoop.yarn.webapp.TestRMWithCSRFFilter
[INFO] Running org.apache.hadoop.yarn.webapp.TestRMWithXFSFilter
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.66 s - in org.apache.hadoop.yarn.webapp.TestRMWithXFSFilter
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.blacklist.TestBlacklistManager
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.209 s - in org.apache.hadoop.yarn.server.resourcemanager.blacklist.TestBlacklistManager
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMHAForAsyncScheduler
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.897 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRMHAForAsyncScheduler
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.ahs.TestRMApplicationHistoryWriter
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 90.282 s - in org.apache.hadoop.yarn.server.resourcemanager.ahs.TestRMApplicationHistoryWriter
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMServerUtils
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.482 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRMServerUtils
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestContainerResourceUsage
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 79.586 s - in org.apache.hadoop.yarn.server.resourcemanager.TestContainerResourceUsage
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyForReservedContainers
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.483 s - in org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyForReservedContainers
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestPreemptionForQueueWithPriorities
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.105 s - in org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestPreemptionForQueueWithPriorities
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyIntraQueueWithDRF
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.915 s - in org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyIntraQueueWithDRF
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyIntraQueueUserLimit
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.79 s - in org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyIntraQueueUserLimit
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyIntraQueue
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.977 s - in org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyIntraQueue
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyMockFramework
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.363 s - in org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyMockFramework
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicy
[INFO] Tests run: 31, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.894 s - in org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicy
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyIntraQueueFairOrdering
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.601 s - in org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyIntraQueueFairOrdering
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyInterQueueWithDRF
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.837 s - in org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyInterQueueWithDRF
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyForNodePartitions
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.132 s - in org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyForNodePartitions
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyPreemptToBalance
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.548 s - in org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.TestProportionalCapacityPreemptionPolicyPreemptToBalance
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.monitor.invariants.TestMetricsInvariantChecker
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.045 s - in org.apache.hadoop.yarn.server.resourcemanager.monitor.invariants.TestMetricsInvariantChecker
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.monitor.TestSchedulingMonitor
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.008 s - in org.apache.hadoop.yarn.server.resourcemanager.monitor.TestSchedulingMonitor
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestResourceManager
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.9 s - in org.apache.hadoop.yarn.server.resourcemanager.TestResourceManager
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebappAuthentication
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.364 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebappAuthentication
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesCapacitySched
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.678 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesCapacitySched
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServices
[INFO] Tests run: 21, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.698 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServices
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.TestFairSchedulerQueueInfo
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.474 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.TestFairSchedulerQueueInfo
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesSchedulerActivities
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.854 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesSchedulerActivities
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebApp
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.857 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebApp
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesFairScheduler
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.061 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesFairScheduler
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesNodeLabels
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.502 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesNodeLabels
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestNodesPage
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.494 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestNodesPage
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesNodes
[INFO] Tests run: 24, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.044 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesNodes
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesApps
[INFO] Tests run: 45, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.761 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesApps
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestApplicationsRequestBuilder
[INFO] Tests run: 51, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.525 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestApplicationsRequestBuilder
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesHttpStaticUserPermissions
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.507 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesHttpStaticUserPermissions
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesForCSWithPartitions
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.68 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesForCSWithPartitions
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesAppsModification
[INFO] Tests run: 48, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.274 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesAppsModification
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebAppFairScheduler
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.994 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebAppFairScheduler
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestAppPage
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.028 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestAppPage
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRedirectionErrorPage
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.027 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRedirectionErrorPage
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesReservation
[INFO] Tests run: 160, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 742.908 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesReservation
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServiceAppsNodelabel
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.921 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServiceAppsNodelabel
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesConfigurationMutation
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.207 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesConfigurationMutation
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesDelegationTokens
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.29 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesDelegationTokens
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesDelegationTokenAuthentication
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.681 s - in org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesDelegationTokenAuthentication
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestAMAuthorization
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.877 s - in org.apache.hadoop.yarn.server.resourcemanager.TestAMAuthorization
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestDecommissioningNodesWatcher
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.187 s - in org.apache.hadoop.yarn.server.resourcemanager.TestDecommissioningNodesWatcher
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMHAForNodeLabels
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.579 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRMHAForNodeLabels
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestSubmitApplicationWithRMHA
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.662 s - in org.apache.hadoop.yarn.server.resourcemanager.TestSubmitApplicationWithRMHA
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.rmapp.TestApplicationLifetimeMonitor
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 214.563 s - in org.apache.hadoop.yarn.server.resourcemanager.rmapp.TestApplicationLifetimeMonitor
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.rmapp.TestRMAppTransitions
[INFO] Tests run: 48, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.816 s - in org.apache.hadoop.yarn.server.resourcemanager.rmapp.TestRMAppTransitions
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.rmapp.TestNodesListManager
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.482 s - in org.apache.hadoop.yarn.server.resourcemanager.rmapp.TestNodesListManager
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.TestRMAppAttemptTransitions
[WARNING] Tests run: 90, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 2.761 s - in org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.TestRMAppAttemptTransitions
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.TestAMLivelinessMonitor
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.832 s - in org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.TestAMLivelinessMonitor
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.TestRMAppAttemptImplDiagnostics
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.446 s - in org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.TestRMAppAttemptImplDiagnostics
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart
[INFO] Tests run: 46, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 61.847 s - in org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.resourcetracker.TestRMNMRPCResponseId
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.572 s - in org.apache.hadoop.yarn.server.resourcemanager.resourcetracker.TestRMNMRPCResponseId
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.resourcetracker.TestNMReconnect
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.61 s - in org.apache.hadoop.yarn.server.resourcemanager.resourcetracker.TestNMReconnect
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.resourcetracker.TestNMExpiry
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.009 s - in org.apache.hadoop.yarn.server.resourcemanager.resourcetracker.TestNMExpiry
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMStoreCommands
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.491 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRMStoreCommands
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestClientRMTokens
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.554 s - in org.apache.hadoop.yarn.server.resourcemanager.TestClientRMTokens
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingUnmanagedAM
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.988 s - in org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingUnmanagedAM
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestSignalContainer
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.507 s - in org.apache.hadoop.yarn.server.resourcemanager.TestSignalContainer
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService
[INFO] Tests run: 32, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.644 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.TestRMContainerImpl
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 48.67 s - in org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.TestRMContainerImpl
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestOpportunisticContainerAllocatorAMService
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.561 s - in org.apache.hadoop.yarn.server.resourcemanager.TestOpportunisticContainerAllocatorAMService
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestAppManager
[INFO] Tests run: 23, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.73 s - in org.apache.hadoop.yarn.server.resourcemanager.TestAppManager
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestKillApplicationWithRMHA
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.635 s - in org.apache.hadoop.yarn.server.resourcemanager.TestKillApplicationWithRMHA
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestApplicationMasterService
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.848 s - in org.apache.hadoop.yarn.server.resourcemanager.TestApplicationMasterService
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRM
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.933 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRM
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.resource.TestResourceProfiles
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.473 s - in org.apache.hadoop.yarn.server.resourcemanager.resource.TestResourceProfiles
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestApplicationMasterLauncher
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.889 s - in org.apache.hadoop.yarn.server.resourcemanager.TestApplicationMasterLauncher
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService
[INFO] Tests run: 36, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.869 s - in org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.269 s - in org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMProxyUsersConf
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.976 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRMProxyUsersConf
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMAuditLogger
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.694 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRMAuditLogger
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestReservationSystemWithRMHA
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.957 s - in org.apache.hadoop.yarn.server.resourcemanager.TestReservationSystemWithRMHA
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMHAMetrics
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.835 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRMHAMetrics
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewerLifecycle
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.348 s - in org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewerLifecycle
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.security.TestRMAuthenticationFilter
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.269 s - in org.apache.hadoop.yarn.server.resourcemanager.security.TestRMAuthenticationFilter
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 42.717 s - in org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer
[INFO] Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 40.41 s - in org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.security.TestClientToAMTokens
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.88 s - in org.apache.hadoop.yarn.server.resourcemanager.security.TestClientToAMTokens
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.security.TestRMDelegationTokens
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.967 s - in org.apache.hadoop.yarn.server.resourcemanager.security.TestRMDelegationTokens
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestClientRMService
[INFO] Tests run: 33, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.27 s - in org.apache.hadoop.yarn.server.resourcemanager.TestClientRMService
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestClusterMetrics
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.354 s - in org.apache.hadoop.yarn.server.resourcemanager.TestClusterMetrics
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart
[INFO] Tests run: 62, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 114.128 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.placement.TestUserGroupMappingPlacementRule
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.368 s - in org.apache.hadoop.yarn.server.resourcemanager.placement.TestUserGroupMappingPlacementRule
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions
[INFO] Tests run: 35, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.849 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestNodeBlacklistingOnAMFailures
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.094 s - in org.apache.hadoop.yarn.server.resourcemanager.TestNodeBlacklistingOnAMFailures
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStorePerf
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 77.595 s - in org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStorePerf
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.359 s - in org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.recovery.TestRMStateStoreUtils
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.187 s - in org.apache.hadoop.yarn.server.resourcemanager.recovery.TestRMStateStoreUtils
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.recovery.TestProtos
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.117 s - in org.apache.hadoop.yarn.server.resourcemanager.recovery.TestProtos
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.recovery.TestMemoryRMStateStore
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.353 s - in org.apache.hadoop.yarn.server.resourcemanager.recovery.TestMemoryRMStateStore
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.308 s - in org.apache.hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStoreZKClientConnections
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.935 s - in org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStoreZKClientConnections
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStore
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.526 s - in org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStore
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestLeaderElectorService
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.109 s - in org.apache.hadoop.yarn.server.resourcemanager.TestLeaderElectorService
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.nodelabels.TestRMDelegatedNodeLabelsUpdater
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.013 s - in org.apache.hadoop.yarn.server.resourcemanager.nodelabels.TestRMDelegatedNodeLabelsUpdater
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.nodelabels.TestRMNodeLabelsManager
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.43 s - in org.apache.hadoop.yarn.server.resourcemanager.nodelabels.TestRMNodeLabelsManager
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCNodeUpdates
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.337 s - in org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCNodeUpdates
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRestart
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 316.056 s - in org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRestart
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCResponseId
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.211 s - in org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCResponseId
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestSchedulerApplicationAttempt
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.638 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestSchedulerApplicationAttempt
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.policy.TestFairOrderingPolicy
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.135 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.policy.TestFairOrderingPolicy
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.policy.TestFifoOrderingPolicyForPendingApps
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.263 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.policy.TestFifoOrderingPolicyForPendingApps
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.policy.TestFifoOrderingPolicy
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.261 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.policy.TestFifoOrderingPolicy
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestQueueMetrics
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.471 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestQueueMetrics
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestClusterNodeTracker
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.304 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestClusterNodeTracker
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestSchedulerUtils
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.635 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestSchedulerUtils
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestAbstractYarnScheduler
[INFO] Tests run: 24, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 57.356 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestAbstractYarnScheduler
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.TestFifoScheduler
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.54 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.TestFifoScheduler
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestConfigurationMutationACLPolicies
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.518 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestConfigurationMutationACLPolicies
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestResourceUsage
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.235 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestResourceUsage
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerNodeLabelUpdate
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.545 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerNodeLabelUpdate
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimitsByPartition
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.585 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimitsByPartition
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestNodeLabelContainerAllocation
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 247.168 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestNodeLabelContainerAllocation
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestInMemoryConfigurationStore
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.194 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestInMemoryConfigurationStore
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.31 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestZKConfigurationStore
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 50.494 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestZKConfigurationStore
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestMutableCSConfigurationProvider
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.547 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestMutableCSConfigurationProvider
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.policy.TestPriorityUtilizationQueueOrderingPolicy
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.435 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.policy.TestPriorityUtilizationQueueOrderingPolicy
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueCapacities
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.126 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueCapacities
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerPerf
[WARNING] Tests run: 4, Failures: 0, Errors: 0, Skipped: 4, Time elapsed: 0.115 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerPerf
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestLeafQueue
[INFO] Tests run: 36, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.498 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestLeafQueue
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerAutoQueueCreation
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.408 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerAutoQueueCreation
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueMappings
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.951 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueMappings
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestWorkPreservingRMRestartForNodeLabel
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.118 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestWorkPreservingRMRestartForNodeLabel
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerAutoCreatedQueuePreemption
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.156 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerAutoCreatedQueuePreemption
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationPriority
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.672 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationPriority
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestChildQueueOrder
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.185 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestChildQueueOrder
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationPriorityACLConfiguration
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.268 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationPriorityACLConfiguration
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.202 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerAllocation
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.289 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerAllocation
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestAbsoluteResourceConfiguration
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.618 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestAbsoluteResourceConfiguration
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueParsing
[INFO] Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.905 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueParsing
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestParentQueue
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.748 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestParentQueue
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestSchedulingRequestContainerAllocationAsync
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.906 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestSchedulingRequestContainerAllocationAsync
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerLazyPreemption
[WARNING] Tests run: 6, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 2.191 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerLazyPreemption
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerWithMultiResourceTypes
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.906 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerWithMultiResourceTypes
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerDynamicBehavior
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.499 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerDynamicBehavior
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestSchedulingRequestContainerAllocation
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.229 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestSchedulingRequestContainerAllocation
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestGuaranteedOrZeroCapacityOverTimePolicy
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.107 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestGuaranteedOrZeroCapacityOverTimePolicy
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationPriorityACLs
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.634 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationPriorityACLs
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.586 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerAsyncScheduling
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.267 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerAsyncScheduling
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueStateManager
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.723 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueStateManager
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerQueueACLs
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.935 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerQueueACLs
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestReservations
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.819 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestReservations
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueState
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.6 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueState
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerSurgicalPreemption
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.919 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerSurgicalPreemption
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacityScheduler
[INFO] Tests run: 64, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 66.519 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacityScheduler
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestReservationQueue
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.624 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestReservationQueue
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 50.868 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.258 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerSchedulingRequestUpdate
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.364 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerSchedulingRequestUpdate
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.TestNodeQueueLoadMonitor
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.334 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.distributed.TestNodeQueueLoadMonitor
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TestPlacementProcessor
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 38.886 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TestPlacementProcessor
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TestBatchedRequestsIterators
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.295 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TestBatchedRequestsIterators
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TestAllocationTagsNamespace
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.207 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TestAllocationTagsNamespace
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.algorithm.TestCircularIterator
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.036 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.algorithm.TestCircularIterator
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.algorithm.TestLocalAllocationTagsManager
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.853 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.algorithm.TestLocalAllocationTagsManager
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TestAllocationTagsManager
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.111 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TestAllocationTagsManager
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TestPlacementConstraintManagerService
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.238 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TestPlacementConstraintManagerService
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TestPlacementConstraintsUtil
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.497 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.TestPlacementConstraintsUtil
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.TestSingleConstraintAppPlacementAllocator
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.637 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.TestSingleConstraintAppPlacementAllocator
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestSchedulingWithAllocationRequestId
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.029 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestSchedulingWithAllocationRequestId
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestSchedulerHealth
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.185 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestSchedulerHealth
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSAppStarvation
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.674 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSAppStarvation
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestContinuousScheduling
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.355 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestContinuousScheduling
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestComputeFairShares
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.289 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestComputeFairShares
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSLeafQueue
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.347 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSLeafQueue
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestConfigurableResource
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.235 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestConfigurableResource
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestSchedulingUpdate
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.814 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestSchedulingUpdate
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerPreemption
[INFO] Tests run: 32, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.418 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerPreemption
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestVisitedResourceRequestTracker
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.317 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestVisitedResourceRequestTracker
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerFairShare
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.059 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerFairShare
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSSchedulerNode
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.54 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSSchedulerNode
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.TestDominantResourceFairnessPolicy
[INFO] Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.496 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.TestDominantResourceFairnessPolicy
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.TestEmptyQueues
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.258 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.TestEmptyQueues
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestQueueManager
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.68 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestQueueManager
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerUtilities
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.042 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerUtilities
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestMaxRunningAppsEnforcer
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.668 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestMaxRunningAppsEnforcer
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestSchedulingPolicy
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.545 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestSchedulingPolicy
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerConfiguration
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.387 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerConfiguration
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAppRunnability
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.908 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAppRunnability
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSAppAttempt
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.232 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSAppAttempt
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestQueueManagerRealScheduler
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.034 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestQueueManagerRealScheduler
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerQueueACLs
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.085 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerQueueACLs
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSQueueMetrics
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.224 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSQueueMetrics
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler
[INFO] Tests run: 100, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.353 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.325 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSParentQueue
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.5 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSParentQueue
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestQueuePlacementPolicy
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.339 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestQueuePlacementPolicy
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestAppSchedulingInfo
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.417 s - in org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestAppSchedulingInfo
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestApplicationCleanup
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.749 s - in org.apache.hadoop.yarn.server.resourcemanager.TestApplicationCleanup
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMTimelineService
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.353 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRMTimelineService
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMHATimelineCollectors
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.752 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRMHATimelineCollectors
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.logaggregationstatus.TestRMAppLogAggregationStatus
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.163 s - in org.apache.hadoop.yarn.server.resourcemanager.logaggregationstatus.TestRMAppLogAggregationStatus
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestCapacitySchedulerMetrics
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.345 s - in org.apache.hadoop.yarn.server.resourcemanager.TestCapacitySchedulerMetrics
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.federation.TestFederationRMStateStoreService
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.497 s - in org.apache.hadoop.yarn.server.resourcemanager.federation.TestFederationRMStateStoreService
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.metrics.TestSystemMetricsPublisherForV2
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.843 s - in org.apache.hadoop.yarn.server.resourcemanager.metrics.TestSystemMetricsPublisherForV2
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.metrics.TestCombinedSystemMetricsPublisher
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.481 s - in org.apache.hadoop.yarn.server.resourcemanager.metrics.TestCombinedSystemMetricsPublisher
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.metrics.TestSystemMetricsPublisher
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.768 s - in org.apache.hadoop.yarn.server.resourcemanager.metrics.TestSystemMetricsPublisher
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMDispatcher
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.414 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRMDispatcher
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMEmbeddedElector
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.326 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRMEmbeddedElector
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestRMHA
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.093 s - in org.apache.hadoop.yarn.server.resourcemanager.TestRMHA
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestTokenClientRMService
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.634 s - in org.apache.hadoop.yarn.server.resourcemanager.TestTokenClientRMService
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.TestApplicationACLs
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.766 s - in org.apache.hadoop.yarn.server.resourcemanager.TestApplicationACLs
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.reservation.TestInMemoryPlan
[INFO] Tests run: 28, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.609 s - in org.apache.hadoop.yarn.server.resourcemanager.reservation.TestInMemoryPlan
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.reservation.TestFairSchedulerPlanFollower
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.106 s - in org.apache.hadoop.yarn.server.resourcemanager.reservation.TestFairSchedulerPlanFollower
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.TestReservationAgents
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 45.696 s - in org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.TestReservationAgents
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.TestAlignedPlanner
[INFO] Tests run: 51, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.426 s - in org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.TestAlignedPlanner
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.TestGreedyReservationAgent
[INFO] Tests run: 60, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.754 s - in org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.TestGreedyReservationAgent
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.TestSimpleCapacityReplanner
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.495 s - in org.apache.hadoop.yarn.server.resourcemanager.reservation.planning.TestSimpleCapacityReplanner
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.reservation.TestNoOverCommitPolicy
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.555 s - in org.apache.hadoop.yarn.server.resourcemanager.reservation.TestNoOverCommitPolicy
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.reservation.TestPeriodicRLESparseResourceAllocation
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.27 s - in org.apache.hadoop.yarn.server.resourcemanager.reservation.TestPeriodicRLESparseResourceAllocation
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.reservation.TestInMemoryReservationAllocation
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.305 s - in org.apache.hadoop.yarn.server.resourcemanager.reservation.TestInMemoryReservationAllocation
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.reservation.TestReservationSystemUtil
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.374 s - in org.apache.hadoop.yarn.server.resourcemanager.reservation.TestReservationSystemUtil
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.reservation.TestCapacityOverTimePolicy
[INFO] Tests run: 30, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.953 s - in org.apache.hadoop.yarn.server.resourcemanager.reservation.TestCapacityOverTimePolicy
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.reservation.TestReservationInputValidator
[INFO] Tests run: 35, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.499 s - in org.apache.hadoop.yarn.server.resourcemanager.reservation.TestReservationInputValidator
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.reservation.TestReservationSystem
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.291 s - in org.apache.hadoop.yarn.server.resourcemanager.reservation.TestReservationSystem
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.reservation.TestCapacitySchedulerPlanFollower
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.127 s - in org.apache.hadoop.yarn.server.resourcemanager.reservation.TestCapacitySchedulerPlanFollower
[INFO] Running org.apache.hadoop.yarn.server.resourcemanager.reservation.TestRLESparseResourceAllocation
[WARNING] Tests run: 15, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.314 s - in org.apache.hadoop.yarn.server.resourcemanager.reservation.TestRLESparseResourceAllocation
[INFO] 
[INFO] Results:
[INFO] 
[WARNING] Tests run: 2323, Failures: 0, Errors: 0, Skipped: 7
[INFO] 
[INFO] 
[INFO] -------------< org.apache.hadoop:hadoop-yarn-server-tests >-------------
[INFO] Building Apache Hadoop YARN Server Tests 3.1.1-TDP-0.1.0-SNAPSHOT [33/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-tests ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-tests ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-tests ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-server-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-server-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:test-protoc (compile-test-protoc) @ hadoop-yarn-server-tests ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-server-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-server-tests ---
[INFO] Compiling 14 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/target/test-classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestMiniYarnCluster.java:[46,8] [deprecation] MiniYARNCluster(String,int,int,int,int,boolean) in MiniYARNCluster has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestMiniYarnCluster.java:[65,8] [deprecation] MiniYARNCluster(String,int,int,int,int,boolean) in MiniYARNCluster has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestMiniYarnCluster.java:[94,8] [deprecation] MiniYARNCluster(String,int,int,int,int,boolean) in MiniYARNCluster has been deprecated
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-yarn-server-tests ---
[INFO] Building jar: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/target/hadoop-yarn-server-tests-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-server-tests ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.server.TestRMNMSecretKeys
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.221 s - in org.apache.hadoop.yarn.server.TestRMNMSecretKeys
[INFO] Running org.apache.hadoop.yarn.server.TestMiniYARNClusterForHA
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.977 s - in org.apache.hadoop.yarn.server.TestMiniYARNClusterForHA
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.TestTimelineServiceClientIntegration
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.147 s - in org.apache.hadoop.yarn.server.timelineservice.TestTimelineServiceClientIntegration
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.security.TestTimelineAuthFilterForV2
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.626 s - in org.apache.hadoop.yarn.server.timelineservice.security.TestTimelineAuthFilterForV2
[INFO] Running org.apache.hadoop.yarn.server.TestMiniYarnCluster
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.318 s - in org.apache.hadoop.yarn.server.TestMiniYarnCluster
[INFO] Running org.apache.hadoop.yarn.server.TestContainerManagerSecurity
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 44.858 s - in org.apache.hadoop.yarn.server.TestContainerManagerSecurity
[INFO] Running org.apache.hadoop.yarn.server.TestMiniYarnClusterNodeUtilization
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 43.117 s - in org.apache.hadoop.yarn.server.TestMiniYarnClusterNodeUtilization
[INFO] Running org.apache.hadoop.yarn.server.TestDiskFailures
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.242 s - in org.apache.hadoop.yarn.server.TestDiskFailures
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-yarn-client >----------------
[INFO] Building Apache Hadoop YARN Client 3.1.1-TDP-0.1.0-SNAPSHOT      [34/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-client ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-client ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:protoc (compile-protoc) @ hadoop-yarn-client ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-client ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-client ---
[INFO] Compiling 37 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 6 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-client ---
[INFO] Compiling 36 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/target/test-classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/ProtocolHATestBase.java:[310,6] [deprecation] MiniYARNCluster(String,int,int,int,int,boolean) in MiniYARNCluster has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/api/impl/TestAMRMClientPlacementConstraints.java:[121,41] [unchecked] unchecked call to registerApplicationMaster(String,int,String,Map<Set<String>,PlacementConstraint>) as a member of the raw type AMRMClientAsync
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/api/impl/TestAMRMClientPlacementConstraints.java:[128,37] [unchecked] unchecked call to addSchedulingRequests(Collection<SchedulingRequest>) as a member of the raw type AMRMClientAsync
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-client ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.client.TestYarnApiClasses
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.244 s - in org.apache.hadoop.yarn.client.TestYarnApiClasses
[INFO] Running org.apache.hadoop.yarn.client.TestFederationRMFailoverProxyProvider
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.3 s - in org.apache.hadoop.yarn.client.TestFederationRMFailoverProxyProvider
[INFO] Running org.apache.hadoop.yarn.client.util.TestYarnClientUtils
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.352 s - in org.apache.hadoop.yarn.client.util.TestYarnClientUtils
[INFO] Running org.apache.hadoop.yarn.client.TestGetGroups
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.245 s - in org.apache.hadoop.yarn.client.TestGetGroups
[INFO] Running org.apache.hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.198 s - in org.apache.hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints
[INFO] Running org.apache.hadoop.yarn.client.api.impl.TestAMRMClientContainerRequest
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.308 s - in org.apache.hadoop.yarn.client.api.impl.TestAMRMClientContainerRequest
[INFO] Running org.apache.hadoop.yarn.client.api.impl.TestAMRMProxy
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 84.136 s - in org.apache.hadoop.yarn.client.api.impl.TestAMRMProxy
[INFO] Running org.apache.hadoop.yarn.client.api.impl.TestOpportunisticContainerAllocationE2E
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.2 s - in org.apache.hadoop.yarn.client.api.impl.TestOpportunisticContainerAllocationE2E
[INFO] Running org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.833 s - in org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation
[INFO] Running org.apache.hadoop.yarn.client.api.impl.TestNMClient
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 93.757 s - in org.apache.hadoop.yarn.client.api.impl.TestNMClient
[INFO] Running org.apache.hadoop.yarn.client.api.impl.TestAHSClient
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.551 s - in org.apache.hadoop.yarn.client.api.impl.TestAHSClient
[INFO] Running org.apache.hadoop.yarn.client.api.impl.TestAMRMClientOnRMRestart
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.095 s - in org.apache.hadoop.yarn.client.api.impl.TestAMRMClientOnRMRestart
[INFO] Running org.apache.hadoop.yarn.client.api.impl.TestSharedCacheClientImpl
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.477 s - in org.apache.hadoop.yarn.client.api.impl.TestSharedCacheClientImpl
[INFO] Running org.apache.hadoop.yarn.client.api.impl.TestAMRMClient
[WARNING] Tests run: 57, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 409.344 s - in org.apache.hadoop.yarn.client.api.impl.TestAMRMClient
[INFO] Running org.apache.hadoop.yarn.client.api.impl.TestYarnClient
[INFO] Tests run: 46, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.309 s - in org.apache.hadoop.yarn.client.api.impl.TestYarnClient
[INFO] Running org.apache.hadoop.yarn.client.api.async.impl.TestNMClientAsync
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.508 s - in org.apache.hadoop.yarn.client.api.async.impl.TestNMClientAsync
[INFO] Running org.apache.hadoop.yarn.client.api.async.impl.TestAMRMClientAsync
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.686 s - in org.apache.hadoop.yarn.client.api.async.impl.TestAMRMClientAsync
[INFO] Running org.apache.hadoop.yarn.client.cli.TestYarnCLI
[INFO] Tests run: 36, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.492 s - in org.apache.hadoop.yarn.client.cli.TestYarnCLI
[INFO] Running org.apache.hadoop.yarn.client.cli.TestRMAdminCLI
[INFO] Tests run: 40, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.563 s - in org.apache.hadoop.yarn.client.cli.TestRMAdminCLI
[INFO] Running org.apache.hadoop.yarn.client.cli.TestTopCLI
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.529 s - in org.apache.hadoop.yarn.client.cli.TestTopCLI
[INFO] Running org.apache.hadoop.yarn.client.cli.TestLogsCLI
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.948 s - in org.apache.hadoop.yarn.client.cli.TestLogsCLI
[INFO] Running org.apache.hadoop.yarn.client.cli.TestSchedConfCLI
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.141 s - in org.apache.hadoop.yarn.client.cli.TestSchedConfCLI
[INFO] Running org.apache.hadoop.yarn.client.cli.TestClusterCLI
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.661 s - in org.apache.hadoop.yarn.client.cli.TestClusterCLI
[INFO] Running org.apache.hadoop.yarn.client.TestRMFailover
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.234 s - in org.apache.hadoop.yarn.client.TestRMFailover
[INFO] Running org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 488.403 s - in org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA
[INFO] Running org.apache.hadoop.yarn.client.TestApplicationMasterServiceProtocolOnHA
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.898 s - in org.apache.hadoop.yarn.client.TestApplicationMasterServiceProtocolOnHA
[INFO] Running org.apache.hadoop.yarn.client.TestResourceTrackerOnHA
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.608 s - in org.apache.hadoop.yarn.client.TestResourceTrackerOnHA
[INFO] Running org.apache.hadoop.yarn.client.TestHedgingRequestRMFailoverProxyProvider
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.501 s - in org.apache.hadoop.yarn.client.TestHedgingRequestRMFailoverProxyProvider
[INFO] Running org.apache.hadoop.yarn.client.TestResourceManagerAdministrationProtocolPBClientImpl
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.289 s - in org.apache.hadoop.yarn.client.TestResourceManagerAdministrationProtocolPBClientImpl
[INFO] Running org.apache.hadoop.yarn.client.TestApplicationMasterServiceProtocolForTimelineV2
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.143 s - in org.apache.hadoop.yarn.client.TestApplicationMasterServiceProtocolForTimelineV2
[INFO] 
[INFO] Results:
[INFO] 
[WARNING] Tests run: 317, Failures: 0, Errors: 0, Skipped: 1
[INFO] 
[INFO] 
[INFO] ------< org.apache.hadoop:hadoop-yarn-server-sharedcachemanager >-------
[INFO] Building Apache Hadoop YARN SharedCacheManager 3.1.1-TDP-0.1.0-SNAPSHOT [35/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-sharedcachemanager ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-sharedcachemanager/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-sharedcachemanager (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-sharedcachemanager ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-sharedcachemanager/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-sharedcachemanager ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-server-sharedcachemanager ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-sharedcachemanager/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-server-sharedcachemanager ---
[INFO] Compiling 19 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-sharedcachemanager/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-server-sharedcachemanager ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-sharedcachemanager/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-server-sharedcachemanager ---
[INFO] Compiling 9 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-sharedcachemanager/target/test-classes
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-yarn-server-sharedcachemanager ---
[INFO] Building jar: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-sharedcachemanager/target/hadoop-yarn-server-sharedcachemanager-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-server-sharedcachemanager ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.server.sharedcachemanager.TestClientSCMProtocolService
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.713 s - in org.apache.hadoop.yarn.server.sharedcachemanager.TestClientSCMProtocolService
[INFO] Running org.apache.hadoop.yarn.server.sharedcachemanager.TestSharedCacheUploaderService
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.083 s - in org.apache.hadoop.yarn.server.sharedcachemanager.TestSharedCacheUploaderService
[INFO] Running org.apache.hadoop.yarn.server.sharedcachemanager.TestSCMAdminProtocolService
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.79 s - in org.apache.hadoop.yarn.server.sharedcachemanager.TestSCMAdminProtocolService
[INFO] Running org.apache.hadoop.yarn.server.sharedcachemanager.store.TestInMemorySCMStore
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.552 s - in org.apache.hadoop.yarn.server.sharedcachemanager.store.TestInMemorySCMStore
[INFO] Running org.apache.hadoop.yarn.server.sharedcachemanager.TestRemoteAppChecker
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.36 s - in org.apache.hadoop.yarn.server.sharedcachemanager.TestRemoteAppChecker
[INFO] Running org.apache.hadoop.yarn.server.sharedcachemanager.metrics.TestCleanerMetrics
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.149 s - in org.apache.hadoop.yarn.server.sharedcachemanager.metrics.TestCleanerMetrics
[INFO] Running org.apache.hadoop.yarn.server.sharedcachemanager.TestCleanerTask
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.357 s - in org.apache.hadoop.yarn.server.sharedcachemanager.TestCleanerTask
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 29, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ----< org.apache.hadoop:hadoop-yarn-server-timeline-pluginstorage >-----
[INFO] Building Apache Hadoop YARN Timeline Plugin Storage 3.1.1-TDP-0.1.0-SNAPSHOT [36/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-timeline-pluginstorage ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-timeline-pluginstorage ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-timeline-pluginstorage ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-server-timeline-pluginstorage ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-server-timeline-pluginstorage ---
[INFO] Compiling 7 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-server-timeline-pluginstorage ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-server-timeline-pluginstorage ---
[INFO] Compiling 6 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/test-classes
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-yarn-server-timeline-pluginstorage ---
[INFO] Building jar: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/hadoop-yarn-server-timeline-pluginstorage-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-server-timeline-pluginstorage ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.server.timeline.TestOverrideTimelineStoreYarnClient
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.674 s - in org.apache.hadoop.yarn.server.timeline.TestOverrideTimelineStoreYarnClient
[INFO] Running org.apache.hadoop.yarn.server.timeline.TestLogInfo
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.904 s - in org.apache.hadoop.yarn.server.timeline.TestLogInfo
[INFO] Running org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 74.166 s - in org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore
[INFO] Running org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.025 s - in org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -----< org.apache.hadoop:hadoop-yarn-server-timelineservice-hbase >-----
[INFO] Building Apache Hadoop YARN TimelineService HBase Backend 3.1.1-TDP-0.1.0-SNAPSHOT [37/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-timelineservice-hbase ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-timelineservice-hbase ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-timelineservice-hbase ---
[INFO] 
[INFO] --< org.apache.hadoop:hadoop-yarn-server-timelineservice-hbase-common >--
[INFO] Building Apache Hadoop YARN TimelineService HBase Common 3.1.1-TDP-0.1.0-SNAPSHOT [38/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-timelineservice-hbase-common ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-common/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-common (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-timelineservice-hbase-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-common/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-timelineservice-hbase-common ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-server-timelineservice-hbase-common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-common/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-server-timelineservice-hbase-common ---
[INFO] Compiling 65 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-common/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-server-timelineservice-hbase-common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-common/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-server-timelineservice-hbase-common ---
[INFO] Compiling 5 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-common/target/test-classes
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-yarn-server-timelineservice-hbase-common ---
[INFO] Building jar: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-common/target/hadoop-yarn-server-timelineservice-hbase-common-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-server-timelineservice-hbase-common ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.storage.common.TestKeyConverters
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.22 s - in org.apache.hadoop.yarn.server.timelineservice.storage.common.TestKeyConverters
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.storage.common.TestCustomApplicationIdConversion
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.188 s - in org.apache.hadoop.yarn.server.timelineservice.storage.common.TestCustomApplicationIdConversion
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.storage.common.TestRowKeysAsString
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.206 s - in org.apache.hadoop.yarn.server.timelineservice.storage.common.TestRowKeysAsString
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.storage.common.TestRowKeys
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.246 s - in org.apache.hadoop.yarn.server.timelineservice.storage.common.TestRowKeys
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.storage.common.TestSeparator
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.128 s - in org.apache.hadoop.yarn.server.timelineservice.storage.common.TestSeparator
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 21, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] --< org.apache.hadoop:hadoop-yarn-server-timelineservice-hbase-client >--
[INFO] Building Apache Hadoop YARN TimelineService HBase Client 3.1.1-TDP-0.1.0-SNAPSHOT [39/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-timelineservice-hbase-client ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-timelineservice-hbase-client ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-timelineservice-hbase-client ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-server-timelineservice-hbase-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-server-timelineservice-hbase-client ---
[INFO] Compiling 33 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-server-timelineservice-hbase-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-server-timelineservice-hbase-client ---
[INFO] Compiling 1 source file to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/target/test-classes
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-yarn-server-timelineservice-hbase-client ---
[INFO] Building jar: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/target/hadoop-yarn-server-timelineservice-hbase-client-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-server-timelineservice-hbase-client ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.storage.common.TestHBaseTimelineStorageUtils
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.104 s - in org.apache.hadoop.yarn.server.timelineservice.storage.common.TestHBaseTimelineStorageUtils
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] --< org.apache.hadoop:hadoop-yarn-server-timelineservice-hbase-server >--
[INFO] Building Apache Hadoop YARN TimelineService HBase Servers 3.1.1-TDP-0.1.0-SNAPSHOT [40/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-timelineservice-hbase-server ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-timelineservice-hbase-server ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-timelineservice-hbase-server ---
[INFO] 
[INFO] --< org.apache.hadoop:hadoop-yarn-server-timelineservice-hbase-server-1 >--
[INFO] Building Apache Hadoop YARN TimelineService HBase Server 1.2 3.1.1-TDP-0.1.0-SNAPSHOT [41/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-timelineservice-hbase-server-1 ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-1/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-1 (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-timelineservice-hbase-server-1 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-1/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-timelineservice-hbase-server-1 ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-server-timelineservice-hbase-server-1 ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-1/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-server-timelineservice-hbase-server-1 ---
[INFO] Compiling 7 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-1/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-server-timelineservice-hbase-server-1 ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-1/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-server-timelineservice-hbase-server-1 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-server-timelineservice-hbase-server-1 ---
[INFO] 
[INFO] --< org.apache.hadoop:hadoop-yarn-server-timelineservice-hbase-tests >--
[INFO] Building Apache Hadoop YARN TimelineService HBase tests 3.1.1-TDP-0.1.0-SNAPSHOT [42/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-timelineservice-hbase-tests ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase-tests/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase-tests (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-timelineservice-hbase-tests ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase-tests/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-timelineservice-hbase-tests ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-server-timelineservice-hbase-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase-tests/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-server-timelineservice-hbase-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-server-timelineservice-hbase-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-server-timelineservice-hbase-tests ---
[INFO] Compiling 11 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase-tests/target/test-classes
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-yarn-server-timelineservice-hbase-tests ---
[INFO] Building jar: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase-tests/target/hadoop-yarn-server-timelineservice-hbase-tests-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-server-timelineservice-hbase-tests ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.587 s - in org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.storage.TestTimelineReaderHBaseDown
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 226.074 s - in org.apache.hadoop.yarn.server.timelineservice.storage.TestTimelineReaderHBaseDown
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 42.428 s - in org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.593 s - in org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.593 s - in org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.644 s - in org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 54.591 s - in org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun
[INFO] Running org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage
[INFO] Tests run: 33, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.579 s - in org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 101, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ------------< org.apache.hadoop:hadoop-yarn-server-router >-------------
[INFO] Building Apache Hadoop YARN Router 3.1.1-TDP-0.1.0-SNAPSHOT      [43/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-server-router ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-server-router ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-server-router ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-server-router ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-server-router ---
[INFO] Compiling 35 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-server-router ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-server-router ---
[INFO] Compiling 23 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-server-router ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.server.router.webapp.TestRouterWebServiceUtil
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.21 s - in org.apache.hadoop.yarn.server.router.webapp.TestRouterWebServiceUtil
[INFO] Running org.apache.hadoop.yarn.server.router.webapp.TestFederationInterceptorREST
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.824 s - in org.apache.hadoop.yarn.server.router.webapp.TestFederationInterceptorREST
[INFO] Running org.apache.hadoop.yarn.server.router.webapp.TestRouterWebServicesREST
[WARNING] Corrupted STDOUT by directly writing to native stream in forked JVM 3. See FAQ web page and the dump file /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/target/surefire-reports/2023-08-16T17-56-12_178-jvmRun3.dumpstream
[INFO] Tests run: 41, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 29.288 s - in org.apache.hadoop.yarn.server.router.webapp.TestRouterWebServicesREST
[WARNING] ForkStarter IOException: 002 INFO  [main] resourcemanager.ResourceManager (LogAdapter.java:info(49)) - STARTUP_MSG: 
013 INFO  [main] resourcemanager.ResourceManager (LogAdapter.java:info(49)) - registered UNIX signal handlers for [TERM, HUP, INT]
157 INFO  [main] conf.Configuration (Configuration.java:getConfResourceAsInputStream(2756)) - found resource core-site.xml at file:/tdp/hadoop/hadoop-common-project/hadoop-common/target/test-classes/core-site.xml
242 INFO  [main] conf.Configuration (Configuration.java:getConfResourceAsInputStream(2753)) - resource-types.xml not found
243 INFO  [main] resource.ResourceUtils (ResourceUtils.java:addResourcesFileToConf(418)) - Unable to find 'resource-types.xml'.
280 INFO  [main] conf.Configuration (Configuration.java:getConfResourceAsInputStream(2756)) - found resource yarn-site.xml at file:/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/target/test-classes/yarn-site.xml
345 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
373 INFO  [main] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:<init>(75)) - NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
376 INFO  [main] security.RMContainerTokenSecretManager (RMContainerTokenSecretManager.java:<init>(81)) - ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
379 INFO  [main] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:<init>(94)) - AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
407 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
410 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
410 INFO  [main] resourcemanager.ResourceManager (ResourceManager.java:createScheduler(432)) - Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
436 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.event.EventDispatcher
436 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
437 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
439 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
517 INFO  [main] beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
545 INFO  [main] impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
599 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
599 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - ResourceManager metrics system started
607 INFO  [main] resourcemanager.ResourceManager (ResourceManager.java:createReservationSystem(455)) - Using ReservationSystem: org.apache.hadoop.yarn.server.resourcemanager.reservation.CapacityReservationSystem
608 INFO  [main] resourcemanager.ResourceManager (ResourceManager.java:serviceInit(755)) - Initialized Reservation system
613 INFO  [main] security.YarnAuthorizationProvider (YarnAuthorizationProvider.java:getInstance(58)) - org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instantiated.
615 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
620 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
622 INFO  [main] resourcemanager.RMNMInfo (RMNMInfo.java:<init>(63)) - Registered RMNMInfo MBean
622 INFO  [main] monitor.RMAppLifetimeMonitor (RMAppLifetimeMonitor.java:serviceInit(66)) - Application lifelime monitor interval set to 3000 ms.
626 INFO  [main] util.HostsFileReader (HostsFileReader.java:refresh(211)) - Refreshing hosts (include/exclude) list
630 INFO  [main] conf.Configuration (Configuration.java:getConfResourceAsInputStream(2756)) - found resource capacity-scheduler.xml at file:/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/target/test-classes/capacity-scheduler.xml
638 INFO  [main] scheduler.AbstractYarnScheduler (AbstractYarnScheduler.java:getMinimumAllocation(1367)) - Minimum allocation = <memory:1024, vCores:1>
638 INFO  [main] scheduler.AbstractYarnScheduler (AbstractYarnScheduler.java:getMaximumAllocation(1379)) - Maximum allocation = <memory:8192, vCores:4>
663 INFO  [main] capacity.CapacitySchedulerConfiguration (CapacitySchedulerConfiguration.java:getMaximumAllocationPerQueue(891)) - max alloc mb per queue for root is undefined
663 INFO  [main] capacity.CapacitySchedulerConfiguration (CapacitySchedulerConfiguration.java:getMaximumAllocationPerQueue(895)) - max alloc vcore per queue for root is undefined
671 INFO  [main] capacity.ParentQueue (ParentQueue.java:setupQueueConfigs(151)) - root, capacity=1.0, absoluteCapacity=1.0, maxCapacity=1.0, absoluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
671 INFO  [main] capacity.ParentQueue (ParentQueue.java:<init>(114)) - Initialized parent-queue root name=root, fullname=root
682 INFO  [main] capacity.CapacitySchedulerConfiguration (CapacitySchedulerConfiguration.java:getMaximumAllocationPerQueue(891)) - max alloc mb per queue for root.default is undefined
682 INFO  [main] capacity.CapacitySchedulerConfiguration (CapacitySchedulerConfiguration.java:getMaximumAllocationPerQueue(895)) - max alloc vcore per queue for root.default is undefined
684 INFO  [main] capacity.LeafQueue (LeafQueue.java:setupQueueConfigs(289)) - Initializing default
684 INFO  [main] capacity.CapacitySchedulerQueueManager (CapacitySchedulerQueueManager.java:parseQueue(298)) - Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0, effectiveMinResource=<memory:0, vCores:0> , effectiveMaxResource=<memory:0, vCores:0>
685 INFO  [main] capacity.CapacitySchedulerQueueManager (CapacitySchedulerQueueManager.java:parseQueue(298)) - Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
686 INFO  [main] capacity.CapacitySchedulerQueueManager (CapacitySchedulerQueueManager.java:initializeQueues(163)) - Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
687 INFO  [main] placement.UserGroupMappingPlacementRule (UserGroupMappingPlacementRule.java:get(232)) - Initialized queue mappings, override: false
688 INFO  [main] capacity.CapacityScheduler (CapacityScheduler.java:initScheduler(392)) - Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
690 INFO  [main] conf.Configuration (Configuration.java:getConfResourceAsInputStream(2753)) - dynamic-resources.xml not found
692 INFO  [main] reservation.AbstractReservationSystem (AbstractReservationSystem.java:initialize(144)) - Initializing Reservation system
693 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for yarn.resourcemanager.reservation-system.planfollower.time-step(1000) assuming MILLISECONDS
695 INFO  [main] reservation.AbstractReservationSystem (AbstractReservationSystem.java:createPlanFollower(253)) - Using PlanFollowerPolicy: org.apache.hadoop.yarn.server.resourcemanager.reservation.CapacitySchedulerPlanFollower
696 INFO  [main] reservation.CapacitySchedulerPlanFollower (CapacitySchedulerPlanFollower.java:init(66)) - Initializing Plan Follower Policy:org.apache.hadoop.yarn.server.resourcemanager.reservation.CapacitySchedulerPlanFollower
696 INFO  [main] resourcemanager.AMSProcessingChain (AMSProcessingChain.java:init(62)) - Initializing AMS Processing chain. Root Processor=[org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor].
696 INFO  [main] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:addPlacementConstraintHandler(130)) - disabled placement handler will be used, all scheduling requests will be rejected.
697 INFO  [main] resourcemanager.AMSProcessingChain (AMSProcessingChain.java:addProcessor(75)) - Adding [org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.processor.DisabledPlacementProcessor] tp top of AMS Processing chain. 
702 INFO  [main] resourcemanager.ResourceManager (ResourceManager.java:createSystemMetricsPublisher(557)) - TimelineServicePublisher is not configured
731 INFO  [main] util.log (Log.java:initialized(192)) - Logging initialized @1077ms
788 INFO  [main] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
791 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.resourcemanager is not defined
794 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(968)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
797 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(941)) - Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
797 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(951)) - Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
798 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(941)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
798 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(951)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
799 INFO  [main] http.HttpServer2 (HttpServer2.java:initializeWebServer(595)) - adding path spec: /cluster/*
799 INFO  [main] http.HttpServer2 (HttpServer2.java:initializeWebServer(595)) - adding path spec: /ws/*
799 INFO  [main] http.HttpServer2 (HttpServer2.java:initializeWebServer(595)) - adding path spec: /app/*
102 INFO  [main] webapp.WebApps (WebApps.java:build(395)) - Registered webapp guice modules
108 INFO  [main] http.HttpServer2 (HttpServer2.java:bindListener(1185)) - Jetty bound to port 8080
110 INFO  [main] server.Server (Server.java:doStart(346)) - jetty-9.3.19.v20170502
133 INFO  [main] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
139 INFO  [main] delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(343)) - Updating the current master key for generating delegation tokens
140 INFO  [Thread[Thread-19,5,main]] delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(675)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
140 INFO  [Thread[Thread-19,5,main]] delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(343)) - Updating the current master key for generating delegation tokens
151 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@217ed35e{/static,file:///tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/,AVAILABLE}
783 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@42561fba{/,file:///tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/cluster/,AVAILABLE}{/cluster}
788 INFO  [main] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3003697{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
788 INFO  [main] server.Server (Server.java:doStart(414)) - Started @2135ms
788 INFO  [main] webapp.WebApps (WebApps.java:start(440)) - Web app cluster started at 8080
816 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
822 INFO  [Socket Reader #1 for port 8033] ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 8033
938 INFO  [main] pb.RpcServerFactoryPBImpl (RpcServerFactoryPBImpl.java:createServer(173)) - Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
939 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
939 INFO  [IPC Server listener on 8033] ipc.Server (Server.java:run(1149)) - IPC Server listener on 8033: starting
939 INFO  [main] resourcemanager.ResourceManager (ResourceManager.java:transitionToActive(1255)) - Transitioning to active state
948 INFO  [main] recovery.RMStateStore (RMStateStore.java:transition(547)) - Updating AMRMToken
949 INFO  [main] security.RMContainerTokenSecretManager (RMContainerTokenSecretManager.java:rollMasterKey(109)) - Rolling master-key for container-tokens
949 INFO  [main] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:rollMasterKey(95)) - Rolling master-key for nm-tokens
949 INFO  [main] delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(343)) - Updating the current master key for generating delegation tokens
949 INFO  [main] security.RMDelegationTokenSecretManager (RMDelegationTokenSecretManager.java:storeNewMasterKey(92)) - storing master key with keyID 1
949 INFO  [main] recovery.RMStateStore (RMStateStore.java:transition(498)) - Storing RMDTMasterKey.
950 INFO  [Thread[Thread-27,5,main]] delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(675)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
950 INFO  [Thread[Thread-27,5,main]] delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(343)) - Updating the current master key for generating delegation tokens
950 INFO  [Thread[Thread-27,5,main]] security.RMDelegationTokenSecretManager (RMDelegationTokenSecretManager.java:storeNewMasterKey(92)) - storing master key with keyID 2
950 INFO  [Thread[Thread-27,5,main]] recovery.RMStateStore (RMStateStore.java:transition(498)) - Storing RMDTMasterKey.
997 INFO  [main] nodelabels.FileSystemNodeLabelsStore (FileSystemNodeLabelsStore.java:recover(289)) - Finished write mirror at:file:/tmp/hadoop-yarn-builder/node-labels/nodelabel.mirror
997 INFO  [main] nodelabels.FileSystemNodeLabelsStore (FileSystemNodeLabelsStore.java:recover(290)) - Finished create editlog file at:file:/tmp/hadoop-yarn-builder/node-labels/nodelabel.editlog
998 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
005 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
005 INFO  [Socket Reader #1 for port 8031] ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 8031
007 INFO  [main] pb.RpcServerFactoryPBImpl (RpcServerFactoryPBImpl.java:createServer(173)) - Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
007 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
007 INFO  [IPC Server listener on 8031] ipc.Server (Server.java:run(1149)) - IPC Server listener on 8031: starting
014 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6872f9c8] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
019 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
023 INFO  [Socket Reader #1 for port 8030] ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 8030
028 INFO  [main] pb.RpcServerFactoryPBImpl (RpcServerFactoryPBImpl.java:createServer(173)) - Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
028 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
029 INFO  [IPC Server listener on 8030] ipc.Server (Server.java:run(1149)) - IPC Server listener on 8030: starting
072 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
073 INFO  [Socket Reader #1 for port 8032] ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 8032
075 INFO  [main] pb.RpcServerFactoryPBImpl (RpcServerFactoryPBImpl.java:createServer(173)) - Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
075 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
075 INFO  [IPC Server listener on 8032] ipc.Server (Server.java:run(1149)) - IPC Server listener on 8032: starting
081 INFO  [main] resourcemanager.ResourceManager (ResourceManager.java:transitionToActive(1271)) - Transitioned to active state
481 INFO  [main] router.Router (LogAdapter.java:info(51)) - STARTUP_MSG: 
489 INFO  [main] router.Router (LogAdapter.java:info(51)) - registered UNIX signal handlers for [TERM, HUP, INT]
705 INFO  [main] beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
739 INFO  [main] impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
818 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
818 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - Router metrics system started
913 INFO  [main] util.log (Log.java:initialized(192)) - Logging initialized @724ms
986 INFO  [main] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
993 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.resourcemanager is not defined
997 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(968)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
004 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(941)) - Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
004 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(951)) - Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
004 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(941)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
005 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(951)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
006 INFO  [main] http.HttpServer2 (HttpServer2.java:initializeWebServer(595)) - adding path spec: /cluster/*
006 INFO  [main] http.HttpServer2 (HttpServer2.java:initializeWebServer(595)) - adding path spec: /ws/*
309 INFO  [main] webapp.WebApps (WebApps.java:build(395)) - Registered webapp guice modules
314 INFO  [main] http.HttpServer2 (HttpServer2.java:bindListener(1185)) - Jetty bound to port 8089
315 INFO  [main] server.Server (Server.java:doStart(346)) - jetty-9.3.19.v20170502
337 INFO  [main] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
366 INFO  [main] delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(343)) - Updating the current master key for generating delegation tokens
368 INFO  [Thread[Thread-12,5,main]] delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(675)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
368 INFO  [Thread[Thread-12,5,main]] delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(343)) - Updating the current master key for generating delegation tokens
385 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@74e52303{/static,file:///tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/,AVAILABLE}
079 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@c1a4620{/,file:///tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/cluster/,AVAILABLE}{/cluster}
084 INFO  [main] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2c1dc8e{HTTP/1.1,[http/1.1]}{0.0.0.0:8089}
084 INFO  [main] server.Server (Server.java:doStart(414)) - Started @1897ms
084 INFO  [main] webapp.WebApps (WebApps.java:start(440)) - Web app cluster started at 8089
084 INFO  [main] clientrm.RouterClientRMService (RouterClientRMService.java:serviceStart(141)) - Starting Router ClientRMService
125 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
137 INFO  [Socket Reader #1 for port 8050] ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 8050
253 INFO  [main] pb.RpcServerFactoryPBImpl (RpcServerFactoryPBImpl.java:createServer(173)) - Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
253 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
253 INFO  [IPC Server listener on 8050] ipc.Server (Server.java:run(1149)) - IPC Server listener on 8050: starting
260 INFO  [main] clientrm.RouterClientRMService (RouterClientRMService.java:serviceStart(169)) - Router ClientRMService listening on address: /0.0.0.0:8050
260 INFO  [main] rmadmin.RouterRMAdminService (RouterRMAdminService.java:serviceStart(104)) - Starting Router RMAdmin Service
276 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
277 INFO  [Socket Reader #1 for port 8052] ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 8052
279 INFO  [main] pb.RpcServerFactoryPBImpl (RpcServerFactoryPBImpl.java:createServer(173)) - Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
279 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
279 INFO  [IPC Server listener on 8052] ipc.Server (Server.java:run(1149)) - IPC Server listener on 8052: starting
279 INFO  [main] rmadmin.RouterRMAdminService (RouterRMAdminService.java:serviceStart(132)) - Router RMAdminService listening on address: /0.0.0.0:8052
352 INFO  [qtp1616974404-21] webapp.RouterWebServices (RouterWebServices.java:initializePipeline(262)) - Initializing request processing pipeline for the user: builder
959 INFO  [main] nodemanager.NodeManager (LogAdapter.java:info(51)) - STARTUP_MSG: 
968 INFO  [main] nodemanager.NodeManager (LogAdapter.java:info(51)) - registered UNIX signal handlers for [TERM, HUP, INT]
325 INFO  [main] nodemanager.NodeManager (NodeManager.java:getNodeHealthScriptRunner(320)) - Node Manager health check script is not available or doesn't have execute permission, so not starting the node health script runner.
355 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
355 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
356 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
357 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
357 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
358 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
358 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
360 INFO  [main] tracker.NMLogAggregationStatusTracker (NMLogAggregationStatusTracker.java:<init>(89)) - the rolling interval seconds for the NodeManager Cached Log aggregation status is 600
373 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
374 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
447 INFO  [main] beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
474 INFO  [main] impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
527 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
528 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NodeManager metrics system started
539 INFO  [main] nodemanager.DirectoryCollection (DirectoryCollection.java:<init>(189)) - Disk Validator: yarn.nodemanager.disk-validator is loaded.
544 INFO  [main] nodemanager.DirectoryCollection (DirectoryCollection.java:<init>(189)) - Disk Validator: yarn.nodemanager.disk-validator is loaded.
562 INFO  [main] nodemanager.NodeResourceMonitorImpl (NodeResourceMonitorImpl.java:serviceInit(75)) -  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@1677d1
564 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
565 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
565 INFO  [main] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:createAMRMProxyService(335)) - AMRMProxyService is disabled
565 INFO  [main] localizer.ResourceLocalizationService (ResourceLocalizationService.java:validateConf(240)) - per directory file limit = 8192
597 INFO  [main] localizer.ResourceLocalizationService (ResourceLocalizationService.java:deleteLocalDir(1549)) - usercache path : file:/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/build/test/nm-local-dir/usercache_DEL_1692220868567
610 INFO  [main] localizer.ResourceLocalizationService (ResourceLocalizationService.java:serviceInit(269)) - Disk Validator: yarn.nodemanager.disk-validator is loaded.
614 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
615 INFO  [main] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:serviceInit(130)) -  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@59d016c9
616 INFO  [main] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:serviceInit(135)) -  Using ResourceCalculatorProcessTree : null
617 INFO  [main] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:serviceInit(176)) - Physical memory check enabled: true
617 INFO  [main] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:serviceInit(177)) - Virtual memory check enabled: true
617 INFO  [main] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:serviceInit(181)) - ContainersMonitor enabled: true
618 INFO  [main] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:recover(386)) - Not a recoverable state store. Nothing to recover.
632 INFO  [main] conf.Configuration (Configuration.java:getConfResourceAsInputStream(2753)) - resource-types.xml not found
632 INFO  [main] resource.ResourceUtils (ResourceUtils.java:addResourcesFileToConf(418)) - Unable to find 'resource-types.xml'.
636 INFO  [main] conf.Configuration (Configuration.java:getConfResourceAsInputStream(2753)) - node-resources.xml not found
637 INFO  [main] resource.ResourceUtils (ResourceUtils.java:addResourcesFileToConf(418)) - Unable to find 'node-resources.xml'.
638 INFO  [main] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:serviceInit(192)) - Nodemanager resources is set to: <memory:8192, vCores:8>
641 INFO  [main] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:serviceInit(236)) - Initialized nodemanager with : physical-memory=8192 virtual-memory=17204 virtual-cores=8
666 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 2000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
679 INFO  [Socket Reader #1 for port 41559] ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41559
822 INFO  [main] pb.RpcServerFactoryPBImpl (RpcServerFactoryPBImpl.java:createServer(173)) - Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
822 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
823 INFO  [IPC Server listener on 41559] ipc.Server (Server.java:run(1149)) - IPC Server listener on 41559: starting
828 INFO  [main] security.NMContainerTokenSecretManager (NMContainerTokenSecretManager.java:setNodeId(260)) - Updating node address : 49f255efa79a:41559
833 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 500 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
834 INFO  [Socket Reader #1 for port 8040] ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 8040
836 INFO  [main] pb.RpcServerFactoryPBImpl (RpcServerFactoryPBImpl.java:createServer(173)) - Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
836 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
836 INFO  [IPC Server listener on 8040] ipc.Server (Server.java:run(1149)) - IPC Server listener on 8040: starting
837 INFO  [main] localizer.ResourceLocalizationService (ResourceLocalizationService.java:serviceStart(386)) - Localizer started on port 8040
839 INFO  [main] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:serviceStart(658)) - ContainerManager started at 49f255efa79a/172.19.0.3:41559
839 INFO  [main] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:serviceStart(659)) - ContainerManager bound to 0.0.0.0/0.0.0.0:0
839 WARN  [main] tracker.NMLogAggregationStatusTracker (NMLogAggregationStatusTracker.java:serviceStart(96)) - Log Aggregation is disabled.So is the LogAggregationStatusTracker.
841 INFO  [main] webapp.WebServer (WebServer.java:serviceStart(99)) - Instantiating NMWebApp at 0.0.0.0:8042
860 INFO  [main] util.log (Log.java:initialized(192)) - Logging initialized @1303ms
939 INFO  [main] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
941 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.nodemanager is not defined
943 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(968)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
944 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(941)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
944 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(951)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
944 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(941)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
945 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(951)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
946 INFO  [main] http.HttpServer2 (HttpServer2.java:initializeWebServer(595)) - adding path spec: /node/*
946 INFO  [main] http.HttpServer2 (HttpServer2.java:initializeWebServer(595)) - adding path spec: /ws/*
163 INFO  [main] webapp.WebApps (WebApps.java:build(395)) - Registered webapp guice modules
165 INFO  [main] http.HttpServer2 (HttpServer2.java:bindListener(1185)) - Jetty bound to port 8042
166 INFO  [main] server.Server (Server.java:doStart(346)) - jetty-9.3.19.v20170502
186 INFO  [main] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
188 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@69e153c5{/static,file:///tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/,AVAILABLE}
744 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3569edd5{/,file:///tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/node/,AVAILABLE}{/node}
748 INFO  [main] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@19f21b6b{HTTP/1.1,[http/1.1]}{0.0.0.0:8042}
748 INFO  [main] server.Server (Server.java:doStart(414)) - Started @2193ms
748 INFO  [main] webapp.WebApps (WebApps.java:start(440)) - Web app node started at 8042
749 INFO  [main] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:serviceStart(250)) - Node ID assigned is : 49f255efa79a:41559
749 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1532c619] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
753 INFO  [main] client.RMProxy (RMProxy.java:newProxyInstance(133)) - Connecting to ResourceManager at /0.0.0.0:8031
778 INFO  [main] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:getNMContainerStatuses(641)) - Sending out 0 NM container statuses: []
784 INFO  [main] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:registerWithRM(382)) - Registering with RM using containers :[]
943 INFO  [IPC Server handler 0 on 8031] resourcemanager.ResourceTrackerService (ResourceTrackerService.java:registerNodeManager(495)) - NodeManager from node 49f255efa79a(cmPort: 41559 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId 49f255efa79a:41559
946 INFO  [RM Event dispatcher] rmnode.RMNodeImpl (RMNodeImpl.java:handle(671)) - 49f255efa79a:41559 Node Transitioned from NEW to RUNNING
954 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addNode(1865)) - Added node 49f255efa79a:41559 clusterResource: <memory:8192, vCores:8>
959 INFO  [main] security.NMContainerTokenSecretManager (NMContainerTokenSecretManager.java:setMasterKey(138)) - Rolling master-key for container-tokens, got key with id -1405857387
960 INFO  [main] security.NMTokenSecretManagerInNM (NMTokenSecretManagerInNM.java:setMasterKey(138)) - Rolling master-key for container-tokens, got key with id 861350877
960 INFO  [main] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:registerWithRM(466)) - Registered with ResourceManager as 49f255efa79a:41559 with total resource of <memory:8192, vCores:8>
015 WARN  [qtp1616974404-21] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
094 INFO  [qtp858952163-31] reservation.AbstractReservationSystem (AbstractReservationSystem.java:getNewReservationId(384)) - Allocated new reservationId: reservation_1692220864940_0001
304 INFO  [qtp1616974404-16] webapp.RouterWebServices (RouterWebServices.java:initializePipeline(262)) - Initializing request processing pipeline for the user: dr.who
393 WARN  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logFailure(500)) - USER=UNKNOWN	OPERATION=Delete Reservation Request	TARGET=ClientRMService	RESULT=FAILURE	DESCRIPTION=The specified reservation with ID: reservation_1692220864940_0001 is unknown. Please try again with a valid reservation.	PERMISSIONS=validate reservation input
720 INFO  [qtp858952163-31] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 1
892 INFO  [qtp858952163-24] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0001
901 WARN  [qtp858952163-24] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
901 INFO  [qtp858952163-24] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 1 submitted by user dr.who
902 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0001
902 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0001
909 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0001
909 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0001 State change from NEW to NEW_SAVING on event = START
910 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0001 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
911 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0001 user: dr.who leaf-queue of parent: root #applications: 1
911 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0001 from user: dr.who, in queue: default
921 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0001 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
937 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0001_000001
938 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0001_000001 State change from NEW to SUBMITTED on event = START
943 WARN  [qtp1616974404-21] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
954 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:activateApplications(911)) - Application application_1692220864940_0001 from user: dr.who activated in queue: default
955 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0001 user: dr.who, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
955 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0001_000001 to scheduler from user dr.who in queue default
959 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0001_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
032 INFO  [SchedulerEventDispatcher:Event Processor] allocator.AbstractContainerAllocator (AbstractContainerAllocator.java:getCSAssignmentFromAllocateResult(129)) - assignedContainer application attempt=appattempt_1692220864940_0001_000001 container=null queue=default clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
036 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0001_01_000001 Container Transitioned from NEW to ALLOCATED
037 INFO  [SchedulerEventDispatcher:Event Processor] fica.FiCaSchedulerNode (FiCaSchedulerNode.java:allocateContainer(169)) - Assigned container container_1692220864940_0001_01_000001 of capacity <memory:1024, vCores:1> on host 49f255efa79a:41559, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
037 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0001	CONTAINERID=container_1692220864940_0001_01_000001	RESOURCE=<memory:1024, vCores:1>
056 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:createAndGetNMToken(200)) - Sending NMToken for nodeId : 49f255efa79a:41559 for container : container_1692220864940_0001_01_000001
065 INFO  [RM Event dispatcher] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
065 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:clearNodeSetForAttempt(146)) - Clear node set for appattempt_1692220864940_0001_000001
065 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:apply(1332)) - assignedContainer queue=root usedCapacity=0.125 absoluteUsedCapacity=0.125 used=<memory:1024, vCores:1> cluster=<memory:8192, vCores:8>
065 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:storeAttempt(2193)) - Storing attempt: AppId: application_1692220864940_0001 AttemptId: appattempt_1692220864940_0001_000001 MasterContainer: Container: [ContainerId: container_1692220864940_0001_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ]
066 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:tryCommit(2853)) - Allocation proposal accepted
078 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING on event = CONTAINER_ALLOCATED
078 INFO  [RM Event dispatcher] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(298)) - USER=dr.who	OPERATION=Kill Application Request	TARGET=RMAppImpl	RESULT=SUCCESS	APPID=application_1692220864940_0001
079 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0001 State change from ACCEPTED to KILLING on event = KILL
083 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED on event = ATTEMPT_NEW_SAVED
085 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:rememberTargetTransitionsAndStoreState(1412)) - Updating application attempt appattempt_1692220864940_0001_000001 with final state: KILLED, and exit status: -1000
086 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0001_000001 State change from ALLOCATED to FINAL_SAVING on event = KILL
088 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:unregisterAttempt(496)) - Unregistering app attempt : appattempt_1692220864940_0001_000001
089 INFO  [RM Event dispatcher] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:applicationMasterFinished(124)) - Application finished, removing password for appattempt_1692220864940_0001_000001
089 INFO  [ApplicationMasterLauncher #0] amlauncher.AMLauncher (AMLauncher.java:run(307)) - Launching masterappattempt_1692220864940_0001_000001
089 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0001_000001 State change from FINAL_SAVING to KILLED on event = ATTEMPT_UPDATE_SAVED
089 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:rememberTargetTransitionsAndStoreState(1278)) - Updating application application_1692220864940_0001 with final state: KILLED
090 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0001 State change from KILLING to FINAL_SAVING on event = ATTEMPT_KILLED
090 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(260)) - Updating info for app: application_1692220864940_0001
090 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:doneApplicationAttempt(1048)) - Application Attempt appattempt_1692220864940_0001_000001 is done. finalState=KILLED
090 INFO  [ApplicationMasterLauncher #1] amlauncher.AMLauncher (AMLauncher.java:run(317)) - Cleaning master appattempt_1692220864940_0001_000001
094 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0001 State change from FINAL_SAVING to KILLED on event = APP_UPDATE_SAVED
095 INFO  [RM Event dispatcher] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(318)) - USER=dr.who	OPERATION=Application Finished - Killed	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1692220864940_0001
099 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0001_01_000001 Container Transitioned from ACQUIRED to KILLED
099 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0001	CONTAINERID=container_1692220864940_0001_01_000001	RESOURCE=<memory:1024, vCores:1>
101 INFO  [SchedulerEventDispatcher:Event Processor] scheduler.AppSchedulingInfo (AppSchedulingInfo.java:clearRequests(159)) - Application application_1692220864940_0001 requests cleared
101 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:removeApplicationAttempt(1003)) - Application removed - appId: application_1692220864940_0001 user: dr.who queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
101 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:removeApplication(522)) - Application removed - appId: application_1692220864940_0001 user: dr.who leaf-queue of parent: root #applications: 0
103 INFO  [RM Event dispatcher] resourcemanager.RMAppManager$ApplicationSummary (RMAppManager.java:logAppSummary(212)) - appId=application_1692220864940_0001,name=,user=dr.who,queue=default,state=KILLED,trackingUrl=http://49f255efa79a:8080/cluster/app/application_1692220864940_0001,appMasterHost=N/A,submitTime=1692220870866,startTime=1692220870901,finishTime=1692220871089,finalStatus=KILLED,memorySeconds=0,vcoreSeconds=0,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=,resourceSeconds=0 MB-seconds\, 0 vcore-seconds,preemptedResourceSeconds=0 MB-seconds\, 0 vcore-seconds
140 INFO  [ApplicationMasterLauncher #0] amlauncher.AMLauncher (AMLauncher.java:launch(109)) - Setting up container Container: [ContainerId: container_1692220864940_0001_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0001_000001
141 INFO  [ApplicationMasterLauncher #0] amlauncher.AMLauncher (AMLauncher.java:onAMLaunchFailed(352)) - Error launching appattempt_1692220864940_0001_000001. Got exception: java.io.IOException: container_1692220864940_0001_01_000001 has been cleaned before launched
243 INFO  [Socket Reader #1 for port 41559] ipc.Server (Server.java:saslProcess(1845)) - Auth successful for appattempt_1692220864940_0001_000001 (auth:SIMPLE)
335 INFO  [IPC Server handler 0 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:stopContainerInternal(1401)) - Stopping container with container Id: container_1692220864940_0001_01_000001
350 WARN  [qtp1616974404-21] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
445 INFO  [qtp858952163-31] reservation.AbstractReservationSystem (AbstractReservationSystem.java:getNewReservationId(384)) - Allocated new reservationId: reservation_1692220864940_0002
478 INFO  [qtp858952163-24] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 2
546 INFO  [qtp858952163-30] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0002
546 WARN  [qtp858952163-30] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 2 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
546 INFO  [qtp858952163-30] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 2 submitted by user dr.who
547 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0002
547 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0002
547 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0002 State change from NEW to NEW_SAVING on event = START
547 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0002
547 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0002 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
548 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0002 user: dr.who leaf-queue of parent: root #applications: 1
548 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0002 from user: dr.who, in queue: default
548 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0002 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
548 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0002_000001
548 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0002_000001 State change from NEW to SUBMITTED on event = START
549 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:activateApplications(911)) - Application application_1692220864940_0002 from user: dr.who activated in queue: default
549 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0002 user: dr.who, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
549 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0002_000001 to scheduler from user dr.who in queue default
550 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0002_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
679 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
726 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
793 INFO  [qtp858952163-24] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 3
852 INFO  [qtp858952163-30] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0003
852 WARN  [qtp858952163-30] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 3 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
852 INFO  [qtp858952163-30] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 3 submitted by user dr.who
853 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0003
853 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0003
853 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0003 State change from NEW to NEW_SAVING on event = START
853 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0003
854 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0003 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
854 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0003 user: dr.who leaf-queue of parent: root #applications: 2
854 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0003 from user: dr.who, in queue: default
854 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0003 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
855 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0003_000001
855 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0003_000001 State change from NEW to SUBMITTED on event = START
855 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0003 user: dr.who, leaf-queue: default #user-pending-applications: 1 #user-active-applications: 1 #queue-pending-applications: 1 #queue-active-applications: 1
855 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0003_000001 to scheduler from user dr.who in queue default
856 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0003_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
015 INFO  [SchedulerEventDispatcher:Event Processor] allocator.AbstractContainerAllocator (AbstractContainerAllocator.java:getCSAssignmentFromAllocateResult(129)) - assignedContainer application attempt=appattempt_1692220864940_0002_000001 container=null queue=default clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
015 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0002_01_000001 Container Transitioned from NEW to ALLOCATED
015 INFO  [SchedulerEventDispatcher:Event Processor] fica.FiCaSchedulerNode (FiCaSchedulerNode.java:allocateContainer(169)) - Assigned container container_1692220864940_0002_01_000001 of capacity <memory:1024, vCores:1> on host 49f255efa79a:41559, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
016 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0002	CONTAINERID=container_1692220864940_0002_01_000001	RESOURCE=<memory:1024, vCores:1>
016 WARN  [NM Event dispatcher] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:handle(1648)) - couldn't find app application_1692220864940_0001 while processing FINISH_CONTAINERS event
016 INFO  [NM Event dispatcher] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:handle(1607)) - couldn't find application application_1692220864940_0001 while processing FINISH_APPS event. The ResourceManager allocated resources for this application to the NodeManager but no active containers were found to process.
017 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:createAndGetNMToken(200)) - Sending NMToken for nodeId : 49f255efa79a:41559 for container : container_1692220864940_0002_01_000001
018 INFO  [RM Event dispatcher] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
019 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:clearNodeSetForAttempt(146)) - Clear node set for appattempt_1692220864940_0002_000001
019 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:storeAttempt(2193)) - Storing attempt: AppId: application_1692220864940_0002 AttemptId: appattempt_1692220864940_0002_000001 MasterContainer: Container: [ContainerId: container_1692220864940_0002_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ]
019 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:apply(1332)) - assignedContainer queue=root usedCapacity=0.125 absoluteUsedCapacity=0.125 used=<memory:1024, vCores:1> cluster=<memory:8192, vCores:8>
019 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:tryCommit(2853)) - Allocation proposal accepted
019 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING on event = CONTAINER_ALLOCATED
020 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED on event = ATTEMPT_NEW_SAVED
020 INFO  [ApplicationMasterLauncher #2] amlauncher.AMLauncher (AMLauncher.java:run(307)) - Launching masterappattempt_1692220864940_0002_000001
022 INFO  [ApplicationMasterLauncher #2] amlauncher.AMLauncher (AMLauncher.java:launch(109)) - Setting up container Container: [ContainerId: container_1692220864940_0002_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0002_000001
022 INFO  [ApplicationMasterLauncher #2] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createAndGetAMRMToken(195)) - Create AMRMToken for ApplicationAttempt: appattempt_1692220864940_0002_000001
025 INFO  [ApplicationMasterLauncher #2] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createPassword(307)) - Creating password for appattempt_1692220864940_0002_000001
037 INFO  [Socket Reader #1 for port 41559] ipc.Server (Server.java:saslProcess(1845)) - Auth successful for appattempt_1692220864940_0002_000001 (auth:SIMPLE)
077 INFO  [IPC Server handler 0 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1062)) - Start request for container_1692220864940_0002_01_000001 by user dr.who
115 INFO  [IPC Server handler 0 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1114)) - Creating a new application reference for app application_1692220864940_0002
124 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0002 transitioned from NEW to INITING
125 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(463)) - Adding container_1692220864940_0002_01_000001 to application application_1692220864940_0002
125 INFO  [IPC Server handler 0 on 41559] nodemanager.NMAuditLogger (NMAuditLogger.java:logSuccess(94)) - USER=dr.who	IP=172.19.0.3	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1692220864940_0002	CONTAINERID=container_1692220864940_0002_01_000001
129 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0002 transitioned from INITING to RUNNING
130 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0002_01_000001 transitioned from NEW to SCHEDULED
130 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_INIT for appId application_1692220864940_0002
132 INFO  [NM ContainerManager dispatcher] scheduler.ContainerScheduler (ContainerScheduler.java:startContainer(503)) - Starting container [container_1692220864940_0002_01_000001]
135 INFO  [ApplicationMasterLauncher #2] amlauncher.AMLauncher (AMLauncher.java:launch(130)) - Done launching container Container: [ContainerId: container_1692220864940_0002_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0002_000001
135 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0002_000001 State change from ALLOCATED to LAUNCHED on event = LAUNCHED
161 WARN  [ContainersLauncher #0] launcher.ContainerLaunch (ContainerLaunch.java:call(331)) - Failed to launch container.
168 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0002_01_000001 transitioned from SCHEDULED to EXITED_WITH_FAILURE
168 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(734)) - Cleaning up container container_1692220864940_0002_01_000001
168 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(747)) - Container container_1692220864940_0002_01_000001 not launched. No cleanup needed to be done
169 WARN  [NM ContainerManager dispatcher] nodemanager.NMAuditLogger (NMAuditLogger.java:logFailure(155)) - USER=dr.who	OPERATION=Container Finished - Failed	TARGET=ContainerImpl	RESULT=FAILURE	DESCRIPTION=Container failed with state: EXITED_WITH_FAILURE	APPID=application_1692220864940_0002	CONTAINERID=container_1692220864940_0002_01_000001
173 INFO  [qtp858952163-31] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 4
176 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0002_01_000001 transitioned from EXITED_WITH_FAILURE to DONE
176 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(512)) - Removing container_1692220864940_0002_01_000001 from application application_1692220864940_0002
177 INFO  [NM ContainerManager dispatcher] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:onStopMonitoringContainer(932)) - Stopping resource-monitoring for container_1692220864940_0002_01_000001
177 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_STOP for appId application_1692220864940_0002
180 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0002_01_000001 Container Transitioned from ACQUIRED to COMPLETED
180 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0002	CONTAINERID=container_1692220864940_0002_01_000001	RESOURCE=<memory:1024, vCores:1>
182 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:rememberTargetTransitionsAndStoreState(1412)) - Updating application attempt appattempt_1692220864940_0002_000001 with final state: FAILED, and exit status: -1
182 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0002_000001 State change from LAUNCHED to FINAL_SAVING on event = CONTAINER_FINISHED
182 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:unregisterAttempt(496)) - Unregistering app attempt : appattempt_1692220864940_0002_000001
182 INFO  [RM Event dispatcher] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:applicationMasterFinished(124)) - Application finished, removing password for appattempt_1692220864940_0002_000001
182 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0002_000001 State change from FINAL_SAVING to FAILED on event = ATTEMPT_UPDATE_SAVED
182 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1538)) - The number of failed attempts is 1. The max attempts is 2
183 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:doneApplicationAttempt(1048)) - Application Attempt appattempt_1692220864940_0002_000001 is done. finalState=FAILED
183 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0002_000002
183 INFO  [SchedulerEventDispatcher:Event Processor] scheduler.AppSchedulingInfo (AppSchedulingInfo.java:clearRequests(159)) - Application application_1692220864940_0002 requests cleared
183 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0002_000002 State change from NEW to SUBMITTED on event = START
183 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:activateApplications(911)) - Application application_1692220864940_0003 from user: dr.who activated in queue: default
183 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:removeApplicationAttempt(1003)) - Application removed - appId: application_1692220864940_0002 user: dr.who queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
184 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0002 user: dr.who, leaf-queue: default #user-pending-applications: 1 #user-active-applications: 1 #queue-pending-applications: 1 #queue-active-applications: 1
184 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0002_000002 to scheduler from user dr.who in queue default
184 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0002_000002 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
236 INFO  [qtp858952163-26] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0004
236 WARN  [qtp858952163-26] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 4 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
236 INFO  [qtp858952163-26] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 4 submitted by user dr.who
237 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0004
237 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0004
237 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0004 State change from NEW to NEW_SAVING on event = START
237 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0004
238 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0004 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
238 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0004 user: dr.who leaf-queue of parent: root #applications: 3
238 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0004 from user: dr.who, in queue: default
238 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0004 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
238 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0004_000001
239 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0004_000001 State change from NEW to SUBMITTED on event = START
239 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0004 user: dr.who, leaf-queue: default #user-pending-applications: 2 #user-active-applications: 1 #queue-pending-applications: 2 #queue-active-applications: 1
239 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0004_000001 to scheduler from user dr.who in queue default
240 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0004_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
406 INFO  [qtp858952163-31] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 5
439 INFO  [qtp858952163-26] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0005
440 WARN  [qtp858952163-26] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 5 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
440 INFO  [qtp858952163-26] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 5 submitted by user dr.who
440 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0005
440 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0005
441 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0005
441 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0005 State change from NEW to NEW_SAVING on event = START
441 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0005 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
441 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0005 user: dr.who leaf-queue of parent: root #applications: 4
441 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0005 from user: dr.who, in queue: default
442 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0005 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
442 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0005_000001
442 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0005_000001 State change from NEW to SUBMITTED on event = START
443 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0005 user: dr.who, leaf-queue: default #user-pending-applications: 3 #user-active-applications: 1 #queue-pending-applications: 3 #queue-active-applications: 1
443 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0005_000001 to scheduler from user dr.who in queue default
444 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0005_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
658 WARN  [qtp1616974404-21] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
699 INFO  [qtp858952163-26] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 6
821 INFO  [qtp858952163-31] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0006
821 WARN  [qtp858952163-31] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 6 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
821 INFO  [qtp858952163-31] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 6 submitted by user dr.who
822 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0006
822 INFO  [qtp858952163-31] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0006
822 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0006 State change from NEW to NEW_SAVING on event = START
822 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0006
822 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0006 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
822 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0006 user: dr.who leaf-queue of parent: root #applications: 5
822 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0006 from user: dr.who, in queue: default
823 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0006 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
823 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0006_000001
823 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0006_000001 State change from NEW to SUBMITTED on event = START
824 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0006 user: dr.who, leaf-queue: default #user-pending-applications: 4 #user-active-applications: 1 #queue-pending-applications: 4 #queue-active-applications: 1
824 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0006_000001 to scheduler from user dr.who in queue default
825 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0006_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
863 INFO  [qtp858952163-30] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 7
917 INFO  [qtp858952163-29] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0007
917 WARN  [qtp858952163-29] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 7 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
918 INFO  [qtp858952163-29] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 7 submitted by user dr.who
918 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0007
918 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0007
918 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0007
918 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0007 State change from NEW to NEW_SAVING on event = START
919 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0007 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
919 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0007 user: dr.who leaf-queue of parent: root #applications: 6
919 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0007 from user: dr.who, in queue: default
919 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0007 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
919 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0007_000001
919 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0007_000001 State change from NEW to SUBMITTED on event = START
920 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0007 user: dr.who, leaf-queue: default #user-pending-applications: 5 #user-active-applications: 1 #queue-pending-applications: 5 #queue-active-applications: 1
920 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0007_000001 to scheduler from user dr.who in queue default
921 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0007_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
949 WARN  [qtp1616974404-17] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
031 INFO  [qtp858952163-24] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '0' is acceptable in queue : default for application: application_1692220864940_0007
032 INFO  [qtp858952163-24] recovery.RMStateStore (RMStateStore.java:transition(260)) - Updating info for app: application_1692220864940_0007
032 INFO  [qtp858952163-24] capacity.CapacityScheduler (CapacityScheduler.java:updateApplicationPriority(2563)) - Priority '0' is updated in queue :default for application: application_1692220864940_0007 for the user: dr.who
032 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(318)) - USER=dr.who	OPERATION=Update Application Priority	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0007
181 INFO  [Node Status Updater] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:removeOrTrackCompletedContainersFromContext(696)) - Removed completed containers from NM context: [container_1692220864940_0002_01_000001]
181 INFO  [SchedulerEventDispatcher:Event Processor] allocator.AbstractContainerAllocator (AbstractContainerAllocator.java:getCSAssignmentFromAllocateResult(129)) - assignedContainer application attempt=appattempt_1692220864940_0003_000001 container=null queue=default clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
182 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0003_01_000001 Container Transitioned from NEW to ALLOCATED
182 INFO  [SchedulerEventDispatcher:Event Processor] fica.FiCaSchedulerNode (FiCaSchedulerNode.java:allocateContainer(169)) - Assigned container container_1692220864940_0003_01_000001 of capacity <memory:1024, vCores:1> on host 49f255efa79a:41559, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
182 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0003	CONTAINERID=container_1692220864940_0003_01_000001	RESOURCE=<memory:1024, vCores:1>
185 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:createAndGetNMToken(200)) - Sending NMToken for nodeId : 49f255efa79a:41559 for container : container_1692220864940_0003_01_000001
186 INFO  [RM Event dispatcher] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0003_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
186 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:clearNodeSetForAttempt(146)) - Clear node set for appattempt_1692220864940_0003_000001
186 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:storeAttempt(2193)) - Storing attempt: AppId: application_1692220864940_0003 AttemptId: appattempt_1692220864940_0003_000001 MasterContainer: Container: [ContainerId: container_1692220864940_0003_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ]
186 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:apply(1332)) - assignedContainer queue=root usedCapacity=0.125 absoluteUsedCapacity=0.125 used=<memory:1024, vCores:1> cluster=<memory:8192, vCores:8>
187 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:tryCommit(2853)) - Allocation proposal accepted
187 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0003_000001 State change from SCHEDULED to ALLOCATED_SAVING on event = CONTAINER_ALLOCATED
187 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0003_000001 State change from ALLOCATED_SAVING to ALLOCATED on event = ATTEMPT_NEW_SAVED
188 INFO  [ApplicationMasterLauncher #3] amlauncher.AMLauncher (AMLauncher.java:run(307)) - Launching masterappattempt_1692220864940_0003_000001
190 INFO  [ApplicationMasterLauncher #3] amlauncher.AMLauncher (AMLauncher.java:launch(109)) - Setting up container Container: [ContainerId: container_1692220864940_0003_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0003_000001
190 INFO  [ApplicationMasterLauncher #3] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createAndGetAMRMToken(195)) - Create AMRMToken for ApplicationAttempt: appattempt_1692220864940_0003_000001
190 INFO  [ApplicationMasterLauncher #3] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createPassword(307)) - Creating password for appattempt_1692220864940_0003_000001
195 INFO  [Socket Reader #1 for port 41559] ipc.Server (Server.java:saslProcess(1845)) - Auth successful for appattempt_1692220864940_0003_000001 (auth:SIMPLE)
199 INFO  [IPC Server handler 1 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1062)) - Start request for container_1692220864940_0003_01_000001 by user dr.who
201 INFO  [IPC Server handler 1 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1114)) - Creating a new application reference for app application_1692220864940_0003
201 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0003 transitioned from NEW to INITING
201 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(463)) - Adding container_1692220864940_0003_01_000001 to application application_1692220864940_0003
201 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0003 transitioned from INITING to RUNNING
201 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0003_01_000001 transitioned from NEW to SCHEDULED
201 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_INIT for appId application_1692220864940_0003
201 INFO  [NM ContainerManager dispatcher] scheduler.ContainerScheduler (ContainerScheduler.java:startContainer(503)) - Starting container [container_1692220864940_0003_01_000001]
201 INFO  [IPC Server handler 1 on 41559] nodemanager.NMAuditLogger (NMAuditLogger.java:logSuccess(94)) - USER=dr.who	IP=172.19.0.3	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1692220864940_0003	CONTAINERID=container_1692220864940_0003_01_000001
203 INFO  [ApplicationMasterLauncher #3] amlauncher.AMLauncher (AMLauncher.java:launch(130)) - Done launching container Container: [ContainerId: container_1692220864940_0003_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0003_000001
204 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0003_000001 State change from ALLOCATED to LAUNCHED on event = LAUNCHED
211 WARN  [ContainersLauncher #0] launcher.ContainerLaunch (ContainerLaunch.java:call(331)) - Failed to launch container.
211 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0003_01_000001 transitioned from SCHEDULED to EXITED_WITH_FAILURE
211 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(734)) - Cleaning up container container_1692220864940_0003_01_000001
211 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(747)) - Container container_1692220864940_0003_01_000001 not launched. No cleanup needed to be done
212 WARN  [NM ContainerManager dispatcher] nodemanager.NMAuditLogger (NMAuditLogger.java:logFailure(155)) - USER=dr.who	OPERATION=Container Finished - Failed	TARGET=ContainerImpl	RESULT=FAILURE	DESCRIPTION=Container failed with state: EXITED_WITH_FAILURE	APPID=application_1692220864940_0003	CONTAINERID=container_1692220864940_0003_01_000001
213 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0003_01_000001 transitioned from EXITED_WITH_FAILURE to DONE
213 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(512)) - Removing container_1692220864940_0003_01_000001 from application application_1692220864940_0003
213 INFO  [NM ContainerManager dispatcher] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:onStopMonitoringContainer(932)) - Stopping resource-monitoring for container_1692220864940_0003_01_000001
213 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_STOP for appId application_1692220864940_0003
215 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0003_01_000001 Container Transitioned from ACQUIRED to COMPLETED
215 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0003	CONTAINERID=container_1692220864940_0003_01_000001	RESOURCE=<memory:1024, vCores:1>
216 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:rememberTargetTransitionsAndStoreState(1412)) - Updating application attempt appattempt_1692220864940_0003_000001 with final state: FAILED, and exit status: -1
216 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0003_000001 State change from LAUNCHED to FINAL_SAVING on event = CONTAINER_FINISHED
216 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:unregisterAttempt(496)) - Unregistering app attempt : appattempt_1692220864940_0003_000001
216 INFO  [RM Event dispatcher] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:applicationMasterFinished(124)) - Application finished, removing password for appattempt_1692220864940_0003_000001
216 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0003_000001 State change from FINAL_SAVING to FAILED on event = ATTEMPT_UPDATE_SAVED
217 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1538)) - The number of failed attempts is 1. The max attempts is 2
217 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:doneApplicationAttempt(1048)) - Application Attempt appattempt_1692220864940_0003_000001 is done. finalState=FAILED
217 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0003_000002
217 INFO  [SchedulerEventDispatcher:Event Processor] scheduler.AppSchedulingInfo (AppSchedulingInfo.java:clearRequests(159)) - Application application_1692220864940_0003 requests cleared
217 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0003_000002 State change from NEW to SUBMITTED on event = START
217 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:activateApplications(911)) - Application application_1692220864940_0007 from user: dr.who activated in queue: default
218 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:removeApplicationAttempt(1003)) - Application removed - appId: application_1692220864940_0003 user: dr.who queue: default #user-pending-applications: 4 #user-active-applications: 1 #queue-pending-applications: 4 #queue-active-applications: 1
218 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0003 user: dr.who, leaf-queue: default #user-pending-applications: 5 #user-active-applications: 1 #queue-pending-applications: 5 #queue-active-applications: 1
218 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0003_000002 to scheduler from user dr.who in queue default
219 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0003_000002 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
231 WARN  [qtp1616974404-17] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
271 INFO  [qtp858952163-24] nodelabels.CommonNodeLabelsManager (CommonNodeLabelsManager.java:addToCluserNodeLabels(335)) - Add labels: [<default:exclusivity=true>]
360 INFO  [qtp858952163-30] nodelabels.CommonNodeLabelsManager (CommonNodeLabelsManager.java:internalUpdateLabelsOnNodes(664)) - REPLACE labels on nodes:
361 INFO  [qtp858952163-30] nodelabels.CommonNodeLabelsManager (CommonNodeLabelsManager.java:internalUpdateLabelsOnNodes(666)) -   NM=49f255efa79a:41559, labels=[]
389 INFO  [qtp858952163-31] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 8
436 INFO  [qtp858952163-29] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0008
437 WARN  [qtp858952163-29] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 8 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
437 INFO  [qtp858952163-29] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 8 submitted by user dr.who
437 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0008
437 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0008
438 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0008 State change from NEW to NEW_SAVING on event = START
438 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0008
438 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0008 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
438 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0008 user: dr.who leaf-queue of parent: root #applications: 7
438 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0008 from user: dr.who, in queue: default
439 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0008 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
439 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0008_000001
439 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0008_000001 State change from NEW to SUBMITTED on event = START
440 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0008 user: dr.who, leaf-queue: default #user-pending-applications: 6 #user-active-applications: 1 #queue-pending-applications: 6 #queue-active-applications: 1
440 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0008_000001 to scheduler from user dr.who in queue default
441 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0008_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
469 WARN  [qtp1616974404-19] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
702 WARN  [qtp858952163-30] nodelabels.CommonNodeLabelsManager (CommonNodeLabelsManager.java:getLabelsToNodesMapping(914)) - getLabelsToNodes : Label [label1] cannot be found
708 WARN  [qtp858952163-24] nodelabels.CommonNodeLabelsManager (CommonNodeLabelsManager.java:getLabelsToNodesMapping(914)) - getLabelsToNodes : Label [label1] cannot be found
912 INFO  [qtp858952163-24] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 9
985 INFO  [qtp858952163-29] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0009
985 WARN  [qtp858952163-29] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 9 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
985 INFO  [qtp858952163-29] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 9 submitted by user dr.who
986 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0009
986 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0009
986 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0009
986 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0009 State change from NEW to NEW_SAVING on event = START
986 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0009 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
986 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0009 user: dr.who leaf-queue of parent: root #applications: 8
986 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0009 from user: dr.who, in queue: default
987 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0009 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
987 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0009_000001
987 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0009_000001 State change from NEW to SUBMITTED on event = START
988 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0009 user: dr.who, leaf-queue: default #user-pending-applications: 7 #user-active-applications: 1 #queue-pending-applications: 7 #queue-active-applications: 1
988 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0009_000001 to scheduler from user dr.who in queue default
988 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0009_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
124 WARN  [qtp1616974404-16] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
198 WARN  [qtp858952163-26] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
217 INFO  [Node Status Updater] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:removeOrTrackCompletedContainersFromContext(696)) - Removed completed containers from NM context: [container_1692220864940_0003_01_000001]
217 INFO  [SchedulerEventDispatcher:Event Processor] allocator.AbstractContainerAllocator (AbstractContainerAllocator.java:getCSAssignmentFromAllocateResult(129)) - assignedContainer application attempt=appattempt_1692220864940_0007_000001 container=null queue=default clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
218 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0007_01_000001 Container Transitioned from NEW to ALLOCATED
218 INFO  [SchedulerEventDispatcher:Event Processor] fica.FiCaSchedulerNode (FiCaSchedulerNode.java:allocateContainer(169)) - Assigned container container_1692220864940_0007_01_000001 of capacity <memory:1024, vCores:1> on host 49f255efa79a:41559, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
218 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0007	CONTAINERID=container_1692220864940_0007_01_000001	RESOURCE=<memory:1024, vCores:1>
221 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:createAndGetNMToken(200)) - Sending NMToken for nodeId : 49f255efa79a:41559 for container : container_1692220864940_0007_01_000001
223 INFO  [RM Event dispatcher] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0007_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
224 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:clearNodeSetForAttempt(146)) - Clear node set for appattempt_1692220864940_0007_000001
224 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:storeAttempt(2193)) - Storing attempt: AppId: application_1692220864940_0007 AttemptId: appattempt_1692220864940_0007_000001 MasterContainer: Container: [ContainerId: container_1692220864940_0007_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ]
224 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:apply(1332)) - assignedContainer queue=root usedCapacity=0.125 absoluteUsedCapacity=0.125 used=<memory:1024, vCores:1> cluster=<memory:8192, vCores:8>
224 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:tryCommit(2853)) - Allocation proposal accepted
224 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0007_000001 State change from SCHEDULED to ALLOCATED_SAVING on event = CONTAINER_ALLOCATED
225 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0007_000001 State change from ALLOCATED_SAVING to ALLOCATED on event = ATTEMPT_NEW_SAVED
225 INFO  [ApplicationMasterLauncher #4] amlauncher.AMLauncher (AMLauncher.java:run(307)) - Launching masterappattempt_1692220864940_0007_000001
227 INFO  [ApplicationMasterLauncher #4] amlauncher.AMLauncher (AMLauncher.java:launch(109)) - Setting up container Container: [ContainerId: container_1692220864940_0007_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0007_000001
227 INFO  [ApplicationMasterLauncher #4] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createAndGetAMRMToken(195)) - Create AMRMToken for ApplicationAttempt: appattempt_1692220864940_0007_000001
227 INFO  [ApplicationMasterLauncher #4] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createPassword(307)) - Creating password for appattempt_1692220864940_0007_000001
230 INFO  [Socket Reader #1 for port 41559] ipc.Server (Server.java:saslProcess(1845)) - Auth successful for appattempt_1692220864940_0007_000001 (auth:SIMPLE)
235 INFO  [IPC Server handler 2 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1062)) - Start request for container_1692220864940_0007_01_000001 by user dr.who
237 INFO  [IPC Server handler 2 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1114)) - Creating a new application reference for app application_1692220864940_0007
237 INFO  [IPC Server handler 2 on 41559] nodemanager.NMAuditLogger (NMAuditLogger.java:logSuccess(94)) - USER=dr.who	IP=172.19.0.3	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1692220864940_0007	CONTAINERID=container_1692220864940_0007_01_000001
237 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0007 transitioned from NEW to INITING
237 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(463)) - Adding container_1692220864940_0007_01_000001 to application application_1692220864940_0007
238 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0007 transitioned from INITING to RUNNING
238 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0007_01_000001 transitioned from NEW to SCHEDULED
238 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_INIT for appId application_1692220864940_0007
238 INFO  [NM ContainerManager dispatcher] scheduler.ContainerScheduler (ContainerScheduler.java:startContainer(503)) - Starting container [container_1692220864940_0007_01_000001]
238 INFO  [ApplicationMasterLauncher #4] amlauncher.AMLauncher (AMLauncher.java:launch(130)) - Done launching container Container: [ContainerId: container_1692220864940_0007_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0007_000001
238 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0007_000001 State change from ALLOCATED to LAUNCHED on event = LAUNCHED
246 WARN  [ContainersLauncher #0] launcher.ContainerLaunch (ContainerLaunch.java:call(331)) - Failed to launch container.
247 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0007_01_000001 transitioned from SCHEDULED to EXITED_WITH_FAILURE
247 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(734)) - Cleaning up container container_1692220864940_0007_01_000001
247 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(747)) - Container container_1692220864940_0007_01_000001 not launched. No cleanup needed to be done
246 WARN  [qtp1616974404-21] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
247 WARN  [NM ContainerManager dispatcher] nodemanager.NMAuditLogger (NMAuditLogger.java:logFailure(155)) - USER=dr.who	OPERATION=Container Finished - Failed	TARGET=ContainerImpl	RESULT=FAILURE	DESCRIPTION=Container failed with state: EXITED_WITH_FAILURE	APPID=application_1692220864940_0007	CONTAINERID=container_1692220864940_0007_01_000001
248 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0007_01_000001 transitioned from EXITED_WITH_FAILURE to DONE
248 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(512)) - Removing container_1692220864940_0007_01_000001 from application application_1692220864940_0007
248 INFO  [NM ContainerManager dispatcher] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:onStopMonitoringContainer(932)) - Stopping resource-monitoring for container_1692220864940_0007_01_000001
249 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_STOP for appId application_1692220864940_0007
252 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0007_01_000001 Container Transitioned from ACQUIRED to COMPLETED
252 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0007	CONTAINERID=container_1692220864940_0007_01_000001	RESOURCE=<memory:1024, vCores:1>
253 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:rememberTargetTransitionsAndStoreState(1412)) - Updating application attempt appattempt_1692220864940_0007_000001 with final state: FAILED, and exit status: -1
254 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0007_000001 State change from LAUNCHED to FINAL_SAVING on event = CONTAINER_FINISHED
254 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:unregisterAttempt(496)) - Unregistering app attempt : appattempt_1692220864940_0007_000001
254 INFO  [RM Event dispatcher] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:applicationMasterFinished(124)) - Application finished, removing password for appattempt_1692220864940_0007_000001
254 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0007_000001 State change from FINAL_SAVING to FAILED on event = ATTEMPT_UPDATE_SAVED
254 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1538)) - The number of failed attempts is 1. The max attempts is 2
255 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:doneApplicationAttempt(1048)) - Application Attempt appattempt_1692220864940_0007_000001 is done. finalState=FAILED
255 INFO  [SchedulerEventDispatcher:Event Processor] scheduler.AppSchedulingInfo (AppSchedulingInfo.java:clearRequests(159)) - Application application_1692220864940_0007 requests cleared
255 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:activateApplications(911)) - Application application_1692220864940_0002 from user: dr.who activated in queue: default
255 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0007_000002
255 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0007_000002 State change from NEW to SUBMITTED on event = START
256 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:removeApplicationAttempt(1003)) - Application removed - appId: application_1692220864940_0007 user: dr.who queue: default #user-pending-applications: 6 #user-active-applications: 1 #queue-pending-applications: 6 #queue-active-applications: 1
256 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0007 user: dr.who, leaf-queue: default #user-pending-applications: 7 #user-active-applications: 1 #queue-pending-applications: 7 #queue-active-applications: 1
256 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0007_000002 to scheduler from user dr.who in queue default
257 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0007_000002 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
296 INFO  [qtp858952163-24] nodelabels.CommonNodeLabelsManager (CommonNodeLabelsManager.java:addToCluserNodeLabels(335)) - Add labels: [<default:exclusivity=true>]
392 INFO  [qtp858952163-31] nodelabels.CommonNodeLabelsManager (RMNodeLabelsManager.java:replaceLabelsOnNode(181)) - No Modified Node label Mapping to replace
422 INFO  [qtp858952163-30] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 10
470 INFO  [qtp858952163-24] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0010
470 WARN  [qtp858952163-24] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 10 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
470 INFO  [qtp858952163-24] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 10 submitted by user dr.who
471 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0010
471 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0010
471 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0010
471 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0010 State change from NEW to NEW_SAVING on event = START
471 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0010 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
472 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0010 user: dr.who leaf-queue of parent: root #applications: 9
472 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0010 from user: dr.who, in queue: default
472 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0010 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
472 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0010_000001
472 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0010_000001 State change from NEW to SUBMITTED on event = START
473 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0010 user: dr.who, leaf-queue: default #user-pending-applications: 8 #user-active-applications: 1 #queue-pending-applications: 8 #queue-active-applications: 1
473 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0010_000001 to scheduler from user dr.who in queue default
474 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0010_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
827 INFO  [qtp858952163-26] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 11
879 INFO  [qtp858952163-27] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0011
879 WARN  [qtp858952163-27] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 11 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
879 INFO  [qtp858952163-27] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 11 submitted by user dr.who
880 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0011
879 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0011
880 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0011
880 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0011 State change from NEW to NEW_SAVING on event = START
880 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0011 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
880 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0011 user: dr.who leaf-queue of parent: root #applications: 10
880 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0011 from user: dr.who, in queue: default
881 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0011 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
881 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0011_000001
881 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0011_000001 State change from NEW to SUBMITTED on event = START
882 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0011 user: dr.who, leaf-queue: default #user-pending-applications: 9 #user-active-applications: 1 #queue-pending-applications: 9 #queue-active-applications: 1
882 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0011_000001 to scheduler from user dr.who in queue default
882 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0011_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
034 INFO  [qtp858952163-26] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 12
070 INFO  [qtp858952163-27] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0012
070 WARN  [qtp858952163-27] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 12 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
070 INFO  [qtp858952163-27] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 12 submitted by user dr.who
071 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0012
071 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0012
071 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0012
071 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0012 State change from NEW to NEW_SAVING on event = START
071 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0012 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
071 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0012 user: dr.who leaf-queue of parent: root #applications: 11
072 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0012 from user: dr.who, in queue: default
072 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0012 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
072 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0012_000001
072 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0012_000001 State change from NEW to SUBMITTED on event = START
073 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0012 user: dr.who, leaf-queue: default #user-pending-applications: 10 #user-active-applications: 1 #queue-pending-applications: 10 #queue-active-applications: 1
073 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0012_000001 to scheduler from user dr.who in queue default
074 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0012_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
254 INFO  [Node Status Updater] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:removeOrTrackCompletedContainersFromContext(696)) - Removed completed containers from NM context: [container_1692220864940_0007_01_000001]
254 INFO  [SchedulerEventDispatcher:Event Processor] allocator.AbstractContainerAllocator (AbstractContainerAllocator.java:getCSAssignmentFromAllocateResult(129)) - assignedContainer application attempt=appattempt_1692220864940_0002_000002 container=null queue=default clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
255 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0002_02_000001 Container Transitioned from NEW to ALLOCATED
255 INFO  [SchedulerEventDispatcher:Event Processor] fica.FiCaSchedulerNode (FiCaSchedulerNode.java:allocateContainer(169)) - Assigned container container_1692220864940_0002_02_000001 of capacity <memory:1024, vCores:1> on host 49f255efa79a:41559, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
255 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0002	CONTAINERID=container_1692220864940_0002_02_000001	RESOURCE=<memory:1024, vCores:1>
256 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:createAndGetNMToken(200)) - Sending NMToken for nodeId : 49f255efa79a:41559 for container : container_1692220864940_0002_02_000001
257 INFO  [RM Event dispatcher] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0002_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
257 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:clearNodeSetForAttempt(146)) - Clear node set for appattempt_1692220864940_0002_000002
257 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:storeAttempt(2193)) - Storing attempt: AppId: application_1692220864940_0002 AttemptId: appattempt_1692220864940_0002_000002 MasterContainer: Container: [ContainerId: container_1692220864940_0002_02_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ]
257 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:apply(1332)) - assignedContainer queue=root usedCapacity=0.125 absoluteUsedCapacity=0.125 used=<memory:1024, vCores:1> cluster=<memory:8192, vCores:8>
258 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:tryCommit(2853)) - Allocation proposal accepted
258 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0002_000002 State change from SCHEDULED to ALLOCATED_SAVING on event = CONTAINER_ALLOCATED
258 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0002_000002 State change from ALLOCATED_SAVING to ALLOCATED on event = ATTEMPT_NEW_SAVED
259 INFO  [ApplicationMasterLauncher #5] amlauncher.AMLauncher (AMLauncher.java:run(307)) - Launching masterappattempt_1692220864940_0002_000002
261 INFO  [ApplicationMasterLauncher #5] amlauncher.AMLauncher (AMLauncher.java:launch(109)) - Setting up container Container: [ContainerId: container_1692220864940_0002_02_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0002_000002
261 INFO  [ApplicationMasterLauncher #5] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createAndGetAMRMToken(195)) - Create AMRMToken for ApplicationAttempt: appattempt_1692220864940_0002_000002
261 INFO  [ApplicationMasterLauncher #5] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createPassword(307)) - Creating password for appattempt_1692220864940_0002_000002
265 INFO  [Socket Reader #1 for port 41559] ipc.Server (Server.java:saslProcess(1845)) - Auth successful for appattempt_1692220864940_0002_000002 (auth:SIMPLE)
269 INFO  [IPC Server handler 4 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1062)) - Start request for container_1692220864940_0002_02_000001 by user dr.who
271 INFO  [IPC Server handler 4 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1148)) - TimelineService V2.0 is not enabled. Skipping updating flowContext for application application_1692220864940_0002
271 INFO  [IPC Server handler 4 on 41559] nodemanager.NMAuditLogger (NMAuditLogger.java:logSuccess(94)) - USER=dr.who	IP=172.19.0.3	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1692220864940_0002	CONTAINERID=container_1692220864940_0002_02_000001
271 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(463)) - Adding container_1692220864940_0002_02_000001 to application application_1692220864940_0002
271 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0002_02_000001 transitioned from NEW to SCHEDULED
272 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_INIT for appId application_1692220864940_0002
272 INFO  [NM ContainerManager dispatcher] scheduler.ContainerScheduler (ContainerScheduler.java:startContainer(503)) - Starting container [container_1692220864940_0002_02_000001]
272 INFO  [ApplicationMasterLauncher #5] amlauncher.AMLauncher (AMLauncher.java:launch(130)) - Done launching container Container: [ContainerId: container_1692220864940_0002_02_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0002_000002
272 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0002_000002 State change from ALLOCATED to LAUNCHED on event = LAUNCHED
279 WARN  [ContainersLauncher #0] launcher.ContainerLaunch (ContainerLaunch.java:call(331)) - Failed to launch container.
280 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0002_02_000001 transitioned from SCHEDULED to EXITED_WITH_FAILURE
280 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(734)) - Cleaning up container container_1692220864940_0002_02_000001
280 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(747)) - Container container_1692220864940_0002_02_000001 not launched. No cleanup needed to be done
280 WARN  [NM ContainerManager dispatcher] nodemanager.NMAuditLogger (NMAuditLogger.java:logFailure(155)) - USER=dr.who	OPERATION=Container Finished - Failed	TARGET=ContainerImpl	RESULT=FAILURE	DESCRIPTION=Container failed with state: EXITED_WITH_FAILURE	APPID=application_1692220864940_0002	CONTAINERID=container_1692220864940_0002_02_000001
281 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0002_02_000001 transitioned from EXITED_WITH_FAILURE to DONE
281 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(512)) - Removing container_1692220864940_0002_02_000001 from application application_1692220864940_0002
281 INFO  [NM ContainerManager dispatcher] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:onStopMonitoringContainer(932)) - Stopping resource-monitoring for container_1692220864940_0002_02_000001
281 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_STOP for appId application_1692220864940_0002
284 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0002_02_000001 Container Transitioned from ACQUIRED to COMPLETED
284 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0002	CONTAINERID=container_1692220864940_0002_02_000001	RESOURCE=<memory:1024, vCores:1>
286 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:rememberTargetTransitionsAndStoreState(1412)) - Updating application attempt appattempt_1692220864940_0002_000002 with final state: FAILED, and exit status: -1
286 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0002_000002 State change from LAUNCHED to FINAL_SAVING on event = CONTAINER_FINISHED
286 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:unregisterAttempt(496)) - Unregistering app attempt : appattempt_1692220864940_0002_000002
287 INFO  [RM Event dispatcher] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:applicationMasterFinished(124)) - Application finished, removing password for appattempt_1692220864940_0002_000002
287 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0002_000002 State change from FINAL_SAVING to FAILED on event = ATTEMPT_UPDATE_SAVED
287 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1538)) - The number of failed attempts is 2. The max attempts is 2
287 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:rememberTargetTransitionsAndStoreState(1278)) - Updating application application_1692220864940_0002 with final state: FAILED
288 INFO  [qtp858952163-27] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 13
288 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0002 State change from ACCEPTED to FINAL_SAVING on event = ATTEMPT_FAILED
288 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(260)) - Updating info for app: application_1692220864940_0002
288 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:doneApplicationAttempt(1048)) - Application Attempt appattempt_1692220864940_0002_000002 is done. finalState=FAILED
288 INFO  [SchedulerEventDispatcher:Event Processor] scheduler.AppSchedulingInfo (AppSchedulingInfo.java:clearRequests(159)) - Application application_1692220864940_0002 requests cleared
288 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1197)) - Application application_1692220864940_0002 failed 2 times due to AM Container for appattempt_1692220864940_0002_000002 exited with  exitCode: -1
288 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:activateApplications(911)) - Application application_1692220864940_0003 from user: dr.who activated in queue: default
289 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0002 State change from FINAL_SAVING to FAILED on event = APP_UPDATE_SAVED
290 WARN  [RM Event dispatcher] resourcemanager.RMAuditLogger (RMAuditLogger.java:logFailure(478)) - USER=dr.who	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1692220864940_0002 failed 2 times due to AM Container for appattempt_1692220864940_0002_000002 exited with  exitCode: -1
291 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:removeApplicationAttempt(1003)) - Application removed - appId: application_1692220864940_0002 user: dr.who queue: default #user-pending-applications: 9 #user-active-applications: 1 #queue-pending-applications: 9 #queue-active-applications: 1
291 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:removeApplication(522)) - Application removed - appId: application_1692220864940_0002 user: dr.who leaf-queue of parent: root #applications: 10
292 INFO  [RM Event dispatcher] resourcemanager.RMAppManager$ApplicationSummary (RMAppManager.java:logAppSummary(212)) - appId=application_1692220864940_0002,name=,user=dr.who,queue=default,state=FAILED,trackingUrl=http://49f255efa79a:8080/cluster/app/application_1692220864940_0002,appMasterHost=N/A,submitTime=1692220871545,startTime=1692220871546,finishTime=1692220875287,finalStatus=FAILED,memorySeconds=198,vcoreSeconds=0,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=,resourceSeconds=198 MB-seconds\, 0 vcore-seconds,preemptedResourceSeconds=0 MB-seconds\, 0 vcore-seconds
341 INFO  [qtp858952163-24] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0013
341 WARN  [qtp858952163-24] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 13 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
341 INFO  [qtp858952163-24] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 13 submitted by user dr.who
342 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0013
342 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0013
343 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0013
343 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0013 State change from NEW to NEW_SAVING on event = START
344 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0013 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
344 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0013 user: dr.who leaf-queue of parent: root #applications: 11
344 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0013 from user: dr.who, in queue: default
344 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0013 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
344 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0013_000001
344 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0013_000001 State change from NEW to SUBMITTED on event = START
345 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0013 user: dr.who, leaf-queue: default #user-pending-applications: 10 #user-active-applications: 1 #queue-pending-applications: 10 #queue-active-applications: 1
345 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0013_000001 to scheduler from user dr.who in queue default
346 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0013_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
539 INFO  [qtp858952163-26] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 14
587 INFO  [qtp858952163-29] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0014
587 WARN  [qtp858952163-29] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 14 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
588 INFO  [qtp858952163-29] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 14 submitted by user dr.who
588 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0014
588 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0014
589 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0014
589 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0014 State change from NEW to NEW_SAVING on event = START
589 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0014 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
589 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0014 user: dr.who leaf-queue of parent: root #applications: 12
589 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0014 from user: dr.who, in queue: default
589 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0014 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
589 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0014_000001
590 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0014_000001 State change from NEW to SUBMITTED on event = START
590 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0014 user: dr.who, leaf-queue: default #user-pending-applications: 11 #user-active-applications: 1 #queue-pending-applications: 11 #queue-active-applications: 1
590 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0014_000001 to scheduler from user dr.who in queue default
591 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0014_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
739 WARN  [qtp1616974404-23] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
770 INFO  [qtp858952163-26] reservation.AbstractReservationSystem (AbstractReservationSystem.java:getNewReservationId(384)) - Allocated new reservationId: reservation_1692220864940_0003
021 WARN  [qtp1616974404-23] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
059 INFO  [qtp858952163-26] reservation.AbstractReservationSystem (AbstractReservationSystem.java:getNewReservationId(384)) - Allocated new reservationId: reservation_1692220864940_0004
285 INFO  [Node Status Updater] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:removeOrTrackCompletedContainersFromContext(696)) - Removed completed containers from NM context: [container_1692220864940_0002_02_000001]
286 INFO  [SchedulerEventDispatcher:Event Processor] allocator.AbstractContainerAllocator (AbstractContainerAllocator.java:getCSAssignmentFromAllocateResult(129)) - assignedContainer application attempt=appattempt_1692220864940_0003_000002 container=null queue=default clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
286 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0003_02_000001 Container Transitioned from NEW to ALLOCATED
286 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0002 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
286 INFO  [SchedulerEventDispatcher:Event Processor] fica.FiCaSchedulerNode (FiCaSchedulerNode.java:allocateContainer(169)) - Assigned container container_1692220864940_0003_02_000001 of capacity <memory:1024, vCores:1> on host 49f255efa79a:41559, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
286 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0003	CONTAINERID=container_1692220864940_0003_02_000001	RESOURCE=<memory:1024, vCores:1>
287 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event APPLICATION_STOP for appId application_1692220864940_0002
287 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0002 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
288 INFO  [NM ContainerManager dispatcher] loghandler.NonAggregatingLogHandler (NonAggregatingLogHandler.java:handle(173)) - Scheduling Log Deletion for application: application_1692220864940_0002, with delay of 10800 seconds
288 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:createAndGetNMToken(200)) - Sending NMToken for nodeId : 49f255efa79a:41559 for container : container_1692220864940_0003_02_000001
288 INFO  [RM Event dispatcher] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0003_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
289 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:clearNodeSetForAttempt(146)) - Clear node set for appattempt_1692220864940_0003_000002
289 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:storeAttempt(2193)) - Storing attempt: AppId: application_1692220864940_0003 AttemptId: appattempt_1692220864940_0003_000002 MasterContainer: Container: [ContainerId: container_1692220864940_0003_02_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ]
289 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:apply(1332)) - assignedContainer queue=root usedCapacity=0.125 absoluteUsedCapacity=0.125 used=<memory:1024, vCores:1> cluster=<memory:8192, vCores:8>
289 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:tryCommit(2853)) - Allocation proposal accepted
289 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0003_000002 State change from SCHEDULED to ALLOCATED_SAVING on event = CONTAINER_ALLOCATED
289 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0003_000002 State change from ALLOCATED_SAVING to ALLOCATED on event = ATTEMPT_NEW_SAVED
290 INFO  [ApplicationMasterLauncher #6] amlauncher.AMLauncher (AMLauncher.java:run(307)) - Launching masterappattempt_1692220864940_0003_000002
292 INFO  [ApplicationMasterLauncher #6] amlauncher.AMLauncher (AMLauncher.java:launch(109)) - Setting up container Container: [ContainerId: container_1692220864940_0003_02_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0003_000002
292 INFO  [ApplicationMasterLauncher #6] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createAndGetAMRMToken(195)) - Create AMRMToken for ApplicationAttempt: appattempt_1692220864940_0003_000002
292 INFO  [ApplicationMasterLauncher #6] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createPassword(307)) - Creating password for appattempt_1692220864940_0003_000002
296 WARN  [qtp1616974404-23] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
296 INFO  [Socket Reader #1 for port 41559] ipc.Server (Server.java:saslProcess(1845)) - Auth successful for appattempt_1692220864940_0003_000002 (auth:SIMPLE)
301 INFO  [IPC Server handler 3 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1062)) - Start request for container_1692220864940_0003_02_000001 by user dr.who
302 INFO  [IPC Server handler 3 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1148)) - TimelineService V2.0 is not enabled. Skipping updating flowContext for application application_1692220864940_0003
303 INFO  [IPC Server handler 3 on 41559] nodemanager.NMAuditLogger (NMAuditLogger.java:logSuccess(94)) - USER=dr.who	IP=172.19.0.3	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1692220864940_0003	CONTAINERID=container_1692220864940_0003_02_000001
303 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(463)) - Adding container_1692220864940_0003_02_000001 to application application_1692220864940_0003
303 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0003_02_000001 transitioned from NEW to SCHEDULED
303 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_INIT for appId application_1692220864940_0003
303 INFO  [NM ContainerManager dispatcher] scheduler.ContainerScheduler (ContainerScheduler.java:startContainer(503)) - Starting container [container_1692220864940_0003_02_000001]
304 INFO  [ApplicationMasterLauncher #6] amlauncher.AMLauncher (AMLauncher.java:launch(130)) - Done launching container Container: [ContainerId: container_1692220864940_0003_02_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0003_000002
304 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0003_000002 State change from ALLOCATED to LAUNCHED on event = LAUNCHED
311 WARN  [ContainersLauncher #0] launcher.ContainerLaunch (ContainerLaunch.java:call(331)) - Failed to launch container.
311 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0003_02_000001 transitioned from SCHEDULED to EXITED_WITH_FAILURE
311 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(734)) - Cleaning up container container_1692220864940_0003_02_000001
311 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(747)) - Container container_1692220864940_0003_02_000001 not launched. No cleanup needed to be done
312 WARN  [NM ContainerManager dispatcher] nodemanager.NMAuditLogger (NMAuditLogger.java:logFailure(155)) - USER=dr.who	OPERATION=Container Finished - Failed	TARGET=ContainerImpl	RESULT=FAILURE	DESCRIPTION=Container failed with state: EXITED_WITH_FAILURE	APPID=application_1692220864940_0003	CONTAINERID=container_1692220864940_0003_02_000001
312 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0003_02_000001 transitioned from EXITED_WITH_FAILURE to DONE
313 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(512)) - Removing container_1692220864940_0003_02_000001 from application application_1692220864940_0003
313 INFO  [NM ContainerManager dispatcher] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:onStopMonitoringContainer(932)) - Stopping resource-monitoring for container_1692220864940_0003_02_000001
313 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_STOP for appId application_1692220864940_0003
315 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0003_02_000001 Container Transitioned from ACQUIRED to COMPLETED
315 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0003	CONTAINERID=container_1692220864940_0003_02_000001	RESOURCE=<memory:1024, vCores:1>
316 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:rememberTargetTransitionsAndStoreState(1412)) - Updating application attempt appattempt_1692220864940_0003_000002 with final state: FAILED, and exit status: -1
316 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0003_000002 State change from LAUNCHED to FINAL_SAVING on event = CONTAINER_FINISHED
316 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:unregisterAttempt(496)) - Unregistering app attempt : appattempt_1692220864940_0003_000002
316 INFO  [RM Event dispatcher] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:applicationMasterFinished(124)) - Application finished, removing password for appattempt_1692220864940_0003_000002
316 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0003_000002 State change from FINAL_SAVING to FAILED on event = ATTEMPT_UPDATE_SAVED
316 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1538)) - The number of failed attempts is 2. The max attempts is 2
316 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:rememberTargetTransitionsAndStoreState(1278)) - Updating application application_1692220864940_0003 with final state: FAILED
316 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(260)) - Updating info for app: application_1692220864940_0003
316 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0003 State change from ACCEPTED to FINAL_SAVING on event = ATTEMPT_FAILED
317 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:doneApplicationAttempt(1048)) - Application Attempt appattempt_1692220864940_0003_000002 is done. finalState=FAILED
317 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1197)) - Application application_1692220864940_0003 failed 2 times due to AM Container for appattempt_1692220864940_0003_000002 exited with  exitCode: -1
317 INFO  [SchedulerEventDispatcher:Event Processor] scheduler.AppSchedulingInfo (AppSchedulingInfo.java:clearRequests(159)) - Application application_1692220864940_0003 requests cleared
317 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:activateApplications(911)) - Application application_1692220864940_0004 from user: dr.who activated in queue: default
317 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0003 State change from FINAL_SAVING to FAILED on event = APP_UPDATE_SAVED
318 WARN  [RM Event dispatcher] resourcemanager.RMAuditLogger (RMAuditLogger.java:logFailure(478)) - USER=dr.who	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1692220864940_0003 failed 2 times due to AM Container for appattempt_1692220864940_0003_000002 exited with  exitCode: -1
318 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:removeApplicationAttempt(1003)) - Application removed - appId: application_1692220864940_0003 user: dr.who queue: default #user-pending-applications: 10 #user-active-applications: 1 #queue-pending-applications: 10 #queue-active-applications: 1
318 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:removeApplication(522)) - Application removed - appId: application_1692220864940_0003 user: dr.who leaf-queue of parent: root #applications: 11
318 INFO  [RM Event dispatcher] resourcemanager.RMAppManager$ApplicationSummary (RMAppManager.java:logAppSummary(212)) - appId=application_1692220864940_0003,name=,user=dr.who,queue=default,state=FAILED,trackingUrl=http://49f255efa79a:8080/cluster/app/application_1692220864940_0003,appMasterHost=N/A,submitTime=1692220871852,startTime=1692220871852,finishTime=1692220876316,finalStatus=FAILED,memorySeconds=63,vcoreSeconds=0,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=,resourceSeconds=63 MB-seconds\, 0 vcore-seconds,preemptedResourceSeconds=0 MB-seconds\, 0 vcore-seconds
380 INFO  [qtp858952163-29] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 15
514 WARN  [qtp1616974404-23] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
546 INFO  [qtp858952163-30] nodelabels.CommonNodeLabelsManager (CommonNodeLabelsManager.java:addToCluserNodeLabels(335)) - Add labels: [<default:exclusivity=true>]
634 INFO  [qtp858952163-31] nodelabels.CommonNodeLabelsManager (CommonNodeLabelsManager.java:internalRemoveFromClusterNodeLabels(459)) - Remove labels: []
135 INFO  [qtp858952163-30] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 16
179 INFO  [qtp858952163-31] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0016
179 WARN  [qtp858952163-31] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 16 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
179 INFO  [qtp858952163-31] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 16 submitted by user dr.who
180 INFO  [qtp858952163-31] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0016
180 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0016
180 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0016
180 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0016 State change from NEW to NEW_SAVING on event = START
181 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0016 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
181 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0016 user: dr.who leaf-queue of parent: root #applications: 12
181 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0016 from user: dr.who, in queue: default
181 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0016 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
181 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0016_000001
181 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0016_000001 State change from NEW to SUBMITTED on event = START
182 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0016 user: dr.who, leaf-queue: default #user-pending-applications: 11 #user-active-applications: 1 #queue-pending-applications: 11 #queue-active-applications: 1
182 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0016_000001 to scheduler from user dr.who in queue default
183 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0016_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
317 INFO  [qtp858952163-30] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 17
318 INFO  [Node Status Updater] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:removeOrTrackCompletedContainersFromContext(696)) - Removed completed containers from NM context: [container_1692220864940_0003_02_000001]
318 INFO  [SchedulerEventDispatcher:Event Processor] allocator.AbstractContainerAllocator (AbstractContainerAllocator.java:getCSAssignmentFromAllocateResult(129)) - assignedContainer application attempt=appattempt_1692220864940_0004_000001 container=null queue=default clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
318 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0003 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
318 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0004_01_000001 Container Transitioned from NEW to ALLOCATED
318 INFO  [SchedulerEventDispatcher:Event Processor] fica.FiCaSchedulerNode (FiCaSchedulerNode.java:allocateContainer(169)) - Assigned container container_1692220864940_0004_01_000001 of capacity <memory:1024, vCores:1> on host 49f255efa79a:41559, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
319 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0004	CONTAINERID=container_1692220864940_0004_01_000001	RESOURCE=<memory:1024, vCores:1>
319 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event APPLICATION_STOP for appId application_1692220864940_0003
319 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0003 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
319 INFO  [NM ContainerManager dispatcher] loghandler.NonAggregatingLogHandler (NonAggregatingLogHandler.java:handle(173)) - Scheduling Log Deletion for application: application_1692220864940_0003, with delay of 10800 seconds
320 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:createAndGetNMToken(200)) - Sending NMToken for nodeId : 49f255efa79a:41559 for container : container_1692220864940_0004_01_000001
321 INFO  [RM Event dispatcher] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0004_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
321 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:clearNodeSetForAttempt(146)) - Clear node set for appattempt_1692220864940_0004_000001
321 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:storeAttempt(2193)) - Storing attempt: AppId: application_1692220864940_0004 AttemptId: appattempt_1692220864940_0004_000001 MasterContainer: Container: [ContainerId: container_1692220864940_0004_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ]
321 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:apply(1332)) - assignedContainer queue=root usedCapacity=0.125 absoluteUsedCapacity=0.125 used=<memory:1024, vCores:1> cluster=<memory:8192, vCores:8>
322 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:tryCommit(2853)) - Allocation proposal accepted
322 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0004_000001 State change from SCHEDULED to ALLOCATED_SAVING on event = CONTAINER_ALLOCATED
322 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0004_000001 State change from ALLOCATED_SAVING to ALLOCATED on event = ATTEMPT_NEW_SAVED
323 INFO  [ApplicationMasterLauncher #7] amlauncher.AMLauncher (AMLauncher.java:run(307)) - Launching masterappattempt_1692220864940_0004_000001
325 INFO  [ApplicationMasterLauncher #7] amlauncher.AMLauncher (AMLauncher.java:launch(109)) - Setting up container Container: [ContainerId: container_1692220864940_0004_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0004_000001
325 INFO  [ApplicationMasterLauncher #7] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createAndGetAMRMToken(195)) - Create AMRMToken for ApplicationAttempt: appattempt_1692220864940_0004_000001
325 INFO  [ApplicationMasterLauncher #7] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createPassword(307)) - Creating password for appattempt_1692220864940_0004_000001
328 INFO  [Socket Reader #1 for port 41559] ipc.Server (Server.java:saslProcess(1845)) - Auth successful for appattempt_1692220864940_0004_000001 (auth:SIMPLE)
331 INFO  [IPC Server handler 6 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1062)) - Start request for container_1692220864940_0004_01_000001 by user dr.who
333 INFO  [IPC Server handler 6 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1114)) - Creating a new application reference for app application_1692220864940_0004
333 INFO  [IPC Server handler 6 on 41559] nodemanager.NMAuditLogger (NMAuditLogger.java:logSuccess(94)) - USER=dr.who	IP=172.19.0.3	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1692220864940_0004	CONTAINERID=container_1692220864940_0004_01_000001
333 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0004 transitioned from NEW to INITING
333 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(463)) - Adding container_1692220864940_0004_01_000001 to application application_1692220864940_0004
334 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0004 transitioned from INITING to RUNNING
334 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0004_01_000001 transitioned from NEW to SCHEDULED
334 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_INIT for appId application_1692220864940_0004
334 INFO  [ApplicationMasterLauncher #7] amlauncher.AMLauncher (AMLauncher.java:launch(130)) - Done launching container Container: [ContainerId: container_1692220864940_0004_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0004_000001
334 INFO  [NM ContainerManager dispatcher] scheduler.ContainerScheduler (ContainerScheduler.java:startContainer(503)) - Starting container [container_1692220864940_0004_01_000001]
334 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0004_000001 State change from ALLOCATED to LAUNCHED on event = LAUNCHED
341 WARN  [ContainersLauncher #0] launcher.ContainerLaunch (ContainerLaunch.java:call(331)) - Failed to launch container.
341 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0004_01_000001 transitioned from SCHEDULED to EXITED_WITH_FAILURE
341 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(734)) - Cleaning up container container_1692220864940_0004_01_000001
341 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(747)) - Container container_1692220864940_0004_01_000001 not launched. No cleanup needed to be done
342 WARN  [NM ContainerManager dispatcher] nodemanager.NMAuditLogger (NMAuditLogger.java:logFailure(155)) - USER=dr.who	OPERATION=Container Finished - Failed	TARGET=ContainerImpl	RESULT=FAILURE	DESCRIPTION=Container failed with state: EXITED_WITH_FAILURE	APPID=application_1692220864940_0004	CONTAINERID=container_1692220864940_0004_01_000001
343 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0004_01_000001 transitioned from EXITED_WITH_FAILURE to DONE
343 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(512)) - Removing container_1692220864940_0004_01_000001 from application application_1692220864940_0004
343 INFO  [NM ContainerManager dispatcher] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:onStopMonitoringContainer(932)) - Stopping resource-monitoring for container_1692220864940_0004_01_000001
343 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_STOP for appId application_1692220864940_0004
345 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0004_01_000001 Container Transitioned from ACQUIRED to COMPLETED
345 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0004	CONTAINERID=container_1692220864940_0004_01_000001	RESOURCE=<memory:1024, vCores:1>
346 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:rememberTargetTransitionsAndStoreState(1412)) - Updating application attempt appattempt_1692220864940_0004_000001 with final state: FAILED, and exit status: -1
346 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0004_000001 State change from LAUNCHED to FINAL_SAVING on event = CONTAINER_FINISHED
346 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:unregisterAttempt(496)) - Unregistering app attempt : appattempt_1692220864940_0004_000001
346 INFO  [RM Event dispatcher] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:applicationMasterFinished(124)) - Application finished, removing password for appattempt_1692220864940_0004_000001
346 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0004_000001 State change from FINAL_SAVING to FAILED on event = ATTEMPT_UPDATE_SAVED
346 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1538)) - The number of failed attempts is 1. The max attempts is 2
346 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:doneApplicationAttempt(1048)) - Application Attempt appattempt_1692220864940_0004_000001 is done. finalState=FAILED
346 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0004_000002
347 INFO  [SchedulerEventDispatcher:Event Processor] scheduler.AppSchedulingInfo (AppSchedulingInfo.java:clearRequests(159)) - Application application_1692220864940_0004 requests cleared
347 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0004_000002 State change from NEW to SUBMITTED on event = START
347 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:activateApplications(911)) - Application application_1692220864940_0005 from user: dr.who activated in queue: default
347 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:removeApplicationAttempt(1003)) - Application removed - appId: application_1692220864940_0004 user: dr.who queue: default #user-pending-applications: 10 #user-active-applications: 1 #queue-pending-applications: 10 #queue-active-applications: 1
348 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0004 user: dr.who, leaf-queue: default #user-pending-applications: 11 #user-active-applications: 1 #queue-pending-applications: 11 #queue-active-applications: 1
348 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0004_000002 to scheduler from user dr.who in queue default
348 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0004_000002 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
371 INFO  [qtp858952163-31] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0017
371 WARN  [qtp858952163-31] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 17 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
371 INFO  [qtp858952163-31] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 17 submitted by user dr.who
372 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0017
372 INFO  [qtp858952163-31] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0017
372 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0017 State change from NEW to NEW_SAVING on event = START
372 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0017
372 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0017 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
372 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0017 user: dr.who leaf-queue of parent: root #applications: 13
372 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0017 from user: dr.who, in queue: default
373 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0017 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
373 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0017_000001
373 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0017_000001 State change from NEW to SUBMITTED on event = START
374 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0017 user: dr.who, leaf-queue: default #user-pending-applications: 12 #user-active-applications: 1 #queue-pending-applications: 12 #queue-active-applications: 1
374 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0017_000001 to scheduler from user dr.who in queue default
375 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0017_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
517 INFO  [qtp858952163-30] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 18
550 INFO  [qtp858952163-31] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0018
550 WARN  [qtp858952163-31] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 18 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
550 INFO  [qtp858952163-31] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 18 submitted by user dr.who
551 INFO  [qtp858952163-31] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0018
551 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0018
552 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0018
552 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0018 State change from NEW to NEW_SAVING on event = START
552 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0018 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
552 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0018 user: dr.who leaf-queue of parent: root #applications: 14
552 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0018 from user: dr.who, in queue: default
552 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0018 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
552 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0018_000001
553 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0018_000001 State change from NEW to SUBMITTED on event = START
553 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0018 user: dr.who, leaf-queue: default #user-pending-applications: 13 #user-active-applications: 1 #queue-pending-applications: 13 #queue-active-applications: 1
553 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0018_000001 to scheduler from user dr.who in queue default
554 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0018_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
592 WARN  [qtp1616974404-21] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
657 WARN  [qtp1616974404-19] webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR
731 INFO  [qtp858952163-29] nodelabels.CommonNodeLabelsManager (CommonNodeLabelsManager.java:addToCluserNodeLabels(335)) - Add labels: [<default:exclusivity=true>]
840 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
930 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
988 INFO  [qtp858952163-31] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 19
033 INFO  [qtp858952163-29] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0019
034 WARN  [qtp858952163-29] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 19 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
034 INFO  [qtp858952163-29] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 19 submitted by user dr.who
034 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0019
034 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0019
035 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0019 State change from NEW to NEW_SAVING on event = START
034 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0019
035 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0019 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
035 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0019 user: dr.who leaf-queue of parent: root #applications: 15
035 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0019 from user: dr.who, in queue: default
035 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0019 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
036 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0019_000001
036 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0019_000001 State change from NEW to SUBMITTED on event = START
037 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0019 user: dr.who, leaf-queue: default #user-pending-applications: 14 #user-active-applications: 1 #queue-pending-applications: 14 #queue-active-applications: 1
037 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0019_000001 to scheduler from user dr.who in queue default
037 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0019_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
197 INFO  [qtp858952163-29] resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(341)) - Allocated new applicationId: 20
270 INFO  [qtp858952163-26] capacity.CapacityScheduler (CapacityScheduler.java:checkAndGetApplicationPriority(2510)) - Priority '-1' is acceptable in queue : default for application: application_1692220864940_0020
270 WARN  [qtp858952163-26] rmapp.RMAppImpl (RMAppImpl.java:<init>(473)) - The specific max attempts: 0 for application: 20 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
270 INFO  [qtp858952163-26] resourcemanager.ClientRMService (ClientRMService.java:submitApplication(648)) - Application with id 20 submitted by user dr.who
271 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1259)) - Storing application with id application_1692220864940_0020
271 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(270)) - USER=dr.who	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1692220864940_0020
271 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(222)) - Storing info for app: application_1692220864940_0020
271 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0020 State change from NEW to NEW_SAVING on event = START
271 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0020 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED
271 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:addApplication(494)) - Application added - appId: application_1692220864940_0020 user: dr.who leaf-queue of parent: root #applications: 16
271 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplication(953)) - Accepted application application_1692220864940_0020 from user: dr.who, in queue: default
272 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0020 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED
272 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0020_000001
272 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0020_000001 State change from NEW to SUBMITTED on event = START
273 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0020 user: dr.who, leaf-queue: default #user-pending-applications: 15 #user-active-applications: 1 #queue-pending-applications: 15 #queue-active-applications: 1
273 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0020_000001 to scheduler from user dr.who in queue default
274 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0020_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
348 INFO  [Node Status Updater] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:removeOrTrackCompletedContainersFromContext(696)) - Removed completed containers from NM context: [container_1692220864940_0004_01_000001]
348 INFO  [SchedulerEventDispatcher:Event Processor] allocator.AbstractContainerAllocator (AbstractContainerAllocator.java:getCSAssignmentFromAllocateResult(129)) - assignedContainer application attempt=appattempt_1692220864940_0005_000001 container=null queue=default clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
349 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0005_01_000001 Container Transitioned from NEW to ALLOCATED
349 INFO  [SchedulerEventDispatcher:Event Processor] fica.FiCaSchedulerNode (FiCaSchedulerNode.java:allocateContainer(169)) - Assigned container container_1692220864940_0005_01_000001 of capacity <memory:1024, vCores:1> on host 49f255efa79a:41559, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
349 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0005	CONTAINERID=container_1692220864940_0005_01_000001	RESOURCE=<memory:1024, vCores:1>
355 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:createAndGetNMToken(200)) - Sending NMToken for nodeId : 49f255efa79a:41559 for container : container_1692220864940_0005_01_000001
356 INFO  [RM Event dispatcher] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0005_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
356 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:clearNodeSetForAttempt(146)) - Clear node set for appattempt_1692220864940_0005_000001
356 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:storeAttempt(2193)) - Storing attempt: AppId: application_1692220864940_0005 AttemptId: appattempt_1692220864940_0005_000001 MasterContainer: Container: [ContainerId: container_1692220864940_0005_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ]
356 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:apply(1332)) - assignedContainer queue=root usedCapacity=0.125 absoluteUsedCapacity=0.125 used=<memory:1024, vCores:1> cluster=<memory:8192, vCores:8>
356 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:tryCommit(2853)) - Allocation proposal accepted
357 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0005_000001 State change from SCHEDULED to ALLOCATED_SAVING on event = CONTAINER_ALLOCATED
357 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0005_000001 State change from ALLOCATED_SAVING to ALLOCATED on event = ATTEMPT_NEW_SAVED
357 INFO  [ApplicationMasterLauncher #8] amlauncher.AMLauncher (AMLauncher.java:run(307)) - Launching masterappattempt_1692220864940_0005_000001
359 INFO  [ApplicationMasterLauncher #8] amlauncher.AMLauncher (AMLauncher.java:launch(109)) - Setting up container Container: [ContainerId: container_1692220864940_0005_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0005_000001
359 INFO  [ApplicationMasterLauncher #8] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createAndGetAMRMToken(195)) - Create AMRMToken for ApplicationAttempt: appattempt_1692220864940_0005_000001
359 INFO  [ApplicationMasterLauncher #8] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createPassword(307)) - Creating password for appattempt_1692220864940_0005_000001
363 INFO  [Socket Reader #1 for port 41559] ipc.Server (Server.java:saslProcess(1845)) - Auth successful for appattempt_1692220864940_0005_000001 (auth:SIMPLE)
367 INFO  [IPC Server handler 7 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1062)) - Start request for container_1692220864940_0005_01_000001 by user dr.who
369 INFO  [IPC Server handler 7 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1114)) - Creating a new application reference for app application_1692220864940_0005
369 INFO  [IPC Server handler 7 on 41559] nodemanager.NMAuditLogger (NMAuditLogger.java:logSuccess(94)) - USER=dr.who	IP=172.19.0.3	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1692220864940_0005	CONTAINERID=container_1692220864940_0005_01_000001
369 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0005 transitioned from NEW to INITING
369 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(463)) - Adding container_1692220864940_0005_01_000001 to application application_1692220864940_0005
370 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0005 transitioned from INITING to RUNNING
370 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0005_01_000001 transitioned from NEW to SCHEDULED
370 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_INIT for appId application_1692220864940_0005
370 INFO  [ApplicationMasterLauncher #8] amlauncher.AMLauncher (AMLauncher.java:launch(130)) - Done launching container Container: [ContainerId: container_1692220864940_0005_01_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0005_000001
370 INFO  [NM ContainerManager dispatcher] scheduler.ContainerScheduler (ContainerScheduler.java:startContainer(503)) - Starting container [container_1692220864940_0005_01_000001]
371 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0005_000001 State change from ALLOCATED to LAUNCHED on event = LAUNCHED
379 WARN  [ContainersLauncher #0] launcher.ContainerLaunch (ContainerLaunch.java:call(331)) - Failed to launch container.
380 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0005_01_000001 transitioned from SCHEDULED to EXITED_WITH_FAILURE
380 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(734)) - Cleaning up container container_1692220864940_0005_01_000001
380 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(747)) - Container container_1692220864940_0005_01_000001 not launched. No cleanup needed to be done
380 INFO  [qtp858952163-31] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
381 WARN  [NM ContainerManager dispatcher] nodemanager.NMAuditLogger (NMAuditLogger.java:logFailure(155)) - USER=dr.who	OPERATION=Container Finished - Failed	TARGET=ContainerImpl	RESULT=FAILURE	DESCRIPTION=Container failed with state: EXITED_WITH_FAILURE	APPID=application_1692220864940_0005	CONTAINERID=container_1692220864940_0005_01_000001
381 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0005_01_000001 transitioned from EXITED_WITH_FAILURE to DONE
381 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(512)) - Removing container_1692220864940_0005_01_000001 from application application_1692220864940_0005
381 INFO  [NM ContainerManager dispatcher] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:onStopMonitoringContainer(932)) - Stopping resource-monitoring for container_1692220864940_0005_01_000001
382 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_STOP for appId application_1692220864940_0005
384 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0005_01_000001 Container Transitioned from ACQUIRED to COMPLETED
384 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0005	CONTAINERID=container_1692220864940_0005_01_000001	RESOURCE=<memory:1024, vCores:1>
385 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:rememberTargetTransitionsAndStoreState(1412)) - Updating application attempt appattempt_1692220864940_0005_000001 with final state: FAILED, and exit status: -1
385 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0005_000001 State change from LAUNCHED to FINAL_SAVING on event = CONTAINER_FINISHED
385 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:unregisterAttempt(496)) - Unregistering app attempt : appattempt_1692220864940_0005_000001
385 INFO  [RM Event dispatcher] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:applicationMasterFinished(124)) - Application finished, removing password for appattempt_1692220864940_0005_000001
385 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0005_000001 State change from FINAL_SAVING to FAILED on event = ATTEMPT_UPDATE_SAVED
385 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1538)) - The number of failed attempts is 1. The max attempts is 2
386 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:doneApplicationAttempt(1048)) - Application Attempt appattempt_1692220864940_0005_000001 is done. finalState=FAILED
386 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:registerAppAttempt(479)) - Registering app attempt : appattempt_1692220864940_0005_000002
386 INFO  [SchedulerEventDispatcher:Event Processor] scheduler.AppSchedulingInfo (AppSchedulingInfo.java:clearRequests(159)) - Application application_1692220864940_0005 requests cleared
386 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0005_000002 State change from NEW to SUBMITTED on event = START
386 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:activateApplications(911)) - Application application_1692220864940_0004 from user: dr.who activated in queue: default
387 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:removeApplicationAttempt(1003)) - Application removed - appId: application_1692220864940_0005 user: dr.who queue: default #user-pending-applications: 14 #user-active-applications: 1 #queue-pending-applications: 14 #queue-active-applications: 1
388 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:addApplicationAttempt(941)) - Application added - appId: application_1692220864940_0005 user: dr.who, leaf-queue: default #user-pending-applications: 15 #user-active-applications: 1 #queue-pending-applications: 15 #queue-active-applications: 1
388 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:addApplicationAttempt(999)) - Added Application Attempt appattempt_1692220864940_0005_000002 to scheduler from user dr.who in queue default
388 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0005_000002 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED
425 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
578 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
608 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
869 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
870 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
900 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
927 INFO  [qtp858952163-31] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
934 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
942 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
063 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
114 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
190 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
222 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
386 INFO  [Node Status Updater] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:removeOrTrackCompletedContainersFromContext(696)) - Removed completed containers from NM context: [container_1692220864940_0005_01_000001]
387 INFO  [SchedulerEventDispatcher:Event Processor] allocator.AbstractContainerAllocator (AbstractContainerAllocator.java:getCSAssignmentFromAllocateResult(129)) - assignedContainer application attempt=appattempt_1692220864940_0004_000002 container=null queue=default clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
388 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0004_02_000001 Container Transitioned from NEW to ALLOCATED
388 INFO  [SchedulerEventDispatcher:Event Processor] fica.FiCaSchedulerNode (FiCaSchedulerNode.java:allocateContainer(169)) - Assigned container container_1692220864940_0004_02_000001 of capacity <memory:1024, vCores:1> on host 49f255efa79a:41559, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
388 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0004	CONTAINERID=container_1692220864940_0004_02_000001	RESOURCE=<memory:1024, vCores:1>
388 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:apply(1332)) - assignedContainer queue=root usedCapacity=0.125 absoluteUsedCapacity=0.125 used=<memory:1024, vCores:1> cluster=<memory:8192, vCores:8>
388 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:tryCommit(2853)) - Allocation proposal accepted
390 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:createAndGetNMToken(200)) - Sending NMToken for nodeId : 49f255efa79a:41559 for container : container_1692220864940_0004_02_000001
390 INFO  [RM Event dispatcher] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0004_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
390 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:clearNodeSetForAttempt(146)) - Clear node set for appattempt_1692220864940_0004_000002
390 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:storeAttempt(2193)) - Storing attempt: AppId: application_1692220864940_0004 AttemptId: appattempt_1692220864940_0004_000002 MasterContainer: Container: [ContainerId: container_1692220864940_0004_02_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ]
391 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0004_000002 State change from SCHEDULED to ALLOCATED_SAVING on event = CONTAINER_ALLOCATED
391 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0004_000002 State change from ALLOCATED_SAVING to ALLOCATED on event = ATTEMPT_NEW_SAVED
401 INFO  [ApplicationMasterLauncher #9] amlauncher.AMLauncher (AMLauncher.java:run(307)) - Launching masterappattempt_1692220864940_0004_000002
405 INFO  [ApplicationMasterLauncher #9] amlauncher.AMLauncher (AMLauncher.java:launch(109)) - Setting up container Container: [ContainerId: container_1692220864940_0004_02_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0004_000002
405 INFO  [ApplicationMasterLauncher #9] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createAndGetAMRMToken(195)) - Create AMRMToken for ApplicationAttempt: appattempt_1692220864940_0004_000002
405 INFO  [ApplicationMasterLauncher #9] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createPassword(307)) - Creating password for appattempt_1692220864940_0004_000002
407 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
411 INFO  [Socket Reader #1 for port 41559] ipc.Server (Server.java:saslProcess(1845)) - Auth successful for appattempt_1692220864940_0004_000002 (auth:SIMPLE)
427 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
442 INFO  [IPC Server handler 9 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1062)) - Start request for container_1692220864940_0004_02_000001 by user dr.who
444 INFO  [IPC Server handler 9 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1148)) - TimelineService V2.0 is not enabled. Skipping updating flowContext for application application_1692220864940_0004
446 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(463)) - Adding container_1692220864940_0004_02_000001 to application application_1692220864940_0004
446 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0004_02_000001 transitioned from NEW to SCHEDULED
446 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_INIT for appId application_1692220864940_0004
446 INFO  [NM ContainerManager dispatcher] scheduler.ContainerScheduler (ContainerScheduler.java:startContainer(503)) - Starting container [container_1692220864940_0004_02_000001]
452 INFO  [IPC Server handler 9 on 41559] nodemanager.NMAuditLogger (NMAuditLogger.java:logSuccess(94)) - USER=dr.who	IP=172.19.0.3	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1692220864940_0004	CONTAINERID=container_1692220864940_0004_02_000001
456 INFO  [ApplicationMasterLauncher #9] amlauncher.AMLauncher (AMLauncher.java:launch(130)) - Done launching container Container: [ContainerId: container_1692220864940_0004_02_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0004_000002
457 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0004_000002 State change from ALLOCATED to LAUNCHED on event = LAUNCHED
459 WARN  [ContainersLauncher #0] launcher.ContainerLaunch (ContainerLaunch.java:call(331)) - Failed to launch container.
461 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0004_02_000001 transitioned from SCHEDULED to EXITED_WITH_FAILURE
461 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(734)) - Cleaning up container container_1692220864940_0004_02_000001
461 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(747)) - Container container_1692220864940_0004_02_000001 not launched. No cleanup needed to be done
461 WARN  [NM ContainerManager dispatcher] nodemanager.NMAuditLogger (NMAuditLogger.java:logFailure(155)) - USER=dr.who	OPERATION=Container Finished - Failed	TARGET=ContainerImpl	RESULT=FAILURE	DESCRIPTION=Container failed with state: EXITED_WITH_FAILURE	APPID=application_1692220864940_0004	CONTAINERID=container_1692220864940_0004_02_000001
463 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0004_02_000001 transitioned from EXITED_WITH_FAILURE to DONE
463 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
463 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(512)) - Removing container_1692220864940_0004_02_000001 from application application_1692220864940_0004
463 INFO  [NM ContainerManager dispatcher] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:onStopMonitoringContainer(932)) - Stopping resource-monitoring for container_1692220864940_0004_02_000001
463 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_STOP for appId application_1692220864940_0004
466 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0004_02_000001 Container Transitioned from ACQUIRED to COMPLETED
467 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0004	CONTAINERID=container_1692220864940_0004_02_000001	RESOURCE=<memory:1024, vCores:1>
467 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:rememberTargetTransitionsAndStoreState(1412)) - Updating application attempt appattempt_1692220864940_0004_000002 with final state: FAILED, and exit status: -1
467 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0004_000002 State change from LAUNCHED to FINAL_SAVING on event = CONTAINER_FINISHED
468 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:unregisterAttempt(496)) - Unregistering app attempt : appattempt_1692220864940_0004_000002
468 INFO  [RM Event dispatcher] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:applicationMasterFinished(124)) - Application finished, removing password for appattempt_1692220864940_0004_000002
468 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0004_000002 State change from FINAL_SAVING to FAILED on event = ATTEMPT_UPDATE_SAVED
468 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1538)) - The number of failed attempts is 2. The max attempts is 2
468 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:rememberTargetTransitionsAndStoreState(1278)) - Updating application application_1692220864940_0004 with final state: FAILED
468 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0004 State change from ACCEPTED to FINAL_SAVING on event = ATTEMPT_FAILED
468 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(260)) - Updating info for app: application_1692220864940_0004
469 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1197)) - Application application_1692220864940_0004 failed 2 times due to AM Container for appattempt_1692220864940_0004_000002 exited with  exitCode: -1
469 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0004 State change from FINAL_SAVING to FAILED on event = APP_UPDATE_SAVED
469 WARN  [RM Event dispatcher] resourcemanager.RMAuditLogger (RMAuditLogger.java:logFailure(478)) - USER=dr.who	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1692220864940_0004 failed 2 times due to AM Container for appattempt_1692220864940_0004_000002 exited with  exitCode: -1
478 INFO  [RM Event dispatcher] resourcemanager.RMAppManager$ApplicationSummary (RMAppManager.java:logAppSummary(212)) - appId=application_1692220864940_0004,name=,user=dr.who,queue=default,state=FAILED,trackingUrl=http://49f255efa79a:8080/cluster/app/application_1692220864940_0004,appMasterHost=N/A,submitTime=1692220872236,startTime=1692220872236,finishTime=1692220879468,finalStatus=FAILED,memorySeconds=107,vcoreSeconds=0,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=,resourceSeconds=107 MB-seconds\, 0 vcore-seconds,preemptedResourceSeconds=0 MB-seconds\, 0 vcore-seconds
483 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:doneApplicationAttempt(1048)) - Application Attempt appattempt_1692220864940_0004_000002 is done. finalState=FAILED
484 INFO  [SchedulerEventDispatcher:Event Processor] scheduler.AppSchedulingInfo (AppSchedulingInfo.java:clearRequests(159)) - Application application_1692220864940_0004 requests cleared
484 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:activateApplications(911)) - Application application_1692220864940_0005 from user: dr.who activated in queue: default
484 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:removeApplicationAttempt(1003)) - Application removed - appId: application_1692220864940_0004 user: dr.who queue: default #user-pending-applications: 14 #user-active-applications: 1 #queue-pending-applications: 14 #queue-active-applications: 1
484 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:removeApplication(522)) - Application removed - appId: application_1692220864940_0004 user: dr.who leaf-queue of parent: root #applications: 15
492 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
601 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
660 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
663 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
681 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
708 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
741 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
749 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
784 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
810 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
833 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
009 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
026 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
053 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
062 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
087 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
106 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
111 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
137 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
235 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
247 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
267 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
317 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
347 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
423 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
435 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
448 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
459 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
482 INFO  [Node Status Updater] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:removeOrTrackCompletedContainersFromContext(696)) - Removed completed containers from NM context: [container_1692220864940_0004_02_000001]
482 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0004 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
483 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event APPLICATION_STOP for appId application_1692220864940_0004
483 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0004 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
483 INFO  [NM ContainerManager dispatcher] loghandler.NonAggregatingLogHandler (NonAggregatingLogHandler.java:handle(173)) - Scheduling Log Deletion for application: application_1692220864940_0004, with delay of 10800 seconds
485 INFO  [SchedulerEventDispatcher:Event Processor] allocator.AbstractContainerAllocator (AbstractContainerAllocator.java:getCSAssignmentFromAllocateResult(129)) - assignedContainer application attempt=appattempt_1692220864940_0005_000002 container=null queue=default clusterResource=<memory:8192, vCores:8> type=OFF_SWITCH requestedPartition=
485 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0005_02_000001 Container Transitioned from NEW to ALLOCATED
485 INFO  [SchedulerEventDispatcher:Event Processor] fica.FiCaSchedulerNode (FiCaSchedulerNode.java:allocateContainer(169)) - Assigned container container_1692220864940_0005_02_000001 of capacity <memory:1024, vCores:1> on host 49f255efa79a:41559, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
485 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0005	CONTAINERID=container_1692220864940_0005_02_000001	RESOURCE=<memory:1024, vCores:1>
487 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:createAndGetNMToken(200)) - Sending NMToken for nodeId : 49f255efa79a:41559 for container : container_1692220864940_0005_02_000001
487 INFO  [RM Event dispatcher] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0005_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
487 INFO  [RM Event dispatcher] security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:clearNodeSetForAttempt(146)) - Clear node set for appattempt_1692220864940_0005_000002
487 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:storeAttempt(2193)) - Storing attempt: AppId: application_1692220864940_0005 AttemptId: appattempt_1692220864940_0005_000002 MasterContainer: Container: [ContainerId: container_1692220864940_0005_02_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ]
488 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0005_000002 State change from SCHEDULED to ALLOCATED_SAVING on event = CONTAINER_ALLOCATED
488 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:apply(1332)) - assignedContainer queue=root usedCapacity=0.125 absoluteUsedCapacity=0.125 used=<memory:1024, vCores:1> cluster=<memory:8192, vCores:8>
502 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:tryCommit(2853)) - Allocation proposal accepted
501 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
504 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0005_000002 State change from ALLOCATED_SAVING to ALLOCATED on event = ATTEMPT_NEW_SAVED
510 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
542 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
570 INFO  [ApplicationMasterLauncher #10] amlauncher.AMLauncher (AMLauncher.java:run(307)) - Launching masterappattempt_1692220864940_0005_000002
572 INFO  [ApplicationMasterLauncher #10] amlauncher.AMLauncher (AMLauncher.java:launch(109)) - Setting up container Container: [ContainerId: container_1692220864940_0005_02_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0005_000002
572 INFO  [ApplicationMasterLauncher #10] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createAndGetAMRMToken(195)) - Create AMRMToken for ApplicationAttempt: appattempt_1692220864940_0005_000002
572 INFO  [ApplicationMasterLauncher #10] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:createPassword(307)) - Creating password for appattempt_1692220864940_0005_000002
588 INFO  [Socket Reader #1 for port 41559] ipc.Server (Server.java:saslProcess(1845)) - Auth successful for appattempt_1692220864940_0005_000002 (auth:SIMPLE)
610 INFO  [IPC Server handler 5 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1062)) - Start request for container_1692220864940_0005_02_000001 by user dr.who
614 INFO  [IPC Server handler 5 on 41559] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:startContainerInternal(1148)) - TimelineService V2.0 is not enabled. Skipping updating flowContext for application application_1692220864940_0005
614 INFO  [IPC Server handler 5 on 41559] nodemanager.NMAuditLogger (NMAuditLogger.java:logSuccess(94)) - USER=dr.who	IP=172.19.0.3	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1692220864940_0005	CONTAINERID=container_1692220864940_0005_02_000001
614 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(463)) - Adding container_1692220864940_0005_02_000001 to application application_1692220864940_0005
614 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0005_02_000001 transitioned from NEW to SCHEDULED
614 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_INIT for appId application_1692220864940_0005
614 INFO  [NM ContainerManager dispatcher] scheduler.ContainerScheduler (ContainerScheduler.java:startContainer(503)) - Starting container [container_1692220864940_0005_02_000001]
617 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
619 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
620 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
649 WARN  [ContainersLauncher #0] launcher.ContainerLaunch (ContainerLaunch.java:call(331)) - Failed to launch container.
651 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0005_02_000001 transitioned from SCHEDULED to EXITED_WITH_FAILURE
651 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(734)) - Cleaning up container container_1692220864940_0005_02_000001
651 INFO  [NM ContainerManager dispatcher] launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(747)) - Container container_1692220864940_0005_02_000001 not launched. No cleanup needed to be done
652 WARN  [NM ContainerManager dispatcher] nodemanager.NMAuditLogger (NMAuditLogger.java:logFailure(155)) - USER=dr.who	OPERATION=Container Finished - Failed	TARGET=ContainerImpl	RESULT=FAILURE	DESCRIPTION=Container failed with state: EXITED_WITH_FAILURE	APPID=application_1692220864940_0005	CONTAINERID=container_1692220864940_0005_02_000001
653 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_1692220864940_0005_02_000001 transitioned from EXITED_WITH_FAILURE to DONE
653 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(512)) - Removing container_1692220864940_0005_02_000001 from application application_1692220864940_0005
653 INFO  [NM ContainerManager dispatcher] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:onStopMonitoringContainer(932)) - Stopping resource-monitoring for container_1692220864940_0005_02_000001
653 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event CONTAINER_STOP for appId application_1692220864940_0005
664 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
684 INFO  [ApplicationMasterLauncher #10] amlauncher.AMLauncher (AMLauncher.java:launch(130)) - Done launching container Container: [ContainerId: container_1692220864940_0005_02_000001, AllocationRequestId: -1, Version: 0, NodeId: 49f255efa79a:41559, NodeHttpAddress: 49f255efa79a:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 172.19.0.3:41559 }, ExecutionType: GUARANTEED, ] for AM appattempt_1692220864940_0005_000002
684 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0005_000002 State change from ALLOCATED to LAUNCHED on event = LAUNCHED
687 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
696 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
697 INFO  [SchedulerEventDispatcher:Event Processor] rmcontainer.RMContainerImpl (RMContainerImpl.java:handle(490)) - container_1692220864940_0005_02_000001 Container Transitioned from ACQUIRED to COMPLETED
697 INFO  [SchedulerEventDispatcher:Event Processor] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(200)) - USER=dr.who	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1692220864940_0005	CONTAINERID=container_1692220864940_0005_02_000001	RESOURCE=<memory:1024, vCores:1>
699 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:rememberTargetTransitionsAndStoreState(1412)) - Updating application attempt appattempt_1692220864940_0005_000002 with final state: FAILED, and exit status: -1
700 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0005_000002 State change from LAUNCHED to FINAL_SAVING on event = CONTAINER_FINISHED
700 INFO  [RM Event dispatcher] resourcemanager.ApplicationMasterService (ApplicationMasterService.java:unregisterAttempt(496)) - Unregistering app attempt : appattempt_1692220864940_0005_000002
700 INFO  [RM Event dispatcher] security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:applicationMasterFinished(124)) - Application finished, removing password for appattempt_1692220864940_0005_000002
700 INFO  [RM Event dispatcher] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(925)) - appattempt_1692220864940_0005_000002 State change from FINAL_SAVING to FAILED on event = ATTEMPT_UPDATE_SAVED
700 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1538)) - The number of failed attempts is 2. The max attempts is 2
700 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:rememberTargetTransitionsAndStoreState(1278)) - Updating application application_1692220864940_0005 with final state: FAILED
700 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0005 State change from ACCEPTED to FINAL_SAVING on event = ATTEMPT_FAILED
700 INFO  [RM StateStore dispatcher] recovery.RMStateStore (RMStateStore.java:transition(260)) - Updating info for app: application_1692220864940_0005
701 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:transition(1197)) - Application application_1692220864940_0005 failed 2 times due to AM Container for appattempt_1692220864940_0005_000002 exited with  exitCode: -1
701 INFO  [RM Event dispatcher] rmapp.RMAppImpl (RMAppImpl.java:handle(912)) - application_1692220864940_0005 State change from FINAL_SAVING to FAILED on event = APP_UPDATE_SAVED
701 WARN  [RM Event dispatcher] resourcemanager.RMAuditLogger (RMAuditLogger.java:logFailure(478)) - USER=dr.who	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1692220864940_0005 failed 2 times due to AM Container for appattempt_1692220864940_0005_000002 exited with  exitCode: -1
702 INFO  [RM Event dispatcher] resourcemanager.RMAppManager$ApplicationSummary (RMAppManager.java:logAppSummary(212)) - appId=application_1692220864940_0005,name=,user=dr.who,queue=default,state=FAILED,trackingUrl=http://49f255efa79a:8080/cluster/app/application_1692220864940_0005,appMasterHost=N/A,submitTime=1692220872439,startTime=1692220872440,finishTime=1692220880700,finalStatus=FAILED,memorySeconds=252,vcoreSeconds=0,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=,resourceSeconds=252 MB-seconds\, 0 vcore-seconds,preemptedResourceSeconds=0 MB-seconds\, 0 vcore-seconds
717 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
718 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
718 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
718 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:doneApplicationAttempt(1048)) - Application Attempt appattempt_1692220864940_0005_000002 is done. finalState=FAILED
724 INFO  [SchedulerEventDispatcher:Event Processor] scheduler.AppSchedulingInfo (AppSchedulingInfo.java:clearRequests(159)) - Application application_1692220864940_0005 requests cleared
731 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
735 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:activateApplications(911)) - Application application_1692220864940_0006 from user: dr.who activated in queue: default
735 INFO  [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue (LeafQueue.java:removeApplicationAttempt(1003)) - Application removed - appId: application_1692220864940_0005 user: dr.who queue: default #user-pending-applications: 13 #user-active-applications: 1 #queue-pending-applications: 13 #queue-active-applications: 1
736 INFO  [SchedulerEventDispatcher:Event Processor] capacity.ParentQueue (ParentQueue.java:removeApplication(522)) - Application removed - appId: application_1692220864940_0005 user: dr.who leaf-queue of parent: root #applications: 14
741 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
789 INFO  [qtp858952163-244] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
791 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
861 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
874 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
901 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
968 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
969 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
004 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
009 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
012 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
077 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
079 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
115 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
118 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
168 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
172 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
206 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
214 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
218 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
225 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
246 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
260 INFO  [qtp858952163-244] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
262 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
263 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
280 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
292 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
296 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
357 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
367 INFO  [qtp858952163-244] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
368 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
381 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
390 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
391 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
401 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
408 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
410 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
432 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
462 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
469 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
489 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
495 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
512 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
515 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
518 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
519 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
520 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
523 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
529 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
531 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
532 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
537 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
547 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
549 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
563 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
604 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
614 ERROR [SIGTERM handler] nodemanager.NodeManager (LogAdapter.java:error(75)) - RECEIVED SIGNAL 15: SIGTERM
623 INFO  [IPC Server handler 16 on 8031] resourcemanager.ResourceTrackerService (ResourceTrackerService.java:unRegisterNodeManager(752)) - Node with node id : 49f255efa79a:41559 has shutdown, hence unregistering the node.
624 INFO  [RM Event dispatcher] rmnode.RMNodeImpl (RMNodeImpl.java:deactivateNode(1077)) - Deactivating Node 49f255efa79a:41559 as it is now SHUTDOWN
625 INFO  [RM Event dispatcher] rmnode.RMNodeImpl (RMNodeImpl.java:handle(671)) - 49f255efa79a:41559 Node Transitioned from RUNNING to SHUTDOWN
626 INFO  [pool-1-thread-1] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:unRegisterNM(298)) - Successfully Unregistered the Node 49f255efa79a:41559 with ResourceManager.
627 INFO  [SchedulerEventDispatcher:Event Processor] capacity.CapacityScheduler (CapacityScheduler.java:removeNode(1923)) - Removed node 49f255efa79a:41559 clusterResource: <memory:0, vCores:0>
637 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
638 INFO  [pool-1-thread-1] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3569edd5{/,null,UNAVAILABLE}{/node}
656 INFO  [pool-1-thread-1] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@19f21b6b{HTTP/1.1,[http/1.1]}{0.0.0.0:8042}
657 INFO  [pool-1-thread-1] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@69e153c5{/static,file:///tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/,UNAVAILABLE}
661 INFO  [pool-1-thread-1] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:cleanUpApplicationsOnNMShutDown(704)) - Applications still running : [application_1692220864940_0002, application_1692220864940_0003, application_1692220864940_0004, application_1692220864940_0005, application_1692220864940_0007]
662 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0005 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
662 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event APPLICATION_STOP for appId application_1692220864940_0005
662 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0005 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
662 INFO  [NM ContainerManager dispatcher] loghandler.NonAggregatingLogHandler (NonAggregatingLogHandler.java:handle(173)) - Scheduling Log Deletion for application: application_1692220864940_0005, with delay of 10800 seconds
666 INFO  [pool-1-thread-1] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:cleanUpApplicationsOnNMShutDown(720)) - Waiting for Applications to be Finished
671 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0007 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
672 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(350)) - Got event APPLICATION_STOP for appId application_1692220864940_0007
672 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(655)) - Application application_1692220864940_0007 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
672 INFO  [NM ContainerManager dispatcher] loghandler.NonAggregatingLogHandler (NonAggregatingLogHandler.java:handle(173)) - Scheduling Log Deletion for application: application_1692220864940_0007, with delay of 10800 seconds
744 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
762 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
765 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
786 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
799 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
811 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
814 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
816 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
823 INFO  [qtp858952163-246] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
848 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
861 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
862 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
868 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
870 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
874 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
875 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
875 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
874 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
890 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
899 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
905 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
908 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
911 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
917 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
926 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
928 INFO  [qtp858952163-244] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
987 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
988 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
989 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
993 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
021 INFO  [qtp858952163-244] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
032 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
035 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
039 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
045 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
098 INFO  [qtp858952163-244] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
113 INFO  [qtp858952163-246] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
115 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
118 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
123 INFO  [qtp858952163-246] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
123 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
125 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
126 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
134 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
141 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
150 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
188 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
190 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
195 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
196 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
207 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
210 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
223 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
226 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
229 INFO  [qtp858952163-244] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
230 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
234 INFO  [qtp858952163-244] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
229 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
238 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
239 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
243 INFO  [qtp858952163-246] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
246 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
268 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
271 INFO  [qtp858952163-246] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
279 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
282 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
296 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
309 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
312 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
312 INFO  [qtp858952163-247] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
312 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
314 INFO  [qtp858952163-239] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
325 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
332 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
337 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
349 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
349 INFO  [qtp858952163-244] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
358 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
362 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
363 INFO  [qtp858952163-27] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
364 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
364 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
373 INFO  [qtp858952163-247] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
374 INFO  [qtp858952163-30] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
383 INFO  [qtp858952163-24] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
395 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
396 INFO  [qtp858952163-25] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
399 INFO  [qtp858952163-26] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
411 INFO  [qtp858952163-238] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
414 INFO  [qtp858952163-29] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
427 INFO  [qtp858952163-245] resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(335)) - USER=builder	OPERATION=Get Applications Request	TARGET=ClientRMService	RESULT=SUCCESS
668 INFO  [pool-1-thread-1] containermanager.ContainerManagerImpl (ContainerManagerImpl.java:cleanUpApplicationsOnNMShutDown(737)) - Done waiting for Applications to be Finished. Still alive: [application_1692220864940_0002, application_1692220864940_0003, application_1692220864940_0004, application_1692220864940_0005, application_1692220864940_0007]
668 INFO  [pool-1-thread-1] ipc.Server (Server.java:stop(3077)) - Stopping server on 41559
670 INFO  [IPC Server listener on 41559] ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41559
670 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
615 WARN  [Thread-1] util.ShutdownHookManager (ShutdownHookManager.java:run(71)) - ShutdownHook 'CompositeServiceShutdownHook' timeout, java.util.concurrent.TimeoutException
618 WARN  [Container Monitor] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:run(519)) - org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
619 INFO  [pool-1-thread-1] ipc.Server (Server.java:stop(3077)) - Stopping server on 8040
620 INFO  [IPC Server listener on 8040] ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 8040
620 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
621 INFO  [Public Localizer] localizer.ResourceLocalizationService (ResourceLocalizationService.java:run(991)) - Public cache exiting
621 WARN  [Node Resource Monitor] nodemanager.NodeResourceMonitorImpl (NodeResourceMonitorImpl.java:run(167)) - org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl is interrupted. Exiting.
623 INFO  [pool-1-thread-1] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping NodeManager metrics system...
624 INFO  [pool-1-thread-1] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - NodeManager metrics system stopped.
625 INFO  [pool-1-thread-1] impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - NodeManager metrics system shutdown complete.
626 INFO  [pool-1-thread-1] nodemanager.NodeManager (LogAdapter.java:info(51)) - SHUTDOWN_MSG: 
677 ERROR [SIGTERM handler] router.Router (LogAdapter.java:error(75)) - RECEIVED SIGNAL 15: SIGTERM
680 ERROR [Thread[Thread-12,5,main]] delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(696)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
681 INFO  [pool-1-thread-1] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@c1a4620{/,null,UNAVAILABLE}{/cluster}
684 INFO  [pool-1-thread-1] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2c1dc8e{HTTP/1.1,[http/1.1]}{0.0.0.0:8089}
684 INFO  [pool-1-thread-1] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@74e52303{/static,file:///tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/,UNAVAILABLE}
686 INFO  [pool-1-thread-1] rmadmin.RouterRMAdminService (RouterRMAdminService.java:serviceStop(139)) - Stopping Router RMAdminService
687 INFO  [pool-1-thread-1] ipc.Server (Server.java:stop(3077)) - Stopping server on 8052
687 INFO  [IPC Server listener on 8052] ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 8052
687 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
687 INFO  [pool-1-thread-1] clientrm.RouterClientRMService (RouterClientRMService.java:serviceStop(176)) - Stopping Router ClientRMService
687 INFO  [pool-1-thread-1] ipc.Server (Server.java:stop(3077)) - Stopping server on 8050
688 INFO  [IPC Server listener on 8050] ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 8050
688 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
688 INFO  [pool-1-thread-1] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping Router metrics system...
689 INFO  [pool-1-thread-1] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - Router metrics system stopped.
689 INFO  [pool-1-thread-1] impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - Router metrics system shutdown complete.
690 INFO  [pool-1-thread-1] router.Router (LogAdapter.java:info(51)) - SHUTDOWN_MSG: 
745 ERROR [SIGTERM handler] resourcemanager.ResourceManager (LogAdapter.java:error(73)) - RECEIVED SIGNAL 15: SIGTERM
747 ERROR [Thread[Thread-19,5,main]] delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(696)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
748 INFO  [pool-1-thread-1] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@42561fba{/,null,UNAVAILABLE}{/cluster}
750 INFO  [pool-1-thread-1] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3003697{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
750 INFO  [pool-1-thread-1] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@217ed35e{/static,file:///tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes/webapps/static/,UNAVAILABLE}
752 INFO  [pool-1-thread-1] ipc.Server (Server.java:stop(3077)) - Stopping server on 8032
752 INFO  [IPC Server listener on 8032] ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 8032
752 INFO  [pool-1-thread-1] ipc.Server (Server.java:stop(3077)) - Stopping server on 8033
752 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
753 INFO  [IPC Server listener on 8033] ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 8033
753 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
754 INFO  [pool-1-thread-1] resourcemanager.ResourceManager (ResourceManager.java:transitionToStandby(1282)) - Transitioning to standby state
754 WARN  [ApplicationMaster Launcher] amlauncher.ApplicationMasterLauncher (ApplicationMasterLauncher.java:run(122)) - org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
754 INFO  [pool-1-thread-1] ipc.Server (Server.java:stop(3077)) - Stopping server on 8030
756 INFO  [IPC Server listener on 8030] ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 8030
756 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
757 INFO  [pool-1-thread-1] ipc.Server (Server.java:stop(3077)) - Stopping server on 8031
758 INFO  [IPC Server listener on 8031] ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 8031
758 INFO  [Ping Checker] util.AbstractLivelinessMonitor (AbstractLivelinessMonitor.java:run(156)) - NMLivelinessMonitor thread interrupted
759 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
758 ERROR [SchedulerEventDispatcher:Event Processor] event.EventDispatcher (EventDispatcher.java:run(61)) - Returning, interrupted : java.lang.InterruptedException
760 INFO  [pool-1-thread-1] event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(155)) - AsyncDispatcher is draining to stop, ignoring any new events.
760 INFO  [Ping Checker] util.AbstractLivelinessMonitor (AbstractLivelinessMonitor.java:run(156)) - org.apache.hadoop.yarn.server.resourcemanager.rmapp.monitor.RMAppLifetimeMonitor thread interrupted
760 INFO  [Ping Checker] util.AbstractLivelinessMonitor (AbstractLivelinessMonitor.java:run(156)) - AMLivelinessMonitor thread interrupted
760 ERROR [Thread[Thread-27,5,main]] delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(696)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
760 INFO  [Ping Checker] util.AbstractLivelinessMonitor (AbstractLivelinessMonitor.java:run(156)) - org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
760 INFO  [Ping Checker] util.AbstractLivelinessMonitor (AbstractLivelinessMonitor.java:run(156)) - AMLivelinessMonitor thread interrupted
760 INFO  [pool-1-thread-1] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ResourceManager metrics system...
761 INFO  [pool-1-thread-1] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ResourceManager metrics system stopped.
761 INFO  [pool-1-thread-1] impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - ResourceManager metrics system shutdown complete.
761 INFO  [pool-1-thread-1] event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(155)) - AsyncDispatcher is draining to stop, ignoring any new events.
762 INFO  [pool-1-thread-1] resourcemanager.ResourceManager (ResourceManager.java:transitionToStandby(1289)) - Transitioned to standby state
762 INFO  [pool-1-thread-1] resourcemanager.ResourceManager (LogAdapter.java:info(49)) - SHUTDOWN_MSG: . See the dump file /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/target/surefire-reports/2023-08-16T17-56-12_178-jvmRun3.dumpstream
[INFO] Running org.apache.hadoop.yarn.server.router.webapp.TestRouterWebServices
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.011 s - in org.apache.hadoop.yarn.server.router.webapp.TestRouterWebServices
[INFO] Running org.apache.hadoop.yarn.server.router.webapp.TestFederationInterceptorRESTRetry
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.799 s - in org.apache.hadoop.yarn.server.router.webapp.TestFederationInterceptorRESTRetry
[INFO] Running org.apache.hadoop.yarn.server.router.clientrm.TestRouterClientRMService
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.588 s - in org.apache.hadoop.yarn.server.router.clientrm.TestRouterClientRMService
[INFO] Running org.apache.hadoop.yarn.server.router.clientrm.TestFederationClientInterceptor
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.764 s - in org.apache.hadoop.yarn.server.router.clientrm.TestFederationClientInterceptor
[INFO] Running org.apache.hadoop.yarn.server.router.clientrm.TestFederationClientInterceptorRetry
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.721 s - in org.apache.hadoop.yarn.server.router.clientrm.TestFederationClientInterceptorRetry
[INFO] Running org.apache.hadoop.yarn.server.router.TestRouterMetrics
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.147 s - in org.apache.hadoop.yarn.server.router.TestRouterMetrics
[INFO] Running org.apache.hadoop.yarn.server.router.rmadmin.TestRouterRMAdminService
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.445 s - in org.apache.hadoop.yarn.server.router.rmadmin.TestRouterRMAdminService
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 118, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -------------< org.apache.hadoop:hadoop-yarn-applications >-------------
[INFO] Building Apache Hadoop YARN Applications 3.1.1-TDP-0.1.0-SNAPSHOT [44/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-applications ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-applications ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-applications ---
[INFO] 
[INFO] ----< org.apache.hadoop:hadoop-yarn-applications-distributedshell >-----
[INFO] Building Apache Hadoop YARN DistributedShell 3.1.1-TDP-0.1.0-SNAPSHOT [45/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-applications-distributedshell ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-applications-distributedshell ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-applications-distributedshell ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-applications-distributedshell ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-applications-distributedshell ---
[INFO] Compiling 7 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/target/classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/ApplicationMaster.java:[1119,44] [unchecked] unchecked conversion
[WARNING]   required: Collection<ContainerRequest>
  found:    Collection
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/ApplicationMaster.java:[1123,45] [unchecked] unchecked call to removeContainerRequest(T) as a member of the raw type AMRMClientAsync
[WARNING]   where T is a type-variable:
    T extends ContainerRequest declared in class AMRMClientAsync
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/ApplicationMaster.java:[1163,40] [unchecked] unchecked call to addSchedulingRequests(Collection<SchedulingRequest>) as a member of the raw type AMRMClientAsync
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-applications-distributedshell ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-applications-distributedshell ---
[INFO] Compiling 6 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/target/test-classes
[INFO] 
[INFO] --- maven-jar-plugin:2.5:jar (default) @ hadoop-yarn-applications-distributedshell ---
[INFO] Building jar: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/target/hadoop-yarn-applications-distributedshell-3.1.1-TDP-0.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-applications-distributedshell ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShellWithNodeLabels
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.121 s - in org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShellWithNodeLabels
[INFO] Running org.apache.hadoop.yarn.applications.distributedshell.TestDSAppMaster
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.061 s - in org.apache.hadoop.yarn.applications.distributedshell.TestDSAppMaster
[INFO] Running org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] --< org.apache.hadoop:hadoop-yarn-applications-unmanaged-am-launcher >--
[INFO] Building Apache Hadoop YARN Unmanaged Am Launcher 3.1.1-TDP-0.1.0-SNAPSHOT [46/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-applications-unmanaged-am-launcher ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-unmanaged-am-launcher/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-unmanaged-am-launcher (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-applications-unmanaged-am-launcher ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-unmanaged-am-launcher/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-applications-unmanaged-am-launcher ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-applications-unmanaged-am-launcher ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-unmanaged-am-launcher/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-applications-unmanaged-am-launcher ---
[INFO] Compiling 1 source file to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-unmanaged-am-launcher/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-applications-unmanaged-am-launcher ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-applications-unmanaged-am-launcher ---
[INFO] Compiling 1 source file to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-unmanaged-am-launcher/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-applications-unmanaged-am-launcher ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.applications.unmanagedamlauncher.TestUnmanagedAMLauncher
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.937 s - in org.apache.hadoop.yarn.applications.unmanagedamlauncher.TestUnmanagedAMLauncher
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -------------< org.apache.hadoop:hadoop-mapreduce-client >--------------
[INFO] Building Apache Hadoop MapReduce Client 3.1.1-TDP-0.1.0-SNAPSHOT [47/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-mapreduce-client ---
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/target
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-mapreduce-client ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-mapreduce-client ---
[INFO] 
[INFO] -----------< org.apache.hadoop:hadoop-mapreduce-client-core >-----------
[INFO] Building Apache Hadoop MapReduce Core 3.1.1-TDP-0.1.0-SNAPSHOT   [48/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-mapreduce-client-core ---
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/site/resources (includes = [configuration.xsl, mapred-default.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-mapreduce-client-core ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- avro-maven-plugin:1.7.7:protocol (default) @ hadoop-mapreduce-client-core ---
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-mapreduce-client-core ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-mapreduce-client-core ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 8 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-mapreduce-client-core ---
[INFO] Compiling 517 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/classes
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Mapper.java:[26,27] [deprecation] Closeable in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Reducer.java:[28,27] [deprecation] Closeable in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/MapReduceBase.java:[25,27] [deprecation] Closeable in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobEndNotifier.java:[30,36] [deprecation] ClientPNames in org.apache.http.client.params has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobEndNotifier.java:[31,34] [deprecation] DefaultHttpClient in org.apache.http.impl.client has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobEndNotifier.java:[32,29] [deprecation] CoreConnectionPNames in org.apache.http.params has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Application.java:[49,44] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Mapper.java:[135,65] [deprecation] Closeable in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Reducer.java:[168,66] [deprecation] Closeable in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[345,16] [deprecation] getLocalCacheFiles() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[335,16] [deprecation] getLocalCacheArchives() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[300,17] [deprecation] getSymlink() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[301,11] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[301,27] [deprecation] getSymlink(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[308,11] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[308,27] [deprecation] getArchiveClassPaths(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[317,11] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[317,27] [deprecation] getCacheArchives(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[327,11] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[327,27] [deprecation] getCacheFiles(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[337,11] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[337,27] [deprecation] getLocalCacheArchives(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[347,11] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[347,27] [deprecation] getLocalCacheFiles(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[354,11] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[354,27] [deprecation] getFileClassPaths(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[379,27] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[379,43] [deprecation] getArchiveTimestamps(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[388,27] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java:[388,43] [deprecation] getFileTimestamps(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java:[83,7] [deprecation] getLocalCacheFiles() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java:[83,7] [deprecation] getLocalCacheArchives() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java:[83,7] [deprecation] getSymlink() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java:[1122,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java:[1122,20] [deprecation] setCacheArchives(URI[],Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java:[1131,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java:[1131,20] [deprecation] setCacheFiles(URI[],Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java:[1140,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java:[1140,20] [deprecation] addCacheArchive(URI,Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java:[1149,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java:[1149,20] [deprecation] addCacheFile(URI,Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java:[1166,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java:[1181,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/SequenceFileAsBinaryInputFormat.java:[66,16] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/generated-sources/avro/org/apache/hadoop/mapreduce/jobhistory/JobSubmitted.java:[722,130] [unchecked] unchecked cast
[WARNING]   required: Map<CharSequence,CharSequence>
  found:    Object
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java:[72,16] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/generated-sources/avro/org/apache/hadoop/mapreduce/jobhistory/JhCounters.java:[189,143] [unchecked] unchecked cast
[WARNING]   required: List<JhCounterGroup>
  found:    Object
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/generated-sources/avro/org/apache/hadoop/mapreduce/jobhistory/JhCounterGroup.java:[243,138] [unchecked] unchecked cast
[WARNING]   required: List<JhCounter>
  found:    Object
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/reduce/WrappedReducer.java:[211,18] [deprecation] getLocalCacheFiles() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/reduce/WrappedReducer.java:[206,18] [deprecation] getLocalCacheArchives() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/reduce/WrappedReducer.java:[280,19] [deprecation] getSymlink() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/reduce/WrappedReducer.java:[207,26] [deprecation] getLocalCacheArchives() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/reduce/WrappedReducer.java:[212,26] [deprecation] getLocalCacheFiles() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/reduce/WrappedReducer.java:[281,26] [deprecation] getSymlink() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/generated-sources/avro/org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinished.java:[885,118] [unchecked] unchecked cast
[WARNING]   required: List<Integer>
  found:    Object
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/generated-sources/avro/org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinished.java:[886,114] [unchecked] unchecked cast
[WARNING]   required: List<Integer>
  found:    Object
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/generated-sources/avro/org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinished.java:[887,116] [unchecked] unchecked cast
[WARNING]   required: List<Integer>
  found:    Object
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/generated-sources/avro/org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinished.java:[888,122] [unchecked] unchecked cast
[WARNING]   required: List<Integer>
  found:    Object
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/generated-sources/avro/org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletion.java:[832,118] [unchecked] unchecked cast
[WARNING]   required: List<Integer>
  found:    Object
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/generated-sources/avro/org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletion.java:[833,114] [unchecked] unchecked cast
[WARNING]   required: List<Integer>
  found:    Object
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/generated-sources/avro/org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletion.java:[834,116] [unchecked] unchecked cast
[WARNING]   required: List<Integer>
  found:    Object
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/generated-sources/avro/org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletion.java:[835,122] [unchecked] unchecked cast
[WARNING]   required: List<Integer>
  found:    Object
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java:[391,38] [deprecation] getAllStatistics() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java:[531,26] [deprecation] read(DataInput) in TaskAttemptID has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java:[1185,35] [deprecation] getAllStatistics() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/SequenceFileRecordReader.java:[54,14] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/SequenceFileRecordReader.java:[49,14] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/output/SequenceFileOutputFormat.java:[64,23] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType,CompressionCodec,Progressable) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/MapReduceBase.java:[35,38] [deprecation] Closeable in org.apache.hadoop.io has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/map/WrappedMapper.java:[218,18] [deprecation] getLocalCacheFiles() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/map/WrappedMapper.java:[213,18] [deprecation] getLocalCacheArchives() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/map/WrappedMapper.java:[287,19] [deprecation] getSymlink() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/map/WrappedMapper.java:[214,23] [deprecation] getLocalCacheArchives() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/map/WrappedMapper.java:[219,23] [deprecation] getLocalCacheFiles() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/map/WrappedMapper.java:[288,23] [deprecation] getSymlink() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/generated-sources/avro/org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinished.java:[938,118] [unchecked] unchecked cast
[WARNING]   required: List<Integer>
  found:    Object
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/generated-sources/avro/org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinished.java:[939,114] [unchecked] unchecked cast
[WARNING]   required: List<Integer>
  found:    Object
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/generated-sources/avro/org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinished.java:[940,116] [unchecked] unchecked cast
[WARNING]   required: List<Integer>
  found:    Object
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/generated-sources/avro/org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinished.java:[941,122] [unchecked] unchecked cast
[WARNING]   required: List<Integer>
  found:    Object
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/join/CompositeRecordReader.java:[329,17] [deprecation] cloneInto(Writable,Writable) in WritableUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/join/JoinRecordReader.java:[53,19] [deprecation] cloneInto(Writable,Writable) in WritableUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/join/JoinRecordReader.java:[63,21] [deprecation] cloneInto(Writable,Writable) in WritableUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/MapTask.java:[175,50] [unchecked] unchecked conversion
[WARNING]   required: RecordReader<K,V>
  found:    RecordReader
  where K,V are type-variables:
    K extends Object declared in class MapTask.TrackedRecordReader
    V extends Object declared in class MapTask.TrackedRecordReader
/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/MapTask.java:[300,22] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType,Progressable) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/join/WrappedRecordReader.java:[101,17] [deprecation] cloneInto(Writable,Writable) in WritableUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/join/WrappedRecordReader.java:[155,19] [deprecation] cloneInto(Writable,Writable) in WritableUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/join/WrappedRecordReader.java:[156,19] [deprecation] cloneInto(Writable,Writable) in WritableUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java:[322,22] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java:[322,38] [deprecation] getCacheFiles(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java:[337,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java:[337,20] [deprecation] setCacheFiles(URI[],Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java:[489,41] [deprecation] toURL() in File has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java:[309,34] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType,Progressable) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobEndNotifier.java:[70,4] [deprecation] DefaultHttpClient in org.apache.http.impl.client has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobEndNotifier.java:[70,35] [deprecation] DefaultHttpClient in org.apache.http.impl.client has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobEndNotifier.java:[73,26] [deprecation] ClientPNames in org.apache.http.client.params has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobEndNotifier.java:[72,25] [deprecation] CoreConnectionPNames in org.apache.http.params has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/chain/ChainMapContextImpl.java:[216,16] [deprecation] getLocalCacheFiles() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/chain/ChainMapContextImpl.java:[211,16] [deprecation] getLocalCacheArchives() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/chain/ChainMapContextImpl.java:[300,17] [deprecation] getSymlink() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/chain/ChainMapContextImpl.java:[212,15] [deprecation] getLocalCacheArchives() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/chain/ChainMapContextImpl.java:[217,15] [deprecation] getLocalCacheArchives() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/chain/ChainMapContextImpl.java:[301,15] [deprecation] getSymlink() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/SequenceFileOutputFormat.java:[64,18] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType,CompressionCodec,Progressable) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/SequenceFileOutputFormat.java:[94,17] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/SequenceFileAsBinaryOutputFormat.java:[131,18] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType,CompressionCodec,Progressable) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/chain/ChainReduceContextImpl.java:[209,16] [deprecation] getLocalCacheFiles() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/chain/ChainReduceContextImpl.java:[204,16] [deprecation] getLocalCacheArchives() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/chain/ChainReduceContextImpl.java:[293,17] [deprecation] getSymlink() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/chain/ChainReduceContextImpl.java:[205,15] [deprecation] getLocalCacheArchives() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/chain/ChainReduceContextImpl.java:[210,15] [deprecation] getLocalCacheFiles() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/chain/ChainReduceContextImpl.java:[294,15] [deprecation] getSymlink() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/partition/InputSampler.java:[326,45] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/output/NullOutputFormat.java:[54,18] [deprecation] cleanupJob(JobContext) in OutputCommitter has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/MapFileOutputFormat.java:[66,6] [deprecation] Writer(Configuration,FileSystem,String,Class<? extends WritableComparable>,Class,CompressionType,CompressionCodec,Progressable) in Writer has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Application.java:[116,24] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Application.java:[116,40] [deprecation] getLocalCacheFiles(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/output/MapFileOutputFormat.java:[71,6] [deprecation] Writer(Configuration,FileSystem,String,Class<? extends WritableComparable>,Class,CompressionType,CompressionCodec,Progressable) in Writer has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/output/MapFileOutputFormat.java:[108,17] [deprecation] Reader(FileSystem,String,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/join/MultiFilterRecordReader.java:[74,19] [deprecation] cloneInto(Writable,Writable) in WritableUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/join/MultiFilterRecordReader.java:[75,19] [deprecation] cloneInto(Writable,Writable) in WritableUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/join/MultiFilterRecordReader.java:[85,21] [deprecation] cloneInto(Writable,Writable) in WritableUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/join/MultiFilterRecordReader.java:[86,21] [deprecation] cloneInto(Writable,Writable) in WritableUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/join/MultiFilterRecordReader.java:[131,21] [deprecation] cloneInto(Writable,Writable) in WritableUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/join/MultiFilterRecordReader.java:[137,19] [deprecation] cloneInto(Writable,Writable) in WritableUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java:[85,22] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java:[85,38] [deprecation] getCacheArchives(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java:[103,19] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java:[103,35] [deprecation] getCacheFiles(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java:[130,22] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java:[130,38] [deprecation] getCacheArchives(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java:[131,19] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java:[131,35] [deprecation] getCacheFiles(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java:[162,22] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java:[162,38] [deprecation] getCacheArchives(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java:[172,19] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java:[172,35] [deprecation] getCacheFiles(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java:[257,34] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java:[317,30] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-mapreduce-client-core ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 9 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-mapreduce-client-core ---
[INFO] Compiling 60 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-classes
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/TestTaskID.java:[59,37] [deprecation] isMap() in TaskID has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/TestTaskID.java:[62,44] [deprecation] isMap() in TaskID has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/TestTaskID.java:[69,28] [deprecation] isMap() in TaskID has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/lib/output/TestPathOutputCommitter.java:[363,18] [deprecation] getLocalCacheFiles() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/lib/output/TestPathOutputCommitter.java:[358,18] [deprecation] getLocalCacheArchives() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/lib/output/TestPathOutputCommitter.java:[338,19] [deprecation] getSymlink() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/filecache/TestDistributedCache.java:[40,6] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/filecache/TestDistributedCache.java:[40,22] [deprecation] addFileToClassPath(Path,Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/filecache/TestDistributedCache.java:[46,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/filecache/TestDistributedCache.java:[46,20] [deprecation] addFileToClassPath(Path,Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/filecache/TestDistributedCache.java:[52,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/filecache/TestDistributedCache.java:[52,20] [deprecation] addFileToClassPath(Path,Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/filecache/TestDistributedCache.java:[65,6] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/filecache/TestDistributedCache.java:[71,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/filecache/TestDistributedCache.java:[77,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/filecache/TestDistributedCache.java:[89,6] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/filecache/TestDistributedCache.java:[95,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/filecache/TestDistributedCache.java:[101,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/filecache/TestDistributedCache.java:[113,6] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/filecache/TestDistributedCache.java:[119,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/filecache/TestDistributedCache.java:[125,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestQueue.java:[125,50] [deprecation] getQueueState() in JobQueueInfo has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestJobConf.java:[276,29] [deprecation] MAPRED_TASK_MAXVMEM_PROPERTY in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestJobConf.java:[315,19] [deprecation] getMaxVirtualMemoryForTask() in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestJobConf.java:[321,19] [deprecation] getMaxVirtualMemoryForTask() in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestJobConf.java:[328,19] [deprecation] getMaxVirtualMemoryForTask() in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestJobConf.java:[333,19] [deprecation] getMaxVirtualMemoryForTask() in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestJobConf.java:[338,17] [deprecation] setMaxVirtualMemoryForTask(long) in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestJobConf.java:[345,17] [deprecation] setMaxVirtualMemoryForTask(long) in JobConf has been deprecated
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-mapreduce-client-core ---
[INFO] Building jar: /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/hadoop-mapreduce-client-core-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-mapreduce-client-core ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.mapred.TestQueue
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.518 s - in org.apache.hadoop.mapred.TestQueue
[INFO] Running org.apache.hadoop.mapred.TestTask
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.379 s - in org.apache.hadoop.mapred.TestTask
[INFO] Running org.apache.hadoop.mapred.TestJobQueueClient
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.054 s - in org.apache.hadoop.mapred.TestJobQueueClient
[INFO] Running org.apache.hadoop.mapred.TestOldMethodsJobID
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.137 s - in org.apache.hadoop.mapred.TestOldMethodsJobID
[INFO] Running org.apache.hadoop.mapred.TestTaskLog
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.701 s - in org.apache.hadoop.mapred.TestTaskLog
[INFO] Running org.apache.hadoop.mapred.TestClock
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.049 s - in org.apache.hadoop.mapred.TestClock
[INFO] Running org.apache.hadoop.mapred.TestTaskProgressReporter
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 44.8 s - in org.apache.hadoop.mapred.TestTaskProgressReporter
[INFO] Running org.apache.hadoop.mapred.TestJobAclsManager
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.352 s - in org.apache.hadoop.mapred.TestJobAclsManager
[INFO] Running org.apache.hadoop.mapred.TestFileInputFormat
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.933 s - in org.apache.hadoop.mapred.TestFileInputFormat
[INFO] Running org.apache.hadoop.mapred.TestClusterStatus
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.047 s - in org.apache.hadoop.mapred.TestClusterStatus
[INFO] Running org.apache.hadoop.mapred.TestMaster
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.228 s - in org.apache.hadoop.mapred.TestMaster
[INFO] Running org.apache.hadoop.mapred.lib.TestCombineFileRecordReader
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.648 s - in org.apache.hadoop.mapred.lib.TestCombineFileRecordReader
[INFO] Running org.apache.hadoop.mapred.lib.db.TestDBInputFormat
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.576 s - in org.apache.hadoop.mapred.lib.db.TestDBInputFormat
[INFO] Running org.apache.hadoop.mapred.TestMapFileOutputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.255 s - in org.apache.hadoop.mapred.TestMapFileOutputFormat
[INFO] Running org.apache.hadoop.mapred.TestJobConf
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.712 s - in org.apache.hadoop.mapred.TestJobConf
[INFO] Running org.apache.hadoop.mapred.TestJobEndNotifier
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.855 s - in org.apache.hadoop.mapred.TestJobEndNotifier
[INFO] Running org.apache.hadoop.mapred.TestTaskLogAppender
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.135 s - in org.apache.hadoop.mapred.TestTaskLogAppender
[INFO] Running org.apache.hadoop.mapred.TestLineRecordReader
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.483 s - in org.apache.hadoop.mapred.TestLineRecordReader
[INFO] Running org.apache.hadoop.mapred.TestMapTask
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.742 s - in org.apache.hadoop.mapred.TestMapTask
[INFO] Running org.apache.hadoop.mapred.TestSkipBadRecords
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.226 s - in org.apache.hadoop.mapred.TestSkipBadRecords
[INFO] Running org.apache.hadoop.mapred.TestJobInfo
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.255 s - in org.apache.hadoop.mapred.TestJobInfo
[INFO] Running org.apache.hadoop.mapred.TestIndexCache
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.781 s - in org.apache.hadoop.mapred.TestIndexCache
[INFO] Running org.apache.hadoop.mapred.TestCounters
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.325 s - in org.apache.hadoop.mapred.TestCounters
[INFO] Running org.apache.hadoop.mapred.TestFileOutputCommitter
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.888 s - in org.apache.hadoop.mapred.TestFileOutputCommitter
[INFO] Running org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.682 s - in org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager
[INFO] Running org.apache.hadoop.mapreduce.filecache.TestDistributedCache
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.517 s - in org.apache.hadoop.mapreduce.filecache.TestDistributedCache
[INFO] Running org.apache.hadoop.mapreduce.TestShufflePlugin
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.485 s - in org.apache.hadoop.mapreduce.TestShufflePlugin
[INFO] Running org.apache.hadoop.mapreduce.TestTaskID
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.129 s - in org.apache.hadoop.mapreduce.TestTaskID
[INFO] Running org.apache.hadoop.mapreduce.TestJob
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.465 s - in org.apache.hadoop.mapreduce.TestJob
[INFO] Running org.apache.hadoop.mapreduce.TestJobResourceUploaderWithSharedCache
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.848 s - in org.apache.hadoop.mapreduce.TestJobResourceUploaderWithSharedCache
[INFO] Running org.apache.hadoop.mapreduce.TestCluster
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.416 s - in org.apache.hadoop.mapreduce.TestCluster
[INFO] Running org.apache.hadoop.mapreduce.TestContextFactory
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.35 s - in org.apache.hadoop.mapreduce.TestContextFactory
[INFO] Running org.apache.hadoop.mapreduce.lib.jobcontrol.TestJobControl
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.365 s - in org.apache.hadoop.mapreduce.lib.jobcontrol.TestJobControl
[INFO] Running org.apache.hadoop.mapreduce.lib.partition.TestRehashPartitioner
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.115 s - in org.apache.hadoop.mapreduce.lib.partition.TestRehashPartitioner
[INFO] Running org.apache.hadoop.mapreduce.lib.output.TestMapFileOutputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.232 s - in org.apache.hadoop.mapreduce.lib.output.TestMapFileOutputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.986 s - in org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory
[INFO] Running org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitter
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.128 s - in org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitter
[INFO] Running org.apache.hadoop.mapreduce.lib.output.TestFileOutputFormat
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.599 s - in org.apache.hadoop.mapreduce.lib.output.TestFileOutputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.output.TestPreemptableFileOutputCommitter
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.337 s - in org.apache.hadoop.mapreduce.lib.output.TestPreemptableFileOutputCommitter
[INFO] Running org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter
[INFO] Tests run: 21, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.173 s - in org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter
[INFO] Running org.apache.hadoop.mapreduce.lib.db.TestDbClasses
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.441 s - in org.apache.hadoop.mapreduce.lib.db.TestDbClasses
[INFO] Running org.apache.hadoop.mapreduce.lib.db.TestSplitters
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.352 s - in org.apache.hadoop.mapreduce.lib.db.TestSplitters
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestFileInputFormat
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.93 s - in org.apache.hadoop.mapreduce.lib.input.TestFileInputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.645 s - in org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.564 s - in org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader
[INFO] Running org.apache.hadoop.mapreduce.TestJobResourceUploader
[INFO] Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.834 s - in org.apache.hadoop.mapreduce.TestJobResourceUploader
[INFO] Running org.apache.hadoop.mapreduce.TestJobSubmissionFiles
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.515 s - in org.apache.hadoop.mapreduce.TestJobSubmissionFiles
[INFO] Running org.apache.hadoop.mapreduce.jobhistory.TestHistoryViewerPrinter
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.302 s - in org.apache.hadoop.mapreduce.jobhistory.TestHistoryViewerPrinter
[INFO] Running org.apache.hadoop.mapreduce.security.TestTokenCache
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.805 s - in org.apache.hadoop.mapreduce.security.TestTokenCache
[INFO] Running org.apache.hadoop.mapreduce.checkpoint.TestFSCheckpointService
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.32 s - in org.apache.hadoop.mapreduce.checkpoint.TestFSCheckpointService
[INFO] Running org.apache.hadoop.mapreduce.checkpoint.TestFSCheckpointID
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.123 s - in org.apache.hadoop.mapreduce.checkpoint.TestFSCheckpointID
[INFO] Running org.apache.hadoop.mapreduce.tools.TestCLI
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.579 s - in org.apache.hadoop.mapreduce.tools.TestCLI
[INFO] Running org.apache.hadoop.mapreduce.split.TestJobSplitWriter
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.589 s - in org.apache.hadoop.mapreduce.split.TestJobSplitWriter
[INFO] Running org.apache.hadoop.mapreduce.task.reduce.TestFetcher
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.105 s - in org.apache.hadoop.mapreduce.task.reduce.TestFetcher
[INFO] Running org.apache.hadoop.mapreduce.task.reduce.TestEventFetcher
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.261 s - in org.apache.hadoop.mapreduce.task.reduce.TestEventFetcher
[INFO] Running org.apache.hadoop.mapreduce.task.reduce.TestShuffleScheduler
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.444 s - in org.apache.hadoop.mapreduce.task.reduce.TestShuffleScheduler
[INFO] Running org.apache.hadoop.mapreduce.task.reduce.TestMergeManager
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.756 s - in org.apache.hadoop.mapreduce.task.reduce.TestMergeManager
[INFO] Running org.apache.hadoop.mapreduce.task.reduce.TestMerger
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.812 s - in org.apache.hadoop.mapreduce.task.reduce.TestMerger
[INFO] Running org.apache.hadoop.mapreduce.TestJobMonitorAndPrint
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.561 s - in org.apache.hadoop.mapreduce.TestJobMonitorAndPrint
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 306, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ----------< org.apache.hadoop:hadoop-mapreduce-client-common >----------
[INFO] Building Apache Hadoop MapReduce Common 3.1.1-TDP-0.1.0-SNAPSHOT [49/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-mapreduce-client-common ---
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/target
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-mapreduce-client-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:protoc (compile-protoc) @ hadoop-mapreduce-client-common ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-mapreduce-client-common ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-mapreduce-client-common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-mapreduce-client-common ---
[INFO] Compiling 130 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/target/classes
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapred/LocalDistributedCacheManager.java:[48,44] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/util/LocalResourceBuilder.java:[31,44] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/util/MRApps.java:[53,44] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/util/MRApps.java:[310,26] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/util/MRApps.java:[521,26] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/util/MRApps.java:[521,42] [deprecation] getCacheArchives(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/util/MRApps.java:[541,23] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/util/MRApps.java:[541,39] [deprecation] getCacheFiles(Configuration) in DistributedCache has been deprecated
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-mapreduce-client-common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-mapreduce-client-common ---
[INFO] Compiling 12 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/target/test-classes
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/test/java/org/apache/hadoop/mapred/TestLocalDistributedCacheManager.java:[47,44] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/test/java/org/apache/hadoop/mapred/TestMRWithDistributedCache.java:[35,34] [deprecation] DistributedCache in org.apache.hadoop.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/test/java/org/apache/hadoop/mapreduce/v2/util/TestMRApps.java:[48,44] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-mapreduce-client-common ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.mapred.TestMRWithDistributedCache
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.18 s - in org.apache.hadoop.mapred.TestMRWithDistributedCache
[INFO] Running org.apache.hadoop.mapred.TestLocalDistributedCacheManager
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.849 s - in org.apache.hadoop.mapred.TestLocalDistributedCacheManager
[INFO] Running org.apache.hadoop.mapred.TestJobClient
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.788 s - in org.apache.hadoop.mapred.TestJobClient
[INFO] Running org.apache.hadoop.mapred.TestLocalModeWithNewApis
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.067 s - in org.apache.hadoop.mapred.TestLocalModeWithNewApis
[INFO] Running org.apache.hadoop.mapred.TestJobClientGetJob
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.029 s - in org.apache.hadoop.mapred.TestJobClientGetJob
[INFO] Running org.apache.hadoop.mapreduce.TestTypeConverter
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.442 s - in org.apache.hadoop.mapreduce.TestTypeConverter
[INFO] Running org.apache.hadoop.mapreduce.v2.util.TestMRApps
[INFO] Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.897 s - in org.apache.hadoop.mapreduce.v2.util.TestMRApps
[INFO] Running org.apache.hadoop.mapreduce.v2.api.records.TestIds
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.186 s - in org.apache.hadoop.mapreduce.v2.api.records.TestIds
[INFO] Running org.apache.hadoop.mapreduce.v2.jobhistory.TestFileNameIndexUtils
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.216 s - in org.apache.hadoop.mapreduce.v2.jobhistory.TestFileNameIndexUtils
[INFO] Running org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.452 s - in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils
[INFO] Running org.apache.hadoop.mapreduce.v2.TestRecordFactory
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.137 s - in org.apache.hadoop.mapreduce.v2.TestRecordFactory
[INFO] Running org.apache.hadoop.mapreduce.v2.TestRPCFactories
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.47 s - in org.apache.hadoop.mapreduce.v2.TestRPCFactories
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 61, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ---------< org.apache.hadoop:hadoop-mapreduce-client-shuffle >----------
[INFO] Building Apache Hadoop MapReduce Shuffle 3.1.1-TDP-0.1.0-SNAPSHOT [50/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-mapreduce-client-shuffle ---
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/target
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-mapreduce-client-shuffle ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:protoc (compile-protoc) @ hadoop-mapreduce-client-shuffle ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-mapreduce-client-shuffle ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-mapreduce-client-shuffle ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-mapreduce-client-shuffle ---
[INFO] Compiling 4 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-mapreduce-client-shuffle ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-mapreduce-client-shuffle ---
[INFO] Compiling 2 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-mapreduce-client-shuffle ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.mapred.TestFadvisedFileRegion
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.286 s - in org.apache.hadoop.mapred.TestFadvisedFileRegion
[INFO] Running org.apache.hadoop.mapred.TestShuffleHandler
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.569 s - in org.apache.hadoop.mapred.TestShuffleHandler
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -----------< org.apache.hadoop:hadoop-mapreduce-client-app >------------
[INFO] Building Apache Hadoop MapReduce App 3.1.1-TDP-0.1.0-SNAPSHOT    [51/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-mapreduce-client-app ---
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/target
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-mapreduce-client-app ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-mapreduce-client-app ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-mapreduce-client-app ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-mapreduce-client-app ---
[INFO] Compiling 163 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/target/classes
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java:[1619,37] [deprecation] SLOTS_MILLIS_MAPS in JobCounter has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java:[1626,37] [deprecation] SLOTS_MILLIS_REDUCES in JobCounter has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java:[1421,29] [deprecation] SLOTS_MILLIS_MAPS in JobCounter has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java:[1427,29] [deprecation] SLOTS_MILLIS_REDUCES in JobCounter has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java:[155,52] [deprecation] getSessionId() in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java:[346,11] [deprecation] delete(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java:[1258,44] [deprecation] DISABLED_MEMORY_LIMIT in JobConf has been deprecated
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-mapreduce-client-app ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-mapreduce-client-app ---
[INFO] Compiling 59 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/target/test-classes
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestTaskAttempt.java:[415,39] [deprecation] SLOTS_MILLIS_MAPS in JobCounter has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestTaskAttempt.java:[417,39] [deprecation] SLOTS_MILLIS_REDUCES in JobCounter has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestTaskAttempt.java:[1828,36] [deprecation] newInstance(ApplicationAttemptId,int) in ContainerId has been deprecated
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-mapreduce-client-app ---
[INFO] Building jar: /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/target/hadoop-mapreduce-client-app-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-mapreduce-client-app ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.mapred.TestTaskAttemptFinishingMonitor
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.762 s - in org.apache.hadoop.mapred.TestTaskAttemptFinishingMonitor
[INFO] Running org.apache.hadoop.mapred.TestTaskAttemptListenerImpl
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.631 s - in org.apache.hadoop.mapred.TestTaskAttemptListenerImpl
[INFO] Running org.apache.hadoop.mapred.TestLocalContainerLauncher
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.084 s - in org.apache.hadoop.mapred.TestLocalContainerLauncher
[INFO] Running org.apache.hadoop.mapreduce.TestMapreduceConfigFields
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.428 s - in org.apache.hadoop.mapreduce.TestMapreduceConfigFields
[INFO] Running org.apache.hadoop.mapreduce.v2.api.records.TestTaskAttemptReport
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.401 s - in org.apache.hadoop.mapreduce.v2.api.records.TestTaskAttemptReport
[INFO] Running org.apache.hadoop.mapreduce.v2.api.records.TestTaskReport
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.336 s - in org.apache.hadoop.mapreduce.v2.api.records.TestTaskReport
[INFO] Running org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator
[INFO] Tests run: 34, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 48.194 s - in org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator
[INFO] Running org.apache.hadoop.mapreduce.v2.app.rm.TestRMCommunicator
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.365 s - in org.apache.hadoop.mapreduce.v2.app.rm.TestRMCommunicator
[INFO] Running org.apache.hadoop.mapreduce.v2.app.rm.TestResourceCalculatorUtils
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.292 s - in org.apache.hadoop.mapreduce.v2.app.rm.TestResourceCalculatorUtils
[INFO] Running org.apache.hadoop.mapreduce.v2.app.TestKillAMPreemptionPolicy
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.435 s - in org.apache.hadoop.mapreduce.v2.app.TestKillAMPreemptionPolicy
[INFO] Running org.apache.hadoop.mapreduce.v2.app.TestRecovery
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.807 s - in org.apache.hadoop.mapreduce.v2.app.TestRecovery
[INFO] Running org.apache.hadoop.mapreduce.v2.app.TestMRAppComponentDependencies
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.524 s - in org.apache.hadoop.mapreduce.v2.app.TestMRAppComponentDependencies
[INFO] Running org.apache.hadoop.mapreduce.v2.app.TestRuntimeEstimators
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.391 s - in org.apache.hadoop.mapreduce.v2.app.TestRuntimeEstimators
[INFO] Running org.apache.hadoop.mapreduce.v2.app.TestTaskHeartbeatHandler
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.521 s - in org.apache.hadoop.mapreduce.v2.app.TestTaskHeartbeatHandler
[INFO] Running org.apache.hadoop.mapreduce.v2.app.TestFail
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.964 s - in org.apache.hadoop.mapreduce.v2.app.TestFail
[INFO] Running org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempt
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.566 s - in org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempt
[INFO] Running org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.165 s - in org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts
[INFO] Running org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.235 s - in org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf
[INFO] Running org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebApp
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.176 s - in org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebApp
[INFO] Running org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs
[INFO] Tests run: 21, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.08 s - in org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs
[INFO] Running org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.069 s - in org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks
[INFO] Running org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServices
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.849 s - in org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServices
[INFO] Running org.apache.hadoop.mapreduce.v2.app.webapp.TestBlocks
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.581 s - in org.apache.hadoop.mapreduce.v2.app.webapp.TestBlocks
[INFO] Running org.apache.hadoop.mapreduce.v2.app.webapp.TestAppController
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.824 s - in org.apache.hadoop.mapreduce.v2.app.webapp.TestAppController
[INFO] Running org.apache.hadoop.mapreduce.v2.app.speculate.TestDataStatistics
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.05 s - in org.apache.hadoop.mapreduce.v2.app.speculate.TestDataStatistics
[INFO] Running org.apache.hadoop.mapreduce.v2.app.TestMRApp
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.199 s - in org.apache.hadoop.mapreduce.v2.app.TestMRApp
[INFO] Running org.apache.hadoop.mapreduce.v2.app.TestMRClientService
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.244 s - in org.apache.hadoop.mapreduce.v2.app.TestMRClientService
[INFO] Running org.apache.hadoop.mapreduce.v2.app.TestStagingCleanup
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 45.628 s - in org.apache.hadoop.mapreduce.v2.app.TestStagingCleanup
[INFO] Running org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt
[INFO] Tests run: 39, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.85 s - in org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt
[INFO] Running org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskImpl
[INFO] Tests run: 23, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.903 s - in org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskImpl
[INFO] Running org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttemptContainerRequest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.833 s - in org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttemptContainerRequest
[INFO] Running org.apache.hadoop.mapreduce.v2.app.job.impl.TestShuffleProvider
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.832 s - in org.apache.hadoop.mapreduce.v2.app.job.impl.TestShuffleProvider
[INFO] Running org.apache.hadoop.mapreduce.v2.app.job.impl.TestMapReduceChildJVM
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.973 s - in org.apache.hadoop.mapreduce.v2.app.job.impl.TestMapReduceChildJVM
[INFO] Running org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.739 s - in org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl
[INFO] Running org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.717 s - in org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster
[INFO] Running org.apache.hadoop.mapreduce.v2.app.TestKill
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.366 s - in org.apache.hadoop.mapreduce.v2.app.TestKill
[INFO] Running org.apache.hadoop.mapreduce.v2.app.TestJobEndNotifier
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 29.182 s - in org.apache.hadoop.mapreduce.v2.app.TestJobEndNotifier
[INFO] Running org.apache.hadoop.mapreduce.v2.app.local.TestLocalContainerAllocator
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.69 s - in org.apache.hadoop.mapreduce.v2.app.local.TestLocalContainerAllocator
[INFO] Running org.apache.hadoop.mapreduce.v2.app.metrics.TestMRAppMetrics
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.348 s - in org.apache.hadoop.mapreduce.v2.app.metrics.TestMRAppMetrics
[INFO] Running org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.902 s - in org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler
[INFO] Running org.apache.hadoop.mapreduce.v2.app.TestFetchFailure
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.728 s - in org.apache.hadoop.mapreduce.v2.app.TestFetchFailure
[INFO] Running org.apache.hadoop.mapreduce.v2.app.TestCheckpointPreemptionPolicy
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.572 s - in org.apache.hadoop.mapreduce.v2.app.TestCheckpointPreemptionPolicy
[INFO] Running org.apache.hadoop.mapreduce.v2.app.TestAMInfos
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.618 s - in org.apache.hadoop.mapreduce.v2.app.TestAMInfos
[INFO] Running org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncher
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.477 s - in org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncher
[INFO] Running org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncherImpl
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.482 s - in org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncherImpl
[INFO] Running org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.593 s - in org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler
[INFO] Running org.apache.hadoop.mapreduce.jobhistory.TestEvents
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.448 s - in org.apache.hadoop.mapreduce.jobhistory.TestEvents
[INFO] Running org.apache.hadoop.mapreduce.jobhistory.TestJobSummary
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.246 s - in org.apache.hadoop.mapreduce.jobhistory.TestJobSummary
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 392, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ------------< org.apache.hadoop:hadoop-mapreduce-client-hs >------------
[INFO] Building Apache Hadoop MapReduce HistoryServer 3.1.1-TDP-0.1.0-SNAPSHOT [52/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-mapreduce-client-hs ---
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/target
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-mapreduce-client-hs ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-mapreduce-client-hs ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-mapreduce-client-hs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-mapreduce-client-hs ---
[INFO] Compiling 49 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-mapreduce-client-hs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 8 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-mapreduce-client-hs ---
[INFO] Compiling 30 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-mapreduce-client-hs ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerLeveldbStateStoreService
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.766 s - in org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerLeveldbStateStoreService
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.TestCompletedTask
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.396 s - in org.apache.hadoop.mapreduce.v2.hs.TestCompletedTask
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.webapp.TestHSWebApp
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.561 s - in org.apache.hadoop.mapreduce.v2.hs.webapp.TestHSWebApp
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.webapp.dao.TestJobInfo
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.016 s - in org.apache.hadoop.mapreduce.v2.hs.webapp.dao.TestJobInfo
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobsQuery
[INFO] Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.261 s - in org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobsQuery
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.632 s - in org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.296 s - in org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServices
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.831 s - in org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServices
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobs
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.656 s - in org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobs
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.328 s - in org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.73 s - in org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsJobBlock
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.631 s - in org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsJobBlock
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAcls
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.854 s - in org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAcls
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEvents
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.111 s - in org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEvents
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.TestJobIdHistoryFileInfoMap
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.325 s - in org.apache.hadoop.mapreduce.v2.hs.TestJobIdHistoryFileInfoMap
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryServer
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.154 s - in org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryServer
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.TestHistoryFileManagerInitWithNonRunningDFS
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.518 s - in org.apache.hadoop.mapreduce.v2.hs.TestHistoryFileManagerInitWithNonRunningDFS
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.TestJobListCache
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.344 s - in org.apache.hadoop.mapreduce.v2.hs.TestJobListCache
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEntities
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.307 s - in org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEntities
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.TestHistoryFileManager
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.624 s - in org.apache.hadoop.mapreduce.v2.hs.TestHistoryFileManager
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.TestUnnecessaryBlockingOnHistoryFileInfo
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.615 s - in org.apache.hadoop.mapreduce.v2.hs.TestUnnecessaryBlockingOnHistoryFileInfo
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.server.TestHSAdminServer
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.037 s - in org.apache.hadoop.mapreduce.v2.hs.server.TestHSAdminServer
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerFileSystemStateStoreService
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.309 s - in org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerFileSystemStateStoreService
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.TestJHSDelegationTokenSecretManager
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.277 s - in org.apache.hadoop.mapreduce.v2.hs.TestJHSDelegationTokenSecretManager
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.TestJobHistory
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.904 s - in org.apache.hadoop.mapreduce.v2.hs.TestJobHistory
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.104 s - in org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 219, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] --------< org.apache.hadoop:hadoop-mapreduce-client-jobclient >---------
[INFO] Building Apache Hadoop MapReduce JobClient 3.1.1-TDP-0.1.0-SNAPSHOT [53/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-mapreduce-client-jobclient ---
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-mapreduce-client-jobclient ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-mapreduce-client-jobclient ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-mapreduce-client-jobclient ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-mapreduce-client-jobclient ---
[INFO] Compiling 6 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-mapreduce-client-jobclient ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 9 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-mapreduce-client-jobclient ---
[INFO] Compiling 297 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/test-classes
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMiniMRProxyUser.java:[27,31] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/MRCaching.java:[37,44] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMROldApiJobs.java:[42,44] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestNonExistentJob.java:[27,31] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/security/token/delegation/TestDelegationToken.java:[25,31] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/pipes/TestPipes.java:[37,31] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestMapReduceLazyOutput.java:[36,31] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMRAppWithCombiner.java:[43,44] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/join/TestJoinProperties.java:[74,15] [deprecation] Writer(FileSystem,Configuration,Path,Class,Class) in Writer has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/join/TestJoinProperties.java:[77,20] [deprecation] Writer(FileSystem,Configuration,Path,Class,Class) in Writer has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMiniMRClasspath.java:[165,4] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMiniMRClasspath.java:[175,15] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMiniMRClasspath.java:[196,4] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMiniMRClasspath.java:[207,15] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestSequenceFileInputFilter.java:[60,18] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/ClusterMapReduceTestCase.java:[47,10] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/ClusterMapReduceTestCase.java:[91,57] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/ClusterMapReduceTestCase.java:[160,12] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/input/TestMRSequenceFileAsBinaryInputFormat.java:[62,33] [deprecation] Writer(FileSystem,Configuration,Path,Class,Class) in Writer has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/HadoopTestCase.java:[133,10] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/HadoopTestCase.java:[156,22] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestCombineOutputCollector.java:[87,19] [deprecation] contentEquals(Counter) in Counter has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestSequenceFileAsTextInputFormat.java:[68,20] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMiniMRProxyUser.java:[46,10] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMiniMRProxyUser.java:[88,20] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/ReliabilityTest.java:[229,14] [deprecation] getJobID() in RunningJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestLazyOutput.java:[139,4] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestLazyOutput.java:[148,15] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestBadRecords.java:[153,35] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[33,15] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[36,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[38,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[40,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[43,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[46,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[51,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[54,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[57,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[60,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[65,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[70,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[77,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[80,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[83,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[86,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[91,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[96,16] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[103,15] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[106,15] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java:[109,15] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/SortValidator.java:[376,36] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/BigMapOutput.java:[69,18] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestSequenceFileAsBinaryInputFormat.java:[57,6] [deprecation] Writer(FileSystem,Configuration,Path,Class,Class) in Writer has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/lib/TestMultipleOutputs.java:[278,6] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/input/TestMRSequenceFileInputFilter.java:[71,18] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestJobSysDirWithDFS.java:[102,26] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestJobSysDirWithDFS.java:[123,4] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestJobSysDirWithDFS.java:[132,15] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/MRCaching.java:[65,31] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/MRCaching.java:[65,47] [deprecation] getLocalCacheArchives(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/MRCaching.java:[66,28] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/MRCaching.java:[66,44] [deprecation] getLocalCacheFiles(Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/MRCaching.java:[84,26] [deprecation] readLine() in DataInputStream has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/MRCaching.java:[94,26] [deprecation] readLine() in DataInputStream has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/MRCaching.java:[257,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/MRCaching.java:[257,20] [deprecation] addCacheFile(URI,Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/MRCaching.java:[265,6] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/MRCaching.java:[265,22] [deprecation] addCacheArchive(URI,Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMiniMRDFSCaching.java:[39,4] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMiniMRDFSCaching.java:[46,15] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMiniMRWithDFSWithDistinctUsers.java:[44,2] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMiniMRWithDFSWithDistinctUsers.java:[97,13] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMiniMRBringup.java:[32,4] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMiniMRBringup.java:[34,15] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMapOutputType.java:[119,45] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMRJobs.java:[707,51] [deprecation] SLOTS_MILLIS_MAPS in JobCounter has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMRJobs.java:[708,46] [deprecation] SLOTS_MILLIS_MAPS in JobCounter has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMRJobs.java:[913,33] [deprecation] getLocalCacheFiles() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMRJobs.java:[915,36] [deprecation] getLocalCacheArchives() in JobContext has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/input/TestMRSequenceFileAsTextInputFormat.java:[68,20] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/UtilsForTests.java:[512,18] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestReduceFetchFromPartialMem.java:[46,19] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestReduceFetchFromPartialMem.java:[53,20] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/output/TestJobOutputCommitter.java:[86,16] [deprecation] cleanupJob(JobContext) in FileOutputCommitter has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestSequenceFileInputFormat.java:[67,20] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestMapReduce.java:[266,18] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestMapReduce.java:[390,29] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestMapReduce.java:[455,28] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMROldApiJobs.java:[200,4] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/join/TestDatamerge.java:[82,15] [deprecation] Writer(FileSystem,Configuration,Path,Class,Class) in Writer has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/join/TestDatamerge.java:[329,6] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestNonExistentJob.java:[42,10] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestNonExistentJob.java:[77,20] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/TestFileSystem.java:[105,8] [deprecation] CommandFormat(String,int,int,String...) in CommandFormat has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/TestFileSystem.java:[114,9] [deprecation] CommandFormat(String,int,int,String...) in CommandFormat has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/TestFileSystem.java:[117,9] [deprecation] CommandFormat(String,int,int,String...) in CommandFormat has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/TestFileSystem.java:[119,9] [deprecation] CommandFormat(String,int,int,String...) in CommandFormat has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/TestFileSystem.java:[134,18] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestCommandLineJobSubmission.java:[49,4] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestCommandLineJobSubmission.java:[60,15] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestChild.java:[65,42] [deprecation] MAPRED_TASK_JAVA_OPTS in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestChild.java:[66,29] [deprecation] MAPRED_TASK_JAVA_OPTS in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestChild.java:[68,28] [deprecation] MAPRED_TASK_JAVA_OPTS in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestChild.java:[97,42] [deprecation] MAPRED_TASK_JAVA_OPTS in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestChild.java:[98,29] [deprecation] MAPRED_TASK_JAVA_OPTS in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestChild.java:[100,28] [deprecation] MAPRED_TASK_JAVA_OPTS in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestChild.java:[125,22] [deprecation] MAPRED_TASK_JAVA_OPTS in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/security/token/delegation/TestDelegationToken.java:[38,10] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/security/token/delegation/TestDelegationToken.java:[48,18] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/pipes/TestPipes.java:[79,4] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/pipes/TestPipes.java:[86,15] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/pipes/TestPipes.java:[154,25] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/pipes/TestPipes.java:[225,33] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/input/TestCombineFileInputFormat.java:[1828,23] [deprecation] getDefaultBlockSize() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestMapReduceLazyOutput.java:[134,4] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestMapReduceLazyOutput.java:[143,15] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/join/TestJoinDatamerge.java:[69,15] [deprecation] Writer(FileSystem,Configuration,Path,Class,Class) in Writer has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/join/TestJoinDatamerge.java:[298,6] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/join/TestJoinDatamerge.java:[314,30] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/join/TestJoinDatamerge.java:[405,6] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestSpecialCharactersInOutputPath.java:[103,4] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestSpecialCharactersInOutputPath.java:[112,15] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/GenericMRLoadGenerator.java:[152,47] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/GenericMRLoadGenerator.java:[423,36] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/DFSCIOTest.java:[136,29] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMultipleLevelCaching.java:[85,4] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMultipleLevelCaching.java:[115,15] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMultipleLevelCaching.java:[150,55] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/output/TestMRMultipleOutputs.java:[230,6] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/io/TestSequenceFileMergeProgress.java:[73,18] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType,CompressionCodec) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/DistributedFSCheck.java:[106,18] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestComparators.java:[341,45] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestComparators.java:[348,25] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMapRed.java:[314,10] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMapRed.java:[349,40] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMapRed.java:[371,28] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMapRed.java:[424,8] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMapRed.java:[491,18] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMapRed.java:[617,29] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMapRed.java:[681,28] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMapRed.java:[763,47] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/GenericMRLoadGenerator.java:[157,47] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/GenericMRLoadGenerator.java:[439,36] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-mapreduce-client-jobclient ---
[INFO] Building jar: /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/hadoop-mapreduce-client-jobclient-3.1.1-TDP-0.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-mapreduce-client-jobclient ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.conf.TestNoDefaultsJobConf
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.936 s - in org.apache.hadoop.conf.TestNoDefaultsJobConf
[INFO] Running org.apache.hadoop.util.TestMRCJCReflectionUtils
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.257 s - in org.apache.hadoop.util.TestMRCJCReflectionUtils
[INFO] Running org.apache.hadoop.util.TestMRCJCRunJar
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.141 s - in org.apache.hadoop.util.TestMRCJCRunJar
[INFO] Running org.apache.hadoop.io.TestSequenceFileMergeProgress
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.852 s - in org.apache.hadoop.io.TestSequenceFileMergeProgress
[INFO] Running org.apache.hadoop.fs.TestJHLA
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.712 s - in org.apache.hadoop.fs.TestJHLA
[INFO] Running org.apache.hadoop.fs.slive.TestSlive
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.54 s - in org.apache.hadoop.fs.slive.TestSlive
[INFO] Running org.apache.hadoop.fs.TestDFSIO
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.411 s - in org.apache.hadoop.fs.TestDFSIO
[INFO] Running org.apache.hadoop.fs.TestFileSystem
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.692 s - in org.apache.hadoop.fs.TestFileSystem
[INFO] Running org.apache.hadoop.hdfs.TestNNBench
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.659 s - in org.apache.hadoop.hdfs.TestNNBench
[INFO] Running org.apache.hadoop.mapred.jobcontrol.TestLocalJobControl
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.846 s - in org.apache.hadoop.mapred.jobcontrol.TestLocalJobControl
[INFO] Running org.apache.hadoop.mapred.jobcontrol.TestJobControl
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.939 s - in org.apache.hadoop.mapred.jobcontrol.TestJobControl
[INFO] Running org.apache.hadoop.mapred.TestTextOutputFormat
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.687 s - in org.apache.hadoop.mapred.TestTextOutputFormat
[INFO] Running org.apache.hadoop.mapred.TestClusterMapReduceTestCase
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 129.409 s - in org.apache.hadoop.mapred.TestClusterMapReduceTestCase
[INFO] Running org.apache.hadoop.mapred.TestClientRedirect
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.241 s - in org.apache.hadoop.mapred.TestClientRedirect
[INFO] Running org.apache.hadoop.mapred.TestSequenceFileAsBinaryInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.771 s - in org.apache.hadoop.mapred.TestSequenceFileAsBinaryInputFormat
[INFO] Running org.apache.hadoop.mapred.TestMapRed
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.937 s - in org.apache.hadoop.mapred.TestMapRed
[INFO] Running org.apache.hadoop.mapred.TestMiniMRClasspath
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 162.427 s - in org.apache.hadoop.mapred.TestMiniMRClasspath
[INFO] Running org.apache.hadoop.mapred.TestMRIntermediateDataEncryption
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 199.445 s - in org.apache.hadoop.mapred.TestMRIntermediateDataEncryption
[INFO] Running org.apache.hadoop.mapred.TestCombineFileInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.674 s - in org.apache.hadoop.mapred.TestCombineFileInputFormat
[INFO] Running org.apache.hadoop.mapred.TestMiniMRClientCluster
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 41.568 s - in org.apache.hadoop.mapred.TestMiniMRClientCluster
[INFO] Running org.apache.hadoop.mapred.TestClientServiceDelegate
[INFO] Tests run: 26, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.108 s - in org.apache.hadoop.mapred.TestClientServiceDelegate
[INFO] Running org.apache.hadoop.mapred.TestJobSysDirWithDFS
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 93.128 s - in org.apache.hadoop.mapred.TestJobSysDirWithDFS
[INFO] Running org.apache.hadoop.mapred.TestSortedRanges
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.114 s - in org.apache.hadoop.mapred.TestSortedRanges
[INFO] Running org.apache.hadoop.mapred.TestMerge
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 67.793 s - in org.apache.hadoop.mapred.TestMerge
[INFO] Running org.apache.hadoop.mapred.TestTextInputFormat
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.707 s - in org.apache.hadoop.mapred.TestTextInputFormat
[INFO] Running org.apache.hadoop.mapred.TestNetworkedJob
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.341 s - in org.apache.hadoop.mapred.TestNetworkedJob
[INFO] Running org.apache.hadoop.mapred.TestMRTimelineEventHandling
[ERROR] Tests run: 7, Failures: 0, Errors: 4, Skipped: 0, Time elapsed: 552.428 s <<< FAILURE! - in org.apache.hadoop.mapred.TestMRTimelineEventHandling
[ERROR] testMRNewTimelineServiceEventHandling(org.apache.hadoop.mapred.TestMRTimelineEventHandling)  Time elapsed: 98.583 s  <<< ERROR!
java.io.IOException: Job didn't finish in 30 seconds
	at org.apache.hadoop.mapred.UtilsForTests.runJobSucceed(UtilsForTests.java:659)
	at org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling(TestMRTimelineEventHandling.java:224)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[ERROR] testMRNewTimelineServiceEventHandling(org.apache.hadoop.mapred.TestMRTimelineEventHandling)  Time elapsed: 98.265 s  <<< ERROR!
java.io.IOException: Job didn't finish in 30 seconds
	at org.apache.hadoop.mapred.UtilsForTests.runJobSucceed(UtilsForTests.java:659)
	at org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling(TestMRTimelineEventHandling.java:224)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[ERROR] testMRNewTimelineServiceEventHandling(org.apache.hadoop.mapred.TestMRTimelineEventHandling)  Time elapsed: 98.169 s  <<< ERROR!
java.io.IOException: Job didn't finish in 30 seconds
	at org.apache.hadoop.mapred.UtilsForTests.runJobSucceed(UtilsForTests.java:659)
	at org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling(TestMRTimelineEventHandling.java:224)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[ERROR] testMRNewTimelineServiceEventHandling(org.apache.hadoop.mapred.TestMRTimelineEventHandling)  Time elapsed: 98.267 s  <<< ERROR!
java.io.IOException: Job didn't finish in 30 seconds
	at org.apache.hadoop.mapred.UtilsForTests.runJobSucceed(UtilsForTests.java:659)
	at org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling(TestMRTimelineEventHandling.java:224)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:290)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[INFO] Running org.apache.hadoop.mapred.join.TestDatamerge
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.844 s - in org.apache.hadoop.mapred.join.TestDatamerge
[INFO] Running org.apache.hadoop.mapred.join.TestTupleWritable
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.182 s - in org.apache.hadoop.mapred.join.TestTupleWritable
[INFO] Running org.apache.hadoop.mapred.join.TestWrappedRecordReaderClassloader
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.626 s - in org.apache.hadoop.mapred.join.TestWrappedRecordReaderClassloader
[INFO] Running org.apache.hadoop.mapred.TestTaskCommit
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.335 s - in org.apache.hadoop.mapred.TestTaskCommit
[INFO] Running org.apache.hadoop.mapred.TestFixedLengthInputFormat
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 46.88 s - in org.apache.hadoop.mapred.TestFixedLengthInputFormat
[INFO] Running org.apache.hadoop.mapred.TestCombineTextInputFormat
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.8 s - in org.apache.hadoop.mapred.TestCombineTextInputFormat
[INFO] Running org.apache.hadoop.mapred.TestBadRecords
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.023 s - in org.apache.hadoop.mapred.TestBadRecords
[INFO] Running org.apache.hadoop.mapred.TestSpecialCharactersInOutputPath
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.929 s - in org.apache.hadoop.mapred.TestSpecialCharactersInOutputPath
[INFO] Running org.apache.hadoop.mapred.TestMiniMRBringup
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.375 s - in org.apache.hadoop.mapred.TestMiniMRBringup
[INFO] Running org.apache.hadoop.mapred.TestCommandLineJobSubmission
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.031 s - in org.apache.hadoop.mapred.TestCommandLineJobSubmission
[INFO] Running org.apache.hadoop.mapred.TestCombineSequenceFileInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.962 s - in org.apache.hadoop.mapred.TestCombineSequenceFileInputFormat
[INFO] Running org.apache.hadoop.mapred.TestTaskStatus
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.165 s - in org.apache.hadoop.mapred.TestTaskStatus
[INFO] Running org.apache.hadoop.mapred.TestInputPath
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.596 s - in org.apache.hadoop.mapred.TestInputPath
[INFO] Running org.apache.hadoop.mapred.TestStatisticsCollector
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.56 s - in org.apache.hadoop.mapred.TestStatisticsCollector
[INFO] Running org.apache.hadoop.mapred.TestIFile
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.653 s - in org.apache.hadoop.mapred.TestIFile
[INFO] Running org.apache.hadoop.mapred.TestMultipleTextOutputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.662 s - in org.apache.hadoop.mapred.TestMultipleTextOutputFormat
[INFO] Running org.apache.hadoop.mapred.TestUserDefinedCounters
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.249 s - in org.apache.hadoop.mapred.TestUserDefinedCounters
[INFO] Running org.apache.hadoop.mapred.TestConcatenatedCompressedInput
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.069 s - in org.apache.hadoop.mapred.TestConcatenatedCompressedInput
[INFO] Running org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.813 s - in org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat
[INFO] Running org.apache.hadoop.mapred.TestMRCJCJobClient
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.022 s - in org.apache.hadoop.mapred.TestMRCJCJobClient
[INFO] Running org.apache.hadoop.mapred.TestReduceFetch
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 166.622 s - in org.apache.hadoop.mapred.TestReduceFetch
[INFO] Running org.apache.hadoop.mapred.TestReporter
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.336 s - in org.apache.hadoop.mapred.TestReporter
[INFO] Running org.apache.hadoop.mapred.TestSequenceFileInputFilter
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.321 s - in org.apache.hadoop.mapred.TestSequenceFileInputFilter
[INFO] Running org.apache.hadoop.mapred.TestLocalMRNotification
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.146 s - in org.apache.hadoop.mapred.TestLocalMRNotification
[INFO] Running org.apache.hadoop.mapred.TestJobCleanup
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 143.864 s - in org.apache.hadoop.mapred.TestJobCleanup
[INFO] Running org.apache.hadoop.mapred.TestMiniMRChildTask
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 47.909 s - in org.apache.hadoop.mapred.TestMiniMRChildTask
[INFO] Running org.apache.hadoop.mapred.TestMultiFileSplit
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.622 s - in org.apache.hadoop.mapred.TestMultiFileSplit
[INFO] Running org.apache.hadoop.mapred.TestOldCombinerGrouping
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.193 s - in org.apache.hadoop.mapred.TestOldCombinerGrouping
[INFO] Running org.apache.hadoop.mapred.TestUtils
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.057 s - in org.apache.hadoop.mapred.TestUtils
[INFO] Running org.apache.hadoop.mapred.TestReduceTask
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.706 s - in org.apache.hadoop.mapred.TestReduceTask
[INFO] Running org.apache.hadoop.mapred.TestSequenceFileAsTextInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.036 s - in org.apache.hadoop.mapred.TestSequenceFileAsTextInputFormat
[INFO] Running org.apache.hadoop.mapred.TestMapProgress
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.723 s - in org.apache.hadoop.mapred.TestMapProgress
[INFO] Running org.apache.hadoop.mapred.lib.TestLineInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.913 s - in org.apache.hadoop.mapred.lib.TestLineInputFormat
[INFO] Running org.apache.hadoop.mapred.lib.TestChainMapReduce
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.589 s - in org.apache.hadoop.mapred.lib.TestChainMapReduce
[INFO] Running org.apache.hadoop.mapred.lib.aggregate.TestAggregates
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.189 s - in org.apache.hadoop.mapred.lib.aggregate.TestAggregates
[INFO] Running org.apache.hadoop.mapred.lib.TestChain
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.366 s - in org.apache.hadoop.mapred.lib.TestChain
[INFO] Running org.apache.hadoop.mapred.lib.TestMultithreadedMapRunner
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.212 s - in org.apache.hadoop.mapred.lib.TestMultithreadedMapRunner
[INFO] Running org.apache.hadoop.mapred.lib.TestDelegatingInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.901 s - in org.apache.hadoop.mapred.lib.TestDelegatingInputFormat
[INFO] Running org.apache.hadoop.mapred.lib.TestKeyFieldBasedPartitioner
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.252 s - in org.apache.hadoop.mapred.lib.TestKeyFieldBasedPartitioner
[INFO] Running org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15 s - in org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator
[INFO] Running org.apache.hadoop.mapred.lib.TestMultipleOutputs
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.332 s - in org.apache.hadoop.mapred.lib.TestMultipleOutputs
[INFO] Running org.apache.hadoop.mapred.lib.db.TestConstructQuery
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.289 s - in org.apache.hadoop.mapred.lib.db.TestConstructQuery
[INFO] Running org.apache.hadoop.mapred.lib.TestMultipleInputs
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.263 s - in org.apache.hadoop.mapred.lib.TestMultipleInputs
[INFO] Running org.apache.hadoop.mapred.TestFieldSelection
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.202 s - in org.apache.hadoop.mapred.TestFieldSelection
[INFO] Running org.apache.hadoop.mapred.TestMultipleLevelCaching
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.028 s - in org.apache.hadoop.mapred.TestMultipleLevelCaching
[INFO] Running org.apache.hadoop.mapred.TestWritableJobConf
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.398 s - in org.apache.hadoop.mapred.TestWritableJobConf
[INFO] Running org.apache.hadoop.mapred.TestMRCJCFileOutputCommitter
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.673 s - in org.apache.hadoop.mapred.TestMRCJCFileOutputCommitter
[INFO] Running org.apache.hadoop.mapred.TestQueueConfigurationParser
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.161 s - in org.apache.hadoop.mapred.TestQueueConfigurationParser
[INFO] Running org.apache.hadoop.mapred.TestClusterMRNotification
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 62 s - in org.apache.hadoop.mapred.TestClusterMRNotification
[INFO] Running org.apache.hadoop.mapred.TestFileInputFormatPathFilter
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.717 s - in org.apache.hadoop.mapred.TestFileInputFormatPathFilter
[INFO] Running org.apache.hadoop.mapred.TestJobCounters
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 75.757 s - in org.apache.hadoop.mapred.TestJobCounters
[INFO] Running org.apache.hadoop.mapred.TestFileOutputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.404 s - in org.apache.hadoop.mapred.TestFileOutputFormat
[INFO] Running org.apache.hadoop.mapred.TestIFileStreams
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.376 s - in org.apache.hadoop.mapred.TestIFileStreams
[INFO] Running org.apache.hadoop.mapred.TestMRCJCJobConf
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.03 s - in org.apache.hadoop.mapred.TestMRCJCJobConf
[INFO] Running org.apache.hadoop.mapred.TestTaskPerformanceSplits
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.055 s - in org.apache.hadoop.mapred.TestTaskPerformanceSplits
[INFO] Running org.apache.hadoop.mapred.TestMRCJCFileInputFormat
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.938 s - in org.apache.hadoop.mapred.TestMRCJCFileInputFormat
[INFO] Running org.apache.hadoop.mapred.TestLazyOutput
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 118.04 s - in org.apache.hadoop.mapred.TestLazyOutput
[INFO] Running org.apache.hadoop.mapred.TestMiniMRWithDFSWithDistinctUsers
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 182.365 s - in org.apache.hadoop.mapred.TestMiniMRWithDFSWithDistinctUsers
[INFO] Running org.apache.hadoop.mapred.TestResourceMgrDelegate
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.601 s - in org.apache.hadoop.mapred.TestResourceMgrDelegate
[INFO] Running org.apache.hadoop.mapred.TestMiniMRDFSCaching
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.031 s - in org.apache.hadoop.mapred.TestMiniMRDFSCaching
[INFO] Running org.apache.hadoop.mapred.TestJobName
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 111.951 s - in org.apache.hadoop.mapred.TestJobName
[INFO] Running org.apache.hadoop.mapred.TestLineRecordReaderJobs
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.213 s - in org.apache.hadoop.mapred.TestLineRecordReaderJobs
[INFO] Running org.apache.hadoop.mapred.TestGetSplitHosts
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.128 s - in org.apache.hadoop.mapred.TestGetSplitHosts
[INFO] Running org.apache.hadoop.mapred.TestMROpportunisticMaps
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.538 s - in org.apache.hadoop.mapred.TestMROpportunisticMaps
[INFO] Running org.apache.hadoop.mapred.TestCombineOutputCollector
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.956 s - in org.apache.hadoop.mapred.TestCombineOutputCollector
[INFO] Running org.apache.hadoop.mapred.TestKeyValueTextInputFormat
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.721 s - in org.apache.hadoop.mapred.TestKeyValueTextInputFormat
[INFO] Running org.apache.hadoop.mapred.TestJavaSerialization
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.3 s - in org.apache.hadoop.mapred.TestJavaSerialization
[INFO] Running org.apache.hadoop.mapred.TestComparators
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.511 s - in org.apache.hadoop.mapred.TestComparators
[INFO] Running org.apache.hadoop.mapred.TestMultiFileInputFormat
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.178 s - in org.apache.hadoop.mapred.TestMultiFileInputFormat
[INFO] Running org.apache.hadoop.mapred.TestYARNRunner
[INFO] Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.134 s - in org.apache.hadoop.mapred.TestYARNRunner
[INFO] Running org.apache.hadoop.mapred.TestCollect
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.13 s - in org.apache.hadoop.mapred.TestCollect
[INFO] Running org.apache.hadoop.mapred.TestLocalJobSubmission
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.953 s - in org.apache.hadoop.mapred.TestLocalJobSubmission
[INFO] Running org.apache.hadoop.mapred.TestSequenceFileInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.741 s - in org.apache.hadoop.mapred.TestSequenceFileInputFormat
[INFO] Running org.apache.hadoop.mapred.TestMapOutputType
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.334 s - in org.apache.hadoop.mapred.TestMapOutputType
[INFO] Running org.apache.hadoop.mapred.pipes.TestPipesNonJavaInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.714 s - in org.apache.hadoop.mapred.pipes.TestPipesNonJavaInputFormat
[INFO] Running org.apache.hadoop.mapred.pipes.TestPipes
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.032 s - in org.apache.hadoop.mapred.pipes.TestPipes
[INFO] Running org.apache.hadoop.mapred.pipes.TestPipeApplication
[INFO] Running org.apache.hadoop.mapred.TestReduceFetchFromPartialMem
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 58.424 s - in org.apache.hadoop.mapred.TestReduceFetchFromPartialMem
[INFO] Running org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.784 s - in org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService
[INFO] Running org.apache.hadoop.mapreduce.filecache.TestURIFragments
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.125 s - in org.apache.hadoop.mapreduce.filecache.TestURIFragments
[INFO] Running org.apache.hadoop.mapreduce.TestLocalRunner
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.097 s - in org.apache.hadoop.mapreduce.TestLocalRunner
[INFO] Running org.apache.hadoop.mapreduce.TestNewCombinerGrouping
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.103 s - in org.apache.hadoop.mapreduce.TestNewCombinerGrouping
[INFO] Running org.apache.hadoop.mapreduce.TestMRJobClient
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 134.03 s - in org.apache.hadoop.mapreduce.TestMRJobClient
[INFO] Running org.apache.hadoop.mapreduce.TestChild
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 69.048 s - in org.apache.hadoop.mapreduce.TestChild
[INFO] Running org.apache.hadoop.mapreduce.TestMapperReducerCleanup
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.431 s - in org.apache.hadoop.mapreduce.TestMapperReducerCleanup
[INFO] Running org.apache.hadoop.mapreduce.TestMapReduce
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.332 s - in org.apache.hadoop.mapreduce.TestMapReduce
[INFO] Running org.apache.hadoop.mapreduce.lib.jobcontrol.TestMapReduceJobControlWithMocks
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.663 s - in org.apache.hadoop.mapreduce.lib.jobcontrol.TestMapReduceJobControlWithMocks
[INFO] Running org.apache.hadoop.mapreduce.lib.jobcontrol.TestMapReduceJobControl
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 42.546 s - in org.apache.hadoop.mapreduce.lib.jobcontrol.TestMapReduceJobControl
[INFO] Running org.apache.hadoop.mapreduce.lib.jobcontrol.TestControlledJob
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.404 s - in org.apache.hadoop.mapreduce.lib.jobcontrol.TestControlledJob
[INFO] Running org.apache.hadoop.mapreduce.lib.join.TestJoinProperties
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.9 s - in org.apache.hadoop.mapreduce.lib.join.TestJoinProperties
[INFO] Running org.apache.hadoop.mapreduce.lib.join.TestWrappedRRClassloader
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.634 s - in org.apache.hadoop.mapreduce.lib.join.TestWrappedRRClassloader
[INFO] Running org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.177 s - in org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable
[INFO] Running org.apache.hadoop.mapreduce.lib.join.TestJoinDatamerge
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.773 s - in org.apache.hadoop.mapreduce.lib.join.TestJoinDatamerge
[INFO] Running org.apache.hadoop.mapreduce.lib.map.TestMultithreadedMapper
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.365 s - in org.apache.hadoop.mapreduce.lib.map.TestMultithreadedMapper
[INFO] Running org.apache.hadoop.mapreduce.lib.aggregate.TestMapReduceAggregates
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.162 s - in org.apache.hadoop.mapreduce.lib.aggregate.TestMapReduceAggregates
[INFO] Running org.apache.hadoop.mapreduce.lib.chain.TestSingleElementChain
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.266 s - in org.apache.hadoop.mapreduce.lib.chain.TestSingleElementChain
[INFO] Running org.apache.hadoop.mapreduce.lib.chain.TestChainErrors
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.799 s - in org.apache.hadoop.mapreduce.lib.chain.TestChainErrors
[INFO] Running org.apache.hadoop.mapreduce.lib.chain.TestMapReduceChain
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.353 s - in org.apache.hadoop.mapreduce.lib.chain.TestMapReduceChain
[INFO] Running org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedPartitioner
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.243 s - in org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedPartitioner
[INFO] Running org.apache.hadoop.mapreduce.lib.partition.TestBinaryPartitioner
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.271 s - in org.apache.hadoop.mapreduce.lib.partition.TestBinaryPartitioner
[INFO] Running org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedComparator
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.061 s - in org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedComparator
[INFO] Running org.apache.hadoop.mapreduce.lib.partition.TestTotalOrderPartitioner
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.714 s - in org.apache.hadoop.mapreduce.lib.partition.TestTotalOrderPartitioner
[INFO] Running org.apache.hadoop.mapreduce.lib.partition.TestInputSampler
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.454 s - in org.apache.hadoop.mapreduce.lib.partition.TestInputSampler
[INFO] Running org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.144 s - in org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper
[INFO] Running org.apache.hadoop.mapreduce.lib.fieldsel.TestMRFieldSelection
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.117 s - in org.apache.hadoop.mapreduce.lib.fieldsel.TestMRFieldSelection
[INFO] Running org.apache.hadoop.mapreduce.lib.output.TestMRMultipleOutputs
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.503 s - in org.apache.hadoop.mapreduce.lib.output.TestMRMultipleOutputs
[INFO] Running org.apache.hadoop.mapreduce.lib.output.TestMRSequenceFileAsBinaryOutputFormat
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.815 s - in org.apache.hadoop.mapreduce.lib.output.TestMRSequenceFileAsBinaryOutputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.output.TestJobOutputCommitter
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 181.313 s - in org.apache.hadoop.mapreduce.lib.output.TestJobOutputCommitter
[INFO] Running org.apache.hadoop.mapreduce.lib.output.TestMRCJCFileOutputCommitter
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.769 s - in org.apache.hadoop.mapreduce.lib.output.TestMRCJCFileOutputCommitter
[INFO] Running org.apache.hadoop.mapreduce.lib.db.TestDataDrivenDBInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.947 s - in org.apache.hadoop.mapreduce.lib.db.TestDataDrivenDBInputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.db.TestDBOutputFormat
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.407 s - in org.apache.hadoop.mapreduce.lib.db.TestDBOutputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.db.TestIntegerSplitter
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.059 s - in org.apache.hadoop.mapreduce.lib.db.TestIntegerSplitter
[INFO] Running org.apache.hadoop.mapreduce.lib.db.TestTextSplitter
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.127 s - in org.apache.hadoop.mapreduce.lib.db.TestTextSplitter
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestNLineInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.075 s - in org.apache.hadoop.mapreduce.lib.input.TestNLineInputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.694 s - in org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 38.731 s - in org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestCombineTextInputFormat
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.836 s - in org.apache.hadoop.mapreduce.lib.input.TestCombineTextInputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestCombineSequenceFileInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.956 s - in org.apache.hadoop.mapreduce.lib.input.TestCombineSequenceFileInputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsTextInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.63 s - in org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsTextInputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsBinaryInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.798 s - in org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsBinaryInputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileInputFilter
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.78 s - in org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileInputFilter
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.435 s - in org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestDelegatingInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.882 s - in org.apache.hadoop.mapreduce.lib.input.TestDelegatingInputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestMRCJCFileInputFormat
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.907 s - in org.apache.hadoop.mapreduce.lib.input.TestMRCJCFileInputFormat
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestLineRecordReaderJobs
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.263 s - in org.apache.hadoop.mapreduce.lib.input.TestLineRecordReaderJobs
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestMultipleInputs
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.255 s - in org.apache.hadoop.mapreduce.lib.input.TestMultipleInputs
[INFO] Running org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 132.459 s - in org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution
[INFO] Running org.apache.hadoop.mapreduce.v2.TestUberAM
[INFO] Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 553.282 s - in org.apache.hadoop.mapreduce.v2.TestUberAM
[INFO] Running org.apache.hadoop.mapreduce.v2.TestSpeculativeExecutionWithMRApp
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.664 s - in org.apache.hadoop.mapreduce.v2.TestSpeculativeExecutionWithMRApp
[INFO] Running org.apache.hadoop.mapreduce.v2.TestRMNMInfo
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.667 s - in org.apache.hadoop.mapreduce.v2.TestRMNMInfo
[INFO] Running org.apache.hadoop.mapreduce.v2.TestMRJobs
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 470.689 s - in org.apache.hadoop.mapreduce.v2.TestMRJobs
[INFO] Running org.apache.hadoop.mapreduce.v2.TestMROldApiJobs
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 50.287 s - in org.apache.hadoop.mapreduce.v2.TestMROldApiJobs
[INFO] Running org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 37.969 s - in org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities
[INFO] Running org.apache.hadoop.mapreduce.v2.TestNonExistentJob
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.287 s - in org.apache.hadoop.mapreduce.v2.TestNonExistentJob
[INFO] Running org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 87.449 s - in org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler
[INFO] Running org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 77.721 s - in org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner
[INFO] Running org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 112.378 s - in org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser
[INFO] Running org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 43.539 s - in org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService
[INFO] Running org.apache.hadoop.mapreduce.security.TestJHSSecurity
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.419 s - in org.apache.hadoop.mapreduce.security.TestJHSSecurity
[INFO] Running org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 86.022 s - in org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle
[INFO] Running org.apache.hadoop.mapreduce.security.TestUmbilicalProtocolWithJobToken
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.85 s - in org.apache.hadoop.mapreduce.security.TestUmbilicalProtocolWithJobToken
[INFO] Running org.apache.hadoop.mapreduce.security.TestMRCredentials
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.791 s - in org.apache.hadoop.mapreduce.security.TestMRCredentials
[INFO] Running org.apache.hadoop.mapreduce.security.TestBinaryTokenFile
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 59.76 s - in org.apache.hadoop.mapreduce.security.TestBinaryTokenFile
[INFO] Running org.apache.hadoop.mapreduce.security.token.delegation.TestDelegationToken
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.022 s - in org.apache.hadoop.mapreduce.security.token.delegation.TestDelegationToken
[INFO] Running org.apache.hadoop.mapreduce.TestClientProtocolProviderImpls
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.045 s - in org.apache.hadoop.mapreduce.TestClientProtocolProviderImpls
[INFO] Running org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.195 s - in org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider
[INFO] Running org.apache.hadoop.mapreduce.TestMapReduceLazyOutput
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 116.707 s - in org.apache.hadoop.mapreduce.TestMapReduceLazyOutput
[INFO] Running org.apache.hadoop.mapreduce.TestTaskContext
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.032 s - in org.apache.hadoop.mapreduce.TestTaskContext
[INFO] Running org.apache.hadoop.mapreduce.TestMROutputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.111 s - in org.apache.hadoop.mapreduce.TestMROutputFormat
[INFO] Running org.apache.hadoop.mapreduce.TestCounters
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.371 s - in org.apache.hadoop.mapreduce.TestCounters
[INFO] Running org.apache.hadoop.mapreduce.TestValueIterReset
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.15 s - in org.apache.hadoop.mapreduce.TestValueIterReset
[INFO] Running org.apache.hadoop.mapreduce.TestMapCollection
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.616 s - in org.apache.hadoop.mapreduce.TestMapCollection
[INFO] Running org.apache.hadoop.mapreduce.TestLargeSort
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 127.396 s - in org.apache.hadoop.mapreduce.TestLargeSort
[INFO] Running org.apache.hadoop.mapreduce.TestNoJobSetupCleanup
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.031 s - in org.apache.hadoop.mapreduce.TestNoJobSetupCleanup
[INFO] Running org.apache.hadoop.ipc.TestMRCJCSocketFactory
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.854 s - in org.apache.hadoop.ipc.TestMRCJCSocketFactory
[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Errors: 
[ERROR] org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling(org.apache.hadoop.mapred.TestMRTimelineEventHandling)
[ERROR]   Run 1: TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling:224 ? IO Job...
[ERROR]   Run 2: TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling:224 ? IO Job...
[ERROR]   Run 3: TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling:224 ? IO Job...
[ERROR]   Run 4: TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling:224 ? IO Job...
[INFO] 
[INFO] 
[ERROR] Tests run: 564, Failures: 0, Errors: 1, Skipped: 10
[INFO] 
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-minicluster >----------------
[INFO] Building Apache Hadoop Mini-Cluster 3.1.1-TDP-0.1.0-SNAPSHOT     [54/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-minicluster ---
[INFO] Deleting /tdp/hadoop/hadoop-minicluster/target
[INFO] Deleting /tdp/hadoop/hadoop-minicluster (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-minicluster ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-minicluster/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-minicluster ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-minicluster ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-minicluster/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-minicluster ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-minicluster ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-minicluster/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-minicluster ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-minicluster ---
[INFO] 
[INFO] ---------------< org.apache.hadoop:hadoop-yarn-services >---------------
[INFO] Building Apache Hadoop YARN Services 3.1.1-TDP-0.1.0-SNAPSHOT    [55/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-services ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-services ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-services ---
[INFO] 
[INFO] ------------< org.apache.hadoop:hadoop-yarn-services-core >-------------
[INFO] Building Apache Hadoop YARN Services Core 3.1.1-TDP-0.1.0-SNAPSHOT [56/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-services-core ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-services-core ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:protoc (compile-protoc) @ hadoop-yarn-services-core ---
[INFO] Wrote protoc checksums to file /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-services-core ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-services-core ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-services-core ---
[INFO] Compiling 125 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/target/classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ServiceApiUtil.java:[85,19] [unchecked] unchecked conversion
[WARNING]   required: JsonSerDeser<Service>
  found:    JsonSerDeser
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceScheduler.java:[498,34] [deprecation] toString(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceScheduler.java:[820,16] [deprecation] onIncreaseContainerResourceError(ContainerId,Throwable) in AbstractCallbackHandler has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceScheduler.java:[804,26] [deprecation] onContainerResourceIncreased(ContainerId,Resource) in AbstractCallbackHandler has been deprecated
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/ProviderUtils.java:[411,35] [deprecation] write(String,OutputStream) in IOUtils has been deprecated
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-services-core ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 8 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-services-core ---
[INFO] Compiling 25 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/target/test-classes
[WARNING] /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/ServiceTestUtils.java:[171,45] [unchecked] unchecked conversion
[WARNING]   required: JsonSerDeser<Service>
  found:    JsonSerDeser
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/MockServiceAM.java:[244,49] [unchecked] unchecked method invocation: method createAMRMClientAsync in class AMRMClientAsync is applied to given types
[WARNING]   required: AMRMClient<T>,int,AbstractCallbackHandler
  found: AMRMClientImpl,int,ServiceScheduler.AMRMClientCallback
  where T is a type-variable:
    T extends ContainerRequest declared in method <T>createAMRMClientAsync(AMRMClient<T>,int,AbstractCallbackHandler)
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/MockServiceAM.java:[244,50] [unchecked] unchecked conversion
[WARNING]   required: AMRMClient<T>
  found:    AMRMClientImpl
  where T is a type-variable:
    T extends ContainerRequest declared in method <T>createAMRMClientAsync(AMRMClient<T>,int,AbstractCallbackHandler)
/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/MockServiceAM.java:[244,49] [unchecked] unchecked conversion
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-services-core ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.service.conf.TestLoadExampleAppJson
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.728 s - in org.apache.hadoop.yarn.service.conf.TestLoadExampleAppJson
[INFO] Running org.apache.hadoop.yarn.service.conf.TestValidateServiceNames
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.341 s - in org.apache.hadoop.yarn.service.conf.TestValidateServiceNames
[INFO] Running org.apache.hadoop.yarn.service.conf.TestAppJsonResolve
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.705 s - in org.apache.hadoop.yarn.service.conf.TestAppJsonResolve
[INFO] Running org.apache.hadoop.yarn.service.TestYarnNativeServices
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 560.813 s - in org.apache.hadoop.yarn.service.TestYarnNativeServices
[INFO] Running org.apache.hadoop.yarn.service.client.TestServiceClient
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.204 s - in org.apache.hadoop.yarn.service.client.TestServiceClient
[INFO] Running org.apache.hadoop.yarn.service.client.TestServiceCLI
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.482 s - in org.apache.hadoop.yarn.service.client.TestServiceCLI
[INFO] Running org.apache.hadoop.yarn.service.client.TestBuildExternalComponents
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.088 s - in org.apache.hadoop.yarn.service.client.TestBuildExternalComponents
[INFO] Running org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.311 s - in org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe
[INFO] Running org.apache.hadoop.yarn.service.monitor.TestServiceMonitor
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.523 s - in org.apache.hadoop.yarn.service.monitor.TestServiceMonitor
[INFO] Running org.apache.hadoop.yarn.service.TestServiceAM
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.184 s - in org.apache.hadoop.yarn.service.TestServiceAM
[INFO] Running org.apache.hadoop.yarn.service.component.TestComponent
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.055 s - in org.apache.hadoop.yarn.service.component.TestComponent
[INFO] Running org.apache.hadoop.yarn.service.component.TestComponentRestartPolicy
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.265 s - in org.apache.hadoop.yarn.service.component.TestComponentRestartPolicy
[INFO] Running org.apache.hadoop.yarn.service.component.instance.TestComponentInstance
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.138 s - in org.apache.hadoop.yarn.service.component.instance.TestComponentInstance
[INFO] Running org.apache.hadoop.yarn.service.TestServiceApiUtil
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.718 s - in org.apache.hadoop.yarn.service.TestServiceApiUtil
[INFO] Running org.apache.hadoop.yarn.service.containerlaunch.TestAbstractLauncher
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.315 s - in org.apache.hadoop.yarn.service.containerlaunch.TestAbstractLauncher
[INFO] Running org.apache.hadoop.yarn.service.timelineservice.TestServiceTimelinePublisher
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.999 s - in org.apache.hadoop.yarn.service.timelineservice.TestServiceTimelinePublisher
[INFO] Running org.apache.hadoop.yarn.service.providers.TestAbstractClientProvider
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.296 s - in org.apache.hadoop.yarn.service.providers.TestAbstractClientProvider
[INFO] Running org.apache.hadoop.yarn.service.providers.TestProviderFactory
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.09 s - in org.apache.hadoop.yarn.service.providers.TestProviderFactory
[INFO] Running org.apache.hadoop.yarn.service.TestServiceManager
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.27 s - in org.apache.hadoop.yarn.service.TestServiceManager
[INFO] Running org.apache.hadoop.yarn.service.provider.TestProviderUtils
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.387 s - in org.apache.hadoop.yarn.service.provider.TestProviderUtils
[INFO] Running org.apache.hadoop.yarn.service.utils.TestCoreFileSystem
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.584 s - in org.apache.hadoop.yarn.service.utils.TestCoreFileSystem
[INFO] Running org.apache.hadoop.yarn.service.TestDefaultUpgradeComponentsFinder
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.284 s - in org.apache.hadoop.yarn.service.TestDefaultUpgradeComponentsFinder
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 92, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -------------< org.apache.hadoop:hadoop-yarn-services-api >-------------
[INFO] Building Apache Hadoop YARN Services API 3.1.1-TDP-0.1.0-SNAPSHOT [57/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-services-api ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-services-api ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-services-api ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-yarn-services-api ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/scripts
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-yarn-services-api ---
[INFO] Compiling 6 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-yarn-services-api ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 9 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-yarn-services-api ---
[INFO] Compiling 5 source files to /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-yarn-services-api ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.service.client.TestSystemServiceManagerImpl
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.822 s - in org.apache.hadoop.yarn.service.client.TestSystemServiceManagerImpl
[INFO] Running org.apache.hadoop.yarn.service.client.TestApiServiceClient
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.052 s - in org.apache.hadoop.yarn.service.client.TestApiServiceClient
[INFO] Running org.apache.hadoop.yarn.service.TestCleanupAfterKill
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 62.868 s - in org.apache.hadoop.yarn.service.TestCleanupAfterKill
[INFO] Running org.apache.hadoop.yarn.service.TestApiServer
[INFO] Tests run: 29, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.4 s - in org.apache.hadoop.yarn.service.TestApiServer
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 47, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -----------------< org.apache.hadoop:hadoop-yarn-site >-----------------
[INFO] Building Apache Hadoop YARN Site 3.1.1-TDP-0.1.0-SNAPSHOT        [58/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-site ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-site ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-site ---
[INFO] 
[INFO] ------------------< org.apache.hadoop:hadoop-yarn-ui >------------------
[INFO] Building Apache Hadoop YARN UI 3.1.1-TDP-0.1.0-SNAPSHOT          [59/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:3.0.0:clean (default-clean) @ hadoop-yarn-ui ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/target
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-ui ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-ui ---
[INFO] 
[INFO] ---------------< org.apache.hadoop:hadoop-yarn-project >----------------
[INFO] Building Apache Hadoop YARN Project 3.1.1-TDP-0.1.0-SNAPSHOT     [60/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-yarn-project ---
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project/target
[INFO] Deleting /tdp/hadoop/hadoop-yarn-project (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-yarn-project ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-yarn-project/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-yarn-project ---
[INFO] 
[INFO] --------< org.apache.hadoop:hadoop-mapreduce-client-hs-plugins >--------
[INFO] Building Apache Hadoop MapReduce HistoryServer Plugins 3.1.1-TDP-0.1.0-SNAPSHOT [61/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-mapreduce-client-hs-plugins ---
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins/target
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-mapreduce-client-hs-plugins ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-mapreduce-client-hs-plugins ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-mapreduce-client-hs-plugins ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-mapreduce-client-hs-plugins ---
[INFO] Compiling 1 source file to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-mapreduce-client-hs-plugins ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-mapreduce-client-hs-plugins ---
[INFO] Compiling 1 source file to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-mapreduce-client-hs-plugins ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.mapreduce.v2.hs.webapp.TestMapReduceTrackingUriPlugin
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.309 s - in org.apache.hadoop.mapreduce.v2.hs.webapp.TestMapReduceTrackingUriPlugin
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] --------< org.apache.hadoop:hadoop-mapreduce-client-nativetask >--------
[INFO] Building Apache Hadoop MapReduce NativeTask 3.1.1-TDP-0.1.0-SNAPSHOT [62/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-mapreduce-client-nativetask ---
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-mapreduce-client-nativetask ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-enforcer-plugin:3.0.0-M1:enforce (enforce-os) @ hadoop-mapreduce-client-nativetask ---
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-mapreduce-client-nativetask ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-mapreduce-client-nativetask ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-mapreduce-client-nativetask ---
[INFO] Compiling 57 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/classes
[INFO] 
[INFO] --- native-maven-plugin:1.0-alpha-8:javah (default) @ hadoop-mapreduce-client-nativetask ---
[INFO] /bin/sh -c cd /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask && /usr/lib/jvm/java-8-openjdk-amd64/bin/javah -d /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/native/javah -classpath /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/classes:/tdp/hadoop/hadoop-common-project/hadoop-common/target/classes:/home/builder/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/builder/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/builder/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/builder/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/builder/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/builder/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-server/9.3.19.v20170502/jetty-server-9.3.19.v20170502.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-http/9.3.19.v20170502/jetty-http-9.3.19.v20170502.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-io/9.3.19.v20170502/jetty-io-9.3.19.v20170502.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-util/9.3.19.v20170502/jetty-util-9.3.19.v20170502.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.19.v20170502/jetty-servlet-9.3.19.v20170502.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-security/9.3.19.v20170502/jetty-security-9.3.19.v20170502.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.19.v20170502/jetty-webapp-9.3.19.v20170502.jar:/home/builder/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.19.v20170502/jetty-xml-9.3.19.v20170502.jar:/home/builder/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/builder/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/builder/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/builder/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/builder/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/builder/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/builder/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/builder/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/builder/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/builder/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/builder/.m2/repository/commons-beanutils/commons-beanutils/1.9.3/commons-beanutils-1.9.3.jar:/home/builder/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/builder/.m2/repository/org/apache/commons/commons-lang3/3.4/commons-lang3-3.4.jar:/home/builder/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/builder/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/tdp/hadoop/hadoop-common-project/hadoop-auth/target/classes:/home/builder/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/builder/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/builder/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/builder/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/builder/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/builder/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/builder/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/builder/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/builder/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/builder/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/builder/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/builder/.m2/repository/org/apache/zookeeper/zookeeper/3.4.9/zookeeper-3.4.9.jar:/home/builder/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/builder/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/builder/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/builder/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.7.8/jackson-databind-2.7.8.jar:/home/builder/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.7.8/jackson-core-2.7.8.jar:/home/builder/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/builder/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/classes:/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/target/classes:/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/classes:/tdp/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes:/home/builder/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/builder/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/builder/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/builder/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.7.8/jackson-module-jaxb-annotations-2.7.8.jar:/home/builder/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.7.8/jackson-jaxrs-json-provider-2.7.8.jar:/home/builder/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.7.8/jackson-jaxrs-base-2.7.8.jar:/home/builder/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/builder/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/builder/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/builder/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/builder/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/tdp/hadoop/hadoop-common-project/hadoop-annotations/target/classes:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/builder/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.7.8/jackson-annotations-2.7.8.jar:/home/builder/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/builder/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/builder/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/builder/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/builder/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar org.apache.hadoop.mapred.nativetask.NativeBatchProcessor org.apache.hadoop.mapred.nativetask.NativeRuntime
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (make) @ hadoop-mapreduce-client-nativetask ---
[INFO] Executing tasks

main:
     [copy] Copying 1 file to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/native
     [copy] Copying 1 file to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/native
     [copy] Copying 1 file to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/native/test/testData
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:cmake-compile (cmake-compile) @ hadoop-mapreduce-client-nativetask ---
[INFO] Running cmake /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src -DGENERATED_JAVAH=/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/native/javah -DJVM_ARCH_DATA_MODEL=64 -DREQUIRE_SNAPPY=true -DREQUIRE_ZSTD=true -G Unix Makefiles
[INFO] with extra environment variables {}
[INFO] Running make -j 8 VERBOSE=1
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:23:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/handler/MCollectorOutputHandler.cc:24:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:30:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/handler/MCollectorOutputHandler.cc:24:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:127:36: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void spill(IFileWriter * writer) throw (IOException, UnsupportException);
[WARNING]                                     ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:23:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/handler/MCollectorOutputHandler.cc:24:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:30:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/handler/MCollectorOutputHandler.cc:24:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:127:36: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void spill(IFileWriter * writer) throw (IOException, UnsupportException);
[WARNING]                                     ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:23:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/handler/AbstractMapHandler.cc:23:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:30:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/handler/AbstractMapHandler.cc:23:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:127:36: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void spill(IFileWriter * writer) throw (IOException, UnsupportException);
[WARNING]                                     ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:23:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/handler/AbstractMapHandler.cc:23:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:30:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/handler/AbstractMapHandler.cc:23:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:127:36: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void spill(IFileWriter * writer) throw (IOException, UnsupportException);
[WARNING]                                     ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:23:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.cc:23:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.cc:23:0:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:127:36: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void spill(IFileWriter * writer) throw (IOException, UnsupportException);
[WARNING]                                     ^~~~~
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.cc:43:3: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    throw(IOException, UnsupportException) {
[WARNING]    ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucketIterator.h:23:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucketIterator.cc:25:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucketIterator.h:30:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucketIterator.cc:25:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:127:36: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void spill(IFileWriter * writer) throw (IOException, UnsupportException);
[WARNING]                                     ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucketIterator.h:23:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucketIterator.cc:25:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/FileSystem.cc: In member function 'virtual void NativeTask::RawFileSystem::remove(const string&)':
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/FileSystem.cc:198:17: warning: ignoring return value of 'char* strerror_r(int, char*, size_t)', declared with attribute warn_unused_result [-Wunused-result]
[WARNING]        strerror_r(err, buff, 256);
[WARNING]        ~~~~~~~~~~^~~~~~~~~~~~~~~~
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/FileSystem.cc: In member function 'virtual uint64_t NativeTask::RawFileSystem::getLength(const string&)':
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/FileSystem.cc:153:17: warning: ignoring return value of 'char* strerror_r(int, char*, size_t)', declared with attribute warn_unused_result [-Wunused-result]
[WARNING]        strerror_r(errno, buff, 256);
[WARNING]        ~~~~~~~~~~^~~~~~~~~~~~~~~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:23:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.cc:23:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucketIterator.h:30:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucketIterator.cc:25:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:127:36: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void spill(IFileWriter * writer) throw (IOException, UnsupportException);
[WARNING]                                     ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.cc:23:0:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:127:36: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void spill(IFileWriter * writer) throw (IOException, UnsupportException);
[WARNING]                                     ^~~~~
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.cc:43:3: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    throw(IOException, UnsupportException) {
[WARNING]    ^~~~~
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:305:9: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]      LOG("%s-spill: { id: %d, collect: %"PRIu64" ms, "
[WARNING]          ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:306:9: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]          "in-memory sort: %"PRIu64" ms, in-memory records: %"PRIu64", "
[WARNING]          ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:306:34: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]          "in-memory sort: %"PRIu64" ms, in-memory records: %"PRIu64", "
[WARNING]                                   ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:307:9: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]          "merge&spill: %"PRIu64" ms, uncompressed size: %"PRIu64", "
[WARNING]          ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:307:31: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]          "merge&spill: %"PRIu64" ms, uncompressed size: %"PRIu64", "
[WARNING]                                ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:308:9: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]          "real size: %"PRIu64" path: %s }",
[WARNING]          ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:373:7: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]    LOG("Final-merge-spill: { id: %d, in-memory sort: %"PRIu64" ms, "
[WARNING]        ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:374:7: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]        "in-memory records: %"PRIu64", merge&spill: %"PRIu64" ms, "
[WARNING]        ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:374:35: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]        "in-memory records: %"PRIu64", merge&spill: %"PRIu64" ms, "
[WARNING]                                    ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:375:7: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]        "records: %"PRIu64", uncompressed size: %"PRIu64", "
[WARNING]        ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:375:25: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]        "records: %"PRIu64", uncompressed size: %"PRIu64", "
[WARNING]                          ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:376:7: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]        "real size: %"PRIu64" path: %s }",
[WARNING]        ^
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:23:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:26:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:30:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:26:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:127:36: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void spill(IFileWriter * writer) throw (IOException, UnsupportException);
[WARNING]                                     ^~~~~
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/FileSystem.cc: In member function 'virtual void NativeTask::RawFileSystem::remove(const string&)':
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/FileSystem.cc:198:17: warning: ignoring return value of 'char* strerror_r(int, char*, size_t)', declared with attribute warn_unused_result [-Wunused-result]
[WARNING]        strerror_r(err, buff, 256);
[WARNING]        ~~~~~~~~~~^~~~~~~~~~~~~~~~
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/FileSystem.cc: In member function 'virtual uint64_t NativeTask::RawFileSystem::getLength(const string&)':
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/FileSystem.cc:153:17: warning: ignoring return value of 'char* strerror_r(int, char*, size_t)', declared with attribute warn_unused_result [-Wunused-result]
[WARNING]        strerror_r(errno, buff, 256);
[WARNING]        ~~~~~~~~~~^~~~~~~~~~~~~~~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryBlock.cc:31:0:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:23:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/Merge.h:24,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/Merge.cc:22:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:30:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/Merge.h:24,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/Merge.cc:22:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:127:36: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void spill(IFileWriter * writer) throw (IOException, UnsupportException);
[WARNING]                                     ^~~~~
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:305:9: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]      LOG("%s-spill: { id: %d, collect: %"PRIu64" ms, "
[WARNING]          ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:306:9: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]          "in-memory sort: %"PRIu64" ms, in-memory records: %"PRIu64", "
[WARNING]          ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:306:34: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]          "in-memory sort: %"PRIu64" ms, in-memory records: %"PRIu64", "
[WARNING]                                   ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:307:9: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]          "merge&spill: %"PRIu64" ms, uncompressed size: %"PRIu64", "
[WARNING]          ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:307:31: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]          "merge&spill: %"PRIu64" ms, uncompressed size: %"PRIu64", "
[WARNING]                                ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:308:9: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]          "real size: %"PRIu64" path: %s }",
[WARNING]          ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:373:7: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]    LOG("Final-merge-spill: { id: %d, in-memory sort: %"PRIu64" ms, "
[WARNING]        ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:374:7: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]        "in-memory records: %"PRIu64", merge&spill: %"PRIu64" ms, "
[WARNING]        ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:374:35: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]        "in-memory records: %"PRIu64", merge&spill: %"PRIu64" ms, "
[WARNING]                                    ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:375:7: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]        "records: %"PRIu64", uncompressed size: %"PRIu64", "
[WARNING]        ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:375:25: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]        "records: %"PRIu64", uncompressed size: %"PRIu64", "
[WARNING]                          ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:376:7: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]        "real size: %"PRIu64" path: %s }",
[WARNING]        ^
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:23:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:26:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:30:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.cc:26:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:127:36: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void spill(IFileWriter * writer) throw (IOException, UnsupportException);
[WARNING]                                     ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryBlock.cc:31:0:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:23:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/Merge.h:24,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/Merge.cc:22:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:30:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/Merge.h:24,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/Merge.cc:22:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:127:36: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void spill(IFileWriter * writer) throw (IOException, UnsupportException);
[WARNING]                                     ^~~~~
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/util/StringUtil.cc:39:21: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]    snprintf(tmp, 32, "%"PRId64, v);
[WARNING]                      ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/util/StringUtil.cc:45:21: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]    snprintf(tmp, 32, "%%%c%"PRId64""PRId64, pad, len);
[WARNING]                      ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/util/StringUtil.cc:45:34: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]    snprintf(tmp, 32, "%%%c%"PRId64""PRId64, pad, len);
[WARNING]                                   ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/util/StringUtil.cc:51:21: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]    snprintf(tmp, 32, "%"PRIu64, v);
[WARNING]                      ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/util/StringUtil.cc:39:21: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]    snprintf(tmp, 32, "%"PRId64, v);
[WARNING]                      ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/util/StringUtil.cc:45:21: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]    snprintf(tmp, 32, "%%%c%"PRId64""PRId64, pad, len);
[WARNING]                      ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/util/StringUtil.cc:45:34: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]    snprintf(tmp, 32, "%%%c%"PRId64""PRId64, pad, len);
[WARNING]                                   ^
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/util/StringUtil.cc:51:21: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]    snprintf(tmp, 32, "%"PRIu64, v);
[WARNING]                      ^
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:23:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/test/lib/TestMemoryPool.cc:21:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/test/lib/TestMemoryPool.cc:21:0:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:127:36: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void spill(IFileWriter * writer) throw (IOException, UnsupportException);
[WARNING]                                     ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:23:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/test/lib/TestPartitionBucket.cc:21:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MemoryPool.h:52:32: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void init(uint32_t capacity) throw (OutOfMemoryException) {
[WARNING]                                 ^~~~~
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/test/lib/TestPartitionBucket.cc:21:0:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:127:36: warning: dynamic exception specifications are deprecated in C++11 [-Wdeprecated]
[WARNING]    void spill(IFileWriter * writer) throw (IOException, UnsupportException);
[WARNING]                                     ^~~~~
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/test/TestCompressions.cc:272:10: warning: invalid suffix on literal; C++11 requires a space between literal and string macro [-Wliteral-suffix]
[WARNING]    printf("Block size: %"PRId64"K\n", blockSize / 1024);
[WARNING]           ^
[WARNING] In file included from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/test/test_commons.h:22:0,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/test/TestPrimitives.cc:19:
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/test/TestPrimitives.cc: In member function 'virtual void Primitives_fmemcmp_Test::TestBody()':
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/test/TestPrimitives.cc:21:6: warning: '__builtin___snprintf_chk' output truncated before the last format character [-Wformat-truncation=]
[WARNING]  TEST(Primitives, fmemcmp) {
[WARNING]       ^
[WARNING] In file included from /usr/include/stdio.h:862:0,
[WARNING]                  from /usr/include/c++/7/cstdio:42,
[WARNING]                  from /usr/include/c++/7/ext/string_conversions.h:43,
[WARNING]                  from /usr/include/c++/7/bits/basic_string.h:6361,
[WARNING]                  from /usr/include/c++/7/string:52,
[WARNING]                  from /usr/include/c++/7/bits/locale_classes.h:40,
[WARNING]                  from /usr/include/c++/7/bits/ios_base.h:41,
[WARNING]                  from /usr/include/c++/7/ios:42,
[WARNING]                  from /usr/include/c++/7/ostream:38,
[WARNING]                  from /tdp/hadoop/hadoop-common-project/hadoop-common/src/main/native/gtest/include/gtest/gtest.h:55,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/test/test_commons.h:22,
[WARNING]                  from /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/test/TestPrimitives.cc:19:
[WARNING] /usr/include/x86_64-linux-gnu/bits/stdio2.h:65:44: note: '__builtin___snprintf_chk' output 11 bytes into a destination of size 10
[WARNING]         __bos (__s), __fmt, __va_arg_pack ());
[WARNING]                                             ^
[INFO] cmake compilation finished successfully in 19868 millisecond(s).
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-mapreduce-client-nativetask ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 8 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-mapreduce-client-nativetask ---
[INFO] Compiling 33 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/test-classes
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/test/java/org/apache/hadoop/mapred/nativetask/testutil/BytesFactory.java:[34,27] [deprecation] UTF8 in org.apache.hadoop.io has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-mapreduce-client-nativetask ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.mapred.nativetask.kvtest.KVTest
[INFO] Tests run: 21, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 195.848 s - in org.apache.hadoop.mapred.nativetask.kvtest.KVTest
[INFO] Running org.apache.hadoop.mapred.nativetask.kvtest.LargeKVTest
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.556 s - in org.apache.hadoop.mapred.nativetask.kvtest.LargeKVTest
[INFO] Running org.apache.hadoop.mapred.nativetask.combinertest.CombinerTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.955 s - in org.apache.hadoop.mapred.nativetask.combinertest.CombinerTest
[INFO] Running org.apache.hadoop.mapred.nativetask.combinertest.OldAPICombinerTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.892 s - in org.apache.hadoop.mapred.nativetask.combinertest.OldAPICombinerTest
[INFO] Running org.apache.hadoop.mapred.nativetask.combinertest.LargeKVCombinerTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.142 s - in org.apache.hadoop.mapred.nativetask.combinertest.LargeKVCombinerTest
[INFO] Running org.apache.hadoop.mapred.nativetask.serde.TestNativeSerialization
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.048 s - in org.apache.hadoop.mapred.nativetask.serde.TestNativeSerialization
[INFO] Running org.apache.hadoop.mapred.nativetask.serde.TestKVSerializer
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.247 s - in org.apache.hadoop.mapred.nativetask.serde.TestKVSerializer
[INFO] Running org.apache.hadoop.mapred.nativetask.buffer.TestByteBufferReadWrite
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.164 s - in org.apache.hadoop.mapred.nativetask.buffer.TestByteBufferReadWrite
[INFO] Running org.apache.hadoop.mapred.nativetask.buffer.TestInputBuffer
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.041 s - in org.apache.hadoop.mapred.nativetask.buffer.TestInputBuffer
[INFO] Running org.apache.hadoop.mapred.nativetask.buffer.TestBufferPushPull
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.374 s - in org.apache.hadoop.mapred.nativetask.buffer.TestBufferPushPull
[INFO] Running org.apache.hadoop.mapred.nativetask.buffer.TestOutputBuffer
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.048 s - in org.apache.hadoop.mapred.nativetask.buffer.TestOutputBuffer
[INFO] Running org.apache.hadoop.mapred.nativetask.nonsorttest.NonSortTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.2 s - in org.apache.hadoop.mapred.nativetask.nonsorttest.NonSortTest
[INFO] Running org.apache.hadoop.mapred.nativetask.TestTaskContext
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.048 s - in org.apache.hadoop.mapred.nativetask.TestTaskContext
[INFO] Running org.apache.hadoop.mapred.nativetask.utils.TestReadWriteBuffer
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.05 s - in org.apache.hadoop.mapred.nativetask.utils.TestReadWriteBuffer
[INFO] Running org.apache.hadoop.mapred.nativetask.utils.TestSizedWritable
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.112 s - in org.apache.hadoop.mapred.nativetask.utils.TestSizedWritable
[INFO] Running org.apache.hadoop.mapred.nativetask.utils.TestBytesUtil
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.052 s - in org.apache.hadoop.mapred.nativetask.utils.TestBytesUtil
[INFO] Running org.apache.hadoop.mapred.nativetask.compresstest.CompressTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.745 s - in org.apache.hadoop.mapred.nativetask.compresstest.CompressTest
[INFO] Running org.apache.hadoop.mapred.nativetask.handlers.TestCombineHandler
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.233 s - in org.apache.hadoop.mapred.nativetask.handlers.TestCombineHandler
[INFO] Running org.apache.hadoop.mapred.nativetask.handlers.TestNativeCollectorOnlyHandler
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.696 s - in org.apache.hadoop.mapred.nativetask.handlers.TestNativeCollectorOnlyHandler
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 59, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:cmake-test (nttest) @ hadoop-mapreduce-client-nativetask ---
[INFO] -------------------------------------------------------
[INFO]  C M A K E B U I L D E R    T E S T
[INFO] -------------------------------------------------------
[INFO] nativetask-nttest: running /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/native/test/nttest --gtest_filter=-Perf. --gtest_output=xml:/tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/surefire-reports/TEST-nativetask-nttest.xml
[INFO] with extra environment variables {}
[INFO] STATUS: SUCCESS after 45772 millisecond(s).
[INFO] -------------------------------------------------------
[INFO] 
[INFO] ---------< org.apache.hadoop:hadoop-mapreduce-client-uploader >---------
[INFO] Building Apache Hadoop MapReduce Uploader 3.1.1-TDP-0.1.0-SNAPSHOT [63/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-mapreduce-client-uploader ---
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader/target
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-mapreduce-client-uploader ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-mapreduce-client-uploader ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-mapreduce-client-uploader ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-mapreduce-client-uploader ---
[INFO] Compiling 4 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-mapreduce-client-uploader ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-mapreduce-client-uploader ---
[INFO] Compiling 1 source file to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader/target/test-classes
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader/src/test/java/org/apache/hadoop/mapred/uploader/TestFrameworkUploader.java:[427,15] [deprecation] writeLines(Collection<?>,String,OutputStream) in IOUtils has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-mapreduce-client-uploader ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.mapred.uploader.TestFrameworkUploader
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.627 s - in org.apache.hadoop.mapred.uploader.TestFrameworkUploader
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ------------< org.apache.hadoop:hadoop-mapreduce-examples >-------------
[INFO] Building Apache Hadoop MapReduce Examples 3.1.1-TDP-0.1.0-SNAPSHOT [64/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-mapreduce-examples ---
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-examples/target
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-examples (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-mapreduce-examples ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-examples/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-mapreduce-examples ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-mapreduce-examples ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-mapreduce-examples ---
[INFO] Compiling 47 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-examples/target/classes
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/QuasiMonteCarlo.java:[236,47] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/QuasiMonteCarlo.java:[293,55] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/QuasiMonteCarlo.java:[319,35] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-mapreduce-examples ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-mapreduce-examples ---
[INFO] Compiling 7 source files to /tdp/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-examples/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-mapreduce-examples ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.examples.TestWordStats
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.351 s - in org.apache.hadoop.examples.TestWordStats
[INFO] Running org.apache.hadoop.examples.terasort.TestTeraSort
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.371 s - in org.apache.hadoop.examples.terasort.TestTeraSort
[INFO] Running org.apache.hadoop.examples.TestBaileyBorweinPlouffe
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.287 s - in org.apache.hadoop.examples.TestBaileyBorweinPlouffe
[INFO] Running org.apache.hadoop.examples.pi.math.TestModular
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.123 s - in org.apache.hadoop.examples.pi.math.TestModular
[INFO] Running org.apache.hadoop.examples.pi.math.TestSummation
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.07 s - in org.apache.hadoop.examples.pi.math.TestSummation
[INFO] Running org.apache.hadoop.examples.pi.math.TestLongLong
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.102 s - in org.apache.hadoop.examples.pi.math.TestLongLong
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -----------------< org.apache.hadoop:hadoop-mapreduce >-----------------
[INFO] Building Apache Hadoop MapReduce 3.1.1-TDP-0.1.0-SNAPSHOT        [65/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-mapreduce ---
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project/target
[INFO] Deleting /tdp/hadoop/hadoop-mapreduce-project (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-mapreduce ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-mapreduce-project/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-mapreduce ---
[INFO] 
[INFO] -----------------< org.apache.hadoop:hadoop-streaming >-----------------
[INFO] Building Apache Hadoop MapReduce Streaming 3.1.1-TDP-0.1.0-SNAPSHOT [66/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-streaming ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-streaming/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-streaming (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-streaming ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-streaming/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-streaming ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-streaming ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-streaming ---
[INFO] Compiling 50 source files to /tdp/hadoop/hadoop-tools/hadoop-streaming/target/classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesOutput.java:[30,31] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesInput.java:[29,31] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[45,44] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesWritableOutput.java:[44,31] [deprecation] Record in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordInput.java:[24,31] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordInput.java:[25,31] [deprecation] Index in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordInput.java:[26,31] [deprecation] RecordInput in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordOutput.java:[26,31] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordOutput.java:[27,31] [deprecation] Record in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordOutput.java:[28,31] [deprecation] RecordOutput in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/PipeMapRed.java:[137,21] [unchecked] unchecked call to add(E) as a member of the raw type ArrayList
[WARNING]   where E is a type-variable:
    E extends Object declared in class ArrayList
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/PipeMapRed.java:[143,37] [unchecked] unchecked call to <T>toArray(T[]) as a member of the raw type ArrayList
[WARNING] 
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/PipeMapRed.java:[384,30] [unchecked] unchecked call to collect(K,V) as a member of the raw type OutputCollector
[WARNING]   where K,V are type-variables:
    K extends Object declared in interface OutputCollector
    V extends Object declared in interface OutputCollector
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesOutput.java:[78,23] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesOutput.java:[79,18] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesOutput.java:[170,25] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesInput.java:[83,17] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesInput.java:[107,17] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesInput.java:[406,4] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesInput.java:[406,24] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesInput.java:[450,4] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesInput.java:[450,24] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesInput.java:[483,4] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesInput.java:[483,24] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[798,27] [unchecked] unchecked method invocation: method setInputFormat in class JobConf is applied to given types
[WARNING]   required: Class<? extends InputFormat>
  found: Class
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[798,28] [unchecked] unchecked conversion
[WARNING]   required: Class<? extends InputFormat>
  found:    Class
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[826,31] [unchecked] unchecked method invocation: method setMapperClass in class JobConf is applied to given types
[WARNING]   required: Class<? extends Mapper>
  found: Class
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[826,32] [unchecked] unchecked conversion
[WARNING]   required: Class<? extends Mapper>
  found:    Class
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[839,33] [unchecked] unchecked method invocation: method setCombinerClass in class JobConf is applied to given types
[WARNING]   required: Class<? extends Reducer>
  found: Class
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[839,34] [unchecked] unchecked conversion
[WARNING]   required: Class<? extends Reducer>
  found:    Class
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[865,36] [unchecked] unchecked method invocation: method setReducerClass in class JobConf is applied to given types
[WARNING]   required: Class<? extends Reducer>
  found: Class
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[865,37] [unchecked] unchecked conversion
[WARNING]   required: Class<? extends Reducer>
  found:    Class
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[935,43] [unchecked] unchecked method invocation: method setOutputFormatClass in class LazyOutputFormat is applied to given types
[WARNING]   required: JobConf,Class<? extends OutputFormat>
  found: JobConf,Class
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[935,54] [unchecked] unchecked conversion
[WARNING]   required: Class<? extends OutputFormat>
  found:    Class
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[937,30] [unchecked] unchecked method invocation: method setOutputFormat in class JobConf is applied to given types
[WARNING]   required: Class<? extends OutputFormat>
  found: Class
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[937,31] [unchecked] unchecked conversion
[WARNING]   required: Class<? extends OutputFormat>
  found:    Class
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[943,36] [unchecked] unchecked method invocation: method setPartitionerClass in class JobConf is applied to given types
[WARNING]   required: Class<? extends Partitioner>
  found: Class
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[943,37] [unchecked] unchecked conversion
[WARNING]   required: Class<? extends Partitioner>
  found:    Class
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[965,18] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[971,6] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[971,22] [deprecation] setCacheArchives(URI[],Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[973,6] [deprecation] DistributedCache in org.apache.hadoop.mapreduce.filecache has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java:[973,22] [deprecation] setCacheFiles(URI[],Configuration) in DistributedCache has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesWritableOutput.java:[135,28] [deprecation] Record in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesWritableOutput.java:[136,19] [deprecation] Record in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesWritableOutput.java:[211,26] [deprecation] Record in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/PipeReducer.java:[101,28] [unchecked] unchecked call to writeKey(K) as a member of the raw type InputWriter
[WARNING]   where K is a type-variable:
    K extends Object declared in class InputWriter
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/PipeReducer.java:[102,30] [unchecked] unchecked call to writeValue(V) as a member of the raw type InputWriter
[WARNING]   where V is a type-variable:
    V extends Object declared in class InputWriter
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/PipeReducer.java:[105,24] [unchecked] unchecked call to collect(K,V) as a member of the raw type OutputCollector
[WARNING]   where K,V are type-variables:
    K extends Object declared in interface OutputCollector
    V extends Object declared in interface OutputCollector
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordInput.java:[31,46] [deprecation] RecordInput in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordInput.java:[90,9] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordInput.java:[92,15] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordInput.java:[129,9] [deprecation] Index in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordInput.java:[134,9] [deprecation] Index in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordInput.java:[145,57] [deprecation] Index in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/JarBuilder.java:[190,19] [unchecked] unchecked call to add(E) as a member of the raw type List
[WARNING]   where E is a type-variable:
    E extends Object declared in interface List
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/JarBuilder.java:[192,19] [unchecked] unchecked call to add(E) as a member of the raw type List
[WARNING]   where E is a type-variable:
    E extends Object declared in interface List
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/PipeMapper.java:[104,28] [unchecked] unchecked call to writeKey(K) as a member of the raw type InputWriter
[WARNING]   where K is a type-variable:
    K extends Object declared in class InputWriter
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/PipeMapper.java:[106,28] [unchecked] unchecked call to writeValue(V) as a member of the raw type InputWriter
[WARNING]   where V is a type-variable:
    V extends Object declared in class InputWriter
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordOutput.java:[33,47] [deprecation] RecordOutput in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordOutput.java:[91,26] [deprecation] Buffer in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordOutput.java:[119,26] [deprecation] Record in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/typedbytes/TypedBytesRecordOutput.java:[131,24] [deprecation] Record in org.apache.hadoop.record has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/LoadTypedBytes.java:[72,45] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/mapreduce/StreamInputFormat.java:[76,39] [unchecked] unchecked call to getConstructor(Class<?>...) as a member of the raw type Class
[WARNING]   where T is a type-variable:
    T extends Object declared in class Class
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/mapreduce/StreamInputFormat.java:[85,58] [unchecked] unchecked cast
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:list (deplist) @ hadoop-streaming ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-streaming ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-log-dir) @ hadoop-streaming ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /tdp/hadoop/hadoop-tools/hadoop-streaming/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-streaming/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-streaming/target/log
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (copy-test-bin) @ hadoop-streaming ---
[INFO] Executing tasks

main:
     [copy] Copying 2 files to /tdp/hadoop/hadoop-tools/hadoop-streaming/target/bin
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-streaming ---
[INFO] Compiling 50 source files to /tdp/hadoop/hadoop-tools/hadoop-streaming/target/test-classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestSymLink.java:[37,31] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamingStatus.java:[35,31] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestMultipleCachefiles.java:[38,31] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestFileArgs.java:[30,31] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreaming.java:[192,10] [deprecation] StreamJob(String[],boolean) in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreaming.java:[193,14] [deprecation] go() in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamReduceNone.java:[92,12] [deprecation] StreamJob(String[],boolean) in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamReduceNone.java:[93,9] [deprecation] go() in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamingKeyValue.java:[103,12] [deprecation] StreamJob(String[],boolean) in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamingKeyValue.java:[104,9] [deprecation] go() in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestSymLink.java:[60,4] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestSymLink.java:[67,16] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestSymLink.java:[88,37] [deprecation] MAPRED_TASK_JAVA_OPTS in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestSymLink.java:[94,37] [deprecation] MAPRED_TASK_JAVA_OPTS in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestSymLink.java:[113,12] [deprecation] StreamJob(String[],boolean) in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestSymLink.java:[114,9] [deprecation] go() in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamDataProtocol.java:[97,12] [deprecation] StreamJob(String[],boolean) in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamDataProtocol.java:[98,9] [deprecation] go() in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamingSeparator.java:[103,12] [deprecation] StreamJob(String[],boolean) in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamingSeparator.java:[104,9] [deprecation] go() in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamingStatus.java:[93,2] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamingStatus.java:[108,13] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamingStatus.java:[254,20] [deprecation] StreamJob(String[],boolean) in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamingStatus.java:[256,25] [deprecation] go() in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestMultipleArchiveFiles.java:[58,10] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestMultipleArchiveFiles.java:[71,14] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamAggregate.java:[84,12] [deprecation] StreamJob(String[],boolean) in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamAggregate.java:[85,9] [deprecation] go() in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamingExitStatus.java:[79,20] [deprecation] StreamJob(String[],boolean) in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamingExitStatus.java:[80,22] [deprecation] go() in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/ValueCountReduce.java:[50,16] [unchecked] unchecked call to collect(K,V) as a member of the raw type OutputCollector
[WARNING]   where K,V are type-variables:
    K extends Object declared in interface OutputCollector
    V extends Object declared in interface OutputCollector
/tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamingBackground.java:[74,20] [deprecation] StreamJob(String[],boolean) in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamingBackground.java:[75,22] [deprecation] go() in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestLoadTypedBytes.java:[69,35] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestMultipleCachefiles.java:[68,4] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestMultipleCachefiles.java:[76,16] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestMultipleCachefiles.java:[95,37] [deprecation] MAPRED_TASK_JAVA_OPTS in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestMultipleCachefiles.java:[101,37] [deprecation] MAPRED_TASK_JAVA_OPTS in JobConf has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestMultipleCachefiles.java:[125,12] [deprecation] StreamJob(String[],boolean) in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestMultipleCachefiles.java:[126,9] [deprecation] go() in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamingStderr.java:[83,20] [deprecation] StreamJob(String[],boolean) in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamingStderr.java:[84,22] [deprecation] go() in StreamJob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestFileArgs.java:[42,10] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestFileArgs.java:[60,14] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-streaming ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.typedbytes.TestTypedBytesWritable
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.137 s - in org.apache.hadoop.typedbytes.TestTypedBytesWritable
[INFO] Running org.apache.hadoop.streaming.TestStreamingKeyValue
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.22 s - in org.apache.hadoop.streaming.TestStreamingKeyValue
[INFO] Running org.apache.hadoop.streaming.TestStreamXmlRecordReader
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.123 s - in org.apache.hadoop.streaming.TestStreamXmlRecordReader
[INFO] Running org.apache.hadoop.streaming.TestFileArgs
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.341 s - in org.apache.hadoop.streaming.TestFileArgs
[INFO] Running org.apache.hadoop.streaming.TestUnconsumedInput
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.155 s - in org.apache.hadoop.streaming.TestUnconsumedInput
[INFO] Running org.apache.hadoop.streaming.TestStreaming
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.2 s - in org.apache.hadoop.streaming.TestStreaming
[INFO] Running org.apache.hadoop.streaming.TestClassWithNoPackage
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.187 s - in org.apache.hadoop.streaming.TestClassWithNoPackage
[INFO] Running org.apache.hadoop.streaming.TestStreamingFailure
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.978 s - in org.apache.hadoop.streaming.TestStreamingFailure
[INFO] Running org.apache.hadoop.streaming.TestStreamAggregate
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.066 s - in org.apache.hadoop.streaming.TestStreamAggregate
[INFO] Running org.apache.hadoop.streaming.io.TestKeyOnlyTextOutputReader
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.188 s - in org.apache.hadoop.streaming.io.TestKeyOnlyTextOutputReader
[INFO] Running org.apache.hadoop.streaming.TestStreamingExitStatus
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.357 s - in org.apache.hadoop.streaming.TestStreamingExitStatus
[INFO] Running org.apache.hadoop.streaming.TestStreamDataProtocol
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.077 s - in org.apache.hadoop.streaming.TestStreamDataProtocol
[INFO] Running org.apache.hadoop.streaming.TestMultipleArchiveFiles
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.435 s - in org.apache.hadoop.streaming.TestMultipleArchiveFiles
[INFO] Running org.apache.hadoop.streaming.TestRawBytesStreaming
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.156 s - in org.apache.hadoop.streaming.TestRawBytesStreaming
[INFO] Running org.apache.hadoop.streaming.TestStreamingSeparator
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.089 s - in org.apache.hadoop.streaming.TestStreamingSeparator
[INFO] Running org.apache.hadoop.streaming.TestStreamingCombiner
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.241 s - in org.apache.hadoop.streaming.TestStreamingCombiner
[INFO] Running org.apache.hadoop.streaming.TestStreamJob
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.609 s - in org.apache.hadoop.streaming.TestStreamJob
[INFO] Running org.apache.hadoop.streaming.TestStreamingOutputKeyValueTypes
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.056 s - in org.apache.hadoop.streaming.TestStreamingOutputKeyValueTypes
[INFO] Running org.apache.hadoop.streaming.TestTypedBytesStreaming
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.124 s - in org.apache.hadoop.streaming.TestTypedBytesStreaming
[INFO] Running org.apache.hadoop.streaming.TestStreamXmlMultipleRecords
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.495 s - in org.apache.hadoop.streaming.TestStreamXmlMultipleRecords
[INFO] Running org.apache.hadoop.streaming.TestDumpTypedBytes
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.486 s - in org.apache.hadoop.streaming.TestDumpTypedBytes
[INFO] Running org.apache.hadoop.streaming.TestStreamingBadRecords
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.672 s - in org.apache.hadoop.streaming.TestStreamingBadRecords
[INFO] Running org.apache.hadoop.streaming.TestStreamReduceNone
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.159 s - in org.apache.hadoop.streaming.TestStreamReduceNone
[INFO] Running org.apache.hadoop.streaming.TestStreamingOutputOnlyKeys
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.236 s - in org.apache.hadoop.streaming.TestStreamingOutputOnlyKeys
[INFO] Running org.apache.hadoop.streaming.TestStreamingBackground
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.093 s - in org.apache.hadoop.streaming.TestStreamingBackground
[INFO] Running org.apache.hadoop.streaming.mapreduce.TestStreamXmlRecordReader
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.126 s - in org.apache.hadoop.streaming.mapreduce.TestStreamXmlRecordReader
[INFO] Running org.apache.hadoop.streaming.TestMRFramework
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.226 s - in org.apache.hadoop.streaming.TestMRFramework
[INFO] Running org.apache.hadoop.streaming.TestGzipInput
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.174 s - in org.apache.hadoop.streaming.TestGzipInput
[INFO] Running org.apache.hadoop.streaming.TestSymLink
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 41.554 s - in org.apache.hadoop.streaming.TestSymLink
[INFO] Running org.apache.hadoop.streaming.TestStreamingCounters
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.158 s - in org.apache.hadoop.streaming.TestStreamingCounters
[INFO] Running org.apache.hadoop.streaming.TestStreamingStderr
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.311 s - in org.apache.hadoop.streaming.TestStreamingStderr
[INFO] Running org.apache.hadoop.streaming.TestMultipleCachefiles
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 40.692 s - in org.apache.hadoop.streaming.TestMultipleCachefiles
[INFO] Running org.apache.hadoop.streaming.TestLoadTypedBytes
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.439 s - in org.apache.hadoop.streaming.TestLoadTypedBytes
[INFO] Running org.apache.hadoop.streaming.TestAutoInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.657 s - in org.apache.hadoop.streaming.TestAutoInputFormat
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 59, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ------------------< org.apache.hadoop:hadoop-distcp >-------------------
[INFO] Building Apache Hadoop Distributed Copy 3.1.1-TDP-0.1.0-SNAPSHOT [67/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-distcp ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-distcp/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-distcp (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-distcp ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-distcp/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-distcp ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-distcp ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-distcp ---
[INFO] Compiling 35 source files to /tdp/hadoop/hadoop-tools/hadoop-distcp/target/classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/lib/DynamicInputChunk.java:[60,25] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/lib/DynamicInputChunk.java:[81,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/CopyListingFileStatus.java:[220,26] [deprecation] getErasureCodedBit() in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/SimpleCopyListing.java:[152,19] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/SimpleCopyListing.java:[312,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/SimpleCopyListing.java:[405,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/SimpleCopyListing.java:[466,39] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java:[300,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/lib/DynamicRecordReader.java:[77,32] [unchecked] unchecked conversion
[WARNING]   required: DynamicInputChunk<K,V>
  found:    DynamicInputChunk
  where K,V are type-variables:
    K extends Object declared in class DynamicRecordReader
    V extends Object declared in class DynamicRecordReader
/tdp/hadoop/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/lib/DynamicRecordReader.java:[122,32] [unchecked] unchecked conversion
[WARNING]   required: DynamicInputChunk<K,V>
  found:    DynamicInputChunk
  where K,V are type-variables:
    K extends Object declared in class DynamicRecordReader
    V extends Object declared in class DynamicRecordReader
/tdp/hadoop/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/RegexCopyFilter.java:[80,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:list (deplist) @ hadoop-distcp ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-distcp ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-distcp ---
[INFO] Compiling 35 source files to /tdp/hadoop/hadoop-tools/hadoop-distcp/target/test-classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/mapred/lib/TestDynamicInputFormat.java:[103,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestGlobbedCopyListing.java:[75,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestGlobbedCopyListing.java:[88,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestGlobbedCopyListing.java:[123,33] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestDistCpSync.java:[79,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestDistCpWithAcls.java:[99,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/mapred/TestCopyMapper.java:[256,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/mapred/TestCopyMapper.java:[414,26] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/mapred/TestCopyMapper.java:[414,51] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/mapred/TestCopyMapper.java:[425,27] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/mapred/TestCopyMapper.java:[1152,12] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestDistCpSyncReverseBase.java:[156,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestDistCpWithXAttrs.java:[117,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestDistCpWithRawXAttrs.java:[72,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/mapred/TestUniformSizeInputFormat.java:[94,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-distcp ---
[WARNING] The parameter forkMode is deprecated since version 2.14. Use forkCount and reuseForks instead.
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.tools.util.TestThrottledInputStream
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 60.477 s - in org.apache.hadoop.tools.util.TestThrottledInputStream
[INFO] Running org.apache.hadoop.tools.util.TestDistCpUtils
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.064 s - in org.apache.hadoop.tools.util.TestDistCpUtils
[INFO] Running org.apache.hadoop.tools.util.TestProducerConsumer
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.191 s - in org.apache.hadoop.tools.util.TestProducerConsumer
[INFO] Running org.apache.hadoop.tools.util.TestRetriableCommand
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.591 s - in org.apache.hadoop.tools.util.TestRetriableCommand
[INFO] Running org.apache.hadoop.tools.TestDistCpSync
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.742 s - in org.apache.hadoop.tools.TestDistCpSync
[INFO] Running org.apache.hadoop.tools.TestTrueCopyFilter
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.051 s - in org.apache.hadoop.tools.TestTrueCopyFilter
[INFO] Running org.apache.hadoop.tools.TestDistCpWithRawXAttrs
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.25 s - in org.apache.hadoop.tools.TestDistCpWithRawXAttrs
[INFO] Running org.apache.hadoop.tools.TestDistCpOptions
[INFO] Tests run: 26, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.109 s - in org.apache.hadoop.tools.TestDistCpOptions
[INFO] Running org.apache.hadoop.tools.TestGlobbedCopyListing
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.037 s - in org.apache.hadoop.tools.TestGlobbedCopyListing
[INFO] Running org.apache.hadoop.tools.TestDistCpSyncReverseFromSource
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.65 s - in org.apache.hadoop.tools.TestDistCpSyncReverseFromSource
[INFO] Running org.apache.hadoop.tools.TestDistCpSystem
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.157 s - in org.apache.hadoop.tools.TestDistCpSystem
[INFO] Running org.apache.hadoop.tools.TestIntegration
[INFO] Tests run: 57, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 78.806 s - in org.apache.hadoop.tools.TestIntegration
[INFO] Running org.apache.hadoop.tools.mapred.TestCopyOutputFormat
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.559 s - in org.apache.hadoop.tools.mapred.TestCopyOutputFormat
[INFO] Running org.apache.hadoop.tools.mapred.TestRetriableFileCopyCommand
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.745 s - in org.apache.hadoop.tools.mapred.TestRetriableFileCopyCommand
[INFO] Running org.apache.hadoop.tools.mapred.TestCopyCommitter
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.633 s - in org.apache.hadoop.tools.mapred.TestCopyCommitter
[INFO] Running org.apache.hadoop.tools.mapred.TestCopyMapperCompositeCrc
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 36.761 s - in org.apache.hadoop.tools.mapred.TestCopyMapperCompositeCrc
[INFO] Running org.apache.hadoop.tools.mapred.lib.TestDynamicInputFormat
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.303 s - in org.apache.hadoop.tools.mapred.lib.TestDynamicInputFormat
[INFO] Running org.apache.hadoop.tools.mapred.TestUniformSizeInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.171 s - in org.apache.hadoop.tools.mapred.TestUniformSizeInputFormat
[INFO] Running org.apache.hadoop.tools.mapred.TestDeletedDirTracker
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.983 s - in org.apache.hadoop.tools.mapred.TestDeletedDirTracker
[INFO] Running org.apache.hadoop.tools.mapred.TestCopyMapper
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 50.447 s - in org.apache.hadoop.tools.mapred.TestCopyMapper
[INFO] Running org.apache.hadoop.tools.TestDistCpWithAcls
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.008 s - in org.apache.hadoop.tools.TestDistCpWithAcls
[INFO] Running org.apache.hadoop.tools.TestRegexCopyFilter
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.054 s - in org.apache.hadoop.tools.TestRegexCopyFilter
[INFO] Running org.apache.hadoop.tools.TestDistCpWithXAttrs
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.874 s - in org.apache.hadoop.tools.TestDistCpWithXAttrs
[INFO] Running org.apache.hadoop.tools.TestDistCpSyncReverseFromTarget
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.848 s - in org.apache.hadoop.tools.TestDistCpSyncReverseFromTarget
[INFO] Running org.apache.hadoop.tools.TestCopyListingFileStatus
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.119 s - in org.apache.hadoop.tools.TestCopyListingFileStatus
[INFO] Running org.apache.hadoop.tools.TestFileBasedCopyListing
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.833 s - in org.apache.hadoop.tools.TestFileBasedCopyListing
[INFO] Running org.apache.hadoop.tools.TestOptionsParser
[INFO] Tests run: 29, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.254 s - in org.apache.hadoop.tools.TestOptionsParser
[INFO] Running org.apache.hadoop.tools.TestCopyListing
[INFO] Tests run: 24, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.462 s - in org.apache.hadoop.tools.TestCopyListing
[INFO] Running org.apache.hadoop.tools.TestDistCpViewFs
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.92 s - in org.apache.hadoop.tools.TestDistCpViewFs
[INFO] Running org.apache.hadoop.tools.TestExternalCall
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.168 s - in org.apache.hadoop.tools.TestExternalCall
[INFO] Running org.apache.hadoop.tools.contract.TestLocalContractDistCp
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.13 s - in org.apache.hadoop.tools.contract.TestLocalContractDistCp
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 323, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -----------------< org.apache.hadoop:hadoop-archives >------------------
[INFO] Building Apache Hadoop Archives 3.1.1-TDP-0.1.0-SNAPSHOT         [68/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-archives ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-archives/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-archives (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-archives ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-archives/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-archives ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-archives ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-archives/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-archives ---
[INFO] Compiling 1 source file to /tdp/hadoop/hadoop-tools/hadoop-archives/target/classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-archives/src/main/java/org/apache/hadoop/tools/HadoopArchives.java:[260,40] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-archives/src/main/java/org/apache/hadoop/tools/HadoopArchives.java:[485,13] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-archives/src/main/java/org/apache/hadoop/tools/HadoopArchives.java:[508,48] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:list (deplist) @ hadoop-archives ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-archives ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-archives/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-log-dir) @ hadoop-archives ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /tdp/hadoop/hadoop-tools/hadoop-archives/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-archives/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-archives/target/log
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-archives ---
[INFO] Compiling 1 source file to /tdp/hadoop/hadoop-tools/hadoop-archives/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-archives ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.tools.TestHadoopArchives
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.433 s - in org.apache.hadoop.tools.TestHadoopArchives
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ---------------< org.apache.hadoop:hadoop-archive-logs >----------------
[INFO] Building Apache Hadoop Archive Logs 3.1.1-TDP-0.1.0-SNAPSHOT     [69/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-archive-logs ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-archive-logs/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-archive-logs (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-archive-logs ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-archive-logs/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-archive-logs ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-archive-logs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-archive-logs/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-archive-logs ---
[INFO] Compiling 2 source files to /tdp/hadoop/hadoop-tools/hadoop-archive-logs/target/classes
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:list (deplist) @ hadoop-archive-logs ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-archive-logs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-archive-logs/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-log-dir) @ hadoop-archive-logs ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /tdp/hadoop/hadoop-tools/hadoop-archive-logs/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-archive-logs/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-archive-logs/target/log
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-archive-logs ---
[INFO] Compiling 2 source files to /tdp/hadoop/hadoop-tools/hadoop-archive-logs/target/test-classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-archive-logs/src/test/java/org/apache/hadoop/tools/TestHadoopArchiveLogs.java:[281,27] [deprecation] toString(URI) in IOUtils has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-archive-logs ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.tools.TestHadoopArchiveLogsRunner
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.139 s - in org.apache.hadoop.tools.TestHadoopArchiveLogsRunner
[INFO] Running org.apache.hadoop.tools.TestHadoopArchiveLogs
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.219 s - in org.apache.hadoop.tools.TestHadoopArchiveLogs
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -------------------< org.apache.hadoop:hadoop-rumen >-------------------
[INFO] Building Apache Hadoop Rumen 3.1.1-TDP-0.1.0-SNAPSHOT            [70/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-rumen ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-rumen/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-rumen (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-rumen ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-rumen/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-rumen ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-rumen ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-rumen ---
[INFO] Compiling 95 source files to /tdp/hadoop/hadoop-tools/hadoop-rumen/target/classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/LoggedTask.java:[271,40] [deprecation] groups in JhCounters has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/LoggedTask.java:[272,36] [deprecation] counts in JhCounterGroup has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/LoggedTask.java:[274,51] [deprecation] name in JhCounter has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/LoggedTask.java:[275,27] [deprecation] value in JhCounter has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/LoggedTaskAttempt.java:[639,40] [deprecation] groups in JhCounters has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/LoggedTaskAttempt.java:[640,36] [deprecation] counts in JhCounterGroup has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/LoggedTaskAttempt.java:[642,51] [deprecation] name in JhCounter has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/LoggedTaskAttempt.java:[643,27] [deprecation] value in JhCounter has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/Folder.java:[473,13] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/JobBuilder.java:[463,62] [deprecation] counters in TaskFinished has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/JobBuilder.java:[475,28] [deprecation] error in TaskFailed has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/JobBuilder.java:[545,69] [deprecation] counters in TaskAttemptFinished has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/JobBuilder.java:[571,71] [deprecation] counters in ReduceAttemptFinished has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/JobBuilder.java:[599,66] [deprecation] counters in MapAttemptFinished has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/JobBuilder.java:[664,43] [deprecation] totalCounters in JobFinished has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/JobBuilder.java:[666,53] [deprecation] mapCounters in JobFinished has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/JobBuilder.java:[668,53] [deprecation] reduceCounters in JobFinished has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/JobHistoryUtils.java:[160,42] [deprecation] groups in JhCounters has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/JobHistoryUtils.java:[161,38] [deprecation] counts in JhCounterGroup has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/JobHistoryUtils.java:[162,33] [deprecation] name in JhCounter has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/JobHistoryUtils.java:[162,58] [deprecation] value in JhCounter has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/TraceBuilder.java:[313,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:list (deplist) @ hadoop-rumen ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-rumen ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-rumen/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-log-dir) @ hadoop-rumen ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /tdp/hadoop/hadoop-tools/hadoop-rumen/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-rumen/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-rumen/target/log
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-rumen ---
[INFO] Compiling 5 source files to /tdp/hadoop/hadoop-tools/hadoop-rumen/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-rumen ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.tools.rumen.TestPiecewiseLinearInterpolation
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.027 s - in org.apache.hadoop.tools.rumen.TestPiecewiseLinearInterpolation
[INFO] Running org.apache.hadoop.tools.rumen.TestHistograms
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.016 s - in org.apache.hadoop.tools.rumen.TestHistograms
[INFO] Running org.apache.hadoop.tools.rumen.TestRandomSeedGenerator
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.103 s - in org.apache.hadoop.tools.rumen.TestRandomSeedGenerator
[INFO] 
[INFO] Results:
[INFO] 
[WARNING] Tests run: 3, Failures: 0, Errors: 0, Skipped: 1
[INFO] 
[INFO] 
[INFO] ------------------< org.apache.hadoop:hadoop-gridmix >------------------
[INFO] Building Apache Hadoop Gridmix 3.1.1-TDP-0.1.0-SNAPSHOT          [71/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-gridmix ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-gridmix/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-gridmix (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-gridmix ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-gridmix/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-gridmix ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-gridmix ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-gridmix ---
[INFO] Compiling 44 source files to /tdp/hadoop/hadoop-tools/hadoop-gridmix/target/classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/GenerateData.java:[163,26] [deprecation] humanReadableInt(long) in StringUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/DistributedCacheEmulator.java:[417,19] [unchecked] unchecked call to ArrayList(Collection<? extends E>) as a member of the raw type ArrayList
[WARNING]   where E is a type-variable:
    E extends Object declared in class ArrayList
/tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/DistributedCacheEmulator.java:[421,22] [unchecked] unchecked call to compareTo(T) as a member of the raw type Comparable
[WARNING]   where T is a type-variable:
    T extends Object declared in interface Comparable
/tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/DistributedCacheEmulator.java:[418,20] [unchecked] unchecked method invocation: method sort in class Collections is applied to given types
[WARNING]   required: List<T>,Comparator<? super T>
  found: List,<anonymous Comparator>
  where T is a type-variable:
    T extends Object declared in method <T>sort(List<T>,Comparator<? super T>)
/tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/DistributedCacheEmulator.java:[418,21] [unchecked] unchecked conversion
[WARNING]   required: List<T>
  found:    List
  where T is a type-variable:
    T extends Object declared in method <T>sort(List<T>,Comparator<? super T>)
/tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/DistributedCacheEmulator.java:[418,30] [unchecked] unchecked conversion
[WARNING]   required: Comparator<? super T>
  found:    <anonymous Comparator>
  where T is a type-variable:
    T extends Object declared in method <T>sort(List<T>,Comparator<? super T>)
/tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/DistributedCacheEmulator.java:[430,49] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/Gridmix.java:[318,39] [unchecked] unchecked method invocation: method addJobStatsListeners in class Statistics is applied to given types
[WARNING]   required: StatListener<JobStats>
  found: JobFactory
/tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/Gridmix.java:[318,40] [unchecked] unchecked conversion
[WARNING]   required: StatListener<JobStats>
  found:    JobFactory
/tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/Gridmix.java:[320,43] [unchecked] unchecked method invocation: method addClusterStatsObservers in class Statistics is applied to given types
[WARNING]   required: StatListener<ClusterStats>
  found: JobFactory
/tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/Gridmix.java:[320,44] [unchecked] unchecked conversion
[WARNING]   required: StatListener<ClusterStats>
  found:    JobFactory
/tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/ExecutionSummarizer.java:[166,36] [deprecation] humanReadableInt(long) in StringUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/ExecutionSummarizer.java:[230,31] [deprecation] humanReadableInt(long) in StringUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/CompressionEmulationUtil.java:[342,26] [deprecation] humanReadableInt(long) in StringUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/SerialJobFactory.java:[146,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/GenerateDistCacheData.java:[227,17] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/ReplayJobFactory.java:[115,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/ReadRecordFactory.java:[82,11] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java:[250,15] [deprecation] cleanup(Log,Closeable...) in IOUtils has been deprecated
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:list (deplist) @ hadoop-gridmix ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-gridmix ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-log-dir) @ hadoop-gridmix ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /tdp/hadoop/hadoop-tools/hadoop-gridmix/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-gridmix/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-gridmix/target/log
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-gridmix ---
[INFO] Compiling 23 source files to /tdp/hadoop/hadoop-tools/hadoop-gridmix/target/test-classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-gridmix/src/test/java/org/apache/hadoop/mapred/gridmix/DebugJobProducer.java:[270,17] [deprecation] MapTaskAttemptInfo(State,TaskInfo,long) in MapTaskAttemptInfo has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-gridmix/src/test/java/org/apache/hadoop/mapred/gridmix/DebugJobProducer.java:[278,17] [deprecation] ReduceTaskAttemptInfo(State,TaskInfo,long,long,long) in ReduceTaskAttemptInfo has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-gridmix/src/test/java/org/apache/hadoop/mapred/gridmix/TestRandomTextDataGenerator.java:[77,25] [unchecked] unchecked call to HashSet(Collection<? extends E>) as a member of the raw type HashSet
[WARNING]   where E is a type-variable:
    E extends Object declared in class HashSet
/tdp/hadoop/hadoop-tools/hadoop-gridmix/src/test/java/org/apache/hadoop/mapred/gridmix/TestRandomTextDataGenerator.java:[77,25] [unchecked] unchecked conversion
[WARNING]   required: Set<String>
  found:    HashSet
/tdp/hadoop/hadoop-tools/hadoop-gridmix/src/test/java/org/apache/hadoop/mapred/gridmix/TestRandomTextDataGenerator.java:[80,25] [unchecked] unchecked call to HashSet(Collection<? extends E>) as a member of the raw type HashSet
[WARNING]   where E is a type-variable:
    E extends Object declared in class HashSet
/tdp/hadoop/hadoop-tools/hadoop-gridmix/src/test/java/org/apache/hadoop/mapred/gridmix/TestRandomTextDataGenerator.java:[80,25] [unchecked] unchecked conversion
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-gridmix ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.mapred.gridmix.TestUserResolve
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.573 s - in org.apache.hadoop.mapred.gridmix.TestUserResolve
[INFO] Running org.apache.hadoop.mapred.gridmix.TestGridmixRecord
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.225 s - in org.apache.hadoop.mapred.gridmix.TestGridmixRecord
[INFO] Running org.apache.hadoop.mapred.gridmix.TestPseudoLocalFs
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.546 s - in org.apache.hadoop.mapred.gridmix.TestPseudoLocalFs
[INFO] Running org.apache.hadoop.mapred.gridmix.TestGridmixSubmission
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 172.368 s - in org.apache.hadoop.mapred.gridmix.TestGridmixSubmission
[INFO] Running org.apache.hadoop.mapred.gridmix.TestFileQueue
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.717 s - in org.apache.hadoop.mapred.gridmix.TestFileQueue
[INFO] Running org.apache.hadoop.mapred.gridmix.TestFilePool
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.764 s - in org.apache.hadoop.mapred.gridmix.TestFilePool
[INFO] Running org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 52.455 s - in org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation
[INFO] Running org.apache.hadoop.mapred.gridmix.TestLoadJob
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 172.029 s - in org.apache.hadoop.mapred.gridmix.TestLoadJob
[INFO] Running org.apache.hadoop.mapred.gridmix.TestRandomAlgorithm
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.13 s - in org.apache.hadoop.mapred.gridmix.TestRandomAlgorithm
[INFO] Running org.apache.hadoop.mapred.gridmix.TestGridmixSummary
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.936 s - in org.apache.hadoop.mapred.gridmix.TestGridmixSummary
[INFO] Running org.apache.hadoop.mapred.gridmix.TestGridmixMemoryEmulation
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.741 s - in org.apache.hadoop.mapred.gridmix.TestGridmixMemoryEmulation
[INFO] Running org.apache.hadoop.mapred.gridmix.TestSleepJob
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 286.555 s - in org.apache.hadoop.mapred.gridmix.TestSleepJob
[INFO] Running org.apache.hadoop.mapred.gridmix.TestGridMixClasses
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.831 s - in org.apache.hadoop.mapred.gridmix.TestGridMixClasses
[INFO] Running org.apache.hadoop.mapred.gridmix.TestRecordFactory
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.321 s - in org.apache.hadoop.mapred.gridmix.TestRecordFactory
[INFO] Running org.apache.hadoop.mapred.gridmix.TestResourceUsageEmulators
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.081 s - in org.apache.hadoop.mapred.gridmix.TestResourceUsageEmulators
[INFO] Running org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.437 s - in org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils
[INFO] Running org.apache.hadoop.mapred.gridmix.TestRandomTextDataGenerator
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.106 s - in org.apache.hadoop.mapred.gridmix.TestRandomTextDataGenerator
[INFO] Running org.apache.hadoop.mapred.gridmix.TestHighRamJob
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.445 s - in org.apache.hadoop.mapred.gridmix.TestHighRamJob
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 72, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -----------------< org.apache.hadoop:hadoop-datajoin >------------------
[INFO] Building Apache Hadoop Data Join 3.1.1-TDP-0.1.0-SNAPSHOT        [72/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-datajoin ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-datajoin/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-datajoin (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-datajoin ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-datajoin/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-datajoin ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-datajoin ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-datajoin/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-datajoin ---
[INFO] Compiling 7 source files to /tdp/hadoop/hadoop-tools/hadoop-datajoin/target/classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-datajoin/src/main/java/org/apache/hadoop/contrib/utils/join/DataJoinReducerBase.java:[157,20] [unchecked] unchecked call to collect(K,V) as a member of the raw type OutputCollector
[WARNING]   where K,V are type-variables:
    K extends Object declared in interface OutputCollector
    V extends Object declared in interface OutputCollector
/tdp/hadoop/hadoop-tools/hadoop-datajoin/src/main/java/org/apache/hadoop/contrib/utils/join/DataJoinJob.java:[99,22] [unchecked] unchecked method invocation: method setInputFormat in class JobConf is applied to given types
[WARNING]   required: Class<? extends InputFormat>
  found: Class
/tdp/hadoop/hadoop-tools/hadoop-datajoin/src/main/java/org/apache/hadoop/contrib/utils/join/DataJoinJob.java:[99,23] [unchecked] unchecked conversion
[WARNING]   required: Class<? extends InputFormat>
  found:    Class
/tdp/hadoop/hadoop-tools/hadoop-datajoin/src/main/java/org/apache/hadoop/contrib/utils/join/DataJoinJob.java:[101,22] [unchecked] unchecked method invocation: method setMapperClass in class JobConf is applied to given types
[WARNING]   required: Class<? extends Mapper>
  found: Class
/tdp/hadoop/hadoop-tools/hadoop-datajoin/src/main/java/org/apache/hadoop/contrib/utils/join/DataJoinJob.java:[101,23] [unchecked] unchecked conversion
[WARNING]   required: Class<? extends Mapper>
  found:    Class
/tdp/hadoop/hadoop-tools/hadoop-datajoin/src/main/java/org/apache/hadoop/contrib/utils/join/DataJoinJob.java:[103,23] [unchecked] unchecked method invocation: method setOutputFormat in class JobConf is applied to given types
[WARNING]   required: Class<? extends OutputFormat>
  found: Class
/tdp/hadoop/hadoop-tools/hadoop-datajoin/src/main/java/org/apache/hadoop/contrib/utils/join/DataJoinJob.java:[103,24] [unchecked] unchecked conversion
[WARNING]   required: Class<? extends OutputFormat>
  found:    Class
/tdp/hadoop/hadoop-tools/hadoop-datajoin/src/main/java/org/apache/hadoop/contrib/utils/join/DataJoinJob.java:[110,23] [unchecked] unchecked method invocation: method setReducerClass in class JobConf is applied to given types
[WARNING]   required: Class<? extends Reducer>
  found: Class
/tdp/hadoop/hadoop-tools/hadoop-datajoin/src/main/java/org/apache/hadoop/contrib/utils/join/DataJoinJob.java:[110,24] [unchecked] unchecked conversion
[WARNING]   required: Class<? extends Reducer>
  found:    Class
/tdp/hadoop/hadoop-tools/hadoop-datajoin/src/main/java/org/apache/hadoop/contrib/utils/join/DataJoinMapperBase.java:[107,18] [unchecked] unchecked call to collect(K,V) as a member of the raw type OutputCollector
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:list (deplist) @ hadoop-datajoin ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-datajoin ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-datajoin/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-log-dir) @ hadoop-datajoin ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /tdp/hadoop/hadoop-tools/hadoop-datajoin/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-datajoin/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-datajoin/target/log
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-datajoin ---
[INFO] Compiling 4 source files to /tdp/hadoop/hadoop-tools/hadoop-datajoin/target/test-classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-datajoin/src/test/java/org/apache/hadoop/contrib/utils/join/TestDataJoin.java:[121,15] [deprecation] Writer(FileSystem,Configuration,Path,Class,Class) in Writer has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-datajoin ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.contrib.utils.join.TestDataJoin
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.65 s - in org.apache.hadoop.contrib.utils.join.TestDataJoin
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ------------------< org.apache.hadoop:hadoop-extras >-------------------
[INFO] Building Apache Hadoop Extras 3.1.1-TDP-0.1.0-SNAPSHOT           [73/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-extras ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-extras/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-extras (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-extras ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-extras/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-extras ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-extras ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-extras/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-extras ---
[INFO] Compiling 5 source files to /tdp/hadoop/hadoop-tools/hadoop-extras/target/classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-extras/src/main/java/org/apache/hadoop/tools/DistCh.java:[205,24] [deprecation] write(DataOutput) in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-extras/src/main/java/org/apache/hadoop/tools/DistCh.java:[243,36] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-extras/src/main/java/org/apache/hadoop/tools/DistCh.java:[448,52] [deprecation] createWriter(FileSystem,Configuration,Path,Class,Class,CompressionType) in SequenceFile has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-extras/src/main/java/org/apache/hadoop/tools/DistCh.java:[491,34] [deprecation] Reader(FileSystem,Path,Configuration) in Reader has been deprecated
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:list (deplist) @ hadoop-extras ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-extras ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-extras/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-log-dir) @ hadoop-extras ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /tdp/hadoop/hadoop-tools/hadoop-extras/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-extras/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-extras/target/log
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-extras ---
[INFO] Compiling 2 source files to /tdp/hadoop/hadoop-tools/hadoop-extras/target/test-classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-extras/src/test/java/org/apache/hadoop/mapred/tools/TestGetGroups.java:[23,31] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-extras/src/test/java/org/apache/hadoop/mapred/tools/TestGetGroups.java:[37,10] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-extras/src/test/java/org/apache/hadoop/mapred/tools/TestGetGroups.java:[41,18] [deprecation] MiniMRCluster in org.apache.hadoop.mapred has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-extras ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.mapred.tools.TestGetGroups
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.016 s - in org.apache.hadoop.mapred.tools.TestGetGroups
[INFO] Running org.apache.hadoop.tools.TestDistCh
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.835 s - in org.apache.hadoop.tools.TestDistCh
[INFO] 
[INFO] Results:
[INFO] 
[WARNING] Tests run: 2, Failures: 0, Errors: 0, Skipped: 1
[INFO] 
[INFO] 
[INFO] -------------------< org.apache.hadoop:hadoop-pipes >-------------------
[INFO] Building Apache Hadoop Pipes 3.1.1-TDP-0.1.0-SNAPSHOT            [74/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-pipes ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-pipes/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-pipes (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-pipes ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-pipes/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-pipes ---
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:cmake-compile (cmake-compile) @ hadoop-pipes ---
[INFO] mkdirs '/tdp/hadoop/hadoop-tools/hadoop-pipes/target/native'
[INFO] Running cmake /tdp/hadoop/hadoop-tools/hadoop-pipes/src -DJVM_ARCH_DATA_MODEL=64 -G Unix Makefiles
[INFO] with extra environment variables {}
[INFO] Running make -j 8 VERBOSE=1
[INFO] cmake compilation finished successfully in 4436 millisecond(s).
[INFO] 
[INFO] -----------------< org.apache.hadoop:hadoop-openstack >-----------------
[INFO] Building Apache Hadoop OpenStack support 3.1.1-TDP-0.1.0-SNAPSHOT [75/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-openstack ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-openstack/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-openstack (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-openstack ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-openstack/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-openstack ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-openstack ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-openstack/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-openstack ---
[INFO] Compiling 50 source files to /tdp/hadoop/hadoop-tools/hadoop-openstack/target/classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/snative/SwiftNativeFileSystem.java:[183,14] [deprecation] getDefaultBlockSize() in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/snative/SwiftNativeFileSystem.java:[199,14] [deprecation] getBlockSize(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/snative/SwiftNativeFileSystem.java:[631,17] [deprecation] delete(Path) in FileSystem has been deprecated
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:list (deplist) @ hadoop-openstack ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-openstack ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-openstack ---
[INFO] Not compiling test sources
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-openstack ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --------------------< org.apache.hadoop:hadoop-aws >--------------------
[INFO] Building Apache Hadoop Amazon Web Services support 3.1.1-TDP-0.1.0-SNAPSHOT [76/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-aws ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-aws/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-aws (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-aws ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-aws/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-aws ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-aws ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-aws ---
[INFO] Compiling 107 source files to /tdp/hadoop/hadoop-tools/hadoop-aws/target/classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java:[322,51] [deprecation] FAST_UPLOAD in Constants has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java:[373,16] [deprecation] doesBucketExist(String) in AmazonS3 has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java:[394,16] [deprecation] TransferManager(AmazonS3,ExecutorService) in TransferManager has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java:[395,13] [deprecation] setConfiguration(TransferManagerConfiguration) in TransferManager has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/DefaultS3ClientFactory.java:[80,11] [deprecation] AmazonS3Client(AWSCredentialsProvider,ClientConfiguration) in AmazonS3Client has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/auth/AssumedRoleCredentialProvider.java:[128,13] [deprecation] withServiceEndpoint(String) in Builder has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/auth/AssumedRoleCredentialProvider.java:[131,11] [deprecation] withLongLivedCredentialsProvider(AWSCredentialsProvider) in Builder has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/LocalMetadataStore.java:[359,53] [unchecked] unchecked cast
[WARNING]   required: T
  found:    PathMetadata
  where T is a type-variable:
    T extends Object declared in method <T>deleteHashByAncestor(Path,Map<Path,T>,boolean)
/tdp/hadoop/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/InconsistentAmazonS3Client.java:[119,4] [deprecation] AmazonS3Client(AWSCredentialsProvider,ClientConfiguration) in AmazonS3Client has been deprecated
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:list (deplist1) @ hadoop-aws ---
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:list (deplist2) @ hadoop-aws ---
[INFO] 
[INFO] --- hadoop-maven-plugins:3.1.1-TDP-0.1.0-SNAPSHOT:parallel-tests-createdir (parallel-tests-createdir) @ hadoop-aws ---
[INFO] Creating /tdp/hadoop/hadoop-tools/hadoop-aws/target/test-dir/1
[INFO] Creating /tdp/hadoop/hadoop-tools/hadoop-aws/target/test-dir/2
[INFO] Creating /tdp/hadoop/hadoop-tools/hadoop-aws/target/test-dir/3
[INFO] Creating /tdp/hadoop/hadoop-tools/hadoop-aws/target/test-dir/4
[INFO] Creating /tdp/hadoop/hadoop-tools/hadoop-aws/target/tmp/1
[INFO] Creating /tdp/hadoop/hadoop-tools/hadoop-aws/target/tmp/2
[INFO] Creating /tdp/hadoop/hadoop-tools/hadoop-aws/target/tmp/3
[INFO] Creating /tdp/hadoop/hadoop-tools/hadoop-aws/target/tmp/4
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-aws ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-aws ---
[INFO] Compiling 130 source files to /tdp/hadoop/hadoop-tools/hadoop-aws/target/test-classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/S3ATestUtils.java:[314,14] [unchecked] unchecked cast
[WARNING]   required: E
  found:    Exception
  where E is a type-variable:
    E extends Throwable declared in method <E>verifyExceptionClass(Class<E>,Exception)
/tdp/hadoop/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/s3guard/ITestS3GuardConcurrentOps.java:[117,36] [unchecked] unchecked conversion
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3ACopyFromLocalFile.java:[41,47] [deprecation] US_ASCII in Charsets has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestListing.java:[81,48] [unchecked] unchecked call to MockRemoteIterator(Collection<FileStatus>) as a member of the raw type MockRemoteIterator
[WARNING]   where FileStatus is a type-variable:
    FileStatus extends Object declared in class MockRemoteIterator
/tdp/hadoop/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestListing.java:[81,48] [unchecked] unchecked conversion
[WARNING]   required: RemoteIterator<FileStatus>
  found:    MockRemoteIterator
/tdp/hadoop/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3ATemporaryCredentials.java:[85,16] [deprecation] AWSSecurityTokenServiceClient(AWSCredentialsProvider) in AWSSecurityTokenServiceClient has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3ATemporaryCredentials.java:[88,15] [deprecation] setEndpoint(String) in AmazonWebServiceClient has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/MockS3ClientFactory.java:[40,11] [deprecation] doesBucketExist(String) in AmazonS3 has been deprecated
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:copy-dependencies (copy) @ hadoop-aws ---
[INFO] Copying libsqlite4java-linux-i386-1.0.392.so to /tdp/hadoop/hadoop-tools/hadoop-aws/target/native-libs/libsqlite4java-linux-i386-1.0.392.so
[INFO] Copying libsqlite4java-linux-amd64-1.0.392.so to /tdp/hadoop/hadoop-tools/hadoop-aws/target/native-libs/libsqlite4java-linux-amd64-1.0.392.so
[INFO] Copying sqlite4java-win32-x64-1.0.392.dll to /tdp/hadoop/hadoop-tools/hadoop-aws/target/native-libs/sqlite4java-win32-x64-1.0.392.dll
[INFO] Copying sqlite4java-win32-x86-1.0.392.dll to /tdp/hadoop/hadoop-tools/hadoop-aws/target/native-libs/sqlite4java-win32-x86-1.0.392.dll
[INFO] Copying libsqlite4java-osx-1.0.392.dylib to /tdp/hadoop/hadoop-tools/hadoop-aws/target/native-libs/libsqlite4java-osx-1.0.392.dylib
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-aws ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.fs.s3a.TestSSEConfiguration
[INFO] Running org.apache.hadoop.fs.s3a.TestS3AGetFileStatus
[INFO] Running org.apache.hadoop.fs.s3native.TestS3xLoginHelper
[INFO] Running org.apache.hadoop.fs.s3a.TestDataBlocks
[INFO] Tests run: 21, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.185 s - in org.apache.hadoop.fs.s3native.TestS3xLoginHelper
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.171 s - in org.apache.hadoop.fs.s3a.TestDataBlocks
[INFO] Running org.apache.hadoop.fs.s3a.TestInvoker
[INFO] Running org.apache.hadoop.fs.s3a.TestS3AInputPolicies
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.142 s - in org.apache.hadoop.fs.s3a.TestS3AInputPolicies
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.18 s - in org.apache.hadoop.fs.s3a.TestS3AGetFileStatus
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.867 s - in org.apache.hadoop.fs.s3a.TestInvoker
[INFO] Running org.apache.hadoop.fs.s3a.s3guard.TestS3Guard
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.105 s - in org.apache.hadoop.fs.s3a.s3guard.TestS3Guard
[INFO] Running org.apache.hadoop.fs.s3a.s3guard.TestDynamoDBMetadataStore
[INFO] Running org.apache.hadoop.fs.s3a.s3guard.TestNullMetadataStore
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.073 s - in org.apache.hadoop.fs.s3a.TestSSEConfiguration
[INFO] Running org.apache.hadoop.fs.s3a.s3guard.TestS3GuardCLI
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.218 s - in org.apache.hadoop.fs.s3a.s3guard.TestS3GuardCLI
[INFO] Running org.apache.hadoop.fs.s3a.s3guard.TestPathMetadataDynamoDBTranslation
[INFO] Running org.apache.hadoop.fs.s3a.s3guard.TestLocalMetadataStore
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.547 s - in org.apache.hadoop.fs.s3a.s3guard.TestPathMetadataDynamoDBTranslation
[INFO] Running org.apache.hadoop.fs.s3a.s3guard.TestDirListingMetadata
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.267 s - in org.apache.hadoop.fs.s3a.s3guard.TestDirListingMetadata
[INFO] Tests run: 24, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.308 s - in org.apache.hadoop.fs.s3a.s3guard.TestLocalMetadataStore
[INFO] Running org.apache.hadoop.fs.s3a.TestListing
[INFO] Running org.apache.hadoop.fs.s3a.commit.TestTasks
[INFO] Tests run: 23, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.554 s - in org.apache.hadoop.fs.s3a.s3guard.TestNullMetadataStore
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.322 s - in org.apache.hadoop.fs.s3a.TestListing
[INFO] Running org.apache.hadoop.fs.s3a.commit.TestMagicCommitPaths
[INFO] Tests run: 28, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.242 s - in org.apache.hadoop.fs.s3a.commit.TestMagicCommitPaths
[INFO] Tests run: 60, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.538 s - in org.apache.hadoop.fs.s3a.commit.TestTasks
[INFO] Running org.apache.hadoop.fs.s3a.commit.staging.TestStagingCommitter
[INFO] Running org.apache.hadoop.fs.s3a.commit.staging.TestStagingPartitionedFileListing
[INFO] Running org.apache.hadoop.fs.s3a.commit.staging.TestPaths
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.088 s - in org.apache.hadoop.fs.s3a.commit.staging.TestPaths
[INFO] Running org.apache.hadoop.fs.s3a.commit.staging.TestStagingDirectoryOutputCommitter
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.227 s - in org.apache.hadoop.fs.s3a.commit.staging.TestStagingPartitionedFileListing
[INFO] Running org.apache.hadoop.fs.s3a.commit.staging.TestStagingPartitionedJobCommit
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.178 s - in org.apache.hadoop.fs.s3a.commit.staging.TestStagingDirectoryOutputCommitter
[INFO] Running org.apache.hadoop.fs.s3a.commit.staging.TestStagingPartitionedTaskCommit
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.344 s - in org.apache.hadoop.fs.s3a.commit.staging.TestStagingPartitionedJobCommit
[INFO] Tests run: 36, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.2 s - in org.apache.hadoop.fs.s3a.s3guard.TestDynamoDBMetadataStore
[INFO] Running org.apache.hadoop.fs.s3a.TestS3AAWSCredentialsProvider
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.341 s - in org.apache.hadoop.fs.s3a.TestS3AAWSCredentialsProvider
[INFO] Running org.apache.hadoop.fs.s3a.TestS3AExceptionTranslation
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.119 s - in org.apache.hadoop.fs.s3a.TestS3AExceptionTranslation
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.656 s - in org.apache.hadoop.fs.s3a.commit.staging.TestStagingPartitionedTaskCommit
[INFO] Tests run: 48, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 232.177 s - in org.apache.hadoop.fs.s3a.commit.staging.TestStagingCommitter
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 391, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -------------------< org.apache.hadoop:hadoop-kafka >-------------------
[INFO] Building Apache Hadoop Kafka Library support 3.1.1-TDP-0.1.0-SNAPSHOT [77/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-kafka ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-kafka/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-kafka (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-kafka ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-kafka/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-kafka ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-kafka ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-kafka/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-kafka ---
[INFO] Compiling 1 source file to /tdp/hadoop/hadoop-tools/hadoop-kafka/target/classes
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:list (deplist) @ hadoop-kafka ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-kafka ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-kafka/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-kafka ---
[INFO] Compiling 1 source file to /tdp/hadoop/hadoop-tools/hadoop-kafka/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-kafka ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.metrics2.impl.TestKafkaMetrics
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.328 s - in org.apache.hadoop.metrics2.impl.TestKafkaMetrics
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] -------------------< org.apache.hadoop:hadoop-azure >-------------------
[INFO] Building Apache Hadoop Azure support 3.1.1-TDP-0.1.0-SNAPSHOT    [78/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-azure ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-azure/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-azure (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-azure ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-azure/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-azure ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-azure ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-azure ---
[INFO] Compiling 61 source files to /tdp/hadoop/hadoop-tools/hadoop-azure/target/classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/security/TokenUtils.java:[43,53] [unchecked] unchecked cast
[WARNING]   required: Token<DelegationTokenIdentifier>
  found:    Token<CAP#1>
  where CAP#1 is a fresh type-variable:
    CAP#1 extends TokenIdentifier from capture of ? extends TokenIdentifier
/tdp/hadoop/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/SecureStorageInterfaceImpl.java:[512,46] [deprecation] getQualifiedUri() in CloudBlob has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/StorageInterfaceImpl.java:[434,46] [deprecation] getQualifiedUri() in CloudBlob has been deprecated
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:list (deplist) @ hadoop-azure ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-azure ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-azure ---
[INFO] Compiling 72 source files to /tdp/hadoop/hadoop-tools/hadoop-azure/target/test-classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/NativeAzureFileSystemBaseTest.java:[369,44] [deprecation] getStatistics(String,Class<? extends FileSystem>) in FileSystem has been deprecated
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-parallel-tests-dirs) @ hadoop-azure ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-azure/target/test-dir/1
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-azure/target/test-dir/2
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-azure/target/test-dir/3
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-azure/target/test-dir/4
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-azure/target/test/1
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-azure/target/test/2
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-azure/target/test/3
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-azure/target/test/4
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-azure ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.fs.azure.TestNativeAzureFileSystemOperationsMocked
[INFO] Running org.apache.hadoop.fs.azure.TestNativeAzureFileSystemBlockCompaction
[INFO] Running org.apache.hadoop.fs.azure.TestNativeAzureFileSystemContractMocked
[INFO] Running org.apache.hadoop.fs.azure.TestShellDecryptionKeyProvider
[WARNING] Tests run: 2, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 0.188 s - in org.apache.hadoop.fs.azure.TestShellDecryptionKeyProvider
[WARNING] Tests run: 2, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 0.507 s - in org.apache.hadoop.fs.azure.TestNativeAzureFileSystemBlockCompaction
[INFO] Running org.apache.hadoop.fs.azure.TestNativeAzureFileSystemAuthorization
[INFO] Running org.apache.hadoop.fs.azure.TestBlobMetadata
[WARNING] Tests run: 59, Failures: 0, Errors: 0, Skipped: 59, Time elapsed: 1.431 s - in org.apache.hadoop.fs.azure.TestNativeAzureFileSystemAuthorization
[WARNING] Tests run: 43, Failures: 0, Errors: 0, Skipped: 5, Time elapsed: 2.473 s - in org.apache.hadoop.fs.azure.TestNativeAzureFileSystemContractMocked
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.353 s - in org.apache.hadoop.fs.azure.TestBlobMetadata
[INFO] Tests run: 50, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.625 s - in org.apache.hadoop.fs.azure.TestNativeAzureFileSystemOperationsMocked
[INFO] Running org.apache.hadoop.fs.azure.TestWasbFsck
[INFO] Running org.apache.hadoop.fs.azure.metrics.TestNativeAzureFileSystemMetricsSystem
[INFO] Running org.apache.hadoop.fs.azure.TestClientThrottlingAnalyzer
[INFO] Running org.apache.hadoop.fs.azure.metrics.TestBandwidthGaugeUpdater
[WARNING] Tests run: 2, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 1.01 s - in org.apache.hadoop.fs.azure.TestWasbFsck
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.602 s - in org.apache.hadoop.fs.azure.metrics.TestBandwidthGaugeUpdater
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.055 s - in org.apache.hadoop.fs.azure.metrics.TestNativeAzureFileSystemMetricsSystem
[INFO] Running org.apache.hadoop.fs.azure.TestOutOfBandAzureBlobOperations
[INFO] Running org.apache.hadoop.fs.azure.TestNativeAzureFileSystemUploadLogic
[WARNING] Tests run: 3, Failures: 0, Errors: 0, Skipped: 3, Time elapsed: 0.078 s - in org.apache.hadoop.fs.azure.TestNativeAzureFileSystemUploadLogic
[INFO] Running org.apache.hadoop.fs.azure.TestNativeAzureFileSystemMocked
[INFO] Running org.apache.hadoop.fs.azure.TestBlobOperationDescriptor
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.097 s - in org.apache.hadoop.fs.azure.TestOutOfBandAzureBlobOperations
[WARNING] Tests run: 4, Failures: 0, Errors: 0, Skipped: 4, Time elapsed: 0.472 s - in org.apache.hadoop.fs.azure.TestBlobOperationDescriptor
[INFO] Running org.apache.hadoop.fs.azure.TestNativeAzureFileSystemFileNameCheck
[INFO] Running org.apache.hadoop.fs.azure.TestNativeAzureFileSystemConcurrency
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.048 s - in org.apache.hadoop.fs.azure.TestNativeAzureFileSystemFileNameCheck
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.181 s - in org.apache.hadoop.fs.azure.TestNativeAzureFileSystemConcurrency
[INFO] Tests run: 46, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.431 s - in org.apache.hadoop.fs.azure.TestNativeAzureFileSystemMocked
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 35.847 s - in org.apache.hadoop.fs.azure.TestClientThrottlingAnalyzer
[INFO] 
[INFO] Results:
[INFO] 
[WARNING] Tests run: 241, Failures: 0, Errors: 0, Skipped: 76
[INFO] 
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (serialized-test) @ hadoop-azure ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.fs.azure.metrics.TestRollingWindowAverage
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.205 s - in org.apache.hadoop.fs.azure.metrics.TestRollingWindowAverage
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ------------------< org.apache.hadoop:hadoop-aliyun >-------------------
[INFO] Building Apache Hadoop Aliyun OSS support 3.1.1-TDP-0.1.0-SNAPSHOT [79/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-aliyun ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-aliyun/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-aliyun (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-aliyun ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-aliyun/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-aliyun ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-aliyun ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-aliyun/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-aliyun ---
[INFO] Compiling 13 source files to /tdp/hadoop/hadoop-tools/hadoop-aliyun/target/classes
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:list (deplist) @ hadoop-aliyun ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-aliyun ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-aliyun ---
[INFO] Not compiling test sources
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-aliyun ---
[INFO] Tests are skipped.
[INFO] 
[INFO] ------------------< org.apache.hadoop:hadoop-client >-------------------
[INFO] Building Apache Hadoop Client Aggregator 3.1.1-TDP-0.1.0-SNAPSHOT [80/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-client ---
[INFO] Deleting /tdp/hadoop/hadoop-client-modules/hadoop-client/target
[INFO] Deleting /tdp/hadoop/hadoop-client-modules/hadoop-client (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-client ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-client-modules/hadoop-client/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-client-modules/hadoop-client/target/test/data
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-client ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-client-modules/hadoop-client/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-client ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-client-modules/hadoop-client/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-client ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-client ---
[INFO] 
[INFO] --------------------< org.apache.hadoop:hadoop-sls >--------------------
[INFO] Building Apache Hadoop Scheduler Load Simulator 3.1.1-TDP-0.1.0-SNAPSHOT [81/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-sls ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-sls/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-sls (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-sls ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-sls/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-sls ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-sls ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 9 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-sls ---
[INFO] Compiling 29 source files to /tdp/hadoop/hadoop-tools/hadoop-sls/target/classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java:[751,65] [unchecked] unchecked method invocation: method newInstance in class ReflectionUtils is applied to given types
[WARNING]   required: Class<T>,Configuration
  found: Class,Configuration
  where T is a type-variable:
    T extends Object declared in method <T>newInstance(Class<T>,Configuration)
/tdp/hadoop/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java:[752,22] [unchecked] unchecked conversion
[WARNING]   required: Class<T>
  found:    Class
  where T is a type-variable:
    T extends Object declared in method <T>newInstance(Class<T>,Configuration)
/tdp/hadoop/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/scheduler/SchedulerMetrics.java:[131,20] [unchecked] unchecked method invocation: method newInstance in class ReflectionUtils is applied to given types
[WARNING]   required: Class<T>,Configuration
  found: Class,Configuration
  where T is a type-variable:
    T extends Object declared in method <T>newInstance(Class<T>,Configuration)
/tdp/hadoop/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/scheduler/SchedulerMetrics.java:[131,21] [unchecked] unchecked conversion
[WARNING]   required: Class<T>
  found:    Class
  where T is a type-variable:
    T extends Object declared in method <T>newInstance(Class<T>,Configuration)
/tdp/hadoop/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/web/SLSWebApp.java:[96,36] [deprecation] toString(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/web/SLSWebApp.java:[98,32] [deprecation] toString(InputStream) in IOUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/web/SLSWebApp.java:[100,29] [deprecation] toString(InputStream) in IOUtils has been deprecated
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-sls ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 15 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-sls ---
[INFO] Compiling 11 source files to /tdp/hadoop/hadoop-tools/hadoop-sls/target/test-classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-sls/src/test/java/org/apache/hadoop/yarn/sls/web/TestSLSWebApp.java:[36,43] [deprecation] readFileToString(File) in FileUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-sls/src/test/java/org/apache/hadoop/yarn/sls/web/TestSLSWebApp.java:[74,39] [deprecation] readFileToString(File) in FileUtils has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-sls/src/test/java/org/apache/hadoop/yarn/sls/web/TestSLSWebApp.java:[98,36] [deprecation] readFileToString(File) in FileUtils has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-sls ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.yarn.sls.nodemanager.TestNMSimulator
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.209 s - in org.apache.hadoop.yarn.sls.nodemanager.TestNMSimulator
[INFO] Running org.apache.hadoop.yarn.sls.TestSLSGenericSynth
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 67.018 s - in org.apache.hadoop.yarn.sls.TestSLSGenericSynth
[INFO] Running org.apache.hadoop.yarn.sls.web.TestSLSWebApp
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.047 s - in org.apache.hadoop.yarn.sls.web.TestSLSWebApp
[INFO] Running org.apache.hadoop.yarn.sls.TestSynthJobGeneration
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.903 s - in org.apache.hadoop.yarn.sls.TestSynthJobGeneration
[INFO] Running org.apache.hadoop.yarn.sls.TestSLSRunner
[ERROR] Tests run: 12, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 251.024 s <<< FAILURE! - in org.apache.hadoop.yarn.sls.TestSLSRunner
[ERROR] testSimulatorRunning[Testing with: SYNTH, org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler, (nodeFile null)](org.apache.hadoop.yarn.sls.TestSLSRunner)  Time elapsed: 12.486 s  <<< FAILURE!
java.lang.AssertionError: TestSLSRunner catched exception from child thread (TaskRunner.TaskDefinition): [java.lang.reflect.UndeclaredThrowableException]
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.yarn.sls.BaseSLSRunnerTest.runSLS(BaseSLSRunnerTest.java:127)
	at org.apache.hadoop.yarn.sls.TestSLSRunner.testSimulatorRunning(TestSLSRunner.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[INFO] Running org.apache.hadoop.yarn.sls.appmaster.TestAMSimulator
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.175 s - in org.apache.hadoop.yarn.sls.appmaster.TestAMSimulator
[INFO] Running org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.529 s - in org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner
[INFO] Running org.apache.hadoop.yarn.sls.utils.TestSLSUtils
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.039 s - in org.apache.hadoop.yarn.sls.utils.TestSLSUtils
[INFO] Running org.apache.hadoop.yarn.sls.TestSLSStreamAMSynth
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 67.119 s - in org.apache.hadoop.yarn.sls.TestSLSStreamAMSynth
[INFO] Running org.apache.hadoop.yarn.sls.TestReservationSystemInvariants
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 185.326 s - in org.apache.hadoop.yarn.sls.TestReservationSystemInvariants
[INFO] 
[INFO] Results:
[INFO] 
[WARNING] Flakes: 
[WARNING] org.apache.hadoop.yarn.sls.TestSLSRunner.testSimulatorRunning[Testing with: SYNTH, org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler, (nodeFile null)](org.apache.hadoop.yarn.sls.TestSLSRunner)
[ERROR]   Run 1: TestSLSRunner.testSimulatorRunning:86->BaseSLSRunnerTest.runSLS:127 TestSLSRunner catched exception from child thread (TaskRunner.TaskDefinition): [java.lang.reflect.UndeclaredThrowableException]
[INFO]   Run 2: PASS
[INFO] 
[INFO] 
[WARNING] Tests run: 38, Failures: 0, Errors: 0, Skipped: 0, Flakes: 1
[INFO] 
[INFO] 
[INFO] -------------< org.apache.hadoop:hadoop-resourceestimator >-------------
[INFO] Building Apache Hadoop Resource Estimator Service 3.1.1-TDP-0.1.0-SNAPSHOT [82/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-resourceestimator ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-resourceestimator/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-resourceestimator (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-resourceestimator ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-resourceestimator/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-resourceestimator ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-resourceestimator ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-resourceestimator ---
[INFO] Compiling 56 source files to /tdp/hadoop/hadoop-tools/hadoop-resourceestimator/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-resourceestimator ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 17 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-resourceestimator ---
[INFO] Compiling 14 source files to /tdp/hadoop/hadoop-tools/hadoop-resourceestimator/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-resourceestimator ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.resourceestimator.translator.api.TestJobMetaData
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.263 s - in org.apache.hadoop.resourceestimator.translator.api.TestJobMetaData
[INFO] Running org.apache.hadoop.resourceestimator.translator.impl.TestNativeParser
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.276 s - in org.apache.hadoop.resourceestimator.translator.impl.TestNativeParser
[INFO] Running org.apache.hadoop.resourceestimator.translator.impl.TestRmParser
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.406 s - in org.apache.hadoop.resourceestimator.translator.impl.TestRmParser
[INFO] Running org.apache.hadoop.resourceestimator.skylinestore.impl.TestInMemoryStore
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.261 s - in org.apache.hadoop.resourceestimator.skylinestore.impl.TestInMemoryStore
[INFO] Running org.apache.hadoop.resourceestimator.service.TestResourceEstimatorService
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.548 s - in org.apache.hadoop.resourceestimator.service.TestResourceEstimatorService
[INFO] Running org.apache.hadoop.resourceestimator.solver.impl.TestLpSolver
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.616 s - in org.apache.hadoop.resourceestimator.solver.impl.TestLpSolver
[INFO] Running org.apache.hadoop.resourceestimator.common.api.TestResourceSkyline
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.266 s - in org.apache.hadoop.resourceestimator.common.api.TestResourceSkyline
[INFO] Running org.apache.hadoop.resourceestimator.common.serialization.TestResourceSerDe
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.275 s - in org.apache.hadoop.resourceestimator.common.serialization.TestResourceSerDe
[INFO] Running org.apache.hadoop.resourceestimator.common.serialization.TestHistorySkylineSerDe
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.274 s - in org.apache.hadoop.resourceestimator.common.serialization.TestHistorySkylineSerDe
[INFO] Running org.apache.hadoop.resourceestimator.common.serialization.TestResourceSkylineSerDe
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.276 s - in org.apache.hadoop.resourceestimator.common.serialization.TestResourceSkylineSerDe
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 47, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] --------------< org.apache.hadoop:hadoop-azure-datalake >---------------
[INFO] Building Apache Hadoop Azure Data Lake support 3.1.1-TDP-0.1.0-SNAPSHOT [83/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-azure-datalake ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-azure-datalake/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-azure-datalake (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-azure-datalake ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-azure-datalake/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-azure-datalake ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-azure-datalake ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-azure-datalake/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-azure-datalake ---
[INFO] Compiling 12 source files to /tdp/hadoop/hadoop-tools/hadoop-azure-datalake/target/classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-azure-datalake/src/main/java/org/apache/hadoop/fs/adl/AdlPermission.java:[49,17] [deprecation] getAclBit() in FsPermission has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-azure-datalake/src/main/java/org/apache/hadoop/fs/adl/AdlFileSystem.java:[304,11] [deprecation] MsiTokenProvider(int) in MsiTokenProvider has been deprecated
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:list (deplist) @ hadoop-azure-datalake ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-azure-datalake ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-azure-datalake ---
[INFO] Compiling 27 source files to /tdp/hadoop/hadoop-tools/hadoop-azure-datalake/target/test-classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestMetadata.java:[75,30] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestMetadata.java:[94,30] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestMetadata.java:[107,24] [deprecation] isFile(Path) in FileSystem has been deprecated
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestMetadata.java:[125,24] [deprecation] isFile(Path) in FileSystem has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-azure-datalake ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.fs.adl.TestValidateConfiguration
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.29 s - in org.apache.hadoop.fs.adl.TestValidateConfiguration
[INFO] Running org.apache.hadoop.fs.adl.TestAzureADTokenProvider
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.549 s - in org.apache.hadoop.fs.adl.TestAzureADTokenProvider
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlInternalCreateNonRecursive
[WARNING] Tests run: 3, Failures: 0, Errors: 0, Skipped: 3, Time elapsed: 0.207 s - in org.apache.hadoop.fs.adl.live.TestAdlInternalCreateNonRecursive
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlContractConcatLive
[WARNING] Tests run: 4, Failures: 0, Errors: 0, Skipped: 4, Time elapsed: 0.173 s - in org.apache.hadoop.fs.adl.live.TestAdlContractConcatLive
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlContractGetFileStatusLive
[WARNING] Tests run: 18, Failures: 0, Errors: 0, Skipped: 18, Time elapsed: 0.221 s - in org.apache.hadoop.fs.adl.live.TestAdlContractGetFileStatusLive
[INFO] Running org.apache.hadoop.fs.adl.live.TestMetadata
[WARNING] Tests run: 4, Failures: 0, Errors: 0, Skipped: 4, Time elapsed: 0.184 s - in org.apache.hadoop.fs.adl.live.TestMetadata
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlContractCreateLive
[WARNING] Tests run: 11, Failures: 0, Errors: 0, Skipped: 11, Time elapsed: 0.22 s - in org.apache.hadoop.fs.adl.live.TestAdlContractCreateLive
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlFileSystemContractLive
[WARNING] Tests run: 43, Failures: 0, Errors: 0, Skipped: 43, Time elapsed: 0.215 s - in org.apache.hadoop.fs.adl.live.TestAdlFileSystemContractLive
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlFileContextCreateMkdirLive
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.193 s - in org.apache.hadoop.fs.adl.live.TestAdlFileContextCreateMkdirLive
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlPermissionLive
[WARNING] Tests run: 128, Failures: 0, Errors: 0, Skipped: 128, Time elapsed: 0.244 s - in org.apache.hadoop.fs.adl.live.TestAdlPermissionLive
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlDifferentSizeWritesLive
[WARNING] Tests run: 12, Failures: 0, Errors: 0, Skipped: 12, Time elapsed: 0.205 s - in org.apache.hadoop.fs.adl.live.TestAdlDifferentSizeWritesLive
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlContractAppendLive
[WARNING] Tests run: 7, Failures: 0, Errors: 0, Skipped: 7, Time elapsed: 0.189 s - in org.apache.hadoop.fs.adl.live.TestAdlContractAppendLive
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlSupportedCharsetInPath
[WARNING] Tests run: 470, Failures: 0, Errors: 0, Skipped: 470, Time elapsed: 0.292 s - in org.apache.hadoop.fs.adl.live.TestAdlSupportedCharsetInPath
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlContractRenameLive
[WARNING] Tests run: 8, Failures: 0, Errors: 0, Skipped: 8, Time elapsed: 0.2 s - in org.apache.hadoop.fs.adl.live.TestAdlContractRenameLive
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlContractMkdirLive
[WARNING] Tests run: 7, Failures: 0, Errors: 0, Skipped: 7, Time elapsed: 0.197 s - in org.apache.hadoop.fs.adl.live.TestAdlContractMkdirLive
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlContractSeekLive
[WARNING] Tests run: 18, Failures: 0, Errors: 0, Skipped: 18, Time elapsed: 0.273 s - in org.apache.hadoop.fs.adl.live.TestAdlContractSeekLive
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlContractDistCpLive
[WARNING] Tests run: 6, Failures: 0, Errors: 0, Skipped: 6, Time elapsed: 0.239 s - in org.apache.hadoop.fs.adl.live.TestAdlContractDistCpLive
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlContractRootDirLive
[WARNING] Tests run: 9, Failures: 0, Errors: 0, Skipped: 9, Time elapsed: 0.191 s - in org.apache.hadoop.fs.adl.live.TestAdlContractRootDirLive
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlContractOpenLive
[WARNING] Tests run: 6, Failures: 0, Errors: 0, Skipped: 6, Time elapsed: 0.224 s - in org.apache.hadoop.fs.adl.live.TestAdlContractOpenLive
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlContractDeleteLive
[WARNING] Tests run: 8, Failures: 0, Errors: 0, Skipped: 8, Time elapsed: 0.188 s - in org.apache.hadoop.fs.adl.live.TestAdlContractDeleteLive
[INFO] Running org.apache.hadoop.fs.adl.live.TestAdlFileContextMainOperationsLive
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.19 s - in org.apache.hadoop.fs.adl.live.TestAdlFileContextMainOperationsLive
[INFO] Running org.apache.hadoop.fs.adl.TestRelativePathFormation
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.331 s - in org.apache.hadoop.fs.adl.TestRelativePathFormation
[INFO] 
[INFO] Results:
[INFO] 
[WARNING] Tests run: 773, Failures: 0, Errors: 0, Skipped: 752
[INFO] 
[INFO] 
[INFO] ------------------< org.apache.hadoop:hadoop-fs2img >-------------------
[INFO] Building Apache Hadoop Image Generation Tool 3.1.1-TDP-0.1.0-SNAPSHOT [84/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-fs2img ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-fs2img/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-fs2img (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-fs2img ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-fs2img/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-fs2img ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-fs2img ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-fs2img/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-fs2img ---
[INFO] Compiling 13 source files to /tdp/hadoop/hadoop-tools/hadoop-fs2img/target/classes
[WARNING] /tdp/hadoop/hadoop-tools/hadoop-fs2img/src/main/java/org/apache/hadoop/hdfs/server/namenode/NullBlockAliasMap.java:[73,16] [unchecked] getWriter(Options,String) in NullBlockAliasMap overrides getWriter(Options,String) in BlockAliasMap
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-fs2img ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-fs2img ---
[INFO] Compiling 5 source files to /tdp/hadoop/hadoop-tools/hadoop-fs2img/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-fs2img ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestRandomTreeWalk
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.143 s - in org.apache.hadoop.hdfs.server.namenode.TestRandomTreeWalk
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestSingleUGIResolver
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.296 s - in org.apache.hadoop.hdfs.server.namenode.TestSingleUGIResolver
[INFO] Running org.apache.hadoop.hdfs.server.namenode.TestFixedBlockResolver
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.158 s - in org.apache.hadoop.hdfs.server.namenode.TestFixedBlockResolver
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-tools-dist >-----------------
[INFO] Building Apache Hadoop Tools Dist 3.1.1-TDP-0.1.0-SNAPSHOT       [85/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-tools-dist ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-tools-dist/target
[INFO] Deleting /tdp/hadoop/hadoop-tools/hadoop-tools-dist (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-tools-dist ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-tools-dist/target/test-dir
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/hadoop-tools-dist/target/test/data
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-tools-dist ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-tools-dist ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-tools-dist/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-tools-dist ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-tools-dist ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-tools/hadoop-tools-dist/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-tools-dist ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-tools-dist ---
[INFO] 
[INFO] -------------------< org.apache.hadoop:hadoop-tools >-------------------
[INFO] Building Apache Hadoop Tools 3.1.1-TDP-0.1.0-SNAPSHOT            [86/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-tools ---
[INFO] Deleting /tdp/hadoop/hadoop-tools/target
[INFO] Deleting /tdp/hadoop/hadoop-tools (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-tools ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-tools/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-tools ---
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-client-api >-----------------
[INFO] Building Apache Hadoop Client API 3.1.1-TDP-0.1.0-SNAPSHOT       [87/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-client-api ---
[INFO] Deleting /tdp/hadoop/hadoop-client-modules/hadoop-client-api/target
[INFO] Deleting /tdp/hadoop/hadoop-client-modules/hadoop-client-api (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-client-api ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-client-modules/hadoop-client-api/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-client-api ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-client-api ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-client-modules/hadoop-client-api/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-client-api ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-client-api ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-client-modules/hadoop-client-api/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-client-api ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-client-api ---
[INFO] 
[INFO] --------------< org.apache.hadoop:hadoop-client-runtime >---------------
[INFO] Building Apache Hadoop Client Runtime 3.1.1-TDP-0.1.0-SNAPSHOT   [88/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-client-runtime ---
[INFO] Deleting /tdp/hadoop/hadoop-client-modules/hadoop-client-runtime/target
[INFO] Deleting /tdp/hadoop/hadoop-client-modules/hadoop-client-runtime (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-client-runtime ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-client-modules/hadoop-client-runtime/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-client-runtime ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-client-runtime ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-client-modules/hadoop-client-runtime/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-client-runtime ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-client-runtime ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-client-modules/hadoop-client-runtime/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-client-runtime ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-client-runtime ---
[INFO] 
[INFO] ----------< org.apache.hadoop:hadoop-client-check-invariants >----------
[INFO] Building Apache Hadoop Client Packaging Invariants 3.1.1-TDP-0.1.0-SNAPSHOT [89/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-client-check-invariants ---
[INFO] Deleting /tdp/hadoop/hadoop-client-modules/hadoop-client-check-invariants/target
[INFO] Deleting /tdp/hadoop/hadoop-client-modules/hadoop-client-check-invariants (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-client-check-invariants ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-client-modules/hadoop-client-check-invariants/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-enforcer-plugin:3.0.0-M1:enforce (enforce-banned-dependencies) @ hadoop-client-check-invariants ---
[INFO] Adding ignorable dependency: org.apache.hadoop:hadoop-annotations:null
[INFO]   Adding ignore: *
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-client-check-invariants ---
[INFO] 
[INFO] ------------< org.apache.hadoop:hadoop-client-minicluster >-------------
[INFO] Building Apache Hadoop Client Test Minicluster 3.1.1-TDP-0.1.0-SNAPSHOT [90/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-client-minicluster ---
[INFO] Deleting /tdp/hadoop/hadoop-client-modules/hadoop-client-minicluster/target
[INFO] Deleting /tdp/hadoop/hadoop-client-modules/hadoop-client-minicluster (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-client-minicluster ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-client-modules/hadoop-client-minicluster/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-client-minicluster ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-client-minicluster ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-client-modules/hadoop-client-minicluster/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-client-minicluster ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-client-minicluster ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-client-modules/hadoop-client-minicluster/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-client-minicluster ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-client-minicluster ---
[INFO] 
[INFO] -------< org.apache.hadoop:hadoop-client-check-test-invariants >--------
[INFO] Building Apache Hadoop Client Packaging Invariants for Test 3.1.1-TDP-0.1.0-SNAPSHOT [91/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-client-check-test-invariants ---
[INFO] Deleting /tdp/hadoop/hadoop-client-modules/hadoop-client-check-test-invariants/target
[INFO] Deleting /tdp/hadoop/hadoop-client-modules/hadoop-client-check-test-invariants (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-client-check-test-invariants ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-client-modules/hadoop-client-check-test-invariants/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-enforcer-plugin:3.0.0-M1:enforce (enforce-banned-dependencies) @ hadoop-client-check-test-invariants ---
[INFO] Adding ignorable dependency: org.apache.hadoop:hadoop-annotations:null
[INFO]   Adding ignore: *
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-client-check-test-invariants ---
[INFO] 
[INFO] ---------< org.apache.hadoop:hadoop-client-integration-tests >----------
[INFO] Building Apache Hadoop Client Packaging Integration Tests 3.1.1-TDP-0.1.0-SNAPSHOT [92/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-client-integration-tests ---
[INFO] Deleting /tdp/hadoop/hadoop-client-modules/hadoop-client-integration-tests/target
[INFO] Deleting /tdp/hadoop/hadoop-client-modules/hadoop-client-integration-tests (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-client-integration-tests ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-client-modules/hadoop-client-integration-tests/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-client-integration-tests ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-client-integration-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-client-modules/hadoop-client-integration-tests/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-client-integration-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-client-integration-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-client-integration-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-client-integration-tests ---
[INFO] 
[INFO] -------------------< org.apache.hadoop:hadoop-dist >--------------------
[INFO] Building Apache Hadoop Distribution 3.1.1-TDP-0.1.0-SNAPSHOT     [93/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-dist ---
[INFO] Deleting /tdp/hadoop/hadoop-dist/target
[INFO] Deleting /tdp/hadoop/hadoop-dist (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-dist ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-dist/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-dist ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-dist ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-dist/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-dist ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-dist ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-dist/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-dist ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-dist ---
[INFO] 
[INFO] --------------< org.apache.hadoop:hadoop-client-modules >---------------
[INFO] Building Apache Hadoop Client Modules 3.1.1-TDP-0.1.0-SNAPSHOT   [94/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-client-modules ---
[INFO] Deleting /tdp/hadoop/hadoop-client-modules/target
[INFO] Deleting /tdp/hadoop/hadoop-client-modules (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-client-modules ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-client-modules/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-client-modules ---
[INFO] 
[INFO] ---------------< org.apache.hadoop:hadoop-cloud-storage >---------------
[INFO] Building Apache Hadoop Cloud Storage 3.1.1-TDP-0.1.0-SNAPSHOT    [95/96]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-cloud-storage ---
[INFO] Deleting /tdp/hadoop/hadoop-cloud-storage-project/hadoop-cloud-storage/target
[INFO] Deleting /tdp/hadoop/hadoop-cloud-storage-project/hadoop-cloud-storage (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-cloud-storage ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-cloud-storage-project/hadoop-cloud-storage/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-cloud-storage ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-cloud-storage ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-cloud-storage-project/hadoop-cloud-storage/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-cloud-storage ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-cloud-storage ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /tdp/hadoop/hadoop-cloud-storage-project/hadoop-cloud-storage/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-cloud-storage ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ hadoop-cloud-storage ---
[INFO] 
[INFO] -----------< org.apache.hadoop:hadoop-cloud-storage-project >-----------
[INFO] Building Apache Hadoop Cloud Storage Project 3.1.1-TDP-0.1.0-SNAPSHOT [96/96]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-cloud-storage-project ---
[INFO] Deleting /tdp/hadoop/hadoop-cloud-storage-project/target
[INFO] Deleting /tdp/hadoop/hadoop-cloud-storage-project (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-testdirs) @ hadoop-cloud-storage-project ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /tdp/hadoop/hadoop-cloud-storage-project/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-cloud-storage-project ---
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary for Apache Hadoop Main 3.1.1-TDP-0.1.0-SNAPSHOT:
[INFO] 
[INFO] Apache Hadoop Main ................................. SUCCESS [  0.315 s]
[INFO] Apache Hadoop Build Tools .......................... SUCCESS [  2.033 s]
[INFO] Apache Hadoop Project POM .......................... SUCCESS [  0.509 s]
[INFO] Apache Hadoop Annotations .......................... SUCCESS [  1.554 s]
[INFO] Apache Hadoop Project Dist POM ..................... SUCCESS [  0.093 s]
[INFO] Apache Hadoop Assemblies ........................... SUCCESS [  0.114 s]
[INFO] Apache Hadoop Maven Plugins ........................ SUCCESS [  2.853 s]
[INFO] Apache Hadoop MiniKDC .............................. SUCCESS [ 11.025 s]
[INFO] Apache Hadoop Auth ................................. SUCCESS [02:11 min]
[INFO] Apache Hadoop Auth Examples ........................ SUCCESS [  0.769 s]
[INFO] Apache Hadoop Common ............................... FAILURE [07:32 min]
[INFO] Apache Hadoop NFS .................................. SUCCESS [ 14.014 s]
[INFO] Apache Hadoop KMS .................................. SUCCESS [02:16 min]
[INFO] Apache Hadoop Common Project ....................... SUCCESS [  0.042 s]
[INFO] Apache Hadoop HDFS Client .......................... SUCCESS [01:00 min]
[INFO] Apache Hadoop HDFS ................................. FAILURE [  01:02 h]
[INFO] Apache Hadoop HDFS Native Client ................... SUCCESS [ 14.909 s]
[INFO] Apache Hadoop HttpFS ............................... SUCCESS [02:10 min]
[INFO] Apache Hadoop HDFS-NFS ............................. SUCCESS [01:24 min]
[INFO] Apache Hadoop HDFS-RBF ............................. SUCCESS [11:32 min]
[INFO] Apache Hadoop HDFS Project ......................... SUCCESS [  0.040 s]
[INFO] Apache Hadoop YARN ................................. SUCCESS [  0.036 s]
[INFO] Apache Hadoop YARN API ............................. SUCCESS [ 14.168 s]
[INFO] Apache Hadoop YARN Common .......................... SUCCESS [02:17 min]
[INFO] Apache Hadoop YARN Registry ........................ SUCCESS [ 24.335 s]
[INFO] Apache Hadoop YARN Server .......................... SUCCESS [  0.037 s]
[INFO] Apache Hadoop YARN Server Common ................... SUCCESS [01:23 min]
[INFO] Apache Hadoop YARN NodeManager ..................... SUCCESS [15:36 min]
[INFO] Apache Hadoop YARN Web Proxy ....................... SUCCESS [ 11.972 s]
[INFO] Apache Hadoop YARN ApplicationHistoryService ....... SUCCESS [02:19 min]
[INFO] Apache Hadoop YARN Timeline Service ................ SUCCESS [ 25.204 s]
[INFO] Apache Hadoop YARN ResourceManager ................. SUCCESS [56:52 min]
[INFO] Apache Hadoop YARN Server Tests .................... SUCCESS [02:13 min]
[INFO] Apache Hadoop YARN Client .......................... SUCCESS [21:14 min]
[INFO] Apache Hadoop YARN SharedCacheManager .............. SUCCESS [ 11.827 s]
[INFO] Apache Hadoop YARN Timeline Plugin Storage ......... SUCCESS [01:35 min]
[INFO] Apache Hadoop YARN TimelineService HBase Backend ... SUCCESS [  0.039 s]
[INFO] Apache Hadoop YARN TimelineService HBase Common .... SUCCESS [  6.552 s]
[INFO] Apache Hadoop YARN TimelineService HBase Client .... SUCCESS [  3.579 s]
[INFO] Apache Hadoop YARN TimelineService HBase Servers ... SUCCESS [  0.038 s]
[INFO] Apache Hadoop YARN TimelineService HBase Server 1.2  SUCCESS [  1.538 s]
[INFO] Apache Hadoop YARN TimelineService HBase tests ..... SUCCESS [07:57 min]
[INFO] Apache Hadoop YARN Router .......................... SUCCESS [ 44.212 s]
[INFO] Apache Hadoop YARN Applications .................... SUCCESS [  0.039 s]
[INFO] Apache Hadoop YARN DistributedShell ................ FAILURE [15:36 min]
[INFO] Apache Hadoop YARN Unmanaged Am Launcher ........... SUCCESS [ 24.350 s]
[INFO] Apache Hadoop MapReduce Client ..................... SUCCESS [  0.119 s]
[INFO] Apache Hadoop MapReduce Core ....................... SUCCESS [02:52 min]
[INFO] Apache Hadoop MapReduce Common ..................... SUCCESS [ 25.491 s]
[INFO] Apache Hadoop MapReduce Shuffle .................... SUCCESS [  6.251 s]
[INFO] Apache Hadoop MapReduce App ........................ SUCCESS [06:48 min]
[INFO] Apache Hadoop MapReduce HistoryServer .............. SUCCESS [01:59 min]
[INFO] Apache Hadoop MapReduce JobClient .................. FAILURE [  01:46 h]
[INFO] Apache Hadoop Mini-Cluster ......................... SUCCESS [  0.694 s]
[INFO] Apache Hadoop YARN Services ........................ SUCCESS [  0.029 s]
[INFO] Apache Hadoop YARN Services Core ................... SUCCESS [10:24 min]
[INFO] Apache Hadoop YARN Services API .................... SUCCESS [01:12 min]
[INFO] Apache Hadoop YARN Site ............................ SUCCESS [  0.032 s]
[INFO] Apache Hadoop YARN UI .............................. SUCCESS [  0.049 s]
[INFO] Apache Hadoop YARN Project ......................... SUCCESS [  0.514 s]
[INFO] Apache Hadoop MapReduce HistoryServer Plugins ...... SUCCESS [  2.448 s]
[INFO] Apache Hadoop MapReduce NativeTask ................. SUCCESS [05:42 min]
[INFO] Apache Hadoop MapReduce Uploader ................... SUCCESS [  3.122 s]
[INFO] Apache Hadoop MapReduce Examples ................... SUCCESS [ 15.987 s]
[INFO] Apache Hadoop MapReduce ............................ SUCCESS [  0.138 s]
[INFO] Apache Hadoop MapReduce Streaming .................. SUCCESS [04:17 min]
[INFO] Apache Hadoop Distributed Copy ..................... SUCCESS [09:06 min]
[INFO] Apache Hadoop Archives ............................. SUCCESS [ 23.246 s]
[INFO] Apache Hadoop Archive Logs ......................... SUCCESS [ 14.794 s]
[INFO] Apache Hadoop Rumen ................................ SUCCESS [  5.818 s]
[INFO] Apache Hadoop Gridmix .............................. SUCCESS [12:26 min]
[INFO] Apache Hadoop Data Join ............................ SUCCESS [  7.137 s]
[INFO] Apache Hadoop Extras ............................... SUCCESS [ 20.094 s]
[INFO] Apache Hadoop Pipes ................................ SUCCESS [  4.474 s]
[INFO] Apache Hadoop OpenStack support .................... SUCCESS [  1.559 s]
[INFO] Apache Hadoop Amazon Web Services support .......... SUCCESS [04:06 min]
[INFO] Apache Hadoop Kafka Library support ................ SUCCESS [  2.531 s]
[INFO] Apache Hadoop Azure support ........................ SUCCESS [ 44.768 s]
[INFO] Apache Hadoop Aliyun OSS support ................... SUCCESS [  1.335 s]
[INFO] Apache Hadoop Client Aggregator .................... SUCCESS [  0.824 s]
[INFO] Apache Hadoop Scheduler Load Simulator ............. SUCCESS [09:47 min]
[INFO] Apache Hadoop Resource Estimator Service ........... SUCCESS [ 13.411 s]
[INFO] Apache Hadoop Azure Data Lake support .............. SUCCESS [ 21.113 s]
[INFO] Apache Hadoop Image Generation Tool ................ SUCCESS [  5.092 s]
[INFO] Apache Hadoop Tools Dist ........................... SUCCESS [  0.743 s]
[INFO] Apache Hadoop Tools ................................ SUCCESS [  0.028 s]
[INFO] Apache Hadoop Client API ........................... SUCCESS [  1.096 s]
[INFO] Apache Hadoop Client Runtime ....................... SUCCESS [  0.358 s]
[INFO] Apache Hadoop Client Packaging Invariants .......... SUCCESS [  0.137 s]
[INFO] Apache Hadoop Client Test Minicluster .............. SUCCESS [  1.571 s]
[INFO] Apache Hadoop Client Packaging Invariants for Test . SUCCESS [  0.083 s]
[INFO] Apache Hadoop Client Packaging Integration Tests ... SUCCESS [  0.069 s]
[INFO] Apache Hadoop Distribution ......................... SUCCESS [  0.232 s]
[INFO] Apache Hadoop Client Modules ....................... SUCCESS [  0.028 s]
[INFO] Apache Hadoop Cloud Storage ........................ SUCCESS [  0.446 s]
[INFO] Apache Hadoop Cloud Storage Project ................ SUCCESS [  0.028 s]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  06:40 h
[INFO] Finished at: 2023-08-17T00:36:27Z
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.21.0:test (default-test) on project hadoop-common: There are test failures.
[ERROR] 
[ERROR] Please refer to /tdp/hadoop/hadoop-common-project/hadoop-common/target/surefire-reports for the individual test results.
[ERROR] Please refer to dump files (if any exist) [date]-jvmRun[N].dump, [date].dumpstream and [date]-jvmRun[N].dumpstream.
[ERROR] -> [Help 1]
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.21.0:test (default-test) on project hadoop-hdfs: There are test failures.
[ERROR] 
[ERROR] Please refer to /tdp/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/surefire-reports for the individual test results.
[ERROR] Please refer to dump files (if any exist) [date]-jvmRun[N].dump, [date].dumpstream and [date]-jvmRun[N].dumpstream.
[ERROR] -> [Help 1]
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.21.0:test (default-test) on project hadoop-yarn-applications-distributedshell: There was a timeout or other error in the fork -> [Help 1]
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.21.0:test (default-test) on project hadoop-mapreduce-client-jobclient: There was a timeout or other error in the fork -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hadoop-common
[INFO] Build failures were ignored.
